{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "from models import NeuralNetwork, TrainConfig, evaluate_nn_model, save_model, load_model, plot_results\n",
    "from utils import load_data, split_data, encode_data, mapping_dict\n",
    "from pathlib import Path\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"Device: cuda\")\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"Device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_balkan = [\n",
    "    'power-ua-train.tsv',\n",
    "    'power-fr-train.tsv',\n",
    "    'power-nl-train.tsv',\n",
    "]\n",
    "\n",
    "data_gb = load_data(folder_path=\"data/train/power/\", file_list=['power-gb-train.tsv'],text_head='text_en')\n",
    "data_hr = load_data(folder_path=\"data/train/power/\", file_list=['power-hr-train.tsv'],text_head='text_en')\n",
    "data_balkan = load_data(folder_path=\"data/train/power/\", file_list=file_list_balkan,text_head='text_en')\n",
    "\n",
    "train_raw_gb, test_raw_gb = split_data(data_gb, test_size=0.2, random_state=0)\n",
    "train_raw_hr, test_raw_hr = split_data(data_hr, test_size=0.2, random_state=0)\n",
    "train_raw_balkan, test_raw_balkan = split_data(data_gb, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data encoder...\n",
      "Prepare data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Prepare data encoder...\")\n",
    "encoder_gb = TfidfVectorizer(max_features=50000)\n",
    "encoder_gb.fit(train_raw_gb.texts)\n",
    "\n",
    "print(\"Prepare data...\")\n",
    "train_gb = encode_data(train_raw_gb, encoder_gb)\n",
    "test_gb = encode_data(test_raw_gb, encoder_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 209/209 [00:05<00:00, 40.45batch/s, batch_accuracy=0.571, loss=0.975]\n",
      "Epoch 2: 100%|██████████| 209/209 [00:05<00:00, 41.11batch/s, batch_accuracy=1, loss=0.19]     \n",
      "Epoch 3: 100%|██████████| 209/209 [00:04<00:00, 42.52batch/s, batch_accuracy=1, loss=0.11]     \n",
      "Epoch 4: 100%|██████████| 209/209 [00:05<00:00, 40.81batch/s, batch_accuracy=1, loss=0.286]     \n",
      "Epoch 5: 100%|██████████| 209/209 [00:04<00:00, 42.00batch/s, batch_accuracy=0.857, loss=0.382] \n",
      "Epoch 6: 100%|██████████| 209/209 [00:05<00:00, 41.29batch/s, batch_accuracy=1, loss=0.00481]   \n",
      "Epoch 7: 100%|██████████| 209/209 [00:04<00:00, 42.15batch/s, batch_accuracy=1, loss=0.000769]  \n",
      "Epoch 8: 100%|██████████| 209/209 [00:05<00:00, 39.19batch/s, batch_accuracy=1, loss=6.07e-5]   \n",
      "Epoch 9: 100%|██████████| 209/209 [00:05<00:00, 40.83batch/s, batch_accuracy=1, loss=4.64e-5]   \n",
      "Epoch 10: 100%|██████████| 209/209 [00:05<00:00, 41.55batch/s, batch_accuracy=1, loss=2.22e-5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7026863694190979, 0.7554714679718018, 0.7394869327545166, 0.3936262379399713)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-002dadeefb1c425b9011dba63cb7d915.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-002dadeefb1c425b9011dba63cb7d915.vega-embed details,\n",
       "  #altair-viz-002dadeefb1c425b9011dba63cb7d915.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-002dadeefb1c425b9011dba63cb7d915\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-002dadeefb1c425b9011dba63cb7d915\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-002dadeefb1c425b9011dba63cb7d915\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-9d00afdc9c364c21a2a4954dabf6435f\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-9d00afdc9c364c21a2a4954dabf6435f\": [{\"training_acc\": 0.4609375, \"training_loss\": 0.6952570676803589, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.4375, \"training_loss\": 0.6957840323448181, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.4375, \"training_loss\": 0.6949625611305237, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 0.6935111880302429, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6930131912231445, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6929378509521484, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6917495131492615, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6908690929412842, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6909223794937134, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6870890855789185, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6875806450843811, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6837908625602722, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6818035840988159, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6834230422973633, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 0.690009593963623, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6748374700546265, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6875813007354736, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.6850583553314209, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6691328287124634, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.670619010925293, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6681974530220032, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6491900682449341, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6440349817276001, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 0.6983859539031982, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6849972009658813, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6890549659729004, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6724615097045898, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6801369190216064, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6658581495285034, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6634533405303955, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.484375, \"training_loss\": 0.7086445093154907, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 0.6924660205841064, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6773827075958252, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6734998226165771, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 0.689145565032959, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6797688007354736, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.6727480888366699, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.6696538925170898, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.6773202419281006, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6710702776908875, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6612839698791504, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6672414541244507, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6584851741790771, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6670265793800354, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6597814559936523, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6460972428321838, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6403361558914185, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.630160927772522, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6638949513435364, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 0.6688329577445984, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6636745929718018, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6655810475349426, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6519639492034912, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6471908092498779, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6418505907058716, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.655012309551239, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6197077035903931, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6202872395515442, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6292989253997803, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6312123537063599, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6197268962860107, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6394076347351074, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6318857669830322, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.6200671792030334, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6295481324195862, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.6270701885223389, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5997698307037354, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6263314485549927, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.6042768359184265, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.6062360405921936, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5672833919525146, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5643633604049683, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5928640365600586, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5486671328544617, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5682111978530884, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.565029501914978, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5345391035079956, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5734220743179321, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5539730191230774, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5545706748962402, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5641390681266785, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5301087498664856, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5798245668411255, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5487012267112732, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5495666265487671, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5123957395553589, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5040391087532043, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5261863470077515, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.52933269739151, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5560470819473267, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5500004291534424, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5026661157608032, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.47479212284088135, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5192869305610657, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.481596976518631, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5172909498214722, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5776262283325195, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4646672010421753, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5324680209159851, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.530303418636322, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.512277364730835, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5268285274505615, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5709310173988342, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5227193236351013, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4857266843318939, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5084143877029419, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4801832139492035, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5259547829627991, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.47126951813697815, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.493303507566452, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6202418208122253, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5086123943328857, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4715617001056671, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4923169016838074, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4504263401031494, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5821924805641174, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4753156900405884, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.51841801404953, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4327179193496704, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4846997857093811, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5380096435546875, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.48472845554351807, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5643484592437744, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4952126741409302, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5615633726119995, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.49411699175834656, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4598506987094879, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4842074513435364, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5416123270988464, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5296200513839722, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.44038093090057373, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.56988924741745, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4581449627876282, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5002615451812744, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5423490405082703, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.43789634108543396, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.4910578429698944, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4193772077560425, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.47767743468284607, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5000940561294556, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5359200835227966, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.875, \"training_loss\": 0.40508538484573364, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4654175043106079, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5316213965415955, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.42071425914764404, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5445410013198853, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4620265066623688, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5050561428070068, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5053899884223938, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4836024343967438, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.442996621131897, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.48369184136390686, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4767343997955322, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.40398702025413513, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5310711860656738, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.45389869809150696, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4787881374359131, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.41375672817230225, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.46667277812957764, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.43909740447998047, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.49570417404174805, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4470682740211487, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5355145335197449, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4315321445465088, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5181023478507996, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4467703402042389, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5815442204475403, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4468575417995453, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5380421876907349, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.47667521238327026, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.507936954498291, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4291876554489136, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.45911353826522827, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5503122806549072, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.46033352613449097, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.570788562297821, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5040909647941589, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.46727150678634644, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4907892644405365, \"iteration\": 179, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.525361180305481, \"iteration\": 180, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.4705290198326111, \"iteration\": 181, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.40199917554855347, \"iteration\": 182, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.533289909362793, \"iteration\": 183, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.48311108350753784, \"iteration\": 184, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.45777633786201477, \"iteration\": 185, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.47946640849113464, \"iteration\": 186, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.48871511220932007, \"iteration\": 187, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5242174863815308, \"iteration\": 188, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5380371809005737, \"iteration\": 189, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.48452621698379517, \"iteration\": 190, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4802980124950409, \"iteration\": 191, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4240471124649048, \"iteration\": 192, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5013769268989563, \"iteration\": 193, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.44070565700531006, \"iteration\": 194, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.483029842376709, \"iteration\": 195, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.48442721366882324, \"iteration\": 196, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5377641916275024, \"iteration\": 197, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.43745672702789307, \"iteration\": 198, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4330335855484009, \"iteration\": 199, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4708155691623688, \"iteration\": 200, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5197638273239136, \"iteration\": 201, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5508021712303162, \"iteration\": 202, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5353764295578003, \"iteration\": 203, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.43040308356285095, \"iteration\": 204, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.42466601729393005, \"iteration\": 205, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4565691649913788, \"iteration\": 206, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.545199453830719, \"iteration\": 207, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4200587272644043, \"iteration\": 208, \"epoch\": 1}, {\"training_acc\": 0.5714285714285714, \"training_loss\": 0.9748865365982056, \"iteration\": 209, \"epoch\": 1}, {\"training_acc\": 0.9140625, \"training_loss\": 0.31933656334877014, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.25461921095848083, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.34216707944869995, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3798999786376953, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2825109362602234, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.36190366744995117, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3286885619163513, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.2809062600135803, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3595713675022125, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3084355294704437, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.31861209869384766, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3616086542606354, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.28062722086906433, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2934853136539459, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32482895255088806, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28500959277153015, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.326694518327713, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.35109633207321167, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3092106580734253, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33330070972442627, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3203306794166565, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3328046202659607, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2611278295516968, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30961278080940247, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.35596176981925964, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29595237970352173, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.318462997674942, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2923058867454529, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2541659474372864, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3016839027404785, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2899954319000244, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24962656199932098, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.29475080966949463, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24492160975933075, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20645269751548767, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.23535138368606567, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24309012293815613, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3025606870651245, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.40465158224105835, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.22776980698108673, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.4065015912055969, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30817216634750366, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.25743338465690613, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3213370144367218, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32653647661209106, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2570613622665405, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3385983407497406, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3271411061286926, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.2997385859489441, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.326072096824646, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3338850438594818, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31007641553878784, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2816033363342285, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2749648988246918, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.29700103402137756, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23729589581489563, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2913946509361267, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.28056180477142334, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2366330623626709, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.28419357538223267, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27172696590423584, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2698621153831482, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2689402103424072, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34031471610069275, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2875741720199585, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.30736395716667175, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.42373865842819214, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.26436135172843933, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.32748711109161377, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3044171929359436, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.30490928888320923, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3083116412162781, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.39856380224227905, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28179991245269775, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2585506737232208, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3416556417942047, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.31434401869773865, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.25482234358787537, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2581595182418823, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32757866382598877, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.27367445826530457, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.32938745617866516, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3638858199119568, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.30068761110305786, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2655283808708191, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2649999260902405, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.35231757164001465, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2903507947921753, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.384429007768631, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.28409749269485474, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.398589164018631, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.27842921018600464, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3499246835708618, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2813922166824341, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22962220013141632, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.284831166267395, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3130861520767212, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3001565635204315, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2926558256149292, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32925084233283997, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3610016703605652, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.28378960490226746, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3548288941383362, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2696216106414795, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2513240873813629, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3232981562614441, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.2963956296443939, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31914401054382324, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.26870667934417725, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.26204031705856323, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3627624213695526, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.2785111367702484, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.29453063011169434, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3721189498901367, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3165753185749054, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22249113023281097, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.22221273183822632, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23672881722450256, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3254616856575012, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.33868253231048584, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2222410887479782, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2694552540779114, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.23408108949661255, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3722882866859436, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2467794418334961, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.318110853433609, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28644484281539917, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.25260093808174133, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.25742924213409424, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3329337537288666, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3700464367866516, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3842869997024536, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3547614812850952, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3037770092487335, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.31525054574012756, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.29019033908843994, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.3186790347099304, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.33302342891693115, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2815449833869934, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.28975990414619446, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28710275888442993, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3934347927570343, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.20416203141212463, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.28379085659980774, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3459981381893158, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.37728452682495117, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.37416478991508484, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4261971116065979, \"iteration\": 357, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.2883351147174835, \"iteration\": 358, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.327311635017395, \"iteration\": 359, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.32847169041633606, \"iteration\": 360, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3025376796722412, \"iteration\": 361, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3869849443435669, \"iteration\": 362, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3038441836833954, \"iteration\": 363, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3448198437690735, \"iteration\": 364, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.26614412665367126, \"iteration\": 365, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.36227208375930786, \"iteration\": 366, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.39279231429100037, \"iteration\": 367, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32364049553871155, \"iteration\": 368, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.42164433002471924, \"iteration\": 369, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.33476147055625916, \"iteration\": 370, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.4014950692653656, \"iteration\": 371, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3036908209323883, \"iteration\": 372, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.49192631244659424, \"iteration\": 373, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.39507317543029785, \"iteration\": 374, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23365844786167145, \"iteration\": 375, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3269708752632141, \"iteration\": 376, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2730470299720764, \"iteration\": 377, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3312721848487854, \"iteration\": 378, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2606464922428131, \"iteration\": 379, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3314269185066223, \"iteration\": 380, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4484793245792389, \"iteration\": 381, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3333806097507477, \"iteration\": 382, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3381284177303314, \"iteration\": 383, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.33733776211738586, \"iteration\": 384, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5037148594856262, \"iteration\": 385, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3175533413887024, \"iteration\": 386, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3354625403881073, \"iteration\": 387, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.39965489506721497, \"iteration\": 388, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3704242706298828, \"iteration\": 389, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.25533556938171387, \"iteration\": 390, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34281498193740845, \"iteration\": 391, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.368880033493042, \"iteration\": 392, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.36803415417671204, \"iteration\": 393, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.305999755859375, \"iteration\": 394, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.39603176712989807, \"iteration\": 395, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2843518853187561, \"iteration\": 396, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.406598299741745, \"iteration\": 397, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3094397783279419, \"iteration\": 398, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3834252655506134, \"iteration\": 399, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32383763790130615, \"iteration\": 400, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.38793957233428955, \"iteration\": 401, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.35591402649879456, \"iteration\": 402, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2888385057449341, \"iteration\": 403, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3470528721809387, \"iteration\": 404, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30864107608795166, \"iteration\": 405, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24478654563426971, \"iteration\": 406, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3380739092826843, \"iteration\": 407, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34657949209213257, \"iteration\": 408, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.40905264019966125, \"iteration\": 409, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34606826305389404, \"iteration\": 410, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3381440043449402, \"iteration\": 411, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.293901264667511, \"iteration\": 412, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.31805139780044556, \"iteration\": 413, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3485049605369568, \"iteration\": 414, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.44202327728271484, \"iteration\": 415, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40159523487091064, \"iteration\": 416, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.38443851470947266, \"iteration\": 417, \"epoch\": 2}, {\"training_acc\": 1.0, \"training_loss\": 0.1901746690273285, \"iteration\": 418, \"epoch\": 2}, {\"training_acc\": 0.9765625, \"training_loss\": 0.20333537459373474, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.20883341133594513, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15640950202941895, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16127195954322815, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2023654282093048, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.19886170327663422, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.20074506103992462, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16313175857067108, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1938714236021042, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17381909489631653, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17902368307113647, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17864197492599487, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14204144477844238, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1860419362783432, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.15412509441375732, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18167945742607117, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.21049600839614868, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1935632824897766, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.23577335476875305, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1630326211452484, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13472720980644226, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22472228109836578, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16820691525936127, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1814197450876236, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.19499212503433228, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.14240236580371857, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19879212975502014, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20110425353050232, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14946120977401733, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10723921656608582, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.171970397233963, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.1094585433602333, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16280795633792877, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16476547718048096, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16823777556419373, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19397512078285217, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.15048304200172424, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14732611179351807, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21128642559051514, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1853015124797821, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1841767430305481, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2014891505241394, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17836274206638336, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14875991642475128, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.16486535966396332, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21639449894428253, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.14738252758979797, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18625974655151367, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11360935866832733, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16504570841789246, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15424957871437073, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12402364611625671, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.264201283454895, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2955739498138428, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14389881491661072, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1977185159921646, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.16835448145866394, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17769068479537964, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1581522673368454, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20761191844940186, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1756841093301773, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17378713190555573, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1453397274017334, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1641552448272705, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1414608508348465, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09595207124948502, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13525989651679993, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2081276774406433, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12686321139335632, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.16009698808193207, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10446978360414505, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15033645927906036, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2624686360359192, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.20801611244678497, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2386297732591629, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.1267721801996231, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12358091026544571, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16230933368206024, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.20313389599323273, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18744255602359772, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11848758161067963, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20972466468811035, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22062748670578003, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20076847076416016, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1755775660276413, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2041081339120865, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2323092669248581, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1894155591726303, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1984294354915619, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23763781785964966, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2835361659526825, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23518234491348267, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09413798153400421, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17428262531757355, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18726593255996704, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18632423877716064, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2252633422613144, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13636407256126404, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18225032091140747, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13770414888858795, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.15145257115364075, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.14908643066883087, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.2280021607875824, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18167568743228912, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2002842277288437, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.17796307802200317, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16050273180007935, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15818853676319122, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24118521809577942, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2800930142402649, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.25896477699279785, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18654772639274597, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1754051148891449, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16335830092430115, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10525970160961151, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24000681936740875, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19303150475025177, \"iteration\": 535, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14664092659950256, \"iteration\": 536, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1317833960056305, \"iteration\": 537, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.20447374880313873, \"iteration\": 538, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19657601416110992, \"iteration\": 539, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2054366171360016, \"iteration\": 540, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1986439824104309, \"iteration\": 541, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.16993503272533417, \"iteration\": 542, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13223271071910858, \"iteration\": 543, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.20888273417949677, \"iteration\": 544, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.26472437381744385, \"iteration\": 545, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2729393243789673, \"iteration\": 546, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.22769629955291748, \"iteration\": 547, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1761748343706131, \"iteration\": 548, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3039966821670532, \"iteration\": 549, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21668210625648499, \"iteration\": 550, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.25846391916275024, \"iteration\": 551, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20155063271522522, \"iteration\": 552, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18442073464393616, \"iteration\": 553, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1826845407485962, \"iteration\": 554, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2452509105205536, \"iteration\": 555, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13213703036308289, \"iteration\": 556, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2553558051586151, \"iteration\": 557, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18155616521835327, \"iteration\": 558, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.25754693150520325, \"iteration\": 559, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18908321857452393, \"iteration\": 560, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.21936771273612976, \"iteration\": 561, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23539038002490997, \"iteration\": 562, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.25757908821105957, \"iteration\": 563, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.145168274641037, \"iteration\": 564, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.175619438290596, \"iteration\": 565, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.23771226406097412, \"iteration\": 566, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19322612881660461, \"iteration\": 567, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2063196301460266, \"iteration\": 568, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2323249876499176, \"iteration\": 569, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2312890887260437, \"iteration\": 570, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2631109654903412, \"iteration\": 571, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1934465914964676, \"iteration\": 572, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18184152245521545, \"iteration\": 573, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2689937353134155, \"iteration\": 574, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.15264613926410675, \"iteration\": 575, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14998692274093628, \"iteration\": 576, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.2126992642879486, \"iteration\": 577, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18050099909305573, \"iteration\": 578, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.237630695104599, \"iteration\": 579, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18911252915859222, \"iteration\": 580, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28963398933410645, \"iteration\": 581, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3034929931163788, \"iteration\": 582, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.17773686349391937, \"iteration\": 583, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33636611700057983, \"iteration\": 584, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16784843802452087, \"iteration\": 585, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2465604543685913, \"iteration\": 586, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1921263188123703, \"iteration\": 587, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18429671227931976, \"iteration\": 588, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.15796822309494019, \"iteration\": 589, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.29569315910339355, \"iteration\": 590, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.24044527113437653, \"iteration\": 591, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21962645649909973, \"iteration\": 592, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14276593923568726, \"iteration\": 593, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2883281707763672, \"iteration\": 594, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.23915880918502808, \"iteration\": 595, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21499811112880707, \"iteration\": 596, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1676170825958252, \"iteration\": 597, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.23104393482208252, \"iteration\": 598, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1826428920030594, \"iteration\": 599, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2883273661136627, \"iteration\": 600, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.22235693037509918, \"iteration\": 601, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18138456344604492, \"iteration\": 602, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.19433274865150452, \"iteration\": 603, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2605191171169281, \"iteration\": 604, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1713677942752838, \"iteration\": 605, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.30827173590660095, \"iteration\": 606, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1811610460281372, \"iteration\": 607, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24522042274475098, \"iteration\": 608, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26313287019729614, \"iteration\": 609, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21257978677749634, \"iteration\": 610, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21628470718860626, \"iteration\": 611, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2740015387535095, \"iteration\": 612, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13499325513839722, \"iteration\": 613, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24705703556537628, \"iteration\": 614, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21057265996932983, \"iteration\": 615, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.217682883143425, \"iteration\": 616, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1606222242116928, \"iteration\": 617, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2711468040943146, \"iteration\": 618, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.16396090388298035, \"iteration\": 619, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2221909910440445, \"iteration\": 620, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17258764803409576, \"iteration\": 621, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.34643352031707764, \"iteration\": 622, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.23173564672470093, \"iteration\": 623, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2253081351518631, \"iteration\": 624, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.24698850512504578, \"iteration\": 625, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21049284934997559, \"iteration\": 626, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.1101188212633133, \"iteration\": 627, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.1099267452955246, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1611865758895874, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10794156044721603, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09311655163764954, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1298571527004242, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10641990602016449, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09789028763771057, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09276890009641647, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.05805639177560806, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10728619247674942, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07548514008522034, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0527239590883255, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07696336507797241, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08118373155593872, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06770290434360504, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12603075802326202, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08292738348245621, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20557621121406555, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10520802438259125, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11097697913646698, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.06378192454576492, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10869869589805603, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08025963604450226, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12311339378356934, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15290391445159912, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11609166860580444, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09757445752620697, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.056592732667922974, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04598882049322128, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06262235343456268, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12164968997240067, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.07541205734014511, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1403871774673462, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08276786655187607, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1259436011314392, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06096596270799637, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06445683538913727, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.06550612300634384, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06882622092962265, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07333684712648392, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.08859729021787643, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08759549260139465, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08818861842155457, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08307711780071259, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.05004087835550308, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.07497815787792206, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07109946757555008, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09259314835071564, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12122852355241776, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.13402310013771057, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14212802052497864, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07484032213687897, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11495984345674515, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1270471215248108, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.120864138007164, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07542677223682404, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07341374456882477, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07911437749862671, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06254617869853973, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11124949157238007, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06865977495908737, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04498507082462311, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08015873283147812, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09848551452159882, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05381503701210022, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.09417305886745453, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.051994770765304565, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10585471242666245, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08722912520170212, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13861414790153503, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09512101858854294, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0695992037653923, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1336136907339096, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08012253791093826, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10622130334377289, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13228747248649597, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08146816492080688, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06054287403821945, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1432865560054779, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10425923764705658, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09075616300106049, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06224701926112175, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0649641752243042, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14694640040397644, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1212485283613205, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07776867598295212, \"iteration\": 713, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11452438682317734, \"iteration\": 714, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10365290194749832, \"iteration\": 715, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08286560326814651, \"iteration\": 716, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09111561626195908, \"iteration\": 717, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06024011969566345, \"iteration\": 718, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11022373288869858, \"iteration\": 719, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07440110296010971, \"iteration\": 720, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10113945603370667, \"iteration\": 721, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08862094581127167, \"iteration\": 722, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.13632550835609436, \"iteration\": 723, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.04877771809697151, \"iteration\": 724, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.20206446945667267, \"iteration\": 725, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1267392486333847, \"iteration\": 726, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.2270178496837616, \"iteration\": 727, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.04121990501880646, \"iteration\": 728, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14787837862968445, \"iteration\": 729, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06357067823410034, \"iteration\": 730, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.0819377601146698, \"iteration\": 731, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09174904227256775, \"iteration\": 732, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13661476969718933, \"iteration\": 733, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06675510108470917, \"iteration\": 734, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20826053619384766, \"iteration\": 735, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08325478434562683, \"iteration\": 736, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1406484842300415, \"iteration\": 737, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07637380063533783, \"iteration\": 738, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.14535973966121674, \"iteration\": 739, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11971288174390793, \"iteration\": 740, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10319767892360687, \"iteration\": 741, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11190607398748398, \"iteration\": 742, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12417831271886826, \"iteration\": 743, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1440243422985077, \"iteration\": 744, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1352114975452423, \"iteration\": 745, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16001445055007935, \"iteration\": 746, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.060185566544532776, \"iteration\": 747, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1178552657365799, \"iteration\": 748, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08645352721214294, \"iteration\": 749, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11360356211662292, \"iteration\": 750, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14319467544555664, \"iteration\": 751, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.05645175650715828, \"iteration\": 752, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.108163982629776, \"iteration\": 753, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21073099970817566, \"iteration\": 754, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10506226867437363, \"iteration\": 755, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11087020486593246, \"iteration\": 756, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1361973136663437, \"iteration\": 757, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12369506806135178, \"iteration\": 758, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09956112504005432, \"iteration\": 759, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15083689987659454, \"iteration\": 760, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07223177701234818, \"iteration\": 761, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13849051296710968, \"iteration\": 762, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1255170702934265, \"iteration\": 763, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1062023937702179, \"iteration\": 764, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.052223965525627136, \"iteration\": 765, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14517000317573547, \"iteration\": 766, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0855051577091217, \"iteration\": 767, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15415775775909424, \"iteration\": 768, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08475210517644882, \"iteration\": 769, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07880973815917969, \"iteration\": 770, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.22351422905921936, \"iteration\": 771, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05811341851949692, \"iteration\": 772, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12806251645088196, \"iteration\": 773, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10615036636590958, \"iteration\": 774, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09653963148593903, \"iteration\": 775, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0742807388305664, \"iteration\": 776, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11413557827472687, \"iteration\": 777, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08481112122535706, \"iteration\": 778, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10823678970336914, \"iteration\": 779, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.13315583765506744, \"iteration\": 780, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08208933472633362, \"iteration\": 781, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12146293371915817, \"iteration\": 782, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.1023637056350708, \"iteration\": 783, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09219483286142349, \"iteration\": 784, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11270862072706223, \"iteration\": 785, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.13395029306411743, \"iteration\": 786, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15639850497245789, \"iteration\": 787, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13215959072113037, \"iteration\": 788, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09326446801424026, \"iteration\": 789, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12861338257789612, \"iteration\": 790, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09252484887838364, \"iteration\": 791, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.12222181260585785, \"iteration\": 792, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07580772787332535, \"iteration\": 793, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.23862186074256897, \"iteration\": 794, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.15976005792617798, \"iteration\": 795, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0649571567773819, \"iteration\": 796, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.10363316535949707, \"iteration\": 797, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10428517311811447, \"iteration\": 798, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.115364670753479, \"iteration\": 799, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11967789381742477, \"iteration\": 800, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12910550832748413, \"iteration\": 801, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07263660430908203, \"iteration\": 802, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11221655458211899, \"iteration\": 803, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08545733243227005, \"iteration\": 804, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18408924341201782, \"iteration\": 805, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09464072436094284, \"iteration\": 806, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08453186601400375, \"iteration\": 807, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.11924391984939575, \"iteration\": 808, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15877428650856018, \"iteration\": 809, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0775003731250763, \"iteration\": 810, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10984586924314499, \"iteration\": 811, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.1712198555469513, \"iteration\": 812, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10939129441976547, \"iteration\": 813, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1496843844652176, \"iteration\": 814, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13091766834259033, \"iteration\": 815, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1404772847890854, \"iteration\": 816, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1955217868089676, \"iteration\": 817, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18220293521881104, \"iteration\": 818, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.17027482390403748, \"iteration\": 819, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10879471153020859, \"iteration\": 820, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2726197838783264, \"iteration\": 821, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07176350057125092, \"iteration\": 822, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1195288598537445, \"iteration\": 823, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11722021549940109, \"iteration\": 824, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.23397213220596313, \"iteration\": 825, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08005861192941666, \"iteration\": 826, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1303454041481018, \"iteration\": 827, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10580547899007797, \"iteration\": 828, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17040029168128967, \"iteration\": 829, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05781169608235359, \"iteration\": 830, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1280161291360855, \"iteration\": 831, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.17804767191410065, \"iteration\": 832, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.16078895330429077, \"iteration\": 833, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2079320251941681, \"iteration\": 834, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15592257678508759, \"iteration\": 835, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.2856306731700897, \"iteration\": 836, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03495535999536514, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06788800656795502, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06908327341079712, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.0853634625673294, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07623891532421112, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03979792818427086, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08715417236089706, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.039469607174396515, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04888703674077988, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04424615204334259, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04397360607981682, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06754349917173386, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.057133257389068604, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.058186016976833344, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.042588651180267334, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0606616735458374, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07538621872663498, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06080649793148041, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.062307294458150864, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.09868253022432327, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05783264338970184, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04332003742456436, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10647175461053848, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02549465000629425, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.08062203228473663, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04917439818382263, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.036479879170656204, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03143934905529022, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030488863587379456, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03982846811413765, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.043031781911849976, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.053084466606378555, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.051930155605077744, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08613310754299164, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05418340861797333, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08294110745191574, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021834850311279297, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.034714650362730026, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02099902555346489, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.027179520577192307, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03615950793027878, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13374072313308716, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.016902750357985497, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03599899262189865, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.019240351393818855, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05567936599254608, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09093339741230011, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05828511714935303, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04852784797549248, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.050244443118572235, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.035482801496982574, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04172955080866814, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030783629044890404, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1174982488155365, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0913599506020546, \"iteration\": 891, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0539398156106472, \"iteration\": 892, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.039679668843746185, \"iteration\": 893, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07722926139831543, \"iteration\": 894, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03523508831858635, \"iteration\": 895, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.057961605489254, \"iteration\": 896, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11292155086994171, \"iteration\": 897, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03846808895468712, \"iteration\": 898, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05706802010536194, \"iteration\": 899, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08280649781227112, \"iteration\": 900, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.052576154470443726, \"iteration\": 901, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02901029959321022, \"iteration\": 902, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.052988842129707336, \"iteration\": 903, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021198391914367676, \"iteration\": 904, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.052167341113090515, \"iteration\": 905, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0768485739827156, \"iteration\": 906, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04409309849143028, \"iteration\": 907, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.105523981153965, \"iteration\": 908, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05736245959997177, \"iteration\": 909, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021345771849155426, \"iteration\": 910, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04369336739182472, \"iteration\": 911, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03708779066801071, \"iteration\": 912, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0440673790872097, \"iteration\": 913, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05033710598945618, \"iteration\": 914, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.033266134560108185, \"iteration\": 915, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030459832400083542, \"iteration\": 916, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05191785469651222, \"iteration\": 917, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.043884456157684326, \"iteration\": 918, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.027426008135080338, \"iteration\": 919, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08914761245250702, \"iteration\": 920, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04173562675714493, \"iteration\": 921, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0396246612071991, \"iteration\": 922, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.062337957322597504, \"iteration\": 923, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05844936892390251, \"iteration\": 924, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06170300394296646, \"iteration\": 925, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06322674453258514, \"iteration\": 926, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028600100427865982, \"iteration\": 927, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06661800295114517, \"iteration\": 928, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.049260593950748444, \"iteration\": 929, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04319104179739952, \"iteration\": 930, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04107264056801796, \"iteration\": 931, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11336081475019455, \"iteration\": 932, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03176761418581009, \"iteration\": 933, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03978988528251648, \"iteration\": 934, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07101086527109146, \"iteration\": 935, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.045590389519929886, \"iteration\": 936, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05779501423239708, \"iteration\": 937, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08143205940723419, \"iteration\": 938, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.042729977518320084, \"iteration\": 939, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.023669445887207985, \"iteration\": 940, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031435880810022354, \"iteration\": 941, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0863782986998558, \"iteration\": 942, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0503578782081604, \"iteration\": 943, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030369367450475693, \"iteration\": 944, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.10048528015613556, \"iteration\": 945, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05822091922163963, \"iteration\": 946, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03417079523205757, \"iteration\": 947, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07777748256921768, \"iteration\": 948, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.04975802078843117, \"iteration\": 949, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04548172652721405, \"iteration\": 950, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.037437595427036285, \"iteration\": 951, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02878694050014019, \"iteration\": 952, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07242406159639359, \"iteration\": 953, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03235974907875061, \"iteration\": 954, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.027519918978214264, \"iteration\": 955, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05769985914230347, \"iteration\": 956, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02652055211365223, \"iteration\": 957, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021965738385915756, \"iteration\": 958, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.027259964495897293, \"iteration\": 959, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08753608912229538, \"iteration\": 960, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09365677833557129, \"iteration\": 961, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.044427841901779175, \"iteration\": 962, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028687849640846252, \"iteration\": 963, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05403418466448784, \"iteration\": 964, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.058646488934755325, \"iteration\": 965, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10141463577747345, \"iteration\": 966, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.061433207243680954, \"iteration\": 967, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06183835119009018, \"iteration\": 968, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0501067154109478, \"iteration\": 969, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.059260934591293335, \"iteration\": 970, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03579741716384888, \"iteration\": 971, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05143596976995468, \"iteration\": 972, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.04276010021567345, \"iteration\": 973, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08691462874412537, \"iteration\": 974, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04718434065580368, \"iteration\": 975, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.043095700442790985, \"iteration\": 976, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06023736298084259, \"iteration\": 977, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05922706052660942, \"iteration\": 978, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.038936797529459, \"iteration\": 979, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10680671781301498, \"iteration\": 980, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07769621908664703, \"iteration\": 981, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05971292033791542, \"iteration\": 982, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040511853992938995, \"iteration\": 983, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.038931433111429214, \"iteration\": 984, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07056037336587906, \"iteration\": 985, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03278137370944023, \"iteration\": 986, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08916690200567245, \"iteration\": 987, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06176844239234924, \"iteration\": 988, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1109958365559578, \"iteration\": 989, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08386916667222977, \"iteration\": 990, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030783923342823982, \"iteration\": 991, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10089771449565887, \"iteration\": 992, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05353975296020508, \"iteration\": 993, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0482841394841671, \"iteration\": 994, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.056269023567438126, \"iteration\": 995, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.050158705562353134, \"iteration\": 996, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07261622697114944, \"iteration\": 997, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04372801631689072, \"iteration\": 998, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11406934261322021, \"iteration\": 999, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03705628588795662, \"iteration\": 1000, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03785702586174011, \"iteration\": 1001, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03302713856101036, \"iteration\": 1002, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.023751389235258102, \"iteration\": 1003, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10272650420665741, \"iteration\": 1004, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06521188467741013, \"iteration\": 1005, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040332019329071045, \"iteration\": 1006, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.042780883610248566, \"iteration\": 1007, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09628251194953918, \"iteration\": 1008, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01848446950316429, \"iteration\": 1009, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05989539250731468, \"iteration\": 1010, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05187351256608963, \"iteration\": 1011, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08966580778360367, \"iteration\": 1012, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04739905521273613, \"iteration\": 1013, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08623918890953064, \"iteration\": 1014, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0478612557053566, \"iteration\": 1015, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07282848656177521, \"iteration\": 1016, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02707371674478054, \"iteration\": 1017, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06056908518075943, \"iteration\": 1018, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04844603314995766, \"iteration\": 1019, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.05782365798950195, \"iteration\": 1020, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03785242885351181, \"iteration\": 1021, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12503032386302948, \"iteration\": 1022, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.026906324550509453, \"iteration\": 1023, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.048799388110637665, \"iteration\": 1024, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1089828684926033, \"iteration\": 1025, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05560971423983574, \"iteration\": 1026, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.016987156122922897, \"iteration\": 1027, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.049481816589832306, \"iteration\": 1028, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05299893766641617, \"iteration\": 1029, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06937341392040253, \"iteration\": 1030, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07083091884851456, \"iteration\": 1031, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10044732689857483, \"iteration\": 1032, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.09057247638702393, \"iteration\": 1033, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07421548664569855, \"iteration\": 1034, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05462682992219925, \"iteration\": 1035, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0931234359741211, \"iteration\": 1036, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0614122711122036, \"iteration\": 1037, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04072442278265953, \"iteration\": 1038, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04436197876930237, \"iteration\": 1039, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0686502680182457, \"iteration\": 1040, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04142346978187561, \"iteration\": 1041, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.015756668522953987, \"iteration\": 1042, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05114450305700302, \"iteration\": 1043, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08838894218206406, \"iteration\": 1044, \"epoch\": 5}, {\"training_acc\": 0.8571428571428571, \"training_loss\": 0.38179701566696167, \"iteration\": 1045, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.012601006776094437, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01135727483779192, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010873669758439064, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022642765194177628, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01842826046049595, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02835892327129841, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011289220303297043, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024614132940769196, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07390716671943665, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032196782529354095, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020333807915449142, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01578645408153534, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015458863228559494, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.026203962042927742, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014056628569960594, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014844618737697601, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029498567804694176, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031649406999349594, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.04323781654238701, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011416741646826267, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010463850572705269, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017046978697180748, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013378137722611427, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.024354198947548866, \"iteration\": 1069, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011589841917157173, \"iteration\": 1070, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01809566654264927, \"iteration\": 1071, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00761550385504961, \"iteration\": 1072, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012538253329694271, \"iteration\": 1073, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010741820558905602, \"iteration\": 1074, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01302387285977602, \"iteration\": 1075, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005581732839345932, \"iteration\": 1076, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019378535449504852, \"iteration\": 1077, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027611033990979195, \"iteration\": 1078, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012842626310884953, \"iteration\": 1079, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017577122896909714, \"iteration\": 1080, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014477571472525597, \"iteration\": 1081, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04213179275393486, \"iteration\": 1082, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019570879638195038, \"iteration\": 1083, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02186211384832859, \"iteration\": 1084, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023902658373117447, \"iteration\": 1085, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010932187549769878, \"iteration\": 1086, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005856913980096579, \"iteration\": 1087, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03739253431558609, \"iteration\": 1088, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04072657600045204, \"iteration\": 1089, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016844240948557854, \"iteration\": 1090, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.024145331233739853, \"iteration\": 1091, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01925669237971306, \"iteration\": 1092, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02997129037976265, \"iteration\": 1093, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03154522925615311, \"iteration\": 1094, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011377912946045399, \"iteration\": 1095, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020747292786836624, \"iteration\": 1096, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009919818490743637, \"iteration\": 1097, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012337343767285347, \"iteration\": 1098, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012628806754946709, \"iteration\": 1099, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022418471053242683, \"iteration\": 1100, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005077790468931198, \"iteration\": 1101, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02076084539294243, \"iteration\": 1102, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.057264167815446854, \"iteration\": 1103, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03011379949748516, \"iteration\": 1104, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020366456359624863, \"iteration\": 1105, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014123084023594856, \"iteration\": 1106, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014395304024219513, \"iteration\": 1107, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018308620899915695, \"iteration\": 1108, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01130561251193285, \"iteration\": 1109, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014203260652720928, \"iteration\": 1110, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04194965586066246, \"iteration\": 1111, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03152945637702942, \"iteration\": 1112, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011586450040340424, \"iteration\": 1113, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029166266322135925, \"iteration\": 1114, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008514286950230598, \"iteration\": 1115, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017940465360879898, \"iteration\": 1116, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.053549520671367645, \"iteration\": 1117, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012266058474779129, \"iteration\": 1118, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028640540316700935, \"iteration\": 1119, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012426227331161499, \"iteration\": 1120, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008425616659224033, \"iteration\": 1121, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008416889235377312, \"iteration\": 1122, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06964195519685745, \"iteration\": 1123, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012458818964660168, \"iteration\": 1124, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009543557651340961, \"iteration\": 1125, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007684294134378433, \"iteration\": 1126, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007764982525259256, \"iteration\": 1127, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011856257915496826, \"iteration\": 1128, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013270724564790726, \"iteration\": 1129, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009416493587195873, \"iteration\": 1130, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03185604512691498, \"iteration\": 1131, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007668185047805309, \"iteration\": 1132, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018917126581072807, \"iteration\": 1133, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00886511616408825, \"iteration\": 1134, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008536849170923233, \"iteration\": 1135, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007494183257222176, \"iteration\": 1136, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.022564232349395752, \"iteration\": 1137, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010251466184854507, \"iteration\": 1138, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006964390631765127, \"iteration\": 1139, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01787879690527916, \"iteration\": 1140, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015055671334266663, \"iteration\": 1141, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08332531154155731, \"iteration\": 1142, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03129012510180473, \"iteration\": 1143, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039778437465429306, \"iteration\": 1144, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009990828111767769, \"iteration\": 1145, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010994210839271545, \"iteration\": 1146, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010325298644602299, \"iteration\": 1147, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007811840623617172, \"iteration\": 1148, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011412132531404495, \"iteration\": 1149, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008754914626479149, \"iteration\": 1150, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0201941579580307, \"iteration\": 1151, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008916810154914856, \"iteration\": 1152, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0066037969663739204, \"iteration\": 1153, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011629842221736908, \"iteration\": 1154, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03300425782799721, \"iteration\": 1155, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03041750006377697, \"iteration\": 1156, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010745879262685776, \"iteration\": 1157, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008136007934808731, \"iteration\": 1158, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02015986666083336, \"iteration\": 1159, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006304181646555662, \"iteration\": 1160, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01353516336530447, \"iteration\": 1161, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007506756577640772, \"iteration\": 1162, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012802252545952797, \"iteration\": 1163, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01674497127532959, \"iteration\": 1164, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020291948691010475, \"iteration\": 1165, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009836725890636444, \"iteration\": 1166, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02689526230096817, \"iteration\": 1167, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01237712986767292, \"iteration\": 1168, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.038927994668483734, \"iteration\": 1169, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012226331047713757, \"iteration\": 1170, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015126705169677734, \"iteration\": 1171, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0073381587862968445, \"iteration\": 1172, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009505211375653744, \"iteration\": 1173, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02285047248005867, \"iteration\": 1174, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0037802821025252342, \"iteration\": 1175, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007307485211640596, \"iteration\": 1176, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.04042288288474083, \"iteration\": 1177, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012407805770635605, \"iteration\": 1178, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022274693474173546, \"iteration\": 1179, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00428562518209219, \"iteration\": 1180, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008101760409772396, \"iteration\": 1181, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06725617498159409, \"iteration\": 1182, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028855513781309128, \"iteration\": 1183, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01867394521832466, \"iteration\": 1184, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008178222924470901, \"iteration\": 1185, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022006403654813766, \"iteration\": 1186, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06270290911197662, \"iteration\": 1187, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009412923827767372, \"iteration\": 1188, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020833833143115044, \"iteration\": 1189, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014408344402909279, \"iteration\": 1190, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01673218235373497, \"iteration\": 1191, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.027468232437968254, \"iteration\": 1192, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008736401796340942, \"iteration\": 1193, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027190042659640312, \"iteration\": 1194, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004904475528746843, \"iteration\": 1195, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04686451703310013, \"iteration\": 1196, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00461489288136363, \"iteration\": 1197, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014122488908469677, \"iteration\": 1198, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009605208411812782, \"iteration\": 1199, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030109263956546783, \"iteration\": 1200, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007712630555033684, \"iteration\": 1201, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010676968842744827, \"iteration\": 1202, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007195399142801762, \"iteration\": 1203, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005451388657093048, \"iteration\": 1204, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03729977458715439, \"iteration\": 1205, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01015634834766388, \"iteration\": 1206, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.026907406747341156, \"iteration\": 1207, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027032991871237755, \"iteration\": 1208, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018964000046253204, \"iteration\": 1209, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012966749258339405, \"iteration\": 1210, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004761583171784878, \"iteration\": 1211, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02745950035750866, \"iteration\": 1212, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007530224043875933, \"iteration\": 1213, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030430546030402184, \"iteration\": 1214, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009597458876669407, \"iteration\": 1215, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0230870358645916, \"iteration\": 1216, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019125202670693398, \"iteration\": 1217, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01595371775329113, \"iteration\": 1218, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015914984047412872, \"iteration\": 1219, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004835790488868952, \"iteration\": 1220, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024150023236870766, \"iteration\": 1221, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010049193166196346, \"iteration\": 1222, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025997895747423172, \"iteration\": 1223, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04103595018386841, \"iteration\": 1224, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015193717554211617, \"iteration\": 1225, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007672225125133991, \"iteration\": 1226, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011375575326383114, \"iteration\": 1227, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03897801414132118, \"iteration\": 1228, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010661061853170395, \"iteration\": 1229, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07693451642990112, \"iteration\": 1230, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013464154675602913, \"iteration\": 1231, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012446465902030468, \"iteration\": 1232, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009331928566098213, \"iteration\": 1233, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.04247940331697464, \"iteration\": 1234, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024520888924598694, \"iteration\": 1235, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0078124175779521465, \"iteration\": 1236, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009277572855353355, \"iteration\": 1237, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019290875643491745, \"iteration\": 1238, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04097936674952507, \"iteration\": 1239, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04225120320916176, \"iteration\": 1240, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025508787482976913, \"iteration\": 1241, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04256667196750641, \"iteration\": 1242, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012670900672674179, \"iteration\": 1243, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009094960987567902, \"iteration\": 1244, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02666608989238739, \"iteration\": 1245, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011420282535254955, \"iteration\": 1246, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022346220910549164, \"iteration\": 1247, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011607874184846878, \"iteration\": 1248, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010629422031342983, \"iteration\": 1249, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04089449346065521, \"iteration\": 1250, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00692173233255744, \"iteration\": 1251, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.035322729498147964, \"iteration\": 1252, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.029576562345027924, \"iteration\": 1253, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004814487416297197, \"iteration\": 1254, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004104978404939175, \"iteration\": 1255, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0066689359955489635, \"iteration\": 1256, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004386445973068476, \"iteration\": 1257, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0046280380338430405, \"iteration\": 1258, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038059898652136326, \"iteration\": 1259, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004221865441650152, \"iteration\": 1260, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019612840842455626, \"iteration\": 1261, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0065065897069871426, \"iteration\": 1262, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031656643841415644, \"iteration\": 1263, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002907994668930769, \"iteration\": 1264, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036220760084688663, \"iteration\": 1265, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0030576952267438173, \"iteration\": 1266, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002809740137308836, \"iteration\": 1267, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004435522481799126, \"iteration\": 1268, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0030859829857945442, \"iteration\": 1269, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002999792108312249, \"iteration\": 1270, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004889088217169046, \"iteration\": 1271, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002256120555102825, \"iteration\": 1272, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004229984246194363, \"iteration\": 1273, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004245837219059467, \"iteration\": 1274, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005684519652277231, \"iteration\": 1275, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003607745049521327, \"iteration\": 1276, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009228979237377644, \"iteration\": 1277, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038824393413960934, \"iteration\": 1278, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009876873344182968, \"iteration\": 1279, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017496591899544, \"iteration\": 1280, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003377864370122552, \"iteration\": 1281, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003918840084224939, \"iteration\": 1282, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006564190145581961, \"iteration\": 1283, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018260576762259007, \"iteration\": 1284, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025084700901061296, \"iteration\": 1285, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0032343051861971617, \"iteration\": 1286, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004671730101108551, \"iteration\": 1287, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028661717660725117, \"iteration\": 1288, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.010475900024175644, \"iteration\": 1289, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025086109526455402, \"iteration\": 1290, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031992290169000626, \"iteration\": 1291, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004729978274554014, \"iteration\": 1292, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003608489641919732, \"iteration\": 1293, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002399446675553918, \"iteration\": 1294, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004219388123601675, \"iteration\": 1295, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017752157291397452, \"iteration\": 1296, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035347677767276764, \"iteration\": 1297, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01613149791955948, \"iteration\": 1298, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004027900286018848, \"iteration\": 1299, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031050159595906734, \"iteration\": 1300, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014113141223788261, \"iteration\": 1301, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002287290059030056, \"iteration\": 1302, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002159629249945283, \"iteration\": 1303, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002795238047838211, \"iteration\": 1304, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002825794043019414, \"iteration\": 1305, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001887606573291123, \"iteration\": 1306, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.05211443826556206, \"iteration\": 1307, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022369769867509604, \"iteration\": 1308, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028879649471491575, \"iteration\": 1309, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019047567620873451, \"iteration\": 1310, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003606293583288789, \"iteration\": 1311, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019838425796478987, \"iteration\": 1312, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0045499238185584545, \"iteration\": 1313, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0030026198364794254, \"iteration\": 1314, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004836096428334713, \"iteration\": 1315, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028688842430710793, \"iteration\": 1316, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004340408369898796, \"iteration\": 1317, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017347680404782295, \"iteration\": 1318, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002499404363334179, \"iteration\": 1319, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00375813664868474, \"iteration\": 1320, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022408708464354277, \"iteration\": 1321, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035098539665341377, \"iteration\": 1322, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035521097015589476, \"iteration\": 1323, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0033551023807376623, \"iteration\": 1324, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025571726262569427, \"iteration\": 1325, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028642292600125074, \"iteration\": 1326, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004990666173398495, \"iteration\": 1327, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002768069040030241, \"iteration\": 1328, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003886082675307989, \"iteration\": 1329, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020395200699567795, \"iteration\": 1330, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038887313567101955, \"iteration\": 1331, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0030171151738613844, \"iteration\": 1332, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003705243580043316, \"iteration\": 1333, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034385095350444317, \"iteration\": 1334, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038009751588106155, \"iteration\": 1335, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005543874576687813, \"iteration\": 1336, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0029743448831140995, \"iteration\": 1337, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0024174628779292107, \"iteration\": 1338, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027234090957790613, \"iteration\": 1339, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002004795940592885, \"iteration\": 1340, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003178688697516918, \"iteration\": 1341, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023559140972793102, \"iteration\": 1342, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002239393536001444, \"iteration\": 1343, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0041528502479195595, \"iteration\": 1344, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003945675678551197, \"iteration\": 1345, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003066752338781953, \"iteration\": 1346, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002274096244946122, \"iteration\": 1347, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012186900712549686, \"iteration\": 1348, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003227207576856017, \"iteration\": 1349, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014535943046212196, \"iteration\": 1350, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023168642073869705, \"iteration\": 1351, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015582172200083733, \"iteration\": 1352, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001735820434987545, \"iteration\": 1353, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004626927897334099, \"iteration\": 1354, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.018923047930002213, \"iteration\": 1355, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031992971897125244, \"iteration\": 1356, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016655998770147562, \"iteration\": 1357, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028536049649119377, \"iteration\": 1358, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0026720459572970867, \"iteration\": 1359, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002412198344245553, \"iteration\": 1360, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023091379553079605, \"iteration\": 1361, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027321549132466316, \"iteration\": 1362, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004739943891763687, \"iteration\": 1363, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0026181419380009174, \"iteration\": 1364, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005701430141925812, \"iteration\": 1365, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002837629057466984, \"iteration\": 1366, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007984618656337261, \"iteration\": 1367, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016368553042411804, \"iteration\": 1368, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.013841657899320126, \"iteration\": 1369, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002917827572673559, \"iteration\": 1370, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038389319088310003, \"iteration\": 1371, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017296472797170281, \"iteration\": 1372, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016682423884049058, \"iteration\": 1373, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017407841514796019, \"iteration\": 1374, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003236934542655945, \"iteration\": 1375, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020984159782528877, \"iteration\": 1376, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010982873849570751, \"iteration\": 1377, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003689190838485956, \"iteration\": 1378, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005591115448623896, \"iteration\": 1379, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0011391200823709369, \"iteration\": 1380, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019469502149149776, \"iteration\": 1381, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007613318972289562, \"iteration\": 1382, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.038986820727586746, \"iteration\": 1383, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016069660196080804, \"iteration\": 1384, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019223096314817667, \"iteration\": 1385, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0029427804984152317, \"iteration\": 1386, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00113343121483922, \"iteration\": 1387, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002474556677043438, \"iteration\": 1388, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013592828763648868, \"iteration\": 1389, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017561957938596606, \"iteration\": 1390, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004059080500155687, \"iteration\": 1391, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035180593840777874, \"iteration\": 1392, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0030736590269953012, \"iteration\": 1393, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0048318528570234776, \"iteration\": 1394, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036557787097990513, \"iteration\": 1395, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020964478608220816, \"iteration\": 1396, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025092379655689, \"iteration\": 1397, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001773723866790533, \"iteration\": 1398, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019379851873964071, \"iteration\": 1399, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0033070025965571404, \"iteration\": 1400, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03242214396595955, \"iteration\": 1401, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0032567251473665237, \"iteration\": 1402, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015479261055588722, \"iteration\": 1403, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028040437027812004, \"iteration\": 1404, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002230629790574312, \"iteration\": 1405, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027024424634873867, \"iteration\": 1406, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0070672957226634026, \"iteration\": 1407, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03161373361945152, \"iteration\": 1408, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019112542504444718, \"iteration\": 1409, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005907431244850159, \"iteration\": 1410, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018136902945116162, \"iteration\": 1411, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0009798388928174973, \"iteration\": 1412, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0026522811967879534, \"iteration\": 1413, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01756593957543373, \"iteration\": 1414, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0008400192600674927, \"iteration\": 1415, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031036872416734695, \"iteration\": 1416, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001279102056287229, \"iteration\": 1417, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001099861110560596, \"iteration\": 1418, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018533826805651188, \"iteration\": 1419, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004313519690185785, \"iteration\": 1420, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017544225556775928, \"iteration\": 1421, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027324429247528315, \"iteration\": 1422, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003757102182134986, \"iteration\": 1423, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008651329204440117, \"iteration\": 1424, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00726136052981019, \"iteration\": 1425, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025973517913371325, \"iteration\": 1426, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017429548315703869, \"iteration\": 1427, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.015270455740392208, \"iteration\": 1428, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019049569964408875, \"iteration\": 1429, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004098141100257635, \"iteration\": 1430, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0029824995435774326, \"iteration\": 1431, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00231198500841856, \"iteration\": 1432, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002922148210927844, \"iteration\": 1433, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0032221826259046793, \"iteration\": 1434, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017851665616035461, \"iteration\": 1435, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028266534209251404, \"iteration\": 1436, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020123969297856092, \"iteration\": 1437, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04329000785946846, \"iteration\": 1438, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037507866509258747, \"iteration\": 1439, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023663791362196207, \"iteration\": 1440, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002005667658522725, \"iteration\": 1441, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018159134779125452, \"iteration\": 1442, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003547727596014738, \"iteration\": 1443, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020860559307038784, \"iteration\": 1444, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001418683910742402, \"iteration\": 1445, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004130559507757425, \"iteration\": 1446, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023240158334374428, \"iteration\": 1447, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005547123029828072, \"iteration\": 1448, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004254856146872044, \"iteration\": 1449, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006197398062795401, \"iteration\": 1450, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022971646394580603, \"iteration\": 1451, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036897496320307255, \"iteration\": 1452, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0021126042120158672, \"iteration\": 1453, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025470012333244085, \"iteration\": 1454, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022541042417287827, \"iteration\": 1455, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00948829110711813, \"iteration\": 1456, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002664011437445879, \"iteration\": 1457, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002782036317512393, \"iteration\": 1458, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020442423410713673, \"iteration\": 1459, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017976966919377446, \"iteration\": 1460, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002739663701504469, \"iteration\": 1461, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0026047660503536463, \"iteration\": 1462, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007690090569667518, \"iteration\": 1463, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007142192334868014, \"iteration\": 1464, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009972754633054137, \"iteration\": 1465, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0035574829671531916, \"iteration\": 1466, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002347463509067893, \"iteration\": 1467, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014310830738395452, \"iteration\": 1468, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010223439894616604, \"iteration\": 1469, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008097245008684695, \"iteration\": 1470, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016155658522620797, \"iteration\": 1471, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001087726210244, \"iteration\": 1472, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010580811649560928, \"iteration\": 1473, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008059559622779489, \"iteration\": 1474, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000824542308691889, \"iteration\": 1475, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013068967964500189, \"iteration\": 1476, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009263394749723375, \"iteration\": 1477, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011702298652380705, \"iteration\": 1478, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007931087748147547, \"iteration\": 1479, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010438930476084352, \"iteration\": 1480, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007310444489121437, \"iteration\": 1481, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013269082410261035, \"iteration\": 1482, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007034400478005409, \"iteration\": 1483, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007996682543307543, \"iteration\": 1484, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009125491487793624, \"iteration\": 1485, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008902973495423794, \"iteration\": 1486, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006904019974172115, \"iteration\": 1487, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007987057906575501, \"iteration\": 1488, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009347837185487151, \"iteration\": 1489, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010912001598626375, \"iteration\": 1490, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010412685805931687, \"iteration\": 1491, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010931624565273523, \"iteration\": 1492, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002198516856878996, \"iteration\": 1493, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008064385619945824, \"iteration\": 1494, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007718298584222794, \"iteration\": 1495, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008212539250962436, \"iteration\": 1496, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000448414939455688, \"iteration\": 1497, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009882497834041715, \"iteration\": 1498, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009252403397113085, \"iteration\": 1499, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000595121004153043, \"iteration\": 1500, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008390112780034542, \"iteration\": 1501, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008877541986294091, \"iteration\": 1502, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000847867748234421, \"iteration\": 1503, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010109513532370329, \"iteration\": 1504, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009613101137802005, \"iteration\": 1505, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009620834607630968, \"iteration\": 1506, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007150385645218194, \"iteration\": 1507, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009464440518058836, \"iteration\": 1508, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000585482339374721, \"iteration\": 1509, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008208556100726128, \"iteration\": 1510, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006978621240705252, \"iteration\": 1511, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008690067334100604, \"iteration\": 1512, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008011379977688193, \"iteration\": 1513, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007994227926246822, \"iteration\": 1514, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001201579230837524, \"iteration\": 1515, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004534433246590197, \"iteration\": 1516, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05746255815029144, \"iteration\": 1517, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007739432621747255, \"iteration\": 1518, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004844732175115496, \"iteration\": 1519, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010687619214877486, \"iteration\": 1520, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007309984066523612, \"iteration\": 1521, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006803112337365746, \"iteration\": 1522, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004386049695312977, \"iteration\": 1523, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006882738089188933, \"iteration\": 1524, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007337484857998788, \"iteration\": 1525, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007846947410143912, \"iteration\": 1526, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004024536348879337, \"iteration\": 1527, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015135827707126737, \"iteration\": 1528, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000562065455596894, \"iteration\": 1529, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007966028060764074, \"iteration\": 1530, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001069745747372508, \"iteration\": 1531, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006937152938917279, \"iteration\": 1532, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001590472413226962, \"iteration\": 1533, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010928570991382003, \"iteration\": 1534, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00046790155465714633, \"iteration\": 1535, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000691340072080493, \"iteration\": 1536, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008524037548340857, \"iteration\": 1537, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006613016012124717, \"iteration\": 1538, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006794833461754024, \"iteration\": 1539, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006011379882693291, \"iteration\": 1540, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008966050227172673, \"iteration\": 1541, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007569003500975668, \"iteration\": 1542, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014231442473828793, \"iteration\": 1543, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007272760849446058, \"iteration\": 1544, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006201805081218481, \"iteration\": 1545, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004947187262587249, \"iteration\": 1546, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005366459372453392, \"iteration\": 1547, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009667143458500504, \"iteration\": 1548, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008942611748352647, \"iteration\": 1549, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000679840100929141, \"iteration\": 1550, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009017552947625518, \"iteration\": 1551, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001265883445739746, \"iteration\": 1552, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012134662829339504, \"iteration\": 1553, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004320953506976366, \"iteration\": 1554, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004619040118996054, \"iteration\": 1555, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007854364812374115, \"iteration\": 1556, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007289171917364001, \"iteration\": 1557, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00043423977331258357, \"iteration\": 1558, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006200189818628132, \"iteration\": 1559, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008733097347430885, \"iteration\": 1560, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007091960869729519, \"iteration\": 1561, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008398291538469493, \"iteration\": 1562, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012198202311992645, \"iteration\": 1563, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004336488782428205, \"iteration\": 1564, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007971860468387604, \"iteration\": 1565, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000705834710970521, \"iteration\": 1566, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001100599067285657, \"iteration\": 1567, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004041849169880152, \"iteration\": 1568, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010424721986055374, \"iteration\": 1569, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005055475048720837, \"iteration\": 1570, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009135506115853786, \"iteration\": 1571, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004505219985730946, \"iteration\": 1572, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006096073193475604, \"iteration\": 1573, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008209916413761675, \"iteration\": 1574, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006108438828960061, \"iteration\": 1575, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006402351427823305, \"iteration\": 1576, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004574487975332886, \"iteration\": 1577, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005428049480542541, \"iteration\": 1578, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004821575712412596, \"iteration\": 1579, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009076346759684384, \"iteration\": 1580, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005508845206350088, \"iteration\": 1581, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005981744034215808, \"iteration\": 1582, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007913830922916532, \"iteration\": 1583, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005754830199293792, \"iteration\": 1584, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011971095809713006, \"iteration\": 1585, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000560907821636647, \"iteration\": 1586, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009755399660207331, \"iteration\": 1587, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004442817880772054, \"iteration\": 1588, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005603147437795997, \"iteration\": 1589, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00048238749150186777, \"iteration\": 1590, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006714367191307247, \"iteration\": 1591, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008986699394881725, \"iteration\": 1592, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003886802587658167, \"iteration\": 1593, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007312217494472861, \"iteration\": 1594, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007113780593499541, \"iteration\": 1595, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007006424712017179, \"iteration\": 1596, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004176977672614157, \"iteration\": 1597, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005418367218226194, \"iteration\": 1598, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005469394382089376, \"iteration\": 1599, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006135988514870405, \"iteration\": 1600, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001863354118540883, \"iteration\": 1601, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005471666227094829, \"iteration\": 1602, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004954849136993289, \"iteration\": 1603, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006731405737809837, \"iteration\": 1604, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007320961449295282, \"iteration\": 1605, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000784257659688592, \"iteration\": 1606, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008739942568354309, \"iteration\": 1607, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004513143212534487, \"iteration\": 1608, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004955996409989893, \"iteration\": 1609, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007694350788369775, \"iteration\": 1610, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024303466081619263, \"iteration\": 1611, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010184284765273333, \"iteration\": 1612, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005205997149460018, \"iteration\": 1613, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004904924426227808, \"iteration\": 1614, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009541741455905139, \"iteration\": 1615, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005719135515391827, \"iteration\": 1616, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000598846236243844, \"iteration\": 1617, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005790686118416488, \"iteration\": 1618, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005346321268007159, \"iteration\": 1619, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00045778488856740296, \"iteration\": 1620, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02110207825899124, \"iteration\": 1621, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000535547558683902, \"iteration\": 1622, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006015802500769496, \"iteration\": 1623, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0040984684601426125, \"iteration\": 1624, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008896123035810888, \"iteration\": 1625, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006489881197921932, \"iteration\": 1626, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007265671738423407, \"iteration\": 1627, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004924465320073068, \"iteration\": 1628, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000703086843714118, \"iteration\": 1629, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019256689120084047, \"iteration\": 1630, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005042110569775105, \"iteration\": 1631, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004944086540490389, \"iteration\": 1632, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002255168743431568, \"iteration\": 1633, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007356805144809186, \"iteration\": 1634, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003253149043302983, \"iteration\": 1635, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005351286963559687, \"iteration\": 1636, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008408629219047725, \"iteration\": 1637, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004248219192959368, \"iteration\": 1638, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005316729075275362, \"iteration\": 1639, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00028868639492429793, \"iteration\": 1640, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00037848501233384013, \"iteration\": 1641, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000565150345209986, \"iteration\": 1642, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008624994661659002, \"iteration\": 1643, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007380456663668156, \"iteration\": 1644, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010882712667807937, \"iteration\": 1645, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005925390869379044, \"iteration\": 1646, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004611280164681375, \"iteration\": 1647, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006380068371072412, \"iteration\": 1648, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005635420675389469, \"iteration\": 1649, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00029343736241571605, \"iteration\": 1650, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005910132895223796, \"iteration\": 1651, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004976684576831758, \"iteration\": 1652, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005155015969648957, \"iteration\": 1653, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00043179927160963416, \"iteration\": 1654, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00047858612379059196, \"iteration\": 1655, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00040712361806072295, \"iteration\": 1656, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008862021495588124, \"iteration\": 1657, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006403223145753145, \"iteration\": 1658, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006715439376421273, \"iteration\": 1659, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006194997113198042, \"iteration\": 1660, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003682043752633035, \"iteration\": 1661, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006770353065803647, \"iteration\": 1662, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00041821005288511515, \"iteration\": 1663, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016344109550118446, \"iteration\": 1664, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007549520232714713, \"iteration\": 1665, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005998640554025769, \"iteration\": 1666, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003688948054332286, \"iteration\": 1667, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008730467525310814, \"iteration\": 1668, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003664530813694, \"iteration\": 1669, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006845829193480313, \"iteration\": 1670, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00036572729004547, \"iteration\": 1671, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.071406096452847e-05, \"iteration\": 1672, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004229382029734552, \"iteration\": 1673, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021145128994248807, \"iteration\": 1674, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003927655052393675, \"iteration\": 1675, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00056732032680884, \"iteration\": 1676, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004390520043671131, \"iteration\": 1677, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00042376076453365386, \"iteration\": 1678, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00047334792907349765, \"iteration\": 1679, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00032773337443359196, \"iteration\": 1680, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003958391025662422, \"iteration\": 1681, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004014975856989622, \"iteration\": 1682, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041510118171572685, \"iteration\": 1683, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003715016646310687, \"iteration\": 1684, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043152912985533476, \"iteration\": 1685, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036101118894293904, \"iteration\": 1686, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041486206464469433, \"iteration\": 1687, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003275727794971317, \"iteration\": 1688, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009017258416861296, \"iteration\": 1689, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003065266937483102, \"iteration\": 1690, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005297623574733734, \"iteration\": 1691, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00030757460626773536, \"iteration\": 1692, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003059511655010283, \"iteration\": 1693, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004207083838991821, \"iteration\": 1694, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005163396708667278, \"iteration\": 1695, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003524334460962564, \"iteration\": 1696, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018167546018958092, \"iteration\": 1697, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00025885773357003927, \"iteration\": 1698, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021418280084617436, \"iteration\": 1699, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002322770596947521, \"iteration\": 1700, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008155188988894224, \"iteration\": 1701, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000360199308488518, \"iteration\": 1702, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004067850823048502, \"iteration\": 1703, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003842176520265639, \"iteration\": 1704, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003647507692221552, \"iteration\": 1705, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00022260358673520386, \"iteration\": 1706, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002795957261696458, \"iteration\": 1707, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003302641271147877, \"iteration\": 1708, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000383487407816574, \"iteration\": 1709, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005355734610930085, \"iteration\": 1710, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045369836152531207, \"iteration\": 1711, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000453457934781909, \"iteration\": 1712, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005373367457650602, \"iteration\": 1713, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00040131021523848176, \"iteration\": 1714, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010401553008705378, \"iteration\": 1715, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028860935708507895, \"iteration\": 1716, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008519487455487251, \"iteration\": 1717, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004086619592271745, \"iteration\": 1718, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041324537596665323, \"iteration\": 1719, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005108722252771258, \"iteration\": 1720, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041980002424679697, \"iteration\": 1721, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000367531378287822, \"iteration\": 1722, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028797960840165615, \"iteration\": 1723, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019357645942363888, \"iteration\": 1724, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034771751961670816, \"iteration\": 1725, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004102419188711792, \"iteration\": 1726, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002871595788747072, \"iteration\": 1727, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002807924756780267, \"iteration\": 1728, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043310000910423696, \"iteration\": 1729, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003652130253612995, \"iteration\": 1730, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00039464799920096993, \"iteration\": 1731, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000315951561788097, \"iteration\": 1732, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007531444425694644, \"iteration\": 1733, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004049823619425297, \"iteration\": 1734, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041802844498306513, \"iteration\": 1735, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003448418283369392, \"iteration\": 1736, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00025746331084519625, \"iteration\": 1737, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026071665342897177, \"iteration\": 1738, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002640609163790941, \"iteration\": 1739, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00025620890664868057, \"iteration\": 1740, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003420046123210341, \"iteration\": 1741, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.022700078785419464, \"iteration\": 1742, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000370955589460209, \"iteration\": 1743, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031562629737891257, \"iteration\": 1744, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004312267410568893, \"iteration\": 1745, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00027698997291736305, \"iteration\": 1746, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037611363222822547, \"iteration\": 1747, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003603607474360615, \"iteration\": 1748, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003279812808614224, \"iteration\": 1749, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003571633715182543, \"iteration\": 1750, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003703662659972906, \"iteration\": 1751, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035124458372592926, \"iteration\": 1752, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005814661853946745, \"iteration\": 1753, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004428293032106012, \"iteration\": 1754, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005573620437644422, \"iteration\": 1755, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004721002478618175, \"iteration\": 1756, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005751783610321581, \"iteration\": 1757, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033558186260052025, \"iteration\": 1758, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004562618851196021, \"iteration\": 1759, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004999626544304192, \"iteration\": 1760, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037186627741903067, \"iteration\": 1761, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004993932088837028, \"iteration\": 1762, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008874659542925656, \"iteration\": 1763, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002645912754815072, \"iteration\": 1764, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.049916770309209824, \"iteration\": 1765, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004746251506730914, \"iteration\": 1766, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028152388404123485, \"iteration\": 1767, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002286359085701406, \"iteration\": 1768, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036289216950535774, \"iteration\": 1769, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045830238377675414, \"iteration\": 1770, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041744144982658327, \"iteration\": 1771, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023549700563307852, \"iteration\": 1772, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002427435974823311, \"iteration\": 1773, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003906494821421802, \"iteration\": 1774, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043403005111031234, \"iteration\": 1775, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00032304925844073296, \"iteration\": 1776, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002672476111911237, \"iteration\": 1777, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004469974956009537, \"iteration\": 1778, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006953435949981213, \"iteration\": 1779, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002463879936840385, \"iteration\": 1780, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003687865100800991, \"iteration\": 1781, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041217595571652055, \"iteration\": 1782, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00046450161607936025, \"iteration\": 1783, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036265846574679017, \"iteration\": 1784, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041049308492802083, \"iteration\": 1785, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003874880203511566, \"iteration\": 1786, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00020827489788644016, \"iteration\": 1787, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002970744390040636, \"iteration\": 1788, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006198289338499308, \"iteration\": 1789, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034414269612170756, \"iteration\": 1790, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003308560117147863, \"iteration\": 1791, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000675709918141365, \"iteration\": 1792, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000628883542958647, \"iteration\": 1793, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006308212177827954, \"iteration\": 1794, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026243741740472615, \"iteration\": 1795, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028018574812449515, \"iteration\": 1796, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024314262554980814, \"iteration\": 1797, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003235271433368325, \"iteration\": 1798, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037716649239882827, \"iteration\": 1799, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003439431602600962, \"iteration\": 1800, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033985459594987333, \"iteration\": 1801, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002186290657846257, \"iteration\": 1802, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002906155423261225, \"iteration\": 1803, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00016617144865449518, \"iteration\": 1804, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003567845851648599, \"iteration\": 1805, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002550788049120456, \"iteration\": 1806, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00018901529256254435, \"iteration\": 1807, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00044231186620891094, \"iteration\": 1808, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037502290797419846, \"iteration\": 1809, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003543031052686274, \"iteration\": 1810, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002748525294009596, \"iteration\": 1811, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003203118103556335, \"iteration\": 1812, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024555326672270894, \"iteration\": 1813, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005058801034465432, \"iteration\": 1814, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034613048774190247, \"iteration\": 1815, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004166081780567765, \"iteration\": 1816, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026212577358819544, \"iteration\": 1817, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002712286659516394, \"iteration\": 1818, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019837834406644106, \"iteration\": 1819, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019965753017459065, \"iteration\": 1820, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003599980555009097, \"iteration\": 1821, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004337187856435776, \"iteration\": 1822, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003210132708773017, \"iteration\": 1823, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004289531789254397, \"iteration\": 1824, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003576981252990663, \"iteration\": 1825, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.017299167811870575, \"iteration\": 1826, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010998181533068419, \"iteration\": 1827, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003875716356560588, \"iteration\": 1828, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00038145339931361377, \"iteration\": 1829, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003704105329234153, \"iteration\": 1830, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000521297799423337, \"iteration\": 1831, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034820515429601073, \"iteration\": 1832, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003043697215616703, \"iteration\": 1833, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00018364521383773535, \"iteration\": 1834, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00030236251768656075, \"iteration\": 1835, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00032069720327854156, \"iteration\": 1836, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000401096825953573, \"iteration\": 1837, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008102669380605221, \"iteration\": 1838, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006846598698757589, \"iteration\": 1839, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004629674949683249, \"iteration\": 1840, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019697743118740618, \"iteration\": 1841, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002860534586943686, \"iteration\": 1842, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002901742118410766, \"iteration\": 1843, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002901348634622991, \"iteration\": 1844, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00022305153834167868, \"iteration\": 1845, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026293282280676067, \"iteration\": 1846, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002588612260296941, \"iteration\": 1847, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002467679441906512, \"iteration\": 1848, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018959753215312958, \"iteration\": 1849, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002996636612806469, \"iteration\": 1850, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026253843680024147, \"iteration\": 1851, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003474336117506027, \"iteration\": 1852, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002578377607278526, \"iteration\": 1853, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00027761099045164883, \"iteration\": 1854, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00044405285734683275, \"iteration\": 1855, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00048599825822748244, \"iteration\": 1856, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003146819944959134, \"iteration\": 1857, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004950190777890384, \"iteration\": 1858, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036566838389262557, \"iteration\": 1859, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003833636292256415, \"iteration\": 1860, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024405482690781355, \"iteration\": 1861, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000434769201092422, \"iteration\": 1862, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002767243713606149, \"iteration\": 1863, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029227666556835175, \"iteration\": 1864, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003391453647054732, \"iteration\": 1865, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003261650854256004, \"iteration\": 1866, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02203300967812538, \"iteration\": 1867, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00025274514337070286, \"iteration\": 1868, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004461160278879106, \"iteration\": 1869, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011321291094645858, \"iteration\": 1870, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006003997987136245, \"iteration\": 1871, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00032701942836865783, \"iteration\": 1872, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041092632454819977, \"iteration\": 1873, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026367660029791296, \"iteration\": 1874, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004459675692487508, \"iteration\": 1875, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000678912503644824, \"iteration\": 1876, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002858018851839006, \"iteration\": 1877, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003152635181322694, \"iteration\": 1878, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004321853048168123, \"iteration\": 1879, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000347926135873422, \"iteration\": 1880, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.6360721171367913e-05, \"iteration\": 1881, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003110208490397781, \"iteration\": 1882, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00034540207707323134, \"iteration\": 1883, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023077218793332577, \"iteration\": 1884, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00038256309926509857, \"iteration\": 1885, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0032205400057137012, \"iteration\": 1886, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031328233308158815, \"iteration\": 1887, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024851111811585724, \"iteration\": 1888, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003116689913440496, \"iteration\": 1889, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024159287568181753, \"iteration\": 1890, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00040516912122257054, \"iteration\": 1891, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004264343297109008, \"iteration\": 1892, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002411430759821087, \"iteration\": 1893, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019943786901421845, \"iteration\": 1894, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002593549434095621, \"iteration\": 1895, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028103776276111603, \"iteration\": 1896, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001001585042104125, \"iteration\": 1897, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002622513275127858, \"iteration\": 1898, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002617126447148621, \"iteration\": 1899, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02675660513341427, \"iteration\": 1900, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031367759220302105, \"iteration\": 1901, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022148095013108104, \"iteration\": 1902, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002813240862451494, \"iteration\": 1903, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008898336673155427, \"iteration\": 1904, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019420018361415714, \"iteration\": 1905, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004633275093510747, \"iteration\": 1906, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032062287209555507, \"iteration\": 1907, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005811513401567936, \"iteration\": 1908, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020678419969044626, \"iteration\": 1909, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00033444189466536045, \"iteration\": 1910, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002680340548977256, \"iteration\": 1911, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027055235113948584, \"iteration\": 1912, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022660786635242403, \"iteration\": 1913, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0053716967813670635, \"iteration\": 1914, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002803202369250357, \"iteration\": 1915, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021525580086745322, \"iteration\": 1916, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00040100057958625257, \"iteration\": 1917, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002877904043998569, \"iteration\": 1918, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024550166563130915, \"iteration\": 1919, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001878140028566122, \"iteration\": 1920, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001868931867647916, \"iteration\": 1921, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001781367463991046, \"iteration\": 1922, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002324468659935519, \"iteration\": 1923, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003340371185913682, \"iteration\": 1924, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018012133659794927, \"iteration\": 1925, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013906616368331015, \"iteration\": 1926, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001655356027185917, \"iteration\": 1927, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025552493752911687, \"iteration\": 1928, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002515123051125556, \"iteration\": 1929, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00039965432370081544, \"iteration\": 1930, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022051591076888144, \"iteration\": 1931, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002444859710521996, \"iteration\": 1932, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002870066382456571, \"iteration\": 1933, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001862366043496877, \"iteration\": 1934, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00037547192187048495, \"iteration\": 1935, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002370662841713056, \"iteration\": 1936, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020494029740802944, \"iteration\": 1937, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032775377621874213, \"iteration\": 1938, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018838231335394084, \"iteration\": 1939, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001798543962650001, \"iteration\": 1940, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016973445599433035, \"iteration\": 1941, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020939737441949546, \"iteration\": 1942, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002596014237497002, \"iteration\": 1943, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003444046596996486, \"iteration\": 1944, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017229914374183863, \"iteration\": 1945, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002292796561960131, \"iteration\": 1946, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002434884081594646, \"iteration\": 1947, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019095292373094708, \"iteration\": 1948, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004335031844675541, \"iteration\": 1949, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017565340385772288, \"iteration\": 1950, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015949287626426667, \"iteration\": 1951, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017888423462864012, \"iteration\": 1952, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002561050350777805, \"iteration\": 1953, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019875606813002378, \"iteration\": 1954, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001348962396150455, \"iteration\": 1955, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.006988982670009136, \"iteration\": 1956, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022846090723760426, \"iteration\": 1957, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000770758546423167, \"iteration\": 1958, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001612369087524712, \"iteration\": 1959, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018713794997893274, \"iteration\": 1960, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002391986345173791, \"iteration\": 1961, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015086992061696947, \"iteration\": 1962, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003448171482887119, \"iteration\": 1963, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00036770966835319996, \"iteration\": 1964, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030288175912573934, \"iteration\": 1965, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014775345334783196, \"iteration\": 1966, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018991199613083154, \"iteration\": 1967, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017070774629246444, \"iteration\": 1968, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002011006436077878, \"iteration\": 1969, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027469065389595926, \"iteration\": 1970, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023804734519217163, \"iteration\": 1971, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017733083222992718, \"iteration\": 1972, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012731582683045417, \"iteration\": 1973, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018771928444039077, \"iteration\": 1974, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012786990555468947, \"iteration\": 1975, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024193957506213337, \"iteration\": 1976, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002639894373714924, \"iteration\": 1977, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022586944396607578, \"iteration\": 1978, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001875224697869271, \"iteration\": 1979, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004331484669819474, \"iteration\": 1980, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00041674956446513534, \"iteration\": 1981, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003204847453162074, \"iteration\": 1982, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002488390018697828, \"iteration\": 1983, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015245824761223048, \"iteration\": 1984, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003524763509631157, \"iteration\": 1985, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00045035919174551964, \"iteration\": 1986, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025759387062862515, \"iteration\": 1987, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021842932619620115, \"iteration\": 1988, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000211383739951998, \"iteration\": 1989, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019097635231446475, \"iteration\": 1990, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002165269252145663, \"iteration\": 1991, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020240659068804234, \"iteration\": 1992, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015606101078446954, \"iteration\": 1993, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011733431165339425, \"iteration\": 1994, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00036784299300052226, \"iteration\": 1995, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021615135483443737, \"iteration\": 1996, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011349196574883536, \"iteration\": 1997, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018501402519177645, \"iteration\": 1998, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003132091660518199, \"iteration\": 1999, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019716075621545315, \"iteration\": 2000, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017765762459021062, \"iteration\": 2001, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022450431424658746, \"iteration\": 2002, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017794936138670892, \"iteration\": 2003, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012788298772647977, \"iteration\": 2004, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026946039870381355, \"iteration\": 2005, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015720800729468465, \"iteration\": 2006, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002366765693295747, \"iteration\": 2007, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018647979595698416, \"iteration\": 2008, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000187659083167091, \"iteration\": 2009, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030168649391271174, \"iteration\": 2010, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00010515448229853064, \"iteration\": 2011, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016414445417467505, \"iteration\": 2012, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019988960411865264, \"iteration\": 2013, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020105067233089358, \"iteration\": 2014, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031544305966235697, \"iteration\": 2015, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002466150908730924, \"iteration\": 2016, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020520424004644156, \"iteration\": 2017, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001544156693853438, \"iteration\": 2018, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025509853730909526, \"iteration\": 2019, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001654185471124947, \"iteration\": 2020, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017468305304646492, \"iteration\": 2021, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001350062811980024, \"iteration\": 2022, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017782980285119265, \"iteration\": 2023, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013846272486262023, \"iteration\": 2024, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002292304125148803, \"iteration\": 2025, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012471222726162523, \"iteration\": 2026, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002535330131649971, \"iteration\": 2027, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016469719412270933, \"iteration\": 2028, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002646153443492949, \"iteration\": 2029, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000162720782100223, \"iteration\": 2030, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001680681889411062, \"iteration\": 2031, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019823094771709293, \"iteration\": 2032, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002189166989410296, \"iteration\": 2033, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002332537405891344, \"iteration\": 2034, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032648700289428234, \"iteration\": 2035, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003213348099961877, \"iteration\": 2036, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001443939981982112, \"iteration\": 2037, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002076527598546818, \"iteration\": 2038, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020286670769564807, \"iteration\": 2039, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000132232133182697, \"iteration\": 2040, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001726198534015566, \"iteration\": 2041, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019437505397945642, \"iteration\": 2042, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003454736724961549, \"iteration\": 2043, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023715707357041538, \"iteration\": 2044, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.698837336851284e-05, \"iteration\": 2045, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016930965648498386, \"iteration\": 2046, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029253546381369233, \"iteration\": 2047, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001433147699572146, \"iteration\": 2048, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011162443843204528, \"iteration\": 2049, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0020285879727452993, \"iteration\": 2050, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002615681441966444, \"iteration\": 2051, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.814720397116616e-05, \"iteration\": 2052, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002276261948281899, \"iteration\": 2053, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014955198275856674, \"iteration\": 2054, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002501417766325176, \"iteration\": 2055, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002181575633585453, \"iteration\": 2056, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021531917445827276, \"iteration\": 2057, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014505107537843287, \"iteration\": 2058, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012882555893156677, \"iteration\": 2059, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011192844976903871, \"iteration\": 2060, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001595790236024186, \"iteration\": 2061, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009681499795988202, \"iteration\": 2062, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.834617230808362e-05, \"iteration\": 2063, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016119549400173128, \"iteration\": 2064, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001254254748346284, \"iteration\": 2065, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011930101027246565, \"iteration\": 2066, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.140573870856315e-05, \"iteration\": 2067, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001837182353483513, \"iteration\": 2068, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018670324061531574, \"iteration\": 2069, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020934257190674543, \"iteration\": 2070, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000287433183984831, \"iteration\": 2071, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021520466543734074, \"iteration\": 2072, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021420084522105753, \"iteration\": 2073, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020944097195751965, \"iteration\": 2074, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024162222689483315, \"iteration\": 2075, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022110107238404453, \"iteration\": 2076, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011311392881907523, \"iteration\": 2077, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019317277474328876, \"iteration\": 2078, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011406875273678452, \"iteration\": 2079, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001697501284070313, \"iteration\": 2080, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002829190343618393, \"iteration\": 2081, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017110865155700594, \"iteration\": 2082, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000513945531565696, \"iteration\": 2083, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020340799528639764, \"iteration\": 2084, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017888926959130913, \"iteration\": 2085, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001508738932898268, \"iteration\": 2086, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017578626284375787, \"iteration\": 2087, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011505457223393023, \"iteration\": 2088, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014254424604587257, \"iteration\": 2089, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.224124727945309e-05, \"iteration\": 2090, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# POC\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "dataloader_gb = DataLoader(train_gb, batch_size=128, shuffle=True)\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "model_nn_gb = NeuralNetwork(\n",
    "    input_size=len(encoder_gb.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "if Path('models/model_nn_gb.pt').exists() and USE_CACHE:\n",
    "    model_nn_gb = load_model(model_nn_gb, 'model_nn_gb')\n",
    "else:\n",
    "    model_nn_gb.fit(dataloader_gb, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn_gb, \"model_nn_gb\")\n",
    "\n",
    "model_nn_gb_results = evaluate_nn_model(model_nn_gb, test_gb)\n",
    "np.save('models/model_nn_gb_results.npy', model_nn_gb_results)\n",
    "print(model_nn_gb_results)\n",
    "\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn_gb, train_config, dataloader_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data encoder...\n",
      "Prepare data...\n",
      "Train model\n",
      "\n",
      "(0.7195895314216614, 0.7760064601898193, 0.7555906176567078, 0.42727444855121854)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-afad7344fa224fcc97ee57aa0992e5fe.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-afad7344fa224fcc97ee57aa0992e5fe.vega-embed details,\n",
       "  #altair-viz-afad7344fa224fcc97ee57aa0992e5fe.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-afad7344fa224fcc97ee57aa0992e5fe\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-afad7344fa224fcc97ee57aa0992e5fe\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-afad7344fa224fcc97ee57aa0992e5fe\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-a6c1212e6dab40a969a0dae1dc1a6c16\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-a6c1212e6dab40a969a0dae1dc1a6c16\": [{\"training_acc\": 0.5625, \"training_loss\": 0.6900999546051025, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6900206804275513, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6887266039848328, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6890832781791687, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6868579387664795, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6858318448066711, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 0.6909735202789307, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6879105567932129, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6737962961196899, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6901741027832031, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6814572811126709, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.680810809135437, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6902936697006226, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6700677871704102, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6900274753570557, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 0.691656768321991, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6710470914840698, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6767926812171936, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6797536611557007, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6665613651275635, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6453530788421631, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6618108749389648, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6706504821777344, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.4921875, \"training_loss\": 0.7002681493759155, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6709253787994385, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.66377192735672, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6609412431716919, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6767207980155945, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6675648093223572, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6593019962310791, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.646896481513977, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6747284531593323, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.661188006401062, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6400448083877563, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6654866337776184, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6696877479553223, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6465965509414673, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6445114612579346, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6593203544616699, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.641198992729187, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6590299606323242, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6414620280265808, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.6388795971870422, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.6309832334518433, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.6375991106033325, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6270670890808105, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6423903107643127, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.604846715927124, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.599158763885498, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.6125574707984924, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6028434038162231, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5632684230804443, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6250970959663391, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.578961968421936, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.6165577173233032, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5973074436187744, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5964365005493164, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5545459389686584, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.548802375793457, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5181143283843994, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5786487460136414, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5386521816253662, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5680022239685059, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5510938167572021, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5891644954681396, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5712350606918335, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5234038829803467, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5429930686950684, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.563062310218811, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5569103360176086, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5585693717002869, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5518923997879028, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.45802170038223267, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5189452171325684, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5759780406951904, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4984704256057739, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.49782323837280273, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5496567487716675, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5367609858512878, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.46326586604118347, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.47284436225891113, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.3967888355255127, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4802396893501282, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.530781090259552, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.48841366171836853, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5075245499610901, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5085479021072388, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.42213648557662964, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.44950321316719055, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4773014783859253, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5324393510818481, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5291405916213989, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5262211561203003, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5659177899360657, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5313891768455505, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5236403942108154, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4880715310573578, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4907107353210449, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5305111408233643, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.49539604783058167, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5130804777145386, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5275979042053223, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5080844759941101, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4978526830673218, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4087158441543579, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.45890289545059204, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5147744417190552, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5353707075119019, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5168972015380859, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4870147705078125, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4391616880893707, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4970749616622925, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5527397394180298, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4508149027824402, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.52105712890625, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5160879492759705, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.42884862422943115, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4788753390312195, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4598081111907959, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5015683174133301, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5424272418022156, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4526149034500122, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.41784292459487915, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.42644548416137695, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.43232348561286926, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4315248131752014, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4406585097312927, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.49253106117248535, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4809477925300598, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.45949363708496094, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4771999418735504, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5644591450691223, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.48394104838371277, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.49090924859046936, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5281482934951782, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.41537314653396606, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.43527209758758545, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.4993298053741455, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.44016000628471375, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5287826657295227, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5661547183990479, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5049517154693604, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.436418354511261, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.43838852643966675, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5047110319137573, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.46920517086982727, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.47441723942756653, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5055521726608276, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.546172022819519, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.614093542098999, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4511415660381317, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4610452651977539, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5107231140136719, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.44774067401885986, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4805006980895996, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5794410705566406, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5139079093933105, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5101329684257507, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.40732818841934204, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.43265965580940247, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.46279335021972656, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.49303126335144043, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.46657615900039673, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.43949368596076965, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4558578431606293, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.44954484701156616, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.44506630301475525, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4711475372314453, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5492479801177979, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.46694397926330566, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4314451515674591, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.459769606590271, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5010272860527039, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.49095937609672546, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.41406896710395813, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5280334949493408, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.49625515937805176, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.553020715713501, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.461297869682312, \"iteration\": 179, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.47315794229507446, \"iteration\": 180, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5461916923522949, \"iteration\": 181, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5236530900001526, \"iteration\": 182, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4577590823173523, \"iteration\": 183, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5165104866027832, \"iteration\": 184, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4095357060432434, \"iteration\": 185, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4307689070701599, \"iteration\": 186, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.42072078585624695, \"iteration\": 187, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4797018766403198, \"iteration\": 188, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.48488712310791016, \"iteration\": 189, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.47453927993774414, \"iteration\": 190, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.44277068972587585, \"iteration\": 191, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.48223158717155457, \"iteration\": 192, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.46920421719551086, \"iteration\": 193, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.46740370988845825, \"iteration\": 194, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4544300436973572, \"iteration\": 195, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.44312161207199097, \"iteration\": 196, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5213456749916077, \"iteration\": 197, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.43597090244293213, \"iteration\": 198, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5167834162712097, \"iteration\": 199, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.48113828897476196, \"iteration\": 200, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.407880038022995, \"iteration\": 201, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4334917366504669, \"iteration\": 202, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.48047935962677, \"iteration\": 203, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5035004019737244, \"iteration\": 204, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4398844242095947, \"iteration\": 205, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4568263292312622, \"iteration\": 206, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.462549090385437, \"iteration\": 207, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4632236361503601, \"iteration\": 208, \"epoch\": 1}, {\"training_acc\": 0.8571428571428571, \"training_loss\": 0.41008609533309937, \"iteration\": 209, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.374321848154068, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.32499372959136963, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.41638392210006714, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.32393747568130493, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3386772871017456, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3224959969520569, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3797680735588074, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.31466835737228394, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3330734670162201, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3133411407470703, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.36474162340164185, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3314923644065857, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2953106462955475, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3804166615009308, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3493032455444336, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.31293800473213196, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2761678695678711, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3672600984573364, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.30609703063964844, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.43752509355545044, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30785638093948364, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.35098204016685486, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.35873663425445557, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3307366371154785, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.40571221709251404, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3544522523880005, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34347161650657654, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33851245045661926, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.36741340160369873, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33152341842651367, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.36635470390319824, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.37322285771369934, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.349833607673645, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.39240390062332153, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4003130793571472, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40200650691986084, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.43300861120224, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.39830151200294495, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3860565423965454, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3309185802936554, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.43230000138282776, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.47260549664497375, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.29762184619903564, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3638693392276764, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 0.4569230377674103, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3588520586490631, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3909887671470642, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3918461799621582, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.34601378440856934, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25788044929504395, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3445690870285034, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4002362787723541, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4134707450866699, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.33476701378822327, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3366425335407257, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.42593368887901306, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.35391688346862793, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3981900215148926, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.35835033655166626, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3209839165210724, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.40178218483924866, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.33357739448547363, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3689309358596802, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.39924097061157227, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2606930136680603, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3183508515357971, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.38041412830352783, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32724836468696594, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.34405583143234253, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4476882219314575, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.46119770407676697, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3723524808883667, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.462510883808136, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3672580122947693, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3871226906776428, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3537372350692749, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.42309775948524475, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.46648943424224854, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.42408737540245056, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.37403687834739685, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.32690662145614624, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2844868004322052, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.32730576395988464, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.38485753536224365, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.36221328377723694, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.30843043327331543, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4276531934738159, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3720242381095886, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3605642318725586, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.415199875831604, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.45722728967666626, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.42198318243026733, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3142467737197876, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4205957055091858, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3742334544658661, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3718178868293762, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31586843729019165, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.39072737097740173, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4123625159263611, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4018048346042633, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.3929471969604492, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4513017535209656, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3948879539966583, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.40087732672691345, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.30128026008605957, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.35487425327301025, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.33962932229042053, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3808697462081909, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.39552342891693115, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3392229676246643, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.44573014974594116, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.456003874540329, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3442961573600769, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.48865681886672974, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.340909868478775, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.438393771648407, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4808562099933624, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3401593863964081, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3411159813404083, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32094958424568176, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4216306209564209, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4086265563964844, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4153083264827728, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3700135052204132, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4299028515815735, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.4024602174758911, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3383563160896301, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3450845181941986, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3270374536514282, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.43833425641059875, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4915257692337036, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4195018410682678, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.43005526065826416, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.403072714805603, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.41283702850341797, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3723405599594116, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.37076354026794434, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.306387335062027, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3467556834220886, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3325607180595398, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4286736249923706, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.35151687264442444, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3969629108905792, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3960711658000946, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.41765761375427246, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4048413634300232, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.415453165769577, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40720048546791077, \"iteration\": 357, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.36185479164123535, \"iteration\": 358, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.396221399307251, \"iteration\": 359, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.36619627475738525, \"iteration\": 360, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4130709767341614, \"iteration\": 361, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3573649525642395, \"iteration\": 362, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3688676059246063, \"iteration\": 363, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3738337457180023, \"iteration\": 364, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3240589499473572, \"iteration\": 365, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4176976680755615, \"iteration\": 366, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.45075109601020813, \"iteration\": 367, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.46343955397605896, \"iteration\": 368, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.36866462230682373, \"iteration\": 369, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3434069752693176, \"iteration\": 370, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.39583685994148254, \"iteration\": 371, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.35143160820007324, \"iteration\": 372, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32717132568359375, \"iteration\": 373, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.413788378238678, \"iteration\": 374, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4111720025539398, \"iteration\": 375, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.36423635482788086, \"iteration\": 376, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.44946572184562683, \"iteration\": 377, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3897666037082672, \"iteration\": 378, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4249899387359619, \"iteration\": 379, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.415332555770874, \"iteration\": 380, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.36866259574890137, \"iteration\": 381, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.41454946994781494, \"iteration\": 382, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4292111098766327, \"iteration\": 383, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 0.4883195459842682, \"iteration\": 384, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.34877440333366394, \"iteration\": 385, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.39391428232192993, \"iteration\": 386, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.41587308049201965, \"iteration\": 387, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.35442593693733215, \"iteration\": 388, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.43369805812835693, \"iteration\": 389, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.30825501680374146, \"iteration\": 390, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4407055079936981, \"iteration\": 391, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.413942813873291, \"iteration\": 392, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.413762629032135, \"iteration\": 393, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4322272539138794, \"iteration\": 394, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.39176398515701294, \"iteration\": 395, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.5232617259025574, \"iteration\": 396, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.39352548122406006, \"iteration\": 397, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.391866534948349, \"iteration\": 398, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.34985417127609253, \"iteration\": 399, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.47533756494522095, \"iteration\": 400, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4328998327255249, \"iteration\": 401, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4355616271495819, \"iteration\": 402, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.37856370210647583, \"iteration\": 403, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.36209601163864136, \"iteration\": 404, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.36088964343070984, \"iteration\": 405, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.41400858759880066, \"iteration\": 406, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4595246911048889, \"iteration\": 407, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.392947793006897, \"iteration\": 408, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.386268675327301, \"iteration\": 409, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.488714337348938, \"iteration\": 410, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.36646464467048645, \"iteration\": 411, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.39373648166656494, \"iteration\": 412, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.36302244663238525, \"iteration\": 413, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.41261500120162964, \"iteration\": 414, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.37353411316871643, \"iteration\": 415, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4468977749347687, \"iteration\": 416, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.44043296575546265, \"iteration\": 417, \"epoch\": 2}, {\"training_acc\": 1.0, \"training_loss\": 0.22043968737125397, \"iteration\": 418, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2652027904987335, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31318753957748413, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.33531835675239563, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.27407538890838623, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31421077251434326, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2772706151008606, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.38460367918014526, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2624973654747009, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28014087677001953, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3032853603363037, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2654295563697815, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2794094681739807, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3089400827884674, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.36092469096183777, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2659929692745209, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28847140073776245, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24759183824062347, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24293573200702667, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30264967679977417, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2400417923927307, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3664538562297821, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3563336133956909, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.24448713660240173, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2563736140727997, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3149868845939636, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.32107454538345337, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3049622178077698, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.324948787689209, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3154914975166321, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.30316388607025146, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3266383409500122, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31948989629745483, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21319276094436646, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2618614435195923, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.30969756841659546, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27088111639022827, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.3035856783390045, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2024017870426178, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.31390708684921265, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26606887578964233, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.36680418252944946, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.23092061281204224, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3512212336063385, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3347208499908447, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3000718355178833, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.28216803073883057, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1903427541255951, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2751159071922302, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.283685564994812, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.30725619196891785, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2896038889884949, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3290961980819702, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.29239094257354736, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2769160866737366, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27190637588500977, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2852720618247986, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3381330966949463, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3253922760486603, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.325023889541626, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3289949893951416, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28812503814697266, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4206125736236572, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3249255418777466, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.35763072967529297, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3649901747703552, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.39048588275909424, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.23847568035125732, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2992962896823883, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.37041497230529785, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.318432480096817, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.28179505467414856, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3284931182861328, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.381769061088562, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.327391654253006, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2694084644317627, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2898278534412384, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2943909168243408, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3365808129310608, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.2578986585140228, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2577645480632782, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26694828271865845, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31164848804473877, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3421657681465149, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3027193546295166, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.33416610956192017, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.32597610354423523, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.38123899698257446, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30443310737609863, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.29468366503715515, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23209147155284882, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.34602972865104675, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2936866879463196, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3348921835422516, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.237514466047287, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5757701396942139, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2784577012062073, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.35364723205566406, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3044149875640869, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2548339366912842, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3315414786338806, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2798112630844116, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3233502507209778, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.23401623964309692, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.336033433675766, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.345938503742218, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.2785090506076813, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2815743684768677, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3805844187736511, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3277268409729004, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26851123571395874, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3509885370731354, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.41053640842437744, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.36877647042274475, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21894259750843048, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.41018134355545044, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3516836166381836, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3016168475151062, \"iteration\": 535, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.34010177850723267, \"iteration\": 536, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3388558328151703, \"iteration\": 537, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.30005544424057007, \"iteration\": 538, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33926790952682495, \"iteration\": 539, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4343600273132324, \"iteration\": 540, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.27414101362228394, \"iteration\": 541, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3274959623813629, \"iteration\": 542, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3731550872325897, \"iteration\": 543, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.383480429649353, \"iteration\": 544, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.34598132967948914, \"iteration\": 545, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.38471922278404236, \"iteration\": 546, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.38416844606399536, \"iteration\": 547, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.39669305086135864, \"iteration\": 548, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3085483908653259, \"iteration\": 549, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.41720449924468994, \"iteration\": 550, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3801041841506958, \"iteration\": 551, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.35019451379776, \"iteration\": 552, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3454504609107971, \"iteration\": 553, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3481307029724121, \"iteration\": 554, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3628300726413727, \"iteration\": 555, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.350958913564682, \"iteration\": 556, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.38294124603271484, \"iteration\": 557, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.263650119304657, \"iteration\": 558, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.37462663650512695, \"iteration\": 559, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.29996949434280396, \"iteration\": 560, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3597866892814636, \"iteration\": 561, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3166177570819855, \"iteration\": 562, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.4183911085128784, \"iteration\": 563, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.32247838377952576, \"iteration\": 564, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3417978882789612, \"iteration\": 565, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3694884181022644, \"iteration\": 566, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3190077543258667, \"iteration\": 567, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.4042147994041443, \"iteration\": 568, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.313991516828537, \"iteration\": 569, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3258429169654846, \"iteration\": 570, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.30732354521751404, \"iteration\": 571, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.32436174154281616, \"iteration\": 572, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33572375774383545, \"iteration\": 573, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3136554956436157, \"iteration\": 574, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4069625735282898, \"iteration\": 575, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.35826122760772705, \"iteration\": 576, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 0.4200739860534668, \"iteration\": 577, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.36301329731941223, \"iteration\": 578, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29446810483932495, \"iteration\": 579, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.38281092047691345, \"iteration\": 580, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.454120397567749, \"iteration\": 581, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30703026056289673, \"iteration\": 582, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.36324894428253174, \"iteration\": 583, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.37050288915634155, \"iteration\": 584, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.3997267484664917, \"iteration\": 585, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.24236047267913818, \"iteration\": 586, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 0.46988779306411743, \"iteration\": 587, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3484013080596924, \"iteration\": 588, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3376375436782837, \"iteration\": 589, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.37887901067733765, \"iteration\": 590, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 0.43761709332466125, \"iteration\": 591, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 0.45550909638404846, \"iteration\": 592, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3106294572353363, \"iteration\": 593, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.34151986241340637, \"iteration\": 594, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.38912835717201233, \"iteration\": 595, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2843843698501587, \"iteration\": 596, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3264763653278351, \"iteration\": 597, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.3814602494239807, \"iteration\": 598, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4024379849433899, \"iteration\": 599, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.4236385226249695, \"iteration\": 600, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3643759489059448, \"iteration\": 601, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3366874158382416, \"iteration\": 602, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.33578765392303467, \"iteration\": 603, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.367786705493927, \"iteration\": 604, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.32484233379364014, \"iteration\": 605, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4021725058555603, \"iteration\": 606, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.3527901768684387, \"iteration\": 607, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32447493076324463, \"iteration\": 608, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.361911416053772, \"iteration\": 609, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.30261170864105225, \"iteration\": 610, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3338438868522644, \"iteration\": 611, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40818625688552856, \"iteration\": 612, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3421195447444916, \"iteration\": 613, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3177233934402466, \"iteration\": 614, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.294659286737442, \"iteration\": 615, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 0.48567309975624084, \"iteration\": 616, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3160756826400757, \"iteration\": 617, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 0.44577014446258545, \"iteration\": 618, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.42287904024124146, \"iteration\": 619, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3776665925979614, \"iteration\": 620, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3298493027687073, \"iteration\": 621, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.42573344707489014, \"iteration\": 622, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3570718467235565, \"iteration\": 623, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3671714663505554, \"iteration\": 624, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.38828665018081665, \"iteration\": 625, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.4329349398612976, \"iteration\": 626, \"epoch\": 3}, {\"training_acc\": 0.8571428571428571, \"training_loss\": 0.4564898610115051, \"iteration\": 627, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2523868680000305, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24937567114830017, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2260737419128418, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23546545207500458, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.29778990149497986, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2538380026817322, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24259714782238007, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22593645751476288, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1788628250360489, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23462003469467163, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2358916997909546, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.29125499725341797, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.260065495967865, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2462312877178192, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.24973581731319427, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.311551034450531, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.22752568125724792, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.23466692864894867, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.23420265316963196, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 0.37540316581726074, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2457635998725891, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20097455382347107, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.1967679262161255, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28112301230430603, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.26430460810661316, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.22797295451164246, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2629357874393463, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1805267632007599, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.24707642197608948, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18678557872772217, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.1845637708902359, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22542725503444672, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.342160165309906, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.3360341787338257, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28141191601753235, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.23760980367660522, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.21444642543792725, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.19290503859519958, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.2924760580062866, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.29565542936325073, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.23385196924209595, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17651133239269257, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28279754519462585, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32659244537353516, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2440745234489441, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24716529250144958, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24867677688598633, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3304564952850342, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26481589674949646, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.30656713247299194, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2493152916431427, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2692549228668213, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.2893671989440918, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24885423481464386, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.25732421875, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1763993501663208, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2610419690608978, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2589185833930969, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24988757073879242, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24109038710594177, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.28638583421707153, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.23313786089420319, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24596433341503143, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1885128915309906, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2240801751613617, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.27417850494384766, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27052807807922363, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.3964378535747528, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.25608688592910767, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2713146209716797, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.22633585333824158, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.27613961696624756, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.26580825448036194, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32590198516845703, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.28294166922569275, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2027530074119568, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22602957487106323, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.25180912017822266, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2956867814064026, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.25979897379875183, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2224624752998352, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28549888730049133, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3127048909664154, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2911052107810974, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31110116839408875, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2985994815826416, \"iteration\": 713, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24120821058750153, \"iteration\": 714, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33888667821884155, \"iteration\": 715, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2915080189704895, \"iteration\": 716, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.32749447226524353, \"iteration\": 717, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.18119508028030396, \"iteration\": 718, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.27005141973495483, \"iteration\": 719, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.30672597885131836, \"iteration\": 720, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.30281877517700195, \"iteration\": 721, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2192516028881073, \"iteration\": 722, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2752593159675598, \"iteration\": 723, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29493552446365356, \"iteration\": 724, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.24376121163368225, \"iteration\": 725, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2618715763092041, \"iteration\": 726, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3287432789802551, \"iteration\": 727, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19503173232078552, \"iteration\": 728, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.26289623975753784, \"iteration\": 729, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.23758165538311005, \"iteration\": 730, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.2979238033294678, \"iteration\": 731, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.3284642696380615, \"iteration\": 732, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2985338568687439, \"iteration\": 733, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3249090611934662, \"iteration\": 734, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2684623599052429, \"iteration\": 735, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28635841608047485, \"iteration\": 736, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.33435702323913574, \"iteration\": 737, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30764418840408325, \"iteration\": 738, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3039770722389221, \"iteration\": 739, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.19304361939430237, \"iteration\": 740, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22898530960083008, \"iteration\": 741, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2134910225868225, \"iteration\": 742, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 0.35206401348114014, \"iteration\": 743, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3027891516685486, \"iteration\": 744, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2278452217578888, \"iteration\": 745, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2591085731983185, \"iteration\": 746, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3357057571411133, \"iteration\": 747, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28624090552330017, \"iteration\": 748, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3225204646587372, \"iteration\": 749, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20445990562438965, \"iteration\": 750, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.33165714144706726, \"iteration\": 751, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.3568519651889801, \"iteration\": 752, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.29672372341156006, \"iteration\": 753, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.26781731843948364, \"iteration\": 754, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4522094428539276, \"iteration\": 755, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.3199586272239685, \"iteration\": 756, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.31080663204193115, \"iteration\": 757, \"epoch\": 4}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3698602318763733, \"iteration\": 758, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.26360294222831726, \"iteration\": 759, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2299347221851349, \"iteration\": 760, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.23955994844436646, \"iteration\": 761, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2515409290790558, \"iteration\": 762, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2789783775806427, \"iteration\": 763, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1873750537633896, \"iteration\": 764, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.31003040075302124, \"iteration\": 765, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.24798209965229034, \"iteration\": 766, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2621326744556427, \"iteration\": 767, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.32382717728614807, \"iteration\": 768, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.21415740251541138, \"iteration\": 769, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3947919011116028, \"iteration\": 770, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27972668409347534, \"iteration\": 771, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.33651039004325867, \"iteration\": 772, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24673087894916534, \"iteration\": 773, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2286663055419922, \"iteration\": 774, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2608005404472351, \"iteration\": 775, \"epoch\": 4}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4349699914455414, \"iteration\": 776, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.21416206657886505, \"iteration\": 777, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29281550645828247, \"iteration\": 778, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.23447078466415405, \"iteration\": 779, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2477634698152542, \"iteration\": 780, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2503547668457031, \"iteration\": 781, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2800464928150177, \"iteration\": 782, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3272132873535156, \"iteration\": 783, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.3295609951019287, \"iteration\": 784, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.26640406250953674, \"iteration\": 785, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2696582078933716, \"iteration\": 786, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.30774828791618347, \"iteration\": 787, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 0.36886775493621826, \"iteration\": 788, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.25608253479003906, \"iteration\": 789, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.21338877081871033, \"iteration\": 790, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3244534730911255, \"iteration\": 791, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24640224874019623, \"iteration\": 792, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 0.4402366280555725, \"iteration\": 793, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3034994304180145, \"iteration\": 794, \"epoch\": 4}, {\"training_acc\": 0.8203125, \"training_loss\": 0.40543127059936523, \"iteration\": 795, \"epoch\": 4}, {\"training_acc\": 0.8046875, \"training_loss\": 0.47196292877197266, \"iteration\": 796, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3076501488685608, \"iteration\": 797, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.27485477924346924, \"iteration\": 798, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2772220969200134, \"iteration\": 799, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.34857749938964844, \"iteration\": 800, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.354999840259552, \"iteration\": 801, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2684820294380188, \"iteration\": 802, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32991036772727966, \"iteration\": 803, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.29040879011154175, \"iteration\": 804, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2760609984397888, \"iteration\": 805, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.310690701007843, \"iteration\": 806, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.4261886477470398, \"iteration\": 807, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.23819294571876526, \"iteration\": 808, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 0.36831703782081604, \"iteration\": 809, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24223199486732483, \"iteration\": 810, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.3168001174926758, \"iteration\": 811, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34372037649154663, \"iteration\": 812, \"epoch\": 4}, {\"training_acc\": 0.796875, \"training_loss\": 0.34770137071609497, \"iteration\": 813, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2390403002500534, \"iteration\": 814, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29169225692749023, \"iteration\": 815, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3043959438800812, \"iteration\": 816, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 0.34188154339790344, \"iteration\": 817, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.2992601990699768, \"iteration\": 818, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.22051353752613068, \"iteration\": 819, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.16537830233573914, \"iteration\": 820, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32311922311782837, \"iteration\": 821, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3765993118286133, \"iteration\": 822, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.294630765914917, \"iteration\": 823, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3055048882961273, \"iteration\": 824, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.35962149500846863, \"iteration\": 825, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.34575867652893066, \"iteration\": 826, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3019830584526062, \"iteration\": 827, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.34213054180145264, \"iteration\": 828, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2912749946117401, \"iteration\": 829, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2920684814453125, \"iteration\": 830, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.24350784718990326, \"iteration\": 831, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28078973293304443, \"iteration\": 832, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.33456140756607056, \"iteration\": 833, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.3195425570011139, \"iteration\": 834, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.2928842008113861, \"iteration\": 835, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.19712629914283752, \"iteration\": 836, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17670336365699768, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.17785358428955078, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.20798662304878235, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.19062602519989014, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.18136483430862427, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16020411252975464, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2166375368833542, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.18384036421775818, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.20223131775856018, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20709869265556335, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.22745463252067566, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.24728062748908997, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 0.2643030285835266, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.19626183807849884, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20201323926448822, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.15245366096496582, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.23014631867408752, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.15699583292007446, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1264691948890686, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2117748260498047, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17157229781150818, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.146236389875412, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2003300040960312, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.18449652194976807, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1657329797744751, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21363800764083862, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13761816918849945, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.16705632209777832, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.17120765149593353, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2570386528968811, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20858289301395416, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.167019322514534, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15590956807136536, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17083047330379486, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1280660480260849, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.22022873163223267, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15516364574432373, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.19337013363838196, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18170878291130066, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.19647648930549622, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.20165720582008362, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18323346972465515, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.15391980111598969, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21462951600551605, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.1579732447862625, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10659033805131912, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 0.19206726551055908, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.19737735390663147, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15965072810649872, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.25831905007362366, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15868306159973145, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2608638107776642, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.13989153504371643, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17704562842845917, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2508202791213989, \"iteration\": 891, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 0.24971245229244232, \"iteration\": 892, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.20113280415534973, \"iteration\": 893, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.21900779008865356, \"iteration\": 894, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.23436114192008972, \"iteration\": 895, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1327907145023346, \"iteration\": 896, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13749317824840546, \"iteration\": 897, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3331732451915741, \"iteration\": 898, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20748773217201233, \"iteration\": 899, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14974774420261383, \"iteration\": 900, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1891382485628128, \"iteration\": 901, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.11779268085956573, \"iteration\": 902, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.16417080163955688, \"iteration\": 903, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.199100524187088, \"iteration\": 904, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.20709623396396637, \"iteration\": 905, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22909218072891235, \"iteration\": 906, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15123826265335083, \"iteration\": 907, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2330569624900818, \"iteration\": 908, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.16260656714439392, \"iteration\": 909, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2231808602809906, \"iteration\": 910, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20225463807582855, \"iteration\": 911, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1957017034292221, \"iteration\": 912, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.16782939434051514, \"iteration\": 913, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2997993528842926, \"iteration\": 914, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1886708289384842, \"iteration\": 915, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19470973312854767, \"iteration\": 916, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18680904805660248, \"iteration\": 917, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.23352625966072083, \"iteration\": 918, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2058575451374054, \"iteration\": 919, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.12857139110565186, \"iteration\": 920, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22186210751533508, \"iteration\": 921, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33233922719955444, \"iteration\": 922, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.23493638634681702, \"iteration\": 923, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2418089359998703, \"iteration\": 924, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21465924382209778, \"iteration\": 925, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1782899796962738, \"iteration\": 926, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21112971007823944, \"iteration\": 927, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18543848395347595, \"iteration\": 928, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.21010828018188477, \"iteration\": 929, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1706756055355072, \"iteration\": 930, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 0.25915127992630005, \"iteration\": 931, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.30519720911979675, \"iteration\": 932, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.2329997420310974, \"iteration\": 933, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.1781211942434311, \"iteration\": 934, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.17271994054317474, \"iteration\": 935, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2340046614408493, \"iteration\": 936, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.14729300141334534, \"iteration\": 937, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.21574220061302185, \"iteration\": 938, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24676281213760376, \"iteration\": 939, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18409839272499084, \"iteration\": 940, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18238955736160278, \"iteration\": 941, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.20517680048942566, \"iteration\": 942, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.20478057861328125, \"iteration\": 943, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.16863292455673218, \"iteration\": 944, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23378488421440125, \"iteration\": 945, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.23033812642097473, \"iteration\": 946, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.2633569836616516, \"iteration\": 947, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.25484994053840637, \"iteration\": 948, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 0.27989035844802856, \"iteration\": 949, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.27141162753105164, \"iteration\": 950, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.15334272384643555, \"iteration\": 951, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.18346667289733887, \"iteration\": 952, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16745242476463318, \"iteration\": 953, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.21540769934654236, \"iteration\": 954, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.18870878219604492, \"iteration\": 955, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.21842114627361298, \"iteration\": 956, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.15963664650917053, \"iteration\": 957, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.21810689568519592, \"iteration\": 958, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23633024096488953, \"iteration\": 959, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1884276568889618, \"iteration\": 960, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.26624929904937744, \"iteration\": 961, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15504908561706543, \"iteration\": 962, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.18908044695854187, \"iteration\": 963, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.19810181856155396, \"iteration\": 964, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.20366881787776947, \"iteration\": 965, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19393330812454224, \"iteration\": 966, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1643214225769043, \"iteration\": 967, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1456594467163086, \"iteration\": 968, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1371471881866455, \"iteration\": 969, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2249603122472763, \"iteration\": 970, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.21783456206321716, \"iteration\": 971, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16104671359062195, \"iteration\": 972, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.2537045478820801, \"iteration\": 973, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2411661297082901, \"iteration\": 974, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.17089632153511047, \"iteration\": 975, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.19644398987293243, \"iteration\": 976, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20402076840400696, \"iteration\": 977, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15830951929092407, \"iteration\": 978, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19787797331809998, \"iteration\": 979, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2219003140926361, \"iteration\": 980, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18031743168830872, \"iteration\": 981, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20164355635643005, \"iteration\": 982, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2547997236251831, \"iteration\": 983, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.19838693737983704, \"iteration\": 984, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2329610288143158, \"iteration\": 985, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.3035765588283539, \"iteration\": 986, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.25785040855407715, \"iteration\": 987, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22371602058410645, \"iteration\": 988, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.2853906750679016, \"iteration\": 989, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20301185548305511, \"iteration\": 990, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18193496763706207, \"iteration\": 991, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1403781622648239, \"iteration\": 992, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.24223825335502625, \"iteration\": 993, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15161272883415222, \"iteration\": 994, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.15955474972724915, \"iteration\": 995, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.12472453713417053, \"iteration\": 996, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.18931029736995697, \"iteration\": 997, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17572318017482758, \"iteration\": 998, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 0.31056371331214905, \"iteration\": 999, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.17035391926765442, \"iteration\": 1000, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.25898244976997375, \"iteration\": 1001, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2407703399658203, \"iteration\": 1002, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 0.3232528865337372, \"iteration\": 1003, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.21125099062919617, \"iteration\": 1004, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 0.28344428539276123, \"iteration\": 1005, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2210119217634201, \"iteration\": 1006, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19851385056972504, \"iteration\": 1007, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14242053031921387, \"iteration\": 1008, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.2110299915075302, \"iteration\": 1009, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19747155904769897, \"iteration\": 1010, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.15754596889019012, \"iteration\": 1011, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.212276428937912, \"iteration\": 1012, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 0.24274155497550964, \"iteration\": 1013, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2556162476539612, \"iteration\": 1014, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18820036947727203, \"iteration\": 1015, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1391986906528473, \"iteration\": 1016, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22133484482765198, \"iteration\": 1017, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2396821826696396, \"iteration\": 1018, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18321013450622559, \"iteration\": 1019, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22637373208999634, \"iteration\": 1020, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.24432328343391418, \"iteration\": 1021, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.23689937591552734, \"iteration\": 1022, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11501524597406387, \"iteration\": 1023, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13977846503257751, \"iteration\": 1024, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.17724554240703583, \"iteration\": 1025, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.19842848181724548, \"iteration\": 1026, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.26998499035835266, \"iteration\": 1027, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.22716093063354492, \"iteration\": 1028, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22425219416618347, \"iteration\": 1029, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19451788067817688, \"iteration\": 1030, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21508419513702393, \"iteration\": 1031, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2529343366622925, \"iteration\": 1032, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2500363290309906, \"iteration\": 1033, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.258206844329834, \"iteration\": 1034, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22055897116661072, \"iteration\": 1035, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.22909826040267944, \"iteration\": 1036, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20508743822574615, \"iteration\": 1037, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15617677569389343, \"iteration\": 1038, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.23120857775211334, \"iteration\": 1039, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14440926909446716, \"iteration\": 1040, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19754207134246826, \"iteration\": 1041, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2912555932998657, \"iteration\": 1042, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1725965142250061, \"iteration\": 1043, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2898734509944916, \"iteration\": 1044, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.22007745504379272, \"iteration\": 1045, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15148431062698364, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.13601788878440857, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13922995328903198, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.115842804312706, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10964670032262802, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11784817278385162, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11765322089195251, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07716456055641174, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.13002437353134155, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1300475299358368, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11835963279008865, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09078558534383774, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05530073121190071, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05788295343518257, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07172688841819763, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10956373810768127, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1380215585231781, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.1500820815563202, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07196933031082153, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08080824464559555, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07460331916809082, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.12162745743989944, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08178996294736862, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.080001100897789, \"iteration\": 1069, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13977381587028503, \"iteration\": 1070, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.14916838705539703, \"iteration\": 1071, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07340465486049652, \"iteration\": 1072, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0684686154127121, \"iteration\": 1073, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09279456734657288, \"iteration\": 1074, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08486929535865784, \"iteration\": 1075, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09975410252809525, \"iteration\": 1076, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12647412717342377, \"iteration\": 1077, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0712796077132225, \"iteration\": 1078, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06511875987052917, \"iteration\": 1079, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07841826230287552, \"iteration\": 1080, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12944330275058746, \"iteration\": 1081, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12126867473125458, \"iteration\": 1082, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.16032516956329346, \"iteration\": 1083, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12084103375673294, \"iteration\": 1084, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.06827288866043091, \"iteration\": 1085, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0750809758901596, \"iteration\": 1086, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10533730685710907, \"iteration\": 1087, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11140948534011841, \"iteration\": 1088, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08523112535476685, \"iteration\": 1089, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09090787172317505, \"iteration\": 1090, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06269566714763641, \"iteration\": 1091, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08797609061002731, \"iteration\": 1092, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12348037958145142, \"iteration\": 1093, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.1580953598022461, \"iteration\": 1094, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0638810396194458, \"iteration\": 1095, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.082308828830719, \"iteration\": 1096, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11636587232351303, \"iteration\": 1097, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10602452605962753, \"iteration\": 1098, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12115012854337692, \"iteration\": 1099, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06985577940940857, \"iteration\": 1100, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.13266687095165253, \"iteration\": 1101, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16042274236679077, \"iteration\": 1102, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07772725075483322, \"iteration\": 1103, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05558313801884651, \"iteration\": 1104, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08968251198530197, \"iteration\": 1105, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11609393358230591, \"iteration\": 1106, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12569651007652283, \"iteration\": 1107, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09830664098262787, \"iteration\": 1108, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07727563381195068, \"iteration\": 1109, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10933484137058258, \"iteration\": 1110, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0780596137046814, \"iteration\": 1111, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1287454068660736, \"iteration\": 1112, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10737761855125427, \"iteration\": 1113, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.12519079446792603, \"iteration\": 1114, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.17909124493598938, \"iteration\": 1115, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11895458400249481, \"iteration\": 1116, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.12922702729701996, \"iteration\": 1117, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11326920986175537, \"iteration\": 1118, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08571181446313858, \"iteration\": 1119, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11796878278255463, \"iteration\": 1120, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0689326748251915, \"iteration\": 1121, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07559932768344879, \"iteration\": 1122, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.061606548726558685, \"iteration\": 1123, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08375388383865356, \"iteration\": 1124, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08367739617824554, \"iteration\": 1125, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09971720725297928, \"iteration\": 1126, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.12109597027301788, \"iteration\": 1127, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07827518880367279, \"iteration\": 1128, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13619942963123322, \"iteration\": 1129, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1644725799560547, \"iteration\": 1130, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06874136626720428, \"iteration\": 1131, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09497193992137909, \"iteration\": 1132, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.09976021945476532, \"iteration\": 1133, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08511443436145782, \"iteration\": 1134, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07891897857189178, \"iteration\": 1135, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.05680594593286514, \"iteration\": 1136, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0645727664232254, \"iteration\": 1137, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1381714791059494, \"iteration\": 1138, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11930558830499649, \"iteration\": 1139, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.096389040350914, \"iteration\": 1140, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07308612763881683, \"iteration\": 1141, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08073265850543976, \"iteration\": 1142, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1889324188232422, \"iteration\": 1143, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11036042869091034, \"iteration\": 1144, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.051738642156124115, \"iteration\": 1145, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09477826207876205, \"iteration\": 1146, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1571599394083023, \"iteration\": 1147, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05564669519662857, \"iteration\": 1148, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11135504394769669, \"iteration\": 1149, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08967343717813492, \"iteration\": 1150, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1264537274837494, \"iteration\": 1151, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11078988760709763, \"iteration\": 1152, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06823626160621643, \"iteration\": 1153, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07082726061344147, \"iteration\": 1154, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06863526254892349, \"iteration\": 1155, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05796133354306221, \"iteration\": 1156, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09423650801181793, \"iteration\": 1157, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09971050173044205, \"iteration\": 1158, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05978049337863922, \"iteration\": 1159, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09097980707883835, \"iteration\": 1160, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.058698929846286774, \"iteration\": 1161, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.17071163654327393, \"iteration\": 1162, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.09655328094959259, \"iteration\": 1163, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06418725848197937, \"iteration\": 1164, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1606285721063614, \"iteration\": 1165, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09591832011938095, \"iteration\": 1166, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.14871953427791595, \"iteration\": 1167, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11350445449352264, \"iteration\": 1168, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10894911736249924, \"iteration\": 1169, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06172367185354233, \"iteration\": 1170, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.1099153682589531, \"iteration\": 1171, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11181018501520157, \"iteration\": 1172, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06869775056838989, \"iteration\": 1173, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.12457114458084106, \"iteration\": 1174, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11116603016853333, \"iteration\": 1175, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13637834787368774, \"iteration\": 1176, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06918498128652573, \"iteration\": 1177, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.08885176479816437, \"iteration\": 1178, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0471075102686882, \"iteration\": 1179, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12851004302501678, \"iteration\": 1180, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06908577680587769, \"iteration\": 1181, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12594690918922424, \"iteration\": 1182, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12157370895147324, \"iteration\": 1183, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11352985352277756, \"iteration\": 1184, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10302513837814331, \"iteration\": 1185, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05219808220863342, \"iteration\": 1186, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04060504585504532, \"iteration\": 1187, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16086527705192566, \"iteration\": 1188, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.16460010409355164, \"iteration\": 1189, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.07125614583492279, \"iteration\": 1190, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08772095292806625, \"iteration\": 1191, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10005386918783188, \"iteration\": 1192, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.17320841550827026, \"iteration\": 1193, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08472773432731628, \"iteration\": 1194, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12710486352443695, \"iteration\": 1195, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1052873283624649, \"iteration\": 1196, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.09732231497764587, \"iteration\": 1197, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09105682373046875, \"iteration\": 1198, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11951462179422379, \"iteration\": 1199, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.035492733120918274, \"iteration\": 1200, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11431194841861725, \"iteration\": 1201, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07656921446323395, \"iteration\": 1202, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09996334463357925, \"iteration\": 1203, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09445951879024506, \"iteration\": 1204, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07050173729658127, \"iteration\": 1205, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0898171216249466, \"iteration\": 1206, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.13642257452011108, \"iteration\": 1207, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04943199083209038, \"iteration\": 1208, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06913578510284424, \"iteration\": 1209, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12264160066843033, \"iteration\": 1210, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09352245926856995, \"iteration\": 1211, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10100919753313065, \"iteration\": 1212, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0908479243516922, \"iteration\": 1213, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.09847714006900787, \"iteration\": 1214, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1111721396446228, \"iteration\": 1215, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11423355340957642, \"iteration\": 1216, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1271960735321045, \"iteration\": 1217, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0841565728187561, \"iteration\": 1218, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07915414869785309, \"iteration\": 1219, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12260667979717255, \"iteration\": 1220, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11656998097896576, \"iteration\": 1221, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11607822775840759, \"iteration\": 1222, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04846567660570145, \"iteration\": 1223, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08914443850517273, \"iteration\": 1224, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054252736270427704, \"iteration\": 1225, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.16331660747528076, \"iteration\": 1226, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06981853395700455, \"iteration\": 1227, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07855448126792908, \"iteration\": 1228, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07972092926502228, \"iteration\": 1229, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.06480579078197479, \"iteration\": 1230, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.12234949320554733, \"iteration\": 1231, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.09198376536369324, \"iteration\": 1232, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1569792926311493, \"iteration\": 1233, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04457051306962967, \"iteration\": 1234, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.09943937510251999, \"iteration\": 1235, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11020378023386002, \"iteration\": 1236, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.06589637696743011, \"iteration\": 1237, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13814593851566315, \"iteration\": 1238, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0949651300907135, \"iteration\": 1239, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08302103728055954, \"iteration\": 1240, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07948754727840424, \"iteration\": 1241, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 0.17355558276176453, \"iteration\": 1242, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.063756562769413, \"iteration\": 1243, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08376026153564453, \"iteration\": 1244, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08707243949174881, \"iteration\": 1245, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1172364130616188, \"iteration\": 1246, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07622888684272766, \"iteration\": 1247, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.06773863732814789, \"iteration\": 1248, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11077640950679779, \"iteration\": 1249, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09635721147060394, \"iteration\": 1250, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09653355926275253, \"iteration\": 1251, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10352285206317902, \"iteration\": 1252, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07691816240549088, \"iteration\": 1253, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04623762145638466, \"iteration\": 1254, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.025006216019392014, \"iteration\": 1255, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10250091552734375, \"iteration\": 1256, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03199341520667076, \"iteration\": 1257, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02987835556268692, \"iteration\": 1258, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02246355637907982, \"iteration\": 1259, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.037558361887931824, \"iteration\": 1260, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03963179886341095, \"iteration\": 1261, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.09679634869098663, \"iteration\": 1262, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.026894399896264076, \"iteration\": 1263, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04983527585864067, \"iteration\": 1264, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02293371595442295, \"iteration\": 1265, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024377141147851944, \"iteration\": 1266, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02246035262942314, \"iteration\": 1267, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054807450622320175, \"iteration\": 1268, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022608917206525803, \"iteration\": 1269, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04271858185529709, \"iteration\": 1270, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022609440609812737, \"iteration\": 1271, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027935508638620377, \"iteration\": 1272, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.037444401532411575, \"iteration\": 1273, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016469281166791916, \"iteration\": 1274, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.025793038308620453, \"iteration\": 1275, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.04439591243863106, \"iteration\": 1276, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05770719796419144, \"iteration\": 1277, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05428996682167053, \"iteration\": 1278, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.034357957541942596, \"iteration\": 1279, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.023482847958803177, \"iteration\": 1280, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03782543167471886, \"iteration\": 1281, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02629886195063591, \"iteration\": 1282, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02431638538837433, \"iteration\": 1283, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01784777082502842, \"iteration\": 1284, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016173355281352997, \"iteration\": 1285, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016261551529169083, \"iteration\": 1286, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.05833837762475014, \"iteration\": 1287, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031777024269104004, \"iteration\": 1288, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014706202782690525, \"iteration\": 1289, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01731092855334282, \"iteration\": 1290, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02088986337184906, \"iteration\": 1291, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032432056963443756, \"iteration\": 1292, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0186600424349308, \"iteration\": 1293, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014679249376058578, \"iteration\": 1294, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06561705470085144, \"iteration\": 1295, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011867472901940346, \"iteration\": 1296, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.017133792862296104, \"iteration\": 1297, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01653607189655304, \"iteration\": 1298, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04948236048221588, \"iteration\": 1299, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.045321665704250336, \"iteration\": 1300, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.04823482036590576, \"iteration\": 1301, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03710586205124855, \"iteration\": 1302, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.040055468678474426, \"iteration\": 1303, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024608492851257324, \"iteration\": 1304, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06273909658193588, \"iteration\": 1305, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.034994736313819885, \"iteration\": 1306, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015287666581571102, \"iteration\": 1307, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015246990136802197, \"iteration\": 1308, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028848227113485336, \"iteration\": 1309, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06898294389247894, \"iteration\": 1310, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.017352186143398285, \"iteration\": 1311, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.026557859033346176, \"iteration\": 1312, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.018767952919006348, \"iteration\": 1313, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016008008271455765, \"iteration\": 1314, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012702012434601784, \"iteration\": 1315, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028345806524157524, \"iteration\": 1316, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040094777941703796, \"iteration\": 1317, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02448282763361931, \"iteration\": 1318, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022077899426221848, \"iteration\": 1319, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02583451196551323, \"iteration\": 1320, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016987580806016922, \"iteration\": 1321, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11577488481998444, \"iteration\": 1322, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03964213281869888, \"iteration\": 1323, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03266354650259018, \"iteration\": 1324, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.04977324232459068, \"iteration\": 1325, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.023890672251582146, \"iteration\": 1326, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02239309810101986, \"iteration\": 1327, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.034843191504478455, \"iteration\": 1328, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.04424799978733063, \"iteration\": 1329, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016129273921251297, \"iteration\": 1330, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.028988000005483627, \"iteration\": 1331, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02133217826485634, \"iteration\": 1332, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02600282058119774, \"iteration\": 1333, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03579256683588028, \"iteration\": 1334, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.036013346165418625, \"iteration\": 1335, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.04206734150648117, \"iteration\": 1336, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016655558720231056, \"iteration\": 1337, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.04707664996385574, \"iteration\": 1338, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06275500357151031, \"iteration\": 1339, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02271352708339691, \"iteration\": 1340, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014283419586718082, \"iteration\": 1341, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01740877330303192, \"iteration\": 1342, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0358857624232769, \"iteration\": 1343, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01691070944070816, \"iteration\": 1344, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03332297503948212, \"iteration\": 1345, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.050223566591739655, \"iteration\": 1346, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02264033444225788, \"iteration\": 1347, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015857957303524017, \"iteration\": 1348, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.020869940519332886, \"iteration\": 1349, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02143758349120617, \"iteration\": 1350, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03132443130016327, \"iteration\": 1351, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.037795573472976685, \"iteration\": 1352, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03171195089817047, \"iteration\": 1353, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012583988718688488, \"iteration\": 1354, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014639832079410553, \"iteration\": 1355, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.017144348472356796, \"iteration\": 1356, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.030537353828549385, \"iteration\": 1357, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026589803397655487, \"iteration\": 1358, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014471447095274925, \"iteration\": 1359, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.021976836025714874, \"iteration\": 1360, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01820531114935875, \"iteration\": 1361, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.025832297280430794, \"iteration\": 1362, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0397379994392395, \"iteration\": 1363, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.035947419703006744, \"iteration\": 1364, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05610334500670433, \"iteration\": 1365, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009527893736958504, \"iteration\": 1366, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0182456336915493, \"iteration\": 1367, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027626700699329376, \"iteration\": 1368, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028056755661964417, \"iteration\": 1369, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02494787983596325, \"iteration\": 1370, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.018099866807460785, \"iteration\": 1371, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0327894352376461, \"iteration\": 1372, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.020724251866340637, \"iteration\": 1373, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02090635523200035, \"iteration\": 1374, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05286503955721855, \"iteration\": 1375, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04250779747962952, \"iteration\": 1376, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.019493818283081055, \"iteration\": 1377, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02766522951424122, \"iteration\": 1378, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03835352510213852, \"iteration\": 1379, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02002229541540146, \"iteration\": 1380, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03163180500268936, \"iteration\": 1381, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.023585889488458633, \"iteration\": 1382, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011221026070415974, \"iteration\": 1383, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03106025792658329, \"iteration\": 1384, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021182693541049957, \"iteration\": 1385, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.021803682669997215, \"iteration\": 1386, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06012152507901192, \"iteration\": 1387, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02118682861328125, \"iteration\": 1388, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03531692177057266, \"iteration\": 1389, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.055656224489212036, \"iteration\": 1390, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0363222137093544, \"iteration\": 1391, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.017690781503915787, \"iteration\": 1392, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04325432702898979, \"iteration\": 1393, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011490619741380215, \"iteration\": 1394, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01230192743241787, \"iteration\": 1395, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07065488398075104, \"iteration\": 1396, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01693296991288662, \"iteration\": 1397, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024277212098240852, \"iteration\": 1398, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05601666867733002, \"iteration\": 1399, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08116437494754791, \"iteration\": 1400, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.061907462775707245, \"iteration\": 1401, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012588213197886944, \"iteration\": 1402, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02675139158964157, \"iteration\": 1403, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02362731471657753, \"iteration\": 1404, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024322520941495895, \"iteration\": 1405, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030447667464613914, \"iteration\": 1406, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015909096226096153, \"iteration\": 1407, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.06941026449203491, \"iteration\": 1408, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016959071159362793, \"iteration\": 1409, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012937158346176147, \"iteration\": 1410, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02510138228535652, \"iteration\": 1411, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02002554200589657, \"iteration\": 1412, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02926437370479107, \"iteration\": 1413, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.09727071225643158, \"iteration\": 1414, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03292103856801987, \"iteration\": 1415, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02819395437836647, \"iteration\": 1416, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016508061438798904, \"iteration\": 1417, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02562440186738968, \"iteration\": 1418, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026527034118771553, \"iteration\": 1419, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02604038268327713, \"iteration\": 1420, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031362224370241165, \"iteration\": 1421, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.049539387226104736, \"iteration\": 1422, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023918338119983673, \"iteration\": 1423, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024791399016976357, \"iteration\": 1424, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01678507588803768, \"iteration\": 1425, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026052530854940414, \"iteration\": 1426, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06297934800386429, \"iteration\": 1427, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05332468822598457, \"iteration\": 1428, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010842325165867805, \"iteration\": 1429, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.09383775293827057, \"iteration\": 1430, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.033260345458984375, \"iteration\": 1431, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02140340767800808, \"iteration\": 1432, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016933193430304527, \"iteration\": 1433, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.08731713891029358, \"iteration\": 1434, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04307398945093155, \"iteration\": 1435, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04724540933966637, \"iteration\": 1436, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0327443853020668, \"iteration\": 1437, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046605564653873444, \"iteration\": 1438, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02174394205212593, \"iteration\": 1439, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.026872480288147926, \"iteration\": 1440, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02246195450425148, \"iteration\": 1441, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.017576903104782104, \"iteration\": 1442, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.045887161046266556, \"iteration\": 1443, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.019390160217881203, \"iteration\": 1444, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.026745175942778587, \"iteration\": 1445, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04201663285493851, \"iteration\": 1446, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.020769517868757248, \"iteration\": 1447, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01627204567193985, \"iteration\": 1448, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.025494974106550217, \"iteration\": 1449, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032243963330984116, \"iteration\": 1450, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014093420468270779, \"iteration\": 1451, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027367278933525085, \"iteration\": 1452, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.023120040073990822, \"iteration\": 1453, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010679090395569801, \"iteration\": 1454, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0399162583053112, \"iteration\": 1455, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04213668778538704, \"iteration\": 1456, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01702301576733589, \"iteration\": 1457, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03641655296087265, \"iteration\": 1458, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.020683085545897484, \"iteration\": 1459, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02558024786412716, \"iteration\": 1460, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012828877195715904, \"iteration\": 1461, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022524509578943253, \"iteration\": 1462, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00784196425229311, \"iteration\": 1463, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006237571127712727, \"iteration\": 1464, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007882984355092049, \"iteration\": 1465, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007915015332400799, \"iteration\": 1466, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010573187842965126, \"iteration\": 1467, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010289633646607399, \"iteration\": 1468, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00619063014164567, \"iteration\": 1469, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004261169582605362, \"iteration\": 1470, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016050636768341064, \"iteration\": 1471, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00598895875737071, \"iteration\": 1472, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009901925921440125, \"iteration\": 1473, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004859303589910269, \"iteration\": 1474, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006457743234932423, \"iteration\": 1475, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00808789860457182, \"iteration\": 1476, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01327646616846323, \"iteration\": 1477, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004067765548825264, \"iteration\": 1478, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00442209467291832, \"iteration\": 1479, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01400807872414589, \"iteration\": 1480, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007322860881686211, \"iteration\": 1481, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0038533469196408987, \"iteration\": 1482, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00424390472471714, \"iteration\": 1483, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010166110470890999, \"iteration\": 1484, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007457420229911804, \"iteration\": 1485, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0033209931571036577, \"iteration\": 1486, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019369710236787796, \"iteration\": 1487, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004656053148210049, \"iteration\": 1488, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004557375330477953, \"iteration\": 1489, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007240755949169397, \"iteration\": 1490, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007407606579363346, \"iteration\": 1491, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009716036729514599, \"iteration\": 1492, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020684441551566124, \"iteration\": 1493, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006597318686544895, \"iteration\": 1494, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0030212856363505125, \"iteration\": 1495, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039019159972667694, \"iteration\": 1496, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0189055148512125, \"iteration\": 1497, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005457643885165453, \"iteration\": 1498, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003746466478332877, \"iteration\": 1499, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009318436495959759, \"iteration\": 1500, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008770434185862541, \"iteration\": 1501, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00358987576328218, \"iteration\": 1502, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0053238049149513245, \"iteration\": 1503, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004417573567479849, \"iteration\": 1504, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01176432240754366, \"iteration\": 1505, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007747145369648933, \"iteration\": 1506, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002708657179027796, \"iteration\": 1507, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.015693003311753273, \"iteration\": 1508, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0028503560461103916, \"iteration\": 1509, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011647511273622513, \"iteration\": 1510, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006381134502589703, \"iteration\": 1511, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00822906382381916, \"iteration\": 1512, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010395150631666183, \"iteration\": 1513, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04299178346991539, \"iteration\": 1514, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0077927010133862495, \"iteration\": 1515, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006620440632104874, \"iteration\": 1516, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005221195984631777, \"iteration\": 1517, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004464862868189812, \"iteration\": 1518, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0041665369644761086, \"iteration\": 1519, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006093861535191536, \"iteration\": 1520, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 0.022745642811059952, \"iteration\": 1521, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010007396340370178, \"iteration\": 1522, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020076898857951164, \"iteration\": 1523, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009211670607328415, \"iteration\": 1524, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003347888356074691, \"iteration\": 1525, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0030567236244678497, \"iteration\": 1526, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009285476058721542, \"iteration\": 1527, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0043997326865792274, \"iteration\": 1528, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007455266080796719, \"iteration\": 1529, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004341966472566128, \"iteration\": 1530, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0036591365933418274, \"iteration\": 1531, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003310492029413581, \"iteration\": 1532, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004929067101329565, \"iteration\": 1533, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00564241036772728, \"iteration\": 1534, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003829204011708498, \"iteration\": 1535, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003027309663593769, \"iteration\": 1536, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004215571563690901, \"iteration\": 1537, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002549797995015979, \"iteration\": 1538, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004551283083856106, \"iteration\": 1539, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0042993417009711266, \"iteration\": 1540, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005135079845786095, \"iteration\": 1541, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007273796480149031, \"iteration\": 1542, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008742528967559338, \"iteration\": 1543, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004381237085908651, \"iteration\": 1544, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0045253075659275055, \"iteration\": 1545, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004251381848007441, \"iteration\": 1546, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06665085256099701, \"iteration\": 1547, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0030928696505725384, \"iteration\": 1548, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004734403919428587, \"iteration\": 1549, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.014114513993263245, \"iteration\": 1550, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004051894415169954, \"iteration\": 1551, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006233288440853357, \"iteration\": 1552, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005540961865335703, \"iteration\": 1553, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004395888186991215, \"iteration\": 1554, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004667786881327629, \"iteration\": 1555, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0041086371056735516, \"iteration\": 1556, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005248721223324537, \"iteration\": 1557, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0043045636266469955, \"iteration\": 1558, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004576471168547869, \"iteration\": 1559, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0051778340712189674, \"iteration\": 1560, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 0.0398004874587059, \"iteration\": 1561, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025138957425951958, \"iteration\": 1562, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006789889186620712, \"iteration\": 1563, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0030197876039892435, \"iteration\": 1564, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003245764644816518, \"iteration\": 1565, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009035657159984112, \"iteration\": 1566, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030378583818674088, \"iteration\": 1567, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017801739741116762, \"iteration\": 1568, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0037805805914103985, \"iteration\": 1569, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006171436980366707, \"iteration\": 1570, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003457454964518547, \"iteration\": 1571, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004717984236776829, \"iteration\": 1572, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01105091068893671, \"iteration\": 1573, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005636563524603844, \"iteration\": 1574, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0031392029486596584, \"iteration\": 1575, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004017415456473827, \"iteration\": 1576, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013199239037930965, \"iteration\": 1577, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004814235959202051, \"iteration\": 1578, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03509601205587387, \"iteration\": 1579, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020860228687524796, \"iteration\": 1580, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0028871982358396053, \"iteration\": 1581, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0032566930167376995, \"iteration\": 1582, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.013583393767476082, \"iteration\": 1583, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0030288700945675373, \"iteration\": 1584, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002947626169770956, \"iteration\": 1585, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003601941280066967, \"iteration\": 1586, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002768114674836397, \"iteration\": 1587, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007593154441565275, \"iteration\": 1588, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0032123157288879156, \"iteration\": 1589, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006187986582517624, \"iteration\": 1590, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00557465897873044, \"iteration\": 1591, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03402409702539444, \"iteration\": 1592, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006319382693618536, \"iteration\": 1593, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00413580983877182, \"iteration\": 1594, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003420543624088168, \"iteration\": 1595, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0038393496070057154, \"iteration\": 1596, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003440616652369499, \"iteration\": 1597, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0033809063024818897, \"iteration\": 1598, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0027473969385027885, \"iteration\": 1599, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004124373663216829, \"iteration\": 1600, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007861263118684292, \"iteration\": 1601, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007012976799160242, \"iteration\": 1602, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0027312845923006535, \"iteration\": 1603, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028484221547842026, \"iteration\": 1604, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00544950645416975, \"iteration\": 1605, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0038852368015795946, \"iteration\": 1606, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022739998530596495, \"iteration\": 1607, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0030553555116057396, \"iteration\": 1608, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 0.05879657343029976, \"iteration\": 1609, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00626735296100378, \"iteration\": 1610, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004049320239573717, \"iteration\": 1611, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003210742026567459, \"iteration\": 1612, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006071224808692932, \"iteration\": 1613, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0025805141776800156, \"iteration\": 1614, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0047165327705442905, \"iteration\": 1615, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019339267164468765, \"iteration\": 1616, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 0.05825953185558319, \"iteration\": 1617, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.017472222447395325, \"iteration\": 1618, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009613094851374626, \"iteration\": 1619, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005068434402346611, \"iteration\": 1620, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004891716875135899, \"iteration\": 1621, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00486136507242918, \"iteration\": 1622, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004236131440848112, \"iteration\": 1623, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011545861139893532, \"iteration\": 1624, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005867946892976761, \"iteration\": 1625, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004285922273993492, \"iteration\": 1626, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003924790304154158, \"iteration\": 1627, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006515969522297382, \"iteration\": 1628, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006327275652438402, \"iteration\": 1629, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0049949283711612225, \"iteration\": 1630, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004532548598945141, \"iteration\": 1631, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00997396744787693, \"iteration\": 1632, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02517659030854702, \"iteration\": 1633, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005671931430697441, \"iteration\": 1634, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002783619798719883, \"iteration\": 1635, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016235608607530594, \"iteration\": 1636, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004493942018598318, \"iteration\": 1637, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004549453034996986, \"iteration\": 1638, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018101150169968605, \"iteration\": 1639, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005259661935269833, \"iteration\": 1640, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008347820490598679, \"iteration\": 1641, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002596792997792363, \"iteration\": 1642, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03410805016756058, \"iteration\": 1643, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005988512188196182, \"iteration\": 1644, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01407464500516653, \"iteration\": 1645, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003143908455967903, \"iteration\": 1646, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030836043879389763, \"iteration\": 1647, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023909397423267365, \"iteration\": 1648, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013362511992454529, \"iteration\": 1649, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007428630720824003, \"iteration\": 1650, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007285013794898987, \"iteration\": 1651, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010920623317360878, \"iteration\": 1652, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010115417651832104, \"iteration\": 1653, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0032371575944125652, \"iteration\": 1654, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007717301603406668, \"iteration\": 1655, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0033849840983748436, \"iteration\": 1656, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004322252236306667, \"iteration\": 1657, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009840462356805801, \"iteration\": 1658, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004613205324858427, \"iteration\": 1659, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0038539590314030647, \"iteration\": 1660, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003726017428562045, \"iteration\": 1661, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005943002179265022, \"iteration\": 1662, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006216912996023893, \"iteration\": 1663, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004260161425918341, \"iteration\": 1664, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00515440059825778, \"iteration\": 1665, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 0.05701051652431488, \"iteration\": 1666, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005073594395071268, \"iteration\": 1667, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0037727386225014925, \"iteration\": 1668, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002331880619749427, \"iteration\": 1669, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004882380831986666, \"iteration\": 1670, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004096372053027153, \"iteration\": 1671, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0033802269026637077, \"iteration\": 1672, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00644884305074811, \"iteration\": 1673, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014423548709601164, \"iteration\": 1674, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017557262908667326, \"iteration\": 1675, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003159312764182687, \"iteration\": 1676, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020334904547780752, \"iteration\": 1677, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021942248567938805, \"iteration\": 1678, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005314447917044163, \"iteration\": 1679, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002314985729753971, \"iteration\": 1680, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020623370073735714, \"iteration\": 1681, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019050739938393235, \"iteration\": 1682, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015583678614348173, \"iteration\": 1683, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015943893231451511, \"iteration\": 1684, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014741865452378988, \"iteration\": 1685, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002690458670258522, \"iteration\": 1686, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0052213724702596664, \"iteration\": 1687, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009620738564990461, \"iteration\": 1688, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003868592670187354, \"iteration\": 1689, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015041162259876728, \"iteration\": 1690, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018526655621826649, \"iteration\": 1691, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001368036842904985, \"iteration\": 1692, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015077649150043726, \"iteration\": 1693, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0053077577613294125, \"iteration\": 1694, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007910721004009247, \"iteration\": 1695, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0023609313648194075, \"iteration\": 1696, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0030656279996037483, \"iteration\": 1697, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00698583759367466, \"iteration\": 1698, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.011216646991670132, \"iteration\": 1699, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002866185735911131, \"iteration\": 1700, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018087434582412243, \"iteration\": 1701, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014537079259753227, \"iteration\": 1702, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0022579734213650227, \"iteration\": 1703, \"epoch\": 9}, {\"training_acc\": 0.984375, \"training_loss\": 0.022097205743193626, \"iteration\": 1704, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014027294237166643, \"iteration\": 1705, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001303971279412508, \"iteration\": 1706, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00622960552573204, \"iteration\": 1707, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013111312873661518, \"iteration\": 1708, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001100302441045642, \"iteration\": 1709, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015733417822048068, \"iteration\": 1710, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013178468216210604, \"iteration\": 1711, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0033275883179157972, \"iteration\": 1712, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004698925651609898, \"iteration\": 1713, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00147996935993433, \"iteration\": 1714, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013451463310047984, \"iteration\": 1715, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002129850210621953, \"iteration\": 1716, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013379345182329416, \"iteration\": 1717, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015286708949133754, \"iteration\": 1718, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05112798139452934, \"iteration\": 1719, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001866562059149146, \"iteration\": 1720, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012739822268486023, \"iteration\": 1721, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018922848394140601, \"iteration\": 1722, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010728520574048162, \"iteration\": 1723, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0027806609869003296, \"iteration\": 1724, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016921323258429766, \"iteration\": 1725, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004193080589175224, \"iteration\": 1726, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002991202985867858, \"iteration\": 1727, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001868936698883772, \"iteration\": 1728, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013690266059711576, \"iteration\": 1729, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001955369021743536, \"iteration\": 1730, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014846178237348795, \"iteration\": 1731, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025076267775148153, \"iteration\": 1732, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021981429308652878, \"iteration\": 1733, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009312027832493186, \"iteration\": 1734, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02232189103960991, \"iteration\": 1735, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014776794705539942, \"iteration\": 1736, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001538993208669126, \"iteration\": 1737, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012610615231096745, \"iteration\": 1738, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002041162922978401, \"iteration\": 1739, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016376643907278776, \"iteration\": 1740, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019095514435321093, \"iteration\": 1741, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0071629853919148445, \"iteration\": 1742, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014632117236033082, \"iteration\": 1743, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031283460557460785, \"iteration\": 1744, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008015648927539587, \"iteration\": 1745, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011242595501244068, \"iteration\": 1746, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002036735415458679, \"iteration\": 1747, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027657082304358482, \"iteration\": 1748, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007965682074427605, \"iteration\": 1749, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016694010701030493, \"iteration\": 1750, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025878725573420525, \"iteration\": 1751, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014957389794290066, \"iteration\": 1752, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021788650192320347, \"iteration\": 1753, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006759824231266975, \"iteration\": 1754, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021609521936625242, \"iteration\": 1755, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002428725128993392, \"iteration\": 1756, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013524063397198915, \"iteration\": 1757, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020130136981606483, \"iteration\": 1758, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017148565966635942, \"iteration\": 1759, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012416999088600278, \"iteration\": 1760, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009199295891448855, \"iteration\": 1761, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002531353384256363, \"iteration\": 1762, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005094404332339764, \"iteration\": 1763, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013563865795731544, \"iteration\": 1764, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001095927320420742, \"iteration\": 1765, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009835455566644669, \"iteration\": 1766, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014956635423004627, \"iteration\": 1767, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002718387870118022, \"iteration\": 1768, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001223765080794692, \"iteration\": 1769, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008843783871270716, \"iteration\": 1770, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008771511493250728, \"iteration\": 1771, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018453131197020411, \"iteration\": 1772, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008201968157663941, \"iteration\": 1773, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015468199271708727, \"iteration\": 1774, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019789007492363453, \"iteration\": 1775, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020548878237605095, \"iteration\": 1776, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012631095014512539, \"iteration\": 1777, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001810882706195116, \"iteration\": 1778, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015661504585295916, \"iteration\": 1779, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010906890965998173, \"iteration\": 1780, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014734093565493822, \"iteration\": 1781, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011232002871111035, \"iteration\": 1782, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015940420562401414, \"iteration\": 1783, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020298787858337164, \"iteration\": 1784, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025309212505817413, \"iteration\": 1785, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016528613632544875, \"iteration\": 1786, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018942933529615402, \"iteration\": 1787, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019374750554561615, \"iteration\": 1788, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0051283566281199455, \"iteration\": 1789, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0039028096944093704, \"iteration\": 1790, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012653958983719349, \"iteration\": 1791, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003185470588505268, \"iteration\": 1792, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011055561481043696, \"iteration\": 1793, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003166677663102746, \"iteration\": 1794, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017620621947571635, \"iteration\": 1795, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023304428905248642, \"iteration\": 1796, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001517819007858634, \"iteration\": 1797, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011620691511780024, \"iteration\": 1798, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001365695265121758, \"iteration\": 1799, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011215012054890394, \"iteration\": 1800, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018835398368537426, \"iteration\": 1801, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013124567922204733, \"iteration\": 1802, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018408952746540308, \"iteration\": 1803, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003304521320387721, \"iteration\": 1804, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017633240204304457, \"iteration\": 1805, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009297806536778808, \"iteration\": 1806, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012396310921758413, \"iteration\": 1807, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001393236918374896, \"iteration\": 1808, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019160781521350145, \"iteration\": 1809, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.009481720626354218, \"iteration\": 1810, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001571000786498189, \"iteration\": 1811, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015052068047225475, \"iteration\": 1812, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018495841650292277, \"iteration\": 1813, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004251487553119659, \"iteration\": 1814, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004904770292341709, \"iteration\": 1815, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007707509212195873, \"iteration\": 1816, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006840377114713192, \"iteration\": 1817, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001224501058459282, \"iteration\": 1818, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011993132065981627, \"iteration\": 1819, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016701531130820513, \"iteration\": 1820, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.009643656201660633, \"iteration\": 1821, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001557978568598628, \"iteration\": 1822, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001493862015195191, \"iteration\": 1823, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013370609376579523, \"iteration\": 1824, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017445817356929183, \"iteration\": 1825, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008140260353684425, \"iteration\": 1826, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001186038483865559, \"iteration\": 1827, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015375199727714062, \"iteration\": 1828, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019930440466850996, \"iteration\": 1829, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028765765950083733, \"iteration\": 1830, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0031405652407556772, \"iteration\": 1831, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011243727058172226, \"iteration\": 1832, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017254118574783206, \"iteration\": 1833, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001571056665852666, \"iteration\": 1834, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001299600931815803, \"iteration\": 1835, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00579436169937253, \"iteration\": 1836, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0055963206104934216, \"iteration\": 1837, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012045623734593391, \"iteration\": 1838, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018387973541393876, \"iteration\": 1839, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001199373509734869, \"iteration\": 1840, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008728395216166973, \"iteration\": 1841, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000991922919638455, \"iteration\": 1842, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012812158092856407, \"iteration\": 1843, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006400458514690399, \"iteration\": 1844, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008273262646980584, \"iteration\": 1845, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010647724848240614, \"iteration\": 1846, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016037411987781525, \"iteration\": 1847, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010759963188320398, \"iteration\": 1848, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09984049946069717, \"iteration\": 1849, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002211453393101692, \"iteration\": 1850, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013729790225625038, \"iteration\": 1851, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028268201276659966, \"iteration\": 1852, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011164338793605566, \"iteration\": 1853, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.01184763852506876, \"iteration\": 1854, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012111177202314138, \"iteration\": 1855, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01552185881882906, \"iteration\": 1856, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015449676429852843, \"iteration\": 1857, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015806588344275951, \"iteration\": 1858, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013676849193871021, \"iteration\": 1859, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001332871150225401, \"iteration\": 1860, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014329735422506928, \"iteration\": 1861, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001751854084432125, \"iteration\": 1862, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001649826648645103, \"iteration\": 1863, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004887151997536421, \"iteration\": 1864, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012669183779507875, \"iteration\": 1865, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001945258816704154, \"iteration\": 1866, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015168414684012532, \"iteration\": 1867, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015414574882015586, \"iteration\": 1868, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002116711111739278, \"iteration\": 1869, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012885539326816797, \"iteration\": 1870, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002226409735158086, \"iteration\": 1871, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014590038917958736, \"iteration\": 1872, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011714051943272352, \"iteration\": 1873, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011681143660098314, \"iteration\": 1874, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011361138895154, \"iteration\": 1875, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003250798210501671, \"iteration\": 1876, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001527387648820877, \"iteration\": 1877, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020907712168991566, \"iteration\": 1878, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016523925587534904, \"iteration\": 1879, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010253133950755, \"iteration\": 1880, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.011220441199839115, \"iteration\": 1881, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007568224100396037, \"iteration\": 1882, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010724698659032583, \"iteration\": 1883, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008733989088796079, \"iteration\": 1884, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008121317368932068, \"iteration\": 1885, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014619363937526941, \"iteration\": 1886, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0019537881016731262, \"iteration\": 1887, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012810591142624617, \"iteration\": 1888, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008978819823823869, \"iteration\": 1889, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000770192185882479, \"iteration\": 1890, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009451947407796979, \"iteration\": 1891, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012193863512948155, \"iteration\": 1892, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.006272817496210337, \"iteration\": 1893, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007880399934947491, \"iteration\": 1894, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001133373356424272, \"iteration\": 1895, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0020442637614905834, \"iteration\": 1896, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015127697261050344, \"iteration\": 1897, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007009052205830812, \"iteration\": 1898, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007033361471258104, \"iteration\": 1899, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001022845390252769, \"iteration\": 1900, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010647827293723822, \"iteration\": 1901, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011717146262526512, \"iteration\": 1902, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009619764168746769, \"iteration\": 1903, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014841292286291718, \"iteration\": 1904, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005945751909166574, \"iteration\": 1905, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007437046733684838, \"iteration\": 1906, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010476931929588318, \"iteration\": 1907, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002799283480271697, \"iteration\": 1908, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000830888980999589, \"iteration\": 1909, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013353948015719652, \"iteration\": 1910, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008802088559605181, \"iteration\": 1911, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010115408804267645, \"iteration\": 1912, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003569788532331586, \"iteration\": 1913, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00513328704982996, \"iteration\": 1914, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007077856571413577, \"iteration\": 1915, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009562778868712485, \"iteration\": 1916, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006831914652138948, \"iteration\": 1917, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00425994535908103, \"iteration\": 1918, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005848722066730261, \"iteration\": 1919, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007547688437625766, \"iteration\": 1920, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005383207462728024, \"iteration\": 1921, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005821863189339638, \"iteration\": 1922, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016037726774811745, \"iteration\": 1923, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007639567484147847, \"iteration\": 1924, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006686004344373941, \"iteration\": 1925, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02697797678411007, \"iteration\": 1926, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001253419672138989, \"iteration\": 1927, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011225789785385132, \"iteration\": 1928, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004786304198205471, \"iteration\": 1929, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011301414342597127, \"iteration\": 1930, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000636489421594888, \"iteration\": 1931, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008470822358503938, \"iteration\": 1932, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005753315053880215, \"iteration\": 1933, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001246966770850122, \"iteration\": 1934, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.009022600948810577, \"iteration\": 1935, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010195918148383498, \"iteration\": 1936, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009846645407378674, \"iteration\": 1937, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006952957483008504, \"iteration\": 1938, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009805273730307817, \"iteration\": 1939, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009478090214543045, \"iteration\": 1940, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008269750978797674, \"iteration\": 1941, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011365117970854044, \"iteration\": 1942, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007843460771255195, \"iteration\": 1943, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007771833334118128, \"iteration\": 1944, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0020340029150247574, \"iteration\": 1945, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008944753208197653, \"iteration\": 1946, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006014746613800526, \"iteration\": 1947, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001176615827716887, \"iteration\": 1948, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005877193761989474, \"iteration\": 1949, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012620767811313272, \"iteration\": 1950, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006446215556934476, \"iteration\": 1951, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006568435346707702, \"iteration\": 1952, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011876337230205536, \"iteration\": 1953, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006999724428169429, \"iteration\": 1954, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012269890867173672, \"iteration\": 1955, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007347258506342769, \"iteration\": 1956, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006202268996275961, \"iteration\": 1957, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007773739635013044, \"iteration\": 1958, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0022058128379285336, \"iteration\": 1959, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011150294449180365, \"iteration\": 1960, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006621171487495303, \"iteration\": 1961, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011499995598569512, \"iteration\": 1962, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 0.02839476242661476, \"iteration\": 1963, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015974434791132808, \"iteration\": 1964, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011352153960615396, \"iteration\": 1965, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006211318541318178, \"iteration\": 1966, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006059080478735268, \"iteration\": 1967, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006347228190861642, \"iteration\": 1968, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006848957855254412, \"iteration\": 1969, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006387591129168868, \"iteration\": 1970, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006999102188274264, \"iteration\": 1971, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016528402920812368, \"iteration\": 1972, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0019597469363361597, \"iteration\": 1973, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012177673634141684, \"iteration\": 1974, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006621172651648521, \"iteration\": 1975, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006626170943491161, \"iteration\": 1976, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011528786271810532, \"iteration\": 1977, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009663623059168458, \"iteration\": 1978, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005010294262319803, \"iteration\": 1979, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009381829877384007, \"iteration\": 1980, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006418815464712679, \"iteration\": 1981, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006508355727419257, \"iteration\": 1982, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007456471212208271, \"iteration\": 1983, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011878821533173323, \"iteration\": 1984, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0029266993515193462, \"iteration\": 1985, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000879641913343221, \"iteration\": 1986, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009131473489105701, \"iteration\": 1987, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007893946021795273, \"iteration\": 1988, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008941555279307067, \"iteration\": 1989, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007519153878092766, \"iteration\": 1990, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009852000512182713, \"iteration\": 1991, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009461336303502321, \"iteration\": 1992, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007963606622070074, \"iteration\": 1993, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000777730077970773, \"iteration\": 1994, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008197722490876913, \"iteration\": 1995, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0034597287885844707, \"iteration\": 1996, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0023805673699826, \"iteration\": 1997, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008417274802923203, \"iteration\": 1998, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009233548771589994, \"iteration\": 1999, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.008145088329911232, \"iteration\": 2000, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013097282499074936, \"iteration\": 2001, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00045200789463706315, \"iteration\": 2002, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012358430540189147, \"iteration\": 2003, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013645447324961424, \"iteration\": 2004, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03285457193851471, \"iteration\": 2005, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013910301495343447, \"iteration\": 2006, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006737232906743884, \"iteration\": 2007, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006308734300546348, \"iteration\": 2008, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00044866264215670526, \"iteration\": 2009, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013043893268331885, \"iteration\": 2010, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006889468058943748, \"iteration\": 2011, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006775388610549271, \"iteration\": 2012, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009414004161953926, \"iteration\": 2013, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008480321266688406, \"iteration\": 2014, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006036931881681085, \"iteration\": 2015, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013622986152768135, \"iteration\": 2016, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008982947911135852, \"iteration\": 2017, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009535622084513307, \"iteration\": 2018, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012146641965955496, \"iteration\": 2019, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011994837550446391, \"iteration\": 2020, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005319364136084914, \"iteration\": 2021, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009118996094912291, \"iteration\": 2022, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007746475748717785, \"iteration\": 2023, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.006125707179307938, \"iteration\": 2024, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006444265600293875, \"iteration\": 2025, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007440046174451709, \"iteration\": 2026, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008554813684895635, \"iteration\": 2027, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0037140653003007174, \"iteration\": 2028, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005770380375906825, \"iteration\": 2029, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0029589806217700243, \"iteration\": 2030, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004242525435984135, \"iteration\": 2031, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001044831471517682, \"iteration\": 2032, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000540492357686162, \"iteration\": 2033, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000753236876334995, \"iteration\": 2034, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007710675126872957, \"iteration\": 2035, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007265798049047589, \"iteration\": 2036, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000540312728844583, \"iteration\": 2037, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010151652386412024, \"iteration\": 2038, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000604715314693749, \"iteration\": 2039, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010686585446819663, \"iteration\": 2040, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007175778737291694, \"iteration\": 2041, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008369795395992696, \"iteration\": 2042, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004600471816956997, \"iteration\": 2043, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005690632970072329, \"iteration\": 2044, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0024138279259204865, \"iteration\": 2045, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006110131507739425, \"iteration\": 2046, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00109424302354455, \"iteration\": 2047, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012696997728198767, \"iteration\": 2048, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008257555309683084, \"iteration\": 2049, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000950444140471518, \"iteration\": 2050, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011233007535338402, \"iteration\": 2051, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003792686155065894, \"iteration\": 2052, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001079691108316183, \"iteration\": 2053, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008722175261937082, \"iteration\": 2054, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021576436702162027, \"iteration\": 2055, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006523077609017491, \"iteration\": 2056, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005229451926425099, \"iteration\": 2057, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005105886375531554, \"iteration\": 2058, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005296114832162857, \"iteration\": 2059, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001045749057084322, \"iteration\": 2060, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000566894537769258, \"iteration\": 2061, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006483618635684252, \"iteration\": 2062, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002165659097954631, \"iteration\": 2063, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.007397547364234924, \"iteration\": 2064, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010031298734247684, \"iteration\": 2065, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008954228833317757, \"iteration\": 2066, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016379868611693382, \"iteration\": 2067, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005999747081659734, \"iteration\": 2068, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04427013918757439, \"iteration\": 2069, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004926121328026056, \"iteration\": 2070, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007541773375123739, \"iteration\": 2071, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006313439225777984, \"iteration\": 2072, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007923140656203032, \"iteration\": 2073, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0022971013095229864, \"iteration\": 2074, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007241687271744013, \"iteration\": 2075, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.007738153450191021, \"iteration\": 2076, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014626941410824656, \"iteration\": 2077, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005918769165873528, \"iteration\": 2078, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010647817980498075, \"iteration\": 2079, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004410819965414703, \"iteration\": 2080, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005365719553083181, \"iteration\": 2081, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011475983774289489, \"iteration\": 2082, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.012193332426249981, \"iteration\": 2083, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010720554273575544, \"iteration\": 2084, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00049647904234007, \"iteration\": 2085, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005443087429739535, \"iteration\": 2086, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000821275869384408, \"iteration\": 2087, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005712526617571712, \"iteration\": 2088, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00392455467954278, \"iteration\": 2089, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007075836765579879, \"iteration\": 2090, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# POC\n",
    "#%%\n",
    "file_list = [\n",
    "    'power-gb-train.tsv',\n",
    "    # 'power-ua-train.tsv',\n",
    "    # 'power-fr-train.tsv',\n",
    "    # 'power-nl-train.tsv',\n",
    "]\n",
    "\n",
    "full_data = load_data(folder_path=\"data/train/power/\", file_list=file_list,text_head='text_en')\n",
    "train_raw_gb, test_raw_gb = split_data(full_data, test_size=0.2, random_state=0)\n",
    "\n",
    "file_list = [\n",
    "    'power-gb-test.tsv',\n",
    "    # 'power-ua-train.tsv',\n",
    "    # 'power-fr-train.tsv',\n",
    "    # 'power-nl-train.tsv',\n",
    "]\n",
    "\n",
    "test_data = load_data(folder_path=\"data/test/power/\", file_list=file_list,text_head='text_en')\n",
    "\n",
    "print(\"Prepare data encoder...\")\n",
    "# train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "train_encoder = TfidfVectorizer(max_features=10000)\n",
    "train_encoder.fit(train_raw.texts)\n",
    "\n",
    "print(\"Prepare data...\")\n",
    "train_dataset = encode_data(train_raw, train_encoder)\n",
    "test_dataset = encode_data(test_raw, train_encoder)\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(train_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "if Path('models/model_nn.pt').exists() and USE_CACHE:\n",
    "    model_nn = load_model(model_nn, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(train_dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn, \"model_nn\")\n",
    "\n",
    "model_nn_results = evaluate_nn_model(model_nn, test_dataset)\n",
    "np.save('models/model_nn_results.npy', model_nn_results)\n",
    "print(model_nn_results)\n",
    "\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power-at-train (0.758832573890686, 0.5467289686203003, 0.5984655022621155)\n",
      "power-ba-train (0.8353909254074097, 0.9308755993843079, 0.9099099040031433)\n",
      "power-be-train (0.540569007396698, 0.39673912525177, 0.5011441707611084)\n",
      "power-bg-train (0.6343283653259277, 0.48170730471611023, 0.5632798671722412)\n",
      "power-cz-train (0.6032568216323853, 0.457337886095047, 0.5)\n",
      "power-dk-train (0.6287744045257568, 0.5846599340438843, 0.6590538620948792)\n",
      "power-es-ct-train (0.7605177760124207, 0.8916256427764893, 0.8302752375602722)\n",
      "power-es-ga-train (0.6823529601097107, 0.8928571343421936, 0.7352941036224365)\n",
      "power-es-pv-train (0.6978723406791687, 0.5773195624351501, 0.6120218634605408)\n",
      "power-es-train (0.7452702522277832, 0.7231897115707397, 0.8071611523628235)\n",
      "power-fi-train (0.5883293151855469, 0.5476190447807312, 0.537286639213562)\n",
      "power-fr-train (0.699592649936676, 0.35103243589401245, 0.4465290904045105)\n",
      "power-gb-train (0.7102324366569519, 0.7643880248069763, 0.7466350197792053)\n",
      "power-gr-train (0.8299845457077026, 0.8501326441764832, 0.853528618812561)\n",
      "power-hr-train (0.6590038537979126, 0.4323641061782837, 0.4899713397026062)\n",
      "power-hu-train (0.7833655476570129, 0.6521739363670349, 0.7466063499450684)\n",
      "power-it-train (0.734215259552002, 0.359375, 0.48364487290382385)\n",
      "power-lv-train (0.6348684430122375, 0.39316239953041077, 0.4532019793987274)\n",
      "power-nl-train (0.6361386179924011, 0.3384379744529724, 0.42912620306015015)\n",
      "power-pl-train (0.639352560043335, 0.5043706297874451, 0.6181039214134216)\n",
      "power-pt-train (0.7231980562210083, 0.4203389883041382, 0.5204616785049438)\n",
      "power-rs-train (0.781697154045105, 0.4863731563091278, 0.5858585834503174)\n",
      "power-si-train (0.7072637677192688, 0.2700348496437073, 0.36643025279045105)\n",
      "power-tr-train (0.835273027420044, 0.8069053888320923, 0.8205461502075195)\n",
      "power-ua-train (0.7176901698112488, 0.3505154550075531, 0.43589743971824646)\n",
      "power-at-train (0.7692780494689941, 0.37476634979248047, 0.5164198279380798)\n",
      "power-ba-train (0.751028835773468, 0.8018433451652527, 0.8518971800804138)\n",
      "power-be-train (0.5426765084266663, 0.3550724685192108, 0.47457626461982727)\n",
      "power-bg-train (0.579104483127594, 0.2301829308271408, 0.34872978925704956)\n",
      "power-cz-train (0.6313841342926025, 0.3464163839817047, 0.4491150379180908)\n",
      "power-dk-train (0.6083481311798096, 0.4862518012523651, 0.6037735939025879)\n",
      "power-es-ct-train (0.7896440029144287, 0.866995096206665, 0.8441246747970581)\n",
      "power-es-ga-train (0.6764705777168274, 0.9285714030265808, 0.7393364906311035)\n",
      "power-es-pv-train (0.7021276354789734, 0.876288652420044, 0.7083333134651184)\n",
      "power-es-train (0.7310810685157776, 0.684692919254303, 0.7896406054496765)\n",
      "power-fi-train (0.636290967464447, 0.24725274741649628, 0.3724137842655182)\n",
      "power-fr-train (0.7041751742362976, 0.29203540086746216, 0.405322402715683)\n",
      "power-gb-train (0.7174766063690186, 0.7887057662010193, 0.7571984529495239)\n",
      "power-gr-train (0.7581143975257874, 0.6140583753585815, 0.7473769187927246)\n",
      "power-hr-train (0.6762452125549316, 0.29962074756622314, 0.41217392683029175)\n",
      "power-hu-train (0.7485493421554565, 0.5415019989013672, 0.6782178282737732)\n",
      "power-it-train (0.7366205453872681, 0.3038194477558136, 0.44416242837905884)\n",
      "power-lv-train (0.6184210777282715, 0.18803419172763824, 0.2750000059604645)\n",
      "power-nl-train (0.6379950642585754, 0.2848392128944397, 0.3887147307395935)\n",
      "power-pl-train (0.6039453744888306, 0.3723776340484619, 0.5211009383201599)\n",
      "power-pt-train (0.7328891754150391, 0.4576271176338196, 0.5504587292671204)\n",
      "power-rs-train (0.7587354183197021, 0.28721174597740173, 0.43047916889190674)\n",
      "power-si-train (0.7187329530715942, 0.203832745552063, 0.31241655349731445)\n",
      "power-tr-train (0.8281109929084778, 0.6668797731399536, 0.7836213111877441)\n",
      "power-ua-train (0.7208982706069946, 0.17820324003696442, 0.2843713164329529)\n",
      "power-at-train.tsv: Positive 41.17%\n",
      "power-ba-train.tsv: Positive 83.17%\n",
      "power-be-train.tsv: Positive 52.57%\n",
      "power-bg-train.tsv: Positive 47.17%\n",
      "power-cz-train.tsv: Positive 52.25%\n",
      "power-dk-train.tsv: Positive 62.81%\n",
      "power-es-ct-train.tsv: Positive 65.18%\n",
      "power-es-ga-train.tsv: Positive 57.50%\n",
      "power-es-pv-train.tsv: Positive 56.35%\n",
      "power-es-train.tsv: Positive 70.73%\n",
      "power-fi-train.tsv: Positive 44.59%\n",
      "power-fr-train.tsv: Positive 37.04%\n",
      "power-gb-train.tsv: Positive 56.39%\n",
      "power-gr-train.tsv: Positive 62.70%\n",
      "power-hr-train.tsv: Positive 39.73%\n",
      "power-hu-train.tsv: Positive 40.89%\n",
      "power-it-train.tsv: Positive 37.49%\n",
      "power-lv-train.tsv: Positive 33.05%\n",
      "power-nl-train.tsv: Positive 41.50%\n",
      "power-pl-train.tsv: Positive 54.80%\n",
      "power-pt-train.tsv: Positive 41.32%\n",
      "power-rs-train.tsv: Positive 27.09%\n",
      "power-si-train.tsv: Positive 37.48%\n",
      "power-tr-train.tsv: Positive 51.38%\n",
      "power-ua-train.tsv: Positive 31.21%\n"
     ]
    }
   ],
   "source": [
    "# Mass testing all countries\"s English text\n",
    "\n",
    "parent_dir = Path(\"data/train/power\")\n",
    "\n",
    "file_list = sorted([file for file in parent_dir.glob(\"*.tsv\")])\n",
    "text_en_result_list = []\n",
    "\n",
    "for file in file_list:\n",
    "\n",
    "    full_data = load_data(folder_path=parent_dir, file_list=[file.name],text_head=\"text_en\")\n",
    "    train_dev_raw, test_raw = split_data(full_data, test_size=0.2, random_state=0)\n",
    "    train_raw, dev_raw = split_data(train_dev_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "    # train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "    train_encoder = TfidfVectorizer()\n",
    "    train_encoder.fit(train_raw.texts)\n",
    "\n",
    "    train_dataset = encode_data(train_raw, train_encoder)\n",
    "    dev_dataset = encode_data(dev_raw, train_encoder)\n",
    "    test_dataset = encode_data(test_raw, train_encoder)\n",
    "\n",
    "    train_config = TrainConfig(\n",
    "        num_epochs      = 10,\n",
    "        early_stop      = False,\n",
    "        violation_limit = 5,\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    dev_dataloader = DataLoader(dev_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "    model_nn = NeuralNetwork(\n",
    "        input_size=len(train_encoder.vocabulary_),\n",
    "        hidden_size=128,\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "    if Path(f\"models/model_nn_{file.stem}_en.pt\").exists():\n",
    "        model_nn = load_model(model_nn, f\"model_nn_{file.stem}_en\")\n",
    "    else:\n",
    "        model_nn.fit(train_dataloader, train_config)\n",
    "        save_model(model_nn, f\"model_nn_{file.stem}_en\")\n",
    "\n",
    "    model_nn_results = evaluate_nn_model(model_nn, test_dataset)\n",
    "    text_en_result_list.append(model_nn_results)\n",
    "    \n",
    "    np.save(f\"models/model_nn_{file.stem}_en_results.npy\", model_nn_results)\n",
    "    print(file.stem, model_nn_results)\n",
    "\n",
    "\n",
    "# Mass testing all countries's original text\n",
    "\n",
    "parent_dir = Path(\"data/train/power\")\n",
    "\n",
    "file_list = sorted([file for file in parent_dir.glob(\"*.tsv\")])\n",
    "text_ori_result_list = []\n",
    "\n",
    "for file in file_list:\n",
    "\n",
    "    full_data = load_data(folder_path=parent_dir, file_list=[file.name],text_head=\"text\")\n",
    "    train_dev_raw, test_raw = split_data(full_data, test_size=0.2, random_state=0)\n",
    "    train_raw, dev_raw = split_data(train_dev_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "    # train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "    train_encoder = TfidfVectorizer()\n",
    "    train_encoder.fit(train_raw.texts)\n",
    "\n",
    "    train_dataset = encode_data(train_raw, train_encoder)\n",
    "    dev_dataset = encode_data(dev_raw, train_encoder)\n",
    "    test_dataset = encode_data(test_raw, train_encoder)\n",
    "\n",
    "    train_config = TrainConfig(\n",
    "        num_epochs      = 10,\n",
    "        early_stop      = False,\n",
    "        violation_limit = 5,\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    dev_dataloader = DataLoader(dev_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "    model_nn = NeuralNetwork(\n",
    "        input_size=len(train_encoder.vocabulary_),\n",
    "        hidden_size=128,\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "    if Path(f\"models/model_nn_{file.stem}_ori.pt\").exists():\n",
    "        model_nn = load_model(model_nn, f\"model_nn_{file.stem}_ori\")\n",
    "    else:\n",
    "        model_nn.fit(train_dataloader, train_config)\n",
    "        save_model(model_nn, f\"model_nn_{file.stem}_ori\")\n",
    "\n",
    "    model_nn_results = evaluate_nn_model(model_nn, test_dataset)\n",
    "    text_ori_result_list.append(model_nn_results)\n",
    "    \n",
    "    np.save(f\"models/model_nn_{file.stem}_ori_results.npy\", model_nn_results)\n",
    "    print(file.stem, model_nn_results)\n",
    "\n",
    "\n",
    "# Detect class imbalance\n",
    "parent_dir = Path(\"data/train/power\")\n",
    "\n",
    "file_list = sorted([file for file in parent_dir.glob(\"*.tsv\")])\n",
    "stats = []\n",
    "\n",
    "for file in file_list:\n",
    "    full_data = load_data(folder_path=parent_dir, file_list=[file.name],text_head=\"text\")\n",
    "    positive = sum(full_data.labels)\n",
    "    stats.append((positive, len(full_data), positive / len(full_data)))\n",
    "    print(f\"{file.name}: Positive {positive / len(full_data) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance of the two languages\n",
    "\n",
    "def plot_countries(country_group):\n",
    "\n",
    "    for file, en ,ori, stat in zip(file_list, text_en_result_list, text_ori_result_list, stats):\n",
    "        data = [\n",
    "            ('en', stat[2], *en),\n",
    "            ('ori', stat[2], *ori)\n",
    "        ]\n",
    "\n",
    "        country_code = file.stem.replace('power-', '').replace('-train', '')\n",
    "        country_name = mapping_dict[country_code]\n",
    "\n",
    "        if country_code in country_group:\n",
    "\n",
    "            results_df = pd.DataFrame(data, columns=[\"language\", \"positive_pct\", \"precision\", \"recall\", 'f1']).melt(id_vars=\"language\")\n",
    "\n",
    "            result_chart = alt.Chart(results_df).mark_bar().encode(\n",
    "                x = alt.X('variable:N', axis = alt.Axis(title = '', labels = False, ticks = False), sort = None, ),\n",
    "                y = alt.Y('value:Q', axis = alt.Axis(title = 'Score'), scale=alt.Scale(domain=(0, 1))),\n",
    "                column=alt.Column('language:N', title='Language', sort = None),\n",
    "                color=alt.Color('variable:N', scale=alt.Scale(scheme='category20'), title='Evaluation Metric', sort = None)\n",
    "            ).properties(\n",
    "                width=200,\n",
    "                height=300,\n",
    "                title = f\"{country_code} - {country_name} - {stat[1]} datapoints\"\n",
    "            )\n",
    "\n",
    "            result_chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result summary\n",
    "- Austria: lots of data, good precision, low recall. Worse performance on original language\n",
    "- Bosnia: Not much data, good results overall\n",
    "- Belgium: medium data, bad result\n",
    "- Bulgaria: medium data, bad\n",
    "- Czechia: medium data, Bad results\n",
    "- Denmark: medium data, bad result\n",
    "- Catalonia: less data, result quite good, precision < recall. EN and ORI are comparable\n",
    "- Galacia: same with Catalonia\n",
    "- Basque: Same with others, but worse result using EN\n",
    "- Spain: Medium-large data, everything is balanced around 0.7 - 0.8, similar perofrmance in both lang. Lots of positive labels\n",
    "- Finland: medium data, overall bad performance, lower performance in ORI\n",
    "- France: medium-large data, very low recall -> cannot capture negative class. Similar performance in both lang\n",
    "- GB: large data, balance results\n",
    "- Greece: Medium data, good result on en text\n",
    "- Croatia: Large data, bad results on both. Slightly better in English\n",
    "- Hungary: less data, quite good results on EN\n",
    "- Italy: Medium data, good precision, bad recall, low positive percentage\n",
    "- Latvia: Not much data, bad result\n",
    "- Netherlands: medium data, slight class imbalance, overall bad result\n",
    "- Poland: class balance, result is bad / so-so\n",
    "- Portugal: medium data, Slight class imbalance, high precision but low recall\n",
    "- Serbia: large data, high class imbalance, high precision, low recall\n",
    "- Slovenia: Medium-large data ,high class imbalance, high precision, low recall\n",
    "- Turkey: Large data, balance class, good overall result on English\n",
    "- Ukraine: medium-large data, high class imbalance, high precision, low recall\n",
    "\n",
    "- Low positive score: good precision, bad recall (true positive / total positive) -> can easily capture true positive and negative by guessing all to be negative, so miss lots of true positive -> the effect of class imbalance\n",
    "\n",
    "- Less data = better result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Test by country groups\n",
    "\n",
    "- Balkan\n",
    "  - Bosnia and Herzegovina (ba)\n",
    "  - Croatia (hr)\n",
    "  - Serbia (rs)\n",
    "\n",
    "- Diff\n",
    "  - Greece (gr)\n",
    "  - Bulgaria (bg)\n",
    "\n",
    "- Spanish\n",
    "  - Spain (es)\n",
    "  - Catalonia (es-ct)\n",
    "  - Galicia (es-ga)\n",
    "  - Basque Country (es-pv) [only power]\n",
    "\n",
    "- Nordic\n",
    "  - Denmark (dk) \n",
    "  - Finland (fi)\n",
    "  - Iceland (is) [only political orientation] \n",
    "  - Norway (no) [only political orientation] \n",
    "  - Sweden (se) [only political orientation] \n",
    "\n",
    "- Slavic\n",
    "  - Poland (pl)\n",
    "  - Ukraine (ua)\n",
    "  - Czechia (cz)\n",
    "  - Serbia (rs)\n",
    "  - Slovenia (si)\n",
    "\n",
    "- West German\n",
    "  - Austria (at)\n",
    "  - Great Britain (gb)\n",
    "  - The Netherlands (nl)\n",
    "  - Norway (no) [only political orientation] \n",
    "  - Sweden (se) [only political orientation] \n",
    "  - Belgium (be)\n",
    "\n",
    "\n",
    "- Romance\n",
    "  - France (fr)\n",
    "  - Portugal (pt)\n",
    "  - Italy (it)\n",
    "\n",
    "- Uralic\n",
    "  - Estonia (ee) \n",
    "  - Hungary (hu)\n",
    "\n",
    "- Baltic\n",
    "  - Latvia (lv)\n",
    "  - Lithuanian\n",
    "\n",
    "\n",
    "- Turkic\n",
    "  - Turkey (tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ba \t Bosnia and Herzegovina \t 2531 \t Zahvaljujem gospodo predsjedavajući, dame i gospodo, Sa žaljenjem mogu konstatovati da na sjednici K\n",
      "hr \t Croatia \t 10741 \t Gospodine predsjedniče, uvaženi kolega zastupnik Leko i kolega zastupnik Arlović iznosili su neke ar\n",
      "rs \t Serbia \t 15114 \t Dame i gospodo, dozvolite da u ime našeg izbornog tela prenesem pozdrave i želju da ova skupština po\n"
     ]
    }
   ],
   "source": [
    "balkans = ['ba', 'hr', 'rs']\n",
    "parent_dir = Path(\"data/train/power\")\n",
    "\n",
    "for code in balkans:\n",
    "    full_data = load_data(folder_path=parent_dir, file_list=[f\"power-{code}-train.tsv\"],text_head=\"text\")\n",
    "    print(\n",
    "        code, \"\\t\", \n",
    "        mapping_dict[code], \"\\t\", \n",
    "        len(full_data), \"\\t\",\n",
    "        full_data.texts[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2c31ffc350554f9d831f0096bf9914de.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2c31ffc350554f9d831f0096bf9914de.vega-embed details,\n",
       "  #altair-viz-2c31ffc350554f9d831f0096bf9914de.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2c31ffc350554f9d831f0096bf9914de\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2c31ffc350554f9d831f0096bf9914de\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2c31ffc350554f9d831f0096bf9914de\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-68863f377eeaf60c46ba5db7d1f0d46f\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"variable\", \"scale\": {\"scheme\": \"category20\"}, \"sort\": null, \"title\": \"Evaluation Metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"language\", \"sort\": null, \"title\": \"Language\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"variable\", \"sort\": null, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Score\"}, \"field\": \"value\", \"scale\": {\"domain\": [0, 1]}, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"ba - Bosnia and Herzegovina - 2531 datapoints\", \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-68863f377eeaf60c46ba5db7d1f0d46f\": [{\"language\": \"en\", \"variable\": \"positive_pct\", \"value\": 0.8316870802054523}, {\"language\": \"ori\", \"variable\": \"positive_pct\", \"value\": 0.8316870802054523}, {\"language\": \"en\", \"variable\": \"precision\", \"value\": 0.8353909254074097}, {\"language\": \"ori\", \"variable\": \"precision\", \"value\": 0.751028835773468}, {\"language\": \"en\", \"variable\": \"recall\", \"value\": 0.9308755993843079}, {\"language\": \"ori\", \"variable\": \"recall\", \"value\": 0.8018433451652527}, {\"language\": \"en\", \"variable\": \"f1\", \"value\": 0.9099099040031433}, {\"language\": \"ori\", \"variable\": \"f1\", \"value\": 0.8518971800804138}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d78971936d43464797a10b586aadabb8.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d78971936d43464797a10b586aadabb8.vega-embed details,\n",
       "  #altair-viz-d78971936d43464797a10b586aadabb8.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d78971936d43464797a10b586aadabb8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d78971936d43464797a10b586aadabb8\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d78971936d43464797a10b586aadabb8\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-73f2c451278ff698a46d7d406845078c\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"variable\", \"scale\": {\"scheme\": \"category20\"}, \"sort\": null, \"title\": \"Evaluation Metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"language\", \"sort\": null, \"title\": \"Language\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"variable\", \"sort\": null, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Score\"}, \"field\": \"value\", \"scale\": {\"domain\": [0, 1]}, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"hr - Croatia - 10741 datapoints\", \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-73f2c451278ff698a46d7d406845078c\": [{\"language\": \"en\", \"variable\": \"positive_pct\", \"value\": 0.3972628246904385}, {\"language\": \"ori\", \"variable\": \"positive_pct\", \"value\": 0.3972628246904385}, {\"language\": \"en\", \"variable\": \"precision\", \"value\": 0.6590038537979126}, {\"language\": \"ori\", \"variable\": \"precision\", \"value\": 0.6762452125549316}, {\"language\": \"en\", \"variable\": \"recall\", \"value\": 0.4323641061782837}, {\"language\": \"ori\", \"variable\": \"recall\", \"value\": 0.29962074756622314}, {\"language\": \"en\", \"variable\": \"f1\", \"value\": 0.4899713397026062}, {\"language\": \"ori\", \"variable\": \"f1\", \"value\": 0.41217392683029175}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-75a02f5dd7ae4116bbf44e4603121dfb.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-75a02f5dd7ae4116bbf44e4603121dfb.vega-embed details,\n",
       "  #altair-viz-75a02f5dd7ae4116bbf44e4603121dfb.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-75a02f5dd7ae4116bbf44e4603121dfb\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-75a02f5dd7ae4116bbf44e4603121dfb\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-75a02f5dd7ae4116bbf44e4603121dfb\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-32a0df100d2301f1b294949a2a7d2dff\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"variable\", \"scale\": {\"scheme\": \"category20\"}, \"sort\": null, \"title\": \"Evaluation Metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"language\", \"sort\": null, \"title\": \"Language\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"variable\", \"sort\": null, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Score\"}, \"field\": \"value\", \"scale\": {\"domain\": [0, 1]}, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"rs - Serbia - 15114 datapoints\", \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-32a0df100d2301f1b294949a2a7d2dff\": [{\"language\": \"en\", \"variable\": \"positive_pct\", \"value\": 0.2708746857218473}, {\"language\": \"ori\", \"variable\": \"positive_pct\", \"value\": 0.2708746857218473}, {\"language\": \"en\", \"variable\": \"precision\", \"value\": 0.781697154045105}, {\"language\": \"ori\", \"variable\": \"precision\", \"value\": 0.7587354183197021}, {\"language\": \"en\", \"variable\": \"recall\", \"value\": 0.4863731563091278}, {\"language\": \"ori\", \"variable\": \"recall\", \"value\": 0.28721174597740173}, {\"language\": \"en\", \"variable\": \"f1\", \"value\": 0.5858585834503174}, {\"language\": \"ori\", \"variable\": \"f1\", \"value\": 0.43047916889190674}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_countries(balkans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to handle Croatia differently\n",
    "# How to deal with class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training and tetsing on original text seems to have good effect\n",
    "- Using character-level tokens seems to work better. a vocabulary of 50000 tokens provides diminishing return.\n",
    "- Still need to deal with imbalance labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC for Balkan countries\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22672 5714\n",
      "Percentage of positive: 0.3698394495412844 0.364193209660483\n"
     ]
    }
   ],
   "source": [
    "# POC for Balkan\n",
    "#%%\n",
    "balkan_file_list = [\n",
    "    'power-ba-train.tsv',\n",
    "    'power-rs-train.tsv',\n",
    "    'power-hr-train.tsv',\n",
    "]\n",
    "\n",
    "balkan_data = load_data(folder_path=\"data/train/power/\", file_list=balkan_file_list,text_head='text')\n",
    "train_raw, test_raw = split_data(balkan_data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(len(train_raw), len(test_raw))\n",
    "print(\"Percentage of positive:\", sum(train_raw.labels) / len(train_raw), sum(test_raw.labels) / len(test_raw))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data encoder...\n",
      "Vocabulary 50000\n",
      "Prepare data...\n",
      "Train model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 178/178 [00:02<00:00, 65.08batch/s, batch_accuracy=0.938, loss=0.509]\n",
      "Epoch 2: 100%|██████████| 178/178 [00:02<00:00, 69.68batch/s, batch_accuracy=0.938, loss=0.363]\n",
      "Epoch 3: 100%|██████████| 178/178 [00:02<00:00, 69.96batch/s, batch_accuracy=0.938, loss=0.462]\n",
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 70.83batch/s, batch_accuracy=0.938, loss=0.304]\n",
      "Epoch 5: 100%|██████████| 178/178 [00:02<00:00, 70.50batch/s, batch_accuracy=1, loss=0.0329]    \n",
      "Epoch 6: 100%|██████████| 178/178 [00:02<00:00, 70.06batch/s, batch_accuracy=1, loss=0.00387]   \n",
      "Epoch 7: 100%|██████████| 178/178 [00:02<00:00, 70.82batch/s, batch_accuracy=1, loss=0.00184]   \n",
      "Epoch 8: 100%|██████████| 178/178 [00:02<00:00, 71.26batch/s, batch_accuracy=1, loss=0.00203]  \n",
      "Epoch 9: 100%|██████████| 178/178 [00:02<00:00, 70.32batch/s, batch_accuracy=1, loss=0.000375]   \n",
      "Epoch 10: 100%|██████████| 178/178 [00:02<00:00, 72.15batch/s, batch_accuracy=1, loss=0.000122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.74833744764328, 0.6410379409790039, 0.649780809879303, 0.4534433923294927)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9dedf62943174fe2ad811fee7b11bcf7.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9dedf62943174fe2ad811fee7b11bcf7.vega-embed details,\n",
       "  #altair-viz-9dedf62943174fe2ad811fee7b11bcf7.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9dedf62943174fe2ad811fee7b11bcf7\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9dedf62943174fe2ad811fee7b11bcf7\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9dedf62943174fe2ad811fee7b11bcf7\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-97fe008702ffbee2b9d53cea5c2b3b14\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-97fe008702ffbee2b9d53cea5c2b3b14\": [{\"training_acc\": 0.59375, \"training_loss\": 0.6927689909934998, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6839762926101685, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6870903968811035, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6711187958717346, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6574884057044983, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6483273506164551, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.670744776725769, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.647454023361206, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6687777638435364, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6720966696739197, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6417843103408813, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6375404596328735, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6443504095077515, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6586780548095703, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6365253925323486, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6177040338516235, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6117408275604248, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6512223482131958, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6158392429351807, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6553804874420166, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.694547712802887, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6669922471046448, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6255388855934143, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6705856919288635, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.587330162525177, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6528264284133911, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6029669642448425, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6732654571533203, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6799566745758057, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6833491325378418, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.662062406539917, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6657217144966125, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6548907160758972, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6283845901489258, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6834142208099365, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6483986973762512, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6325982809066772, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6235349178314209, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6336060762405396, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6246169209480286, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.634230375289917, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 0.6728862524032593, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6112475991249084, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6279165744781494, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6087955236434937, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6020610332489014, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6429905891418457, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6186716556549072, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6144403219223022, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6045967936515808, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6142511367797852, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5771970748901367, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5803031921386719, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5802596807479858, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.619030773639679, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.584180474281311, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6077505350112915, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.49554014205932617, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.5859071612358093, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.5965912342071533, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5255653262138367, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5565977096557617, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5692284107208252, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5352321267127991, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5712812542915344, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5893545746803284, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5561190843582153, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5919589400291443, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5489578247070312, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5358303189277649, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5363600254058838, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5526049137115479, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5287050008773804, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4632530212402344, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5536548495292664, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6188740730285645, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.5941676497459412, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4820437431335449, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4930151104927063, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5792953968048096, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5654431581497192, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5501154661178589, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5170419216156006, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.4918811321258545, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4985988736152649, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4898985028266907, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6184029579162598, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5793778896331787, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4423173666000366, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5359710454940796, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5327880382537842, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5700523853302002, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5494217276573181, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.514149010181427, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5213687419891357, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5338476896286011, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.4793740510940552, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5279867053031921, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5275675058364868, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5167058706283569, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.46933263540267944, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4637482166290283, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4882771968841553, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5075121521949768, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5149616599082947, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5463142395019531, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5574336051940918, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.48370763659477234, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5696945786476135, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.455710232257843, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.8671875, \"training_loss\": 0.44376128911972046, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5935415029525757, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5161453485488892, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5310818552970886, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.49051064252853394, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5344655513763428, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.44311749935150146, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5037275552749634, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.47966745495796204, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5888917446136475, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.41681861877441406, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5207860469818115, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5139880180358887, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.49049270153045654, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.4971849322319031, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4826675057411194, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5227873921394348, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.44306281208992004, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.49699893593788147, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.42615413665771484, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.4887203872203827, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4809543490409851, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5266275405883789, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.480449378490448, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4285021424293518, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4612730145454407, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.45831194519996643, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.49931201338768005, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.49788689613342285, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5295231342315674, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4642188549041748, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5175304412841797, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.48396068811416626, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.45343267917633057, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5189319849014282, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5015873908996582, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5192591547966003, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.8671875, \"training_loss\": 0.41068652272224426, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5002785921096802, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.515095591545105, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5358772277832031, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4987832009792328, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4303446412086487, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4057866334915161, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.42843538522720337, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5519187450408936, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4769803285598755, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4363839030265808, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.48091447353363037, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5170184969902039, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5274582505226135, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.42339566349983215, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.42057347297668457, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4713584780693054, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5375629663467407, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5072853565216064, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.40031781792640686, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5024423599243164, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.45391255617141724, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.42365384101867676, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.46938973665237427, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.47232353687286377, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.43531787395477295, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5235989689826965, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.48605605959892273, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.42145615816116333, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4403045177459717, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.9375, \"training_loss\": 0.5090914368629456, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.40023648738861084, \"iteration\": 179, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3813230097293854, \"iteration\": 180, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3597341477870941, \"iteration\": 181, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.35444197058677673, \"iteration\": 182, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3657912611961365, \"iteration\": 183, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3899812698364258, \"iteration\": 184, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.40875956416130066, \"iteration\": 185, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.35568398237228394, \"iteration\": 186, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.39625561237335205, \"iteration\": 187, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.36803796887397766, \"iteration\": 188, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.34407854080200195, \"iteration\": 189, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3589075803756714, \"iteration\": 190, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.364928662776947, \"iteration\": 191, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.39668765664100647, \"iteration\": 192, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.36781471967697144, \"iteration\": 193, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3596346378326416, \"iteration\": 194, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.380306601524353, \"iteration\": 195, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.36294662952423096, \"iteration\": 196, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.37233346700668335, \"iteration\": 197, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3555883765220642, \"iteration\": 198, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4626844525337219, \"iteration\": 199, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.30358701944351196, \"iteration\": 200, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3583126962184906, \"iteration\": 201, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3056635856628418, \"iteration\": 202, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.35551753640174866, \"iteration\": 203, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.438625693321228, \"iteration\": 204, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.35478585958480835, \"iteration\": 205, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3587673306465149, \"iteration\": 206, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.2989952564239502, \"iteration\": 207, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4382617473602295, \"iteration\": 208, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3994668126106262, \"iteration\": 209, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29144972562789917, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.31454336643218994, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3534858822822571, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33970728516578674, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4182281494140625, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3341880142688751, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.33022308349609375, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.35508885979652405, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2704676389694214, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.41935157775878906, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.34939563274383545, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3378766179084778, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.33953553438186646, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.33061474561691284, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4092817008495331, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.36883026361465454, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2960772216320038, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3312016725540161, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.47229480743408203, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.2944948375225067, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.512537956237793, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.35367822647094727, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.34781527519226074, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3479892611503601, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3214436173439026, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3795613646507263, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3721754550933838, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.37874162197113037, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.2780023515224457, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3654709458351135, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4230179786682129, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3997042775154114, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3520747125148773, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.32591021060943604, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.45558962225914, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.38688135147094727, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.39714622497558594, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2930948734283447, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40230506658554077, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.29756343364715576, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.32156306505203247, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.4211695194244385, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.35832375288009644, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3288157880306244, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.354843407869339, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3435675799846649, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.3934693932533264, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.38523000478744507, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3504716753959656, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.44167840480804443, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.42542755603790283, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.25927311182022095, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4528815746307373, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.36680299043655396, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3338967561721802, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.47600868344306946, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3515434265136719, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4020651578903198, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34347841143608093, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.43730872869491577, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.44882529973983765, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.3977857828140259, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.47699296474456787, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3436371386051178, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.36103957891464233, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.39490121603012085, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.34382301568984985, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3544189929962158, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.37568190693855286, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3911516070365906, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4111205041408539, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5052236914634705, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.41059714555740356, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3422040045261383, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3727967441082001, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.4685463309288025, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3646997809410095, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.37969106435775757, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4287579655647278, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40653979778289795, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.43354785442352295, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3416364789009094, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3868334889411926, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.40676093101501465, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4387134313583374, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3273840844631195, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.41707712411880493, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.34438908100128174, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3282597064971924, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4452800154685974, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3716283142566681, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 0.4744880497455597, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4288397431373596, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.3766515254974365, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.4539627432823181, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.443718820810318, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.37928250432014465, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3995789587497711, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3816733956336975, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3997224271297455, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3711608648300171, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.41125035285949707, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4011688828468323, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.3890320658683777, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.39778411388397217, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.33094531297683716, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.418956458568573, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.35675549507141113, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.42245686054229736, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.370247483253479, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3928670883178711, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3295125961303711, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3709857761859894, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.42531222105026245, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3772384524345398, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.36133265495300293, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3634480834007263, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4171924591064453, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2889137864112854, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.37126868963241577, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3313169479370117, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 0.48508042097091675, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3453753888607025, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33124056458473206, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.30968526005744934, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3495231866836548, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.35159832239151, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3639910817146301, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.31861984729766846, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.2998168170452118, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3865148425102234, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.31728458404541016, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4161343574523926, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4683052897453308, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.39441025257110596, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.40907394886016846, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4558751583099365, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.314184308052063, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.38232243061065674, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.37050580978393555, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.39217308163642883, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.45360690355300903, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3624032735824585, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3459482192993164, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29585760831832886, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.34748438000679016, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.3631945252418518, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3104857802391052, \"iteration\": 357, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.34299057722091675, \"iteration\": 358, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24501991271972656, \"iteration\": 359, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.30456894636154175, \"iteration\": 360, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2671114504337311, \"iteration\": 361, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2561400830745697, \"iteration\": 362, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.32816100120544434, \"iteration\": 363, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2266816347837448, \"iteration\": 364, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2508605122566223, \"iteration\": 365, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.1790143847465515, \"iteration\": 366, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3050277829170227, \"iteration\": 367, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2572016417980194, \"iteration\": 368, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26694703102111816, \"iteration\": 369, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30760109424591064, \"iteration\": 370, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.282052218914032, \"iteration\": 371, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2592349052429199, \"iteration\": 372, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2502656877040863, \"iteration\": 373, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2661812901496887, \"iteration\": 374, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.215072363615036, \"iteration\": 375, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.20955738425254822, \"iteration\": 376, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2647976279258728, \"iteration\": 377, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.20482003688812256, \"iteration\": 378, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2728603184223175, \"iteration\": 379, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.30616647005081177, \"iteration\": 380, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.28538817167282104, \"iteration\": 381, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24375461041927338, \"iteration\": 382, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.25552302598953247, \"iteration\": 383, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21575602889060974, \"iteration\": 384, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1975555121898651, \"iteration\": 385, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2056845873594284, \"iteration\": 386, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.19920477271080017, \"iteration\": 387, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2848290205001831, \"iteration\": 388, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27047911286354065, \"iteration\": 389, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.32360726594924927, \"iteration\": 390, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.28571975231170654, \"iteration\": 391, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22138798236846924, \"iteration\": 392, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25893691182136536, \"iteration\": 393, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2518996000289917, \"iteration\": 394, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.229380264878273, \"iteration\": 395, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23777037858963013, \"iteration\": 396, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.28850847482681274, \"iteration\": 397, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2563630938529968, \"iteration\": 398, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.25141477584838867, \"iteration\": 399, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.24790309369564056, \"iteration\": 400, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.286572128534317, \"iteration\": 401, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20571348071098328, \"iteration\": 402, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.277843177318573, \"iteration\": 403, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.275982141494751, \"iteration\": 404, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.2040068805217743, \"iteration\": 405, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2696918547153473, \"iteration\": 406, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24686279892921448, \"iteration\": 407, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2118067443370819, \"iteration\": 408, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2364647090435028, \"iteration\": 409, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.23228326439857483, \"iteration\": 410, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.248509019613266, \"iteration\": 411, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21393772959709167, \"iteration\": 412, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16911375522613525, \"iteration\": 413, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2461928129196167, \"iteration\": 414, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19327330589294434, \"iteration\": 415, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2896271347999573, \"iteration\": 416, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.26774343848228455, \"iteration\": 417, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.12406961619853973, \"iteration\": 418, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.24918489158153534, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21996784210205078, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2632265090942383, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31636345386505127, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20344775915145874, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3203190267086029, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.252783864736557, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22079607844352722, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.32444119453430176, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2816399037837982, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2525179386138916, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2851621210575104, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26564741134643555, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3144788146018982, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20294833183288574, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18938246369361877, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.189413920044899, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3066825866699219, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.22562935948371887, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.31911396980285645, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.29372990131378174, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.41923630237579346, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.2234523594379425, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32856589555740356, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4042646586894989, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.31154903769493103, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.31746479868888855, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.30589598417282104, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.27788081765174866, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3064514994621277, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.30785638093948364, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.21642149984836578, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23761896789073944, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.22955866158008575, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.24551701545715332, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27919530868530273, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19604694843292236, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19432365894317627, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.24171903729438782, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3078387975692749, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.23581591248512268, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2222369909286499, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.34385883808135986, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16895104944705963, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.34920287132263184, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2839238941669464, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.24001304805278778, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.22133320569992065, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2791372835636139, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3993825316429138, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33403220772743225, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.25242292881011963, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.28757190704345703, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.21470554172992706, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32646340131759644, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3069228231906891, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.27503103017807007, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3068002462387085, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2856004536151886, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.21574324369430542, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25127270817756653, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2786734402179718, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.29031574726104736, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1990623027086258, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.24814310669898987, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1759987771511078, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.30675578117370605, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.287443071603775, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.22708025574684143, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2741233706474304, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27595123648643494, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.27189159393310547, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28894275426864624, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.28326380252838135, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19027099013328552, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.355757474899292, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3239704370498657, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19024547934532166, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.24032796919345856, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.26080024242401123, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.33649182319641113, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29893583059310913, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.32764318585395813, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 0.49147433042526245, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2406371533870697, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23036685585975647, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.27341020107269287, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.24220150709152222, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3660677969455719, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3061766028404236, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31639212369918823, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2625340223312378, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32591620087623596, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33364686369895935, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2984119951725006, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.26861804723739624, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2653653621673584, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22220471501350403, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2595198154449463, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2709094285964966, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3484678268432617, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28468453884124756, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.29289907217025757, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19766858220100403, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.268034964799881, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2849865257740021, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.25643259286880493, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2938729524612427, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22780224680900574, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28427523374557495, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.28315848112106323, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23221051692962646, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.30748075246810913, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.37397652864456177, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28423169255256653, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.46175268292427063, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16974957287311554, \"iteration\": 535, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1350807547569275, \"iteration\": 536, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14122262597084045, \"iteration\": 537, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15660780668258667, \"iteration\": 538, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15490339696407318, \"iteration\": 539, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.19567197561264038, \"iteration\": 540, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1678357869386673, \"iteration\": 541, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10549262166023254, \"iteration\": 542, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.16893966495990753, \"iteration\": 543, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1780368685722351, \"iteration\": 544, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21931777894496918, \"iteration\": 545, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11723904311656952, \"iteration\": 546, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13296325504779816, \"iteration\": 547, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14620321989059448, \"iteration\": 548, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21239809691905975, \"iteration\": 549, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.16214540600776672, \"iteration\": 550, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.16882812976837158, \"iteration\": 551, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17114879190921783, \"iteration\": 552, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15168508887290955, \"iteration\": 553, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14499923586845398, \"iteration\": 554, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.15812626481056213, \"iteration\": 555, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18473100662231445, \"iteration\": 556, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.18864183127880096, \"iteration\": 557, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.14277181029319763, \"iteration\": 558, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.16250774264335632, \"iteration\": 559, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11494313925504684, \"iteration\": 560, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14389047026634216, \"iteration\": 561, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16134896874427795, \"iteration\": 562, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.18542394042015076, \"iteration\": 563, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13130313158035278, \"iteration\": 564, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.13870717585086823, \"iteration\": 565, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08229123055934906, \"iteration\": 566, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16563770174980164, \"iteration\": 567, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10595525801181793, \"iteration\": 568, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1238216683268547, \"iteration\": 569, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15853430330753326, \"iteration\": 570, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.19030436873435974, \"iteration\": 571, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1460593044757843, \"iteration\": 572, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09634609520435333, \"iteration\": 573, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17990811169147491, \"iteration\": 574, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1451406180858612, \"iteration\": 575, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15861937403678894, \"iteration\": 576, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.128856360912323, \"iteration\": 577, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10325586795806885, \"iteration\": 578, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.17858105897903442, \"iteration\": 579, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1427271068096161, \"iteration\": 580, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14920689165592194, \"iteration\": 581, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16229912638664246, \"iteration\": 582, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11812417209148407, \"iteration\": 583, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.1280156970024109, \"iteration\": 584, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.15214699506759644, \"iteration\": 585, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2237166166305542, \"iteration\": 586, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.14968791604042053, \"iteration\": 587, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1940847933292389, \"iteration\": 588, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1585417240858078, \"iteration\": 589, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.1918821632862091, \"iteration\": 590, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.16226933896541595, \"iteration\": 591, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10713104903697968, \"iteration\": 592, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11486531794071198, \"iteration\": 593, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13481688499450684, \"iteration\": 594, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12593668699264526, \"iteration\": 595, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20372167229652405, \"iteration\": 596, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11942877620458603, \"iteration\": 597, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12076129019260406, \"iteration\": 598, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18652579188346863, \"iteration\": 599, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1478341668844223, \"iteration\": 600, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10671841353178024, \"iteration\": 601, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14490541815757751, \"iteration\": 602, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1595183163881302, \"iteration\": 603, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13125255703926086, \"iteration\": 604, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13737797737121582, \"iteration\": 605, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18625915050506592, \"iteration\": 606, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.15710920095443726, \"iteration\": 607, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1396530717611313, \"iteration\": 608, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1716427206993103, \"iteration\": 609, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11323923617601395, \"iteration\": 610, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.21630355715751648, \"iteration\": 611, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20220676064491272, \"iteration\": 612, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08783688396215439, \"iteration\": 613, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11824894696474075, \"iteration\": 614, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10845670104026794, \"iteration\": 615, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14950624108314514, \"iteration\": 616, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.18465378880500793, \"iteration\": 617, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10048351436853409, \"iteration\": 618, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10726587474346161, \"iteration\": 619, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2083030343055725, \"iteration\": 620, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1342112421989441, \"iteration\": 621, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2640989124774933, \"iteration\": 622, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11039507389068604, \"iteration\": 623, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1680729240179062, \"iteration\": 624, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2198828160762787, \"iteration\": 625, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14012861251831055, \"iteration\": 626, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13519594073295593, \"iteration\": 627, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1376112997531891, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10129153728485107, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1961376816034317, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09989762306213379, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13017314672470093, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1231786236166954, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.1577669084072113, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.19530728459358215, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17305123805999756, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14229758083820343, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.15891297161579132, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15883608162403107, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.19249558448791504, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.17782853543758392, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16112305223941803, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.15411868691444397, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1329312026500702, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11077140271663666, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1305805742740631, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.16643327474594116, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18376019597053528, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.15392038226127625, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15758857131004333, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17280900478363037, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.21003711223602295, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20133328437805176, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20127946138381958, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.17408981919288635, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22931650280952454, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1925238072872162, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15800458192825317, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1664924919605255, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12292218208312988, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.18049095571041107, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14513008296489716, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1410946249961853, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20250022411346436, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.08952886611223221, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19859176874160767, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18550065159797668, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2102319896221161, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15655940771102905, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15080797672271729, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1452445387840271, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19977177679538727, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15824837982654572, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.13554057478904724, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.15215283632278442, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.15004238486289978, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1861327737569809, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2568773627281189, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11428813636302948, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.11963494122028351, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22075089812278748, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1841333508491516, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18294760584831238, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11573518812656403, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1471441686153412, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16919326782226562, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1646423637866974, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12240487337112427, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17825238406658173, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17927402257919312, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.27546215057373047, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17402145266532898, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24765220284461975, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1407967358827591, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22940638661384583, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1643814891576767, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17526577413082123, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20054787397384644, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.18356607854366302, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.21014373004436493, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17464113235473633, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.11574557423591614, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20006883144378662, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20240211486816406, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21106502413749695, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21354828774929047, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.10995978862047195, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2240268439054489, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14992818236351013, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21897174417972565, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.16833363473415375, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.3041851222515106, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09421107172966003, \"iteration\": 713, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0647365152835846, \"iteration\": 714, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1298586130142212, \"iteration\": 715, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09427028894424438, \"iteration\": 716, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0655650943517685, \"iteration\": 717, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.0818425640463829, \"iteration\": 718, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08092840015888214, \"iteration\": 719, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.08085234463214874, \"iteration\": 720, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10896258801221848, \"iteration\": 721, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.07126963138580322, \"iteration\": 722, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07155604660511017, \"iteration\": 723, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07958374917507172, \"iteration\": 724, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05722980201244354, \"iteration\": 725, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09356484562158585, \"iteration\": 726, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06840244680643082, \"iteration\": 727, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06840266287326813, \"iteration\": 728, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06526100635528564, \"iteration\": 729, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.058322954922914505, \"iteration\": 730, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04949706047773361, \"iteration\": 731, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0606079138815403, \"iteration\": 732, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08356985449790955, \"iteration\": 733, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.034100476652383804, \"iteration\": 734, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0828017145395279, \"iteration\": 735, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06939755380153656, \"iteration\": 736, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0618983693420887, \"iteration\": 737, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0777290090918541, \"iteration\": 738, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.06499762088060379, \"iteration\": 739, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03888417035341263, \"iteration\": 740, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05781382694840431, \"iteration\": 741, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05039601773023605, \"iteration\": 742, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1215163916349411, \"iteration\": 743, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.050781190395355225, \"iteration\": 744, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.09820395708084106, \"iteration\": 745, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08534008264541626, \"iteration\": 746, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.061761245131492615, \"iteration\": 747, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08350366353988647, \"iteration\": 748, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07089607417583466, \"iteration\": 749, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06604817509651184, \"iteration\": 750, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04591904580593109, \"iteration\": 751, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10371851921081543, \"iteration\": 752, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.09714081883430481, \"iteration\": 753, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07340463995933533, \"iteration\": 754, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05962368845939636, \"iteration\": 755, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.104275181889534, \"iteration\": 756, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.058955367654561996, \"iteration\": 757, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09884916245937347, \"iteration\": 758, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.050351038575172424, \"iteration\": 759, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06524118781089783, \"iteration\": 760, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14912118017673492, \"iteration\": 761, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.07317611575126648, \"iteration\": 762, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07420168817043304, \"iteration\": 763, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08302178978919983, \"iteration\": 764, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08484931290149689, \"iteration\": 765, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05065816640853882, \"iteration\": 766, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07061891257762909, \"iteration\": 767, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05885430797934532, \"iteration\": 768, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.06362859904766083, \"iteration\": 769, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03925573080778122, \"iteration\": 770, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0848466232419014, \"iteration\": 771, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07693688571453094, \"iteration\": 772, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1279844045639038, \"iteration\": 773, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08994221687316895, \"iteration\": 774, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08828860521316528, \"iteration\": 775, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04519994184374809, \"iteration\": 776, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09554839879274368, \"iteration\": 777, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.05244753509759903, \"iteration\": 778, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07547903805971146, \"iteration\": 779, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04523688554763794, \"iteration\": 780, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08909738063812256, \"iteration\": 781, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08218574523925781, \"iteration\": 782, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10662885755300522, \"iteration\": 783, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.05296294391155243, \"iteration\": 784, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0486743226647377, \"iteration\": 785, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07662485539913177, \"iteration\": 786, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028223427012562752, \"iteration\": 787, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09472981840372086, \"iteration\": 788, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.04995190352201462, \"iteration\": 789, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09296797215938568, \"iteration\": 790, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054175831377506256, \"iteration\": 791, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.031304750591516495, \"iteration\": 792, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1296759992837906, \"iteration\": 793, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04943349212408066, \"iteration\": 794, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11191894114017487, \"iteration\": 795, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.06618951261043549, \"iteration\": 796, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05431926250457764, \"iteration\": 797, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07156387716531754, \"iteration\": 798, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08928251266479492, \"iteration\": 799, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0721898078918457, \"iteration\": 800, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08894133567810059, \"iteration\": 801, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03560751676559448, \"iteration\": 802, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.06107078492641449, \"iteration\": 803, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08033524453639984, \"iteration\": 804, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07109810411930084, \"iteration\": 805, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06326133012771606, \"iteration\": 806, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04779352620244026, \"iteration\": 807, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05828718841075897, \"iteration\": 808, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09352914988994598, \"iteration\": 809, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06650464981794357, \"iteration\": 810, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05330252647399902, \"iteration\": 811, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06832285970449448, \"iteration\": 812, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1307263821363449, \"iteration\": 813, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05858743190765381, \"iteration\": 814, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07777629792690277, \"iteration\": 815, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07553036510944366, \"iteration\": 816, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09260464459657669, \"iteration\": 817, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10267487913370132, \"iteration\": 818, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0836096853017807, \"iteration\": 819, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.033309806138277054, \"iteration\": 820, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03671380504965782, \"iteration\": 821, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0917782187461853, \"iteration\": 822, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11924624443054199, \"iteration\": 823, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.10660199075937271, \"iteration\": 824, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.057132020592689514, \"iteration\": 825, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11859893798828125, \"iteration\": 826, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04566791653633118, \"iteration\": 827, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03791320323944092, \"iteration\": 828, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05734950304031372, \"iteration\": 829, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08979080617427826, \"iteration\": 830, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0810471922159195, \"iteration\": 831, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07996253669261932, \"iteration\": 832, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08233658969402313, \"iteration\": 833, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0779200941324234, \"iteration\": 834, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04696248471736908, \"iteration\": 835, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.052709102630615234, \"iteration\": 836, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.057411957532167435, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.07432503998279572, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08446978032588959, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07692550122737885, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04587309807538986, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09025394916534424, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06282693147659302, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.035569529980421066, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.026605043560266495, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11888237297534943, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07444174587726593, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0430261567234993, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.051808230578899384, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08158982545137405, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0789545476436615, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.05086608976125717, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.050551578402519226, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.05162586271762848, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09365947544574738, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0497918576002121, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10137990862131119, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08838841319084167, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1559891700744629, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.13533611595630646, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.07054723054170609, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1574230045080185, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.04673650115728378, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08665185421705246, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.058353859931230545, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07095853984355927, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07311765849590302, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.05976215749979019, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05221276357769966, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09093302488327026, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09241978079080582, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0726667046546936, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.05270322412252426, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11776456236839294, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04478215426206589, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07805010676383972, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05678786337375641, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11170613765716553, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.05966951698064804, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06744623184204102, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07804394513368607, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.056189246475696564, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.050830259919166565, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05650794506072998, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05883735045790672, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15646466612815857, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.048524752259254456, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08580154925584793, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0599936842918396, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03285400569438934, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03177739679813385, \"iteration\": 891, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05047091469168663, \"iteration\": 892, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09020237624645233, \"iteration\": 893, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02414146438241005, \"iteration\": 894, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020813938230276108, \"iteration\": 895, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02832772210240364, \"iteration\": 896, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018856756389141083, \"iteration\": 897, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03774600476026535, \"iteration\": 898, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01972871832549572, \"iteration\": 899, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022287607192993164, \"iteration\": 900, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.021035727113485336, \"iteration\": 901, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.028330370783805847, \"iteration\": 902, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02035840041935444, \"iteration\": 903, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03286633640527725, \"iteration\": 904, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011247425340116024, \"iteration\": 905, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02000821940600872, \"iteration\": 906, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012388716451823711, \"iteration\": 907, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02165786363184452, \"iteration\": 908, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01656102016568184, \"iteration\": 909, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02660847082734108, \"iteration\": 910, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012756548821926117, \"iteration\": 911, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01988058350980282, \"iteration\": 912, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03817176818847656, \"iteration\": 913, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01578323170542717, \"iteration\": 914, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020130451768636703, \"iteration\": 915, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022830616682767868, \"iteration\": 916, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0129105094820261, \"iteration\": 917, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020668987184762955, \"iteration\": 918, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017861217260360718, \"iteration\": 919, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015619833022356033, \"iteration\": 920, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015999604016542435, \"iteration\": 921, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0172564834356308, \"iteration\": 922, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011922802776098251, \"iteration\": 923, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03225227817893028, \"iteration\": 924, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01287062093615532, \"iteration\": 925, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019621174782514572, \"iteration\": 926, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01728675328195095, \"iteration\": 927, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.028119917958974838, \"iteration\": 928, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015008673071861267, \"iteration\": 929, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010586230084300041, \"iteration\": 930, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.026503056287765503, \"iteration\": 931, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009176495485007763, \"iteration\": 932, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022158991545438766, \"iteration\": 933, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016712719574570656, \"iteration\": 934, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019213354215025902, \"iteration\": 935, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009259624406695366, \"iteration\": 936, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04237495735287666, \"iteration\": 937, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02167651243507862, \"iteration\": 938, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0071981740184128284, \"iteration\": 939, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.025935959070920944, \"iteration\": 940, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018474014475941658, \"iteration\": 941, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012543655931949615, \"iteration\": 942, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020621519535779953, \"iteration\": 943, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.027081981301307678, \"iteration\": 944, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01618034578859806, \"iteration\": 945, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011183556169271469, \"iteration\": 946, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.04647514969110489, \"iteration\": 947, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01872289925813675, \"iteration\": 948, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.045286837965250015, \"iteration\": 949, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.021590963006019592, \"iteration\": 950, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013880554586648941, \"iteration\": 951, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01317675318568945, \"iteration\": 952, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011015609838068485, \"iteration\": 953, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010818551294505596, \"iteration\": 954, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.025981690734624863, \"iteration\": 955, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02762286551296711, \"iteration\": 956, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010490268468856812, \"iteration\": 957, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01902189664542675, \"iteration\": 958, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040392011404037476, \"iteration\": 959, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014521609991788864, \"iteration\": 960, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01446627452969551, \"iteration\": 961, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017019715160131454, \"iteration\": 962, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01622646301984787, \"iteration\": 963, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02647976577281952, \"iteration\": 964, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06473974883556366, \"iteration\": 965, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05613316595554352, \"iteration\": 966, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02729848399758339, \"iteration\": 967, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0073232948780059814, \"iteration\": 968, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01592312753200531, \"iteration\": 969, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012037249282002449, \"iteration\": 970, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05727238208055496, \"iteration\": 971, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01758386567234993, \"iteration\": 972, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01726359874010086, \"iteration\": 973, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02484232746064663, \"iteration\": 974, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016322381794452667, \"iteration\": 975, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.034278467297554016, \"iteration\": 976, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014986712485551834, \"iteration\": 977, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.015927892178297043, \"iteration\": 978, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.024403851479291916, \"iteration\": 979, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01761319674551487, \"iteration\": 980, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01735452562570572, \"iteration\": 981, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015415037982165813, \"iteration\": 982, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008886132389307022, \"iteration\": 983, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00952718686312437, \"iteration\": 984, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.031444113701581955, \"iteration\": 985, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.021825412288308144, \"iteration\": 986, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020052876323461533, \"iteration\": 987, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015543051064014435, \"iteration\": 988, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016611987724900246, \"iteration\": 989, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009894568473100662, \"iteration\": 990, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03671303391456604, \"iteration\": 991, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011581082828342915, \"iteration\": 992, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01304716058075428, \"iteration\": 993, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013375737704336643, \"iteration\": 994, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014025294221937656, \"iteration\": 995, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016752393916249275, \"iteration\": 996, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02827909216284752, \"iteration\": 997, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04997995123267174, \"iteration\": 998, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023214951157569885, \"iteration\": 999, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05947659909725189, \"iteration\": 1000, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008075029589235783, \"iteration\": 1001, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02709488570690155, \"iteration\": 1002, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014081219211220741, \"iteration\": 1003, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03251571208238602, \"iteration\": 1004, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03709392622113228, \"iteration\": 1005, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010441366583108902, \"iteration\": 1006, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032179445028305054, \"iteration\": 1007, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01747092604637146, \"iteration\": 1008, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030928708612918854, \"iteration\": 1009, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018773069605231285, \"iteration\": 1010, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04245501756668091, \"iteration\": 1011, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024220651015639305, \"iteration\": 1012, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014474056661128998, \"iteration\": 1013, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009871264919638634, \"iteration\": 1014, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011054778471589088, \"iteration\": 1015, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013182872906327248, \"iteration\": 1016, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.038251858204603195, \"iteration\": 1017, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016936825588345528, \"iteration\": 1018, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009653113782405853, \"iteration\": 1019, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06458093971014023, \"iteration\": 1020, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022223761305212975, \"iteration\": 1021, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019584085792303085, \"iteration\": 1022, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03325490653514862, \"iteration\": 1023, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011510924436151981, \"iteration\": 1024, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018107939511537552, \"iteration\": 1025, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05752165988087654, \"iteration\": 1026, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01930825412273407, \"iteration\": 1027, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019595762714743614, \"iteration\": 1028, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015088608488440514, \"iteration\": 1029, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.021883733570575714, \"iteration\": 1030, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01938920095562935, \"iteration\": 1031, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011854263022542, \"iteration\": 1032, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015527602285146713, \"iteration\": 1033, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011562442407011986, \"iteration\": 1034, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005535881966352463, \"iteration\": 1035, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.05029045045375824, \"iteration\": 1036, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017815720289945602, \"iteration\": 1037, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014150790870189667, \"iteration\": 1038, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05031348764896393, \"iteration\": 1039, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01742321066558361, \"iteration\": 1040, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020376868546009064, \"iteration\": 1041, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.052932895720005035, \"iteration\": 1042, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04411175847053528, \"iteration\": 1043, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007422714028507471, \"iteration\": 1044, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010431523434817791, \"iteration\": 1045, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03121155872941017, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016241492703557014, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015380820259451866, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014387344010174274, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013557163067162037, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01359183806926012, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023306850343942642, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013886615633964539, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0758737102150917, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019287005066871643, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016454054042696953, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04492635279893875, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02132522687315941, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09794603288173676, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.031365349888801575, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.032877057790756226, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0336424857378006, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01552230678498745, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00965072214603424, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018455835059285164, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03650857135653496, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03233284130692482, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.003872947534546256, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006520388647913933, \"iteration\": 1069, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006834371015429497, \"iteration\": 1070, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009179787710309029, \"iteration\": 1071, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008797215297818184, \"iteration\": 1072, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006366373971104622, \"iteration\": 1073, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03645440191030502, \"iteration\": 1074, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0071067409589886665, \"iteration\": 1075, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005739303305745125, \"iteration\": 1076, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011221574619412422, \"iteration\": 1077, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009568269364535809, \"iteration\": 1078, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005987446755170822, \"iteration\": 1079, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00859481655061245, \"iteration\": 1080, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036533658858388662, \"iteration\": 1081, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006975552067160606, \"iteration\": 1082, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005111881531774998, \"iteration\": 1083, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008103849366307259, \"iteration\": 1084, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0073238275945186615, \"iteration\": 1085, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009026902727782726, \"iteration\": 1086, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007991081103682518, \"iteration\": 1087, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004211275838315487, \"iteration\": 1088, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009544819593429565, \"iteration\": 1089, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004774370696395636, \"iteration\": 1090, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006039632484316826, \"iteration\": 1091, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005768028553575277, \"iteration\": 1092, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009697452187538147, \"iteration\": 1093, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006805895362049341, \"iteration\": 1094, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004855922423303127, \"iteration\": 1095, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002742532640695572, \"iteration\": 1096, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004744484089314938, \"iteration\": 1097, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002934145275503397, \"iteration\": 1098, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016353679820895195, \"iteration\": 1099, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006769273895770311, \"iteration\": 1100, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008143893443048, \"iteration\": 1101, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004838073160499334, \"iteration\": 1102, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007144758477807045, \"iteration\": 1103, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0065376609563827515, \"iteration\": 1104, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007584686391055584, \"iteration\": 1105, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035153664648532867, \"iteration\": 1106, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02692163549363613, \"iteration\": 1107, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005112391896545887, \"iteration\": 1108, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005813797004520893, \"iteration\": 1109, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004715234972536564, \"iteration\": 1110, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00973287969827652, \"iteration\": 1111, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004950409755110741, \"iteration\": 1112, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.019328247755765915, \"iteration\": 1113, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004391707479953766, \"iteration\": 1114, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00540181016549468, \"iteration\": 1115, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008771724998950958, \"iteration\": 1116, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037739903200417757, \"iteration\": 1117, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014644695445895195, \"iteration\": 1118, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035680271685123444, \"iteration\": 1119, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004610102623701096, \"iteration\": 1120, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002703398000448942, \"iteration\": 1121, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004713662900030613, \"iteration\": 1122, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008094241842627525, \"iteration\": 1123, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0071309455670416355, \"iteration\": 1124, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003556786570698023, \"iteration\": 1125, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004666987806558609, \"iteration\": 1126, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009524546563625336, \"iteration\": 1127, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0050785476341843605, \"iteration\": 1128, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004598635248839855, \"iteration\": 1129, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0072696274146437645, \"iteration\": 1130, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005166664719581604, \"iteration\": 1131, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031784549355506897, \"iteration\": 1132, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004174788948148489, \"iteration\": 1133, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004527196288108826, \"iteration\": 1134, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031363326124846935, \"iteration\": 1135, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037552390713244677, \"iteration\": 1136, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004206380341202021, \"iteration\": 1137, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003442372428253293, \"iteration\": 1138, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005304328165948391, \"iteration\": 1139, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012558689340949059, \"iteration\": 1140, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005188485607504845, \"iteration\": 1141, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004912571515887976, \"iteration\": 1142, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004111464601010084, \"iteration\": 1143, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005321410484611988, \"iteration\": 1144, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004880672320723534, \"iteration\": 1145, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005218314938247204, \"iteration\": 1146, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005226378329098225, \"iteration\": 1147, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007360312156379223, \"iteration\": 1148, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007962978444993496, \"iteration\": 1149, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009437867440283298, \"iteration\": 1150, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006693191360682249, \"iteration\": 1151, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036117760464549065, \"iteration\": 1152, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023540668189525604, \"iteration\": 1153, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019607774913311005, \"iteration\": 1154, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005934480577707291, \"iteration\": 1155, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003200237639248371, \"iteration\": 1156, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004545251838862896, \"iteration\": 1157, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00493866391479969, \"iteration\": 1158, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034397521521896124, \"iteration\": 1159, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004198403097689152, \"iteration\": 1160, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07782809436321259, \"iteration\": 1161, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008428916335105896, \"iteration\": 1162, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007534174248576164, \"iteration\": 1163, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001455575693398714, \"iteration\": 1164, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036056828685104847, \"iteration\": 1165, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003434335347265005, \"iteration\": 1166, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005732567515224218, \"iteration\": 1167, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037403670139610767, \"iteration\": 1168, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00902305357158184, \"iteration\": 1169, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031524724327027798, \"iteration\": 1170, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031971975695341825, \"iteration\": 1171, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004999890923500061, \"iteration\": 1172, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005621909163892269, \"iteration\": 1173, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004624736495316029, \"iteration\": 1174, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028372618835419416, \"iteration\": 1175, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0026254102122038603, \"iteration\": 1176, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005385369993746281, \"iteration\": 1177, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022706291638314724, \"iteration\": 1178, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037274581845849752, \"iteration\": 1179, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006110238377004862, \"iteration\": 1180, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004071967676281929, \"iteration\": 1181, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002710402011871338, \"iteration\": 1182, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006982386112213135, \"iteration\": 1183, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006102392915636301, \"iteration\": 1184, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004533041268587112, \"iteration\": 1185, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00503486767411232, \"iteration\": 1186, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004203394055366516, \"iteration\": 1187, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002804867923259735, \"iteration\": 1188, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007689331192523241, \"iteration\": 1189, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006391062401235104, \"iteration\": 1190, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004107246175408363, \"iteration\": 1191, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027377342339605093, \"iteration\": 1192, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0058537875302135944, \"iteration\": 1193, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004539023153483868, \"iteration\": 1194, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005428495351225138, \"iteration\": 1195, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006874488666653633, \"iteration\": 1196, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0039054318331182003, \"iteration\": 1197, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0041954959742724895, \"iteration\": 1198, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003954671323299408, \"iteration\": 1199, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005613948218524456, \"iteration\": 1200, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003194226184859872, \"iteration\": 1201, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00502296257764101, \"iteration\": 1202, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038423766382038593, \"iteration\": 1203, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027352951001375914, \"iteration\": 1204, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0039001416880637407, \"iteration\": 1205, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034850514493882656, \"iteration\": 1206, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002879900624975562, \"iteration\": 1207, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027868447359651327, \"iteration\": 1208, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037936512380838394, \"iteration\": 1209, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007062621880322695, \"iteration\": 1210, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006553165148943663, \"iteration\": 1211, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.011022820137441158, \"iteration\": 1212, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007580483332276344, \"iteration\": 1213, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002591269090771675, \"iteration\": 1214, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023689570371061563, \"iteration\": 1215, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.013708855956792831, \"iteration\": 1216, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037587652914226055, \"iteration\": 1217, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003650062717497349, \"iteration\": 1218, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0045063430443406105, \"iteration\": 1219, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014064467512071133, \"iteration\": 1220, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023126890882849693, \"iteration\": 1221, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018842432647943497, \"iteration\": 1222, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036805227864533663, \"iteration\": 1223, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002629610477015376, \"iteration\": 1224, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034388641361147165, \"iteration\": 1225, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003652755869552493, \"iteration\": 1226, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008177303709089756, \"iteration\": 1227, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037982012145221233, \"iteration\": 1228, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034285730216652155, \"iteration\": 1229, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0039147986099123955, \"iteration\": 1230, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005175095982849598, \"iteration\": 1231, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005455844569951296, \"iteration\": 1232, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005302204750478268, \"iteration\": 1233, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012721870094537735, \"iteration\": 1234, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027121100574731827, \"iteration\": 1235, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003160889493301511, \"iteration\": 1236, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0030890144407749176, \"iteration\": 1237, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038029635325074196, \"iteration\": 1238, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002454862231388688, \"iteration\": 1239, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004954702686518431, \"iteration\": 1240, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005061489995568991, \"iteration\": 1241, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009040514007210732, \"iteration\": 1242, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009319416247308254, \"iteration\": 1243, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005350083112716675, \"iteration\": 1244, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00823281705379486, \"iteration\": 1245, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018363695126026869, \"iteration\": 1246, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002059898106381297, \"iteration\": 1247, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003718135179951787, \"iteration\": 1248, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002227852353826165, \"iteration\": 1249, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002604590728878975, \"iteration\": 1250, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015893833478912711, \"iteration\": 1251, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020315921865403652, \"iteration\": 1252, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001892145024612546, \"iteration\": 1253, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04151187464594841, \"iteration\": 1254, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003609983716160059, \"iteration\": 1255, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002505786018446088, \"iteration\": 1256, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002781254006549716, \"iteration\": 1257, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001596357673406601, \"iteration\": 1258, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021789371967315674, \"iteration\": 1259, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007753590471111238, \"iteration\": 1260, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017030127346515656, \"iteration\": 1261, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002434920519590378, \"iteration\": 1262, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0041885580867528915, \"iteration\": 1263, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002531609497964382, \"iteration\": 1264, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018204638035967946, \"iteration\": 1265, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014657038263976574, \"iteration\": 1266, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018897344125434756, \"iteration\": 1267, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018217662582173944, \"iteration\": 1268, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0029891282320022583, \"iteration\": 1269, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010686484165489674, \"iteration\": 1270, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015944608021527529, \"iteration\": 1271, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0026401961222290993, \"iteration\": 1272, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016766167245805264, \"iteration\": 1273, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017939149402081966, \"iteration\": 1274, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023560652043670416, \"iteration\": 1275, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014024979900568724, \"iteration\": 1276, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017195339314639568, \"iteration\": 1277, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003175437683239579, \"iteration\": 1278, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017173737287521362, \"iteration\": 1279, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022243931889533997, \"iteration\": 1280, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008380567654967308, \"iteration\": 1281, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016517631011083722, \"iteration\": 1282, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020134742371737957, \"iteration\": 1283, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016317786648869514, \"iteration\": 1284, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020834817551076412, \"iteration\": 1285, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01609211415052414, \"iteration\": 1286, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013673051726073027, \"iteration\": 1287, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015538835432380438, \"iteration\": 1288, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00136988190934062, \"iteration\": 1289, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002290958072990179, \"iteration\": 1290, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023125435691326857, \"iteration\": 1291, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022245042491704226, \"iteration\": 1292, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00204090285114944, \"iteration\": 1293, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013347240164875984, \"iteration\": 1294, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0025684332940727472, \"iteration\": 1295, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019223438575863838, \"iteration\": 1296, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015633043367415667, \"iteration\": 1297, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013817755971103907, \"iteration\": 1298, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019461236661300063, \"iteration\": 1299, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018989986274391413, \"iteration\": 1300, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016021480550989509, \"iteration\": 1301, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016003400087356567, \"iteration\": 1302, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016297213733196259, \"iteration\": 1303, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011673399712890387, \"iteration\": 1304, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015670614084228873, \"iteration\": 1305, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016411193646490574, \"iteration\": 1306, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015960211167111993, \"iteration\": 1307, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000981883960776031, \"iteration\": 1308, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022843019105494022, \"iteration\": 1309, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023714641574770212, \"iteration\": 1310, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016662618145346642, \"iteration\": 1311, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021029850468039513, \"iteration\": 1312, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014653766993433237, \"iteration\": 1313, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002483681309968233, \"iteration\": 1314, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009195657330565155, \"iteration\": 1315, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010877500753849745, \"iteration\": 1316, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010849754326045513, \"iteration\": 1317, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010751038789749146, \"iteration\": 1318, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016279369592666626, \"iteration\": 1319, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022422433830797672, \"iteration\": 1320, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001823970815166831, \"iteration\": 1321, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0028212526813149452, \"iteration\": 1322, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016387084033340216, \"iteration\": 1323, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017392141744494438, \"iteration\": 1324, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009568812092766166, \"iteration\": 1325, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007016906747594476, \"iteration\": 1326, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001459390390664339, \"iteration\": 1327, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001418456551618874, \"iteration\": 1328, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014461808605119586, \"iteration\": 1329, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014288576785475016, \"iteration\": 1330, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009067535866051912, \"iteration\": 1331, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001050387043505907, \"iteration\": 1332, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001675447914749384, \"iteration\": 1333, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009171935962513089, \"iteration\": 1334, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017016128404065967, \"iteration\": 1335, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00099925696849823, \"iteration\": 1336, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013938758056610823, \"iteration\": 1337, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016094226157292724, \"iteration\": 1338, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014661757741123438, \"iteration\": 1339, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013046925887465477, \"iteration\": 1340, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002110840752720833, \"iteration\": 1341, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003077126108109951, \"iteration\": 1342, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012946787755936384, \"iteration\": 1343, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001101611997000873, \"iteration\": 1344, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021284506656229496, \"iteration\": 1345, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0029531654436141253, \"iteration\": 1346, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002151409164071083, \"iteration\": 1347, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001414690283127129, \"iteration\": 1348, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015503594186156988, \"iteration\": 1349, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013356390409171581, \"iteration\": 1350, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012953865807503462, \"iteration\": 1351, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001262039178982377, \"iteration\": 1352, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014008719008415937, \"iteration\": 1353, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015770264435559511, \"iteration\": 1354, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014091595076024532, \"iteration\": 1355, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011498323874548078, \"iteration\": 1356, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013533065794035792, \"iteration\": 1357, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008974927477538586, \"iteration\": 1358, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014447560533881187, \"iteration\": 1359, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008011652389541268, \"iteration\": 1360, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015281345695257187, \"iteration\": 1361, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018117005238309503, \"iteration\": 1362, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017800754867494106, \"iteration\": 1363, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008081636624410748, \"iteration\": 1364, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001495291362516582, \"iteration\": 1365, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001182379201054573, \"iteration\": 1366, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007169921882450581, \"iteration\": 1367, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009220045758411288, \"iteration\": 1368, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016022182535380125, \"iteration\": 1369, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010394687997177243, \"iteration\": 1370, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005653827684000134, \"iteration\": 1371, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012775273062288761, \"iteration\": 1372, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017837360501289368, \"iteration\": 1373, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007510730065405369, \"iteration\": 1374, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012222644872963428, \"iteration\": 1375, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006927823415026069, \"iteration\": 1376, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008215995039790869, \"iteration\": 1377, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007747180061414838, \"iteration\": 1378, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015599809121340513, \"iteration\": 1379, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008497268427163363, \"iteration\": 1380, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001420138985849917, \"iteration\": 1381, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010962144006043673, \"iteration\": 1382, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0028195949271321297, \"iteration\": 1383, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002061181701719761, \"iteration\": 1384, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001355507643893361, \"iteration\": 1385, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001960473135113716, \"iteration\": 1386, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013763393508270383, \"iteration\": 1387, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001504231826402247, \"iteration\": 1388, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001434519188478589, \"iteration\": 1389, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008172616362571716, \"iteration\": 1390, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013496095780283213, \"iteration\": 1391, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016417177394032478, \"iteration\": 1392, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007673754007555544, \"iteration\": 1393, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001458441256545484, \"iteration\": 1394, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007509414572268724, \"iteration\": 1395, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011870297603309155, \"iteration\": 1396, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001120064058341086, \"iteration\": 1397, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009263071115128696, \"iteration\": 1398, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001085266238078475, \"iteration\": 1399, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010353026445955038, \"iteration\": 1400, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016916422173380852, \"iteration\": 1401, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012745354324579239, \"iteration\": 1402, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007037530886009336, \"iteration\": 1403, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007589002489112318, \"iteration\": 1404, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014887347351759672, \"iteration\": 1405, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012604998191818595, \"iteration\": 1406, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022327033802866936, \"iteration\": 1407, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006860910798422992, \"iteration\": 1408, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006581798661500216, \"iteration\": 1409, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010766640771180391, \"iteration\": 1410, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015643960796296597, \"iteration\": 1411, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013698856346309185, \"iteration\": 1412, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00100430054590106, \"iteration\": 1413, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009857147233560681, \"iteration\": 1414, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018579204333946109, \"iteration\": 1415, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011050672037526965, \"iteration\": 1416, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010353701654821634, \"iteration\": 1417, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010908145923167467, \"iteration\": 1418, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000880375795532018, \"iteration\": 1419, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006976024014875293, \"iteration\": 1420, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011915686773136258, \"iteration\": 1421, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008654796984046698, \"iteration\": 1422, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008719027973711491, \"iteration\": 1423, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020304860081523657, \"iteration\": 1424, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000582991458941251, \"iteration\": 1425, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006813958752900362, \"iteration\": 1426, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008325014496222138, \"iteration\": 1427, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00038539216620847583, \"iteration\": 1428, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000598588609136641, \"iteration\": 1429, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011678910814225674, \"iteration\": 1430, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006849588244222105, \"iteration\": 1431, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005170961376279593, \"iteration\": 1432, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007611899054609239, \"iteration\": 1433, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008336968603543937, \"iteration\": 1434, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005753753939643502, \"iteration\": 1435, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007559909718111157, \"iteration\": 1436, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006233899621292949, \"iteration\": 1437, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006960727041587234, \"iteration\": 1438, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000841229222714901, \"iteration\": 1439, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005978777189739048, \"iteration\": 1440, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007184183341450989, \"iteration\": 1441, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005204819608479738, \"iteration\": 1442, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005895531503483653, \"iteration\": 1443, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005522528663277626, \"iteration\": 1444, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007147050928324461, \"iteration\": 1445, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006891664816066623, \"iteration\": 1446, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005442124675028026, \"iteration\": 1447, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005427990690805018, \"iteration\": 1448, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000708232750184834, \"iteration\": 1449, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041028275154531, \"iteration\": 1450, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003269547887612134, \"iteration\": 1451, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004977673524990678, \"iteration\": 1452, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006768584717065096, \"iteration\": 1453, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007562510436400771, \"iteration\": 1454, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008496050722897053, \"iteration\": 1455, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000508891767822206, \"iteration\": 1456, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004639737890101969, \"iteration\": 1457, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005391584127210081, \"iteration\": 1458, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005193428951315582, \"iteration\": 1459, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00044028402771800756, \"iteration\": 1460, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006542372284457088, \"iteration\": 1461, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008066478767432272, \"iteration\": 1462, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005634999834001064, \"iteration\": 1463, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005708371172659099, \"iteration\": 1464, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005040834075771272, \"iteration\": 1465, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005946988821960986, \"iteration\": 1466, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005684599746018648, \"iteration\": 1467, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00046629004646092653, \"iteration\": 1468, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009683871176093817, \"iteration\": 1469, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007147638243623078, \"iteration\": 1470, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007148347795009613, \"iteration\": 1471, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006650624563917518, \"iteration\": 1472, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006661443621851504, \"iteration\": 1473, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006321414257399738, \"iteration\": 1474, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007013120921328664, \"iteration\": 1475, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006430220673792064, \"iteration\": 1476, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007936681504361331, \"iteration\": 1477, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009664323879405856, \"iteration\": 1478, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006192827131599188, \"iteration\": 1479, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045737239997833967, \"iteration\": 1480, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004872307472396642, \"iteration\": 1481, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005391925806179643, \"iteration\": 1482, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005623014876618981, \"iteration\": 1483, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006772800115868449, \"iteration\": 1484, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009880706202238798, \"iteration\": 1485, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009133546845987439, \"iteration\": 1486, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034435378620401025, \"iteration\": 1487, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004784210759680718, \"iteration\": 1488, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006534766871482134, \"iteration\": 1489, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005589475040324032, \"iteration\": 1490, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010302509181201458, \"iteration\": 1491, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005806828266941011, \"iteration\": 1492, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007993584731593728, \"iteration\": 1493, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045710368431173265, \"iteration\": 1494, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00047121947864070535, \"iteration\": 1495, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0027088928036391735, \"iteration\": 1496, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00038496425258927047, \"iteration\": 1497, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004810021782759577, \"iteration\": 1498, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003472519456408918, \"iteration\": 1499, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010436666198074818, \"iteration\": 1500, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006816418608650565, \"iteration\": 1501, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004288676427677274, \"iteration\": 1502, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005334338638931513, \"iteration\": 1503, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005833182367496192, \"iteration\": 1504, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006453112000599504, \"iteration\": 1505, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007612080662511289, \"iteration\": 1506, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005604003090411425, \"iteration\": 1507, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006220820941962302, \"iteration\": 1508, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000633584859315306, \"iteration\": 1509, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006373062497004867, \"iteration\": 1510, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006321824621409178, \"iteration\": 1511, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005143990856595337, \"iteration\": 1512, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005107643664814532, \"iteration\": 1513, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004984009428881109, \"iteration\": 1514, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005978448898531497, \"iteration\": 1515, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004851019475609064, \"iteration\": 1516, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005272608250379562, \"iteration\": 1517, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005642332835122943, \"iteration\": 1518, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009041617740876973, \"iteration\": 1519, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001921622664667666, \"iteration\": 1520, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010801225434988737, \"iteration\": 1521, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006246082484722137, \"iteration\": 1522, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004995940835215151, \"iteration\": 1523, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007251753122545779, \"iteration\": 1524, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003618236514739692, \"iteration\": 1525, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000912100134883076, \"iteration\": 1526, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004586738650687039, \"iteration\": 1527, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000447894970420748, \"iteration\": 1528, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006212752196006477, \"iteration\": 1529, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00090985675342381, \"iteration\": 1530, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004558792570605874, \"iteration\": 1531, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003626174293458462, \"iteration\": 1532, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000526116113178432, \"iteration\": 1533, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006455999100580812, \"iteration\": 1534, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005350338760763407, \"iteration\": 1535, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004989140434190631, \"iteration\": 1536, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005097658140584826, \"iteration\": 1537, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00046493939589709044, \"iteration\": 1538, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043967351666651666, \"iteration\": 1539, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00046314121573232114, \"iteration\": 1540, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004591583856381476, \"iteration\": 1541, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006837426335550845, \"iteration\": 1542, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005307219107635319, \"iteration\": 1543, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005339639028534293, \"iteration\": 1544, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000631886359769851, \"iteration\": 1545, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000520542380400002, \"iteration\": 1546, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000425061589339748, \"iteration\": 1547, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005945413722656667, \"iteration\": 1548, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00042426996515132487, \"iteration\": 1549, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00038455246249213815, \"iteration\": 1550, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006251984741538763, \"iteration\": 1551, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029944709967821836, \"iteration\": 1552, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003397988621145487, \"iteration\": 1553, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005421102978289127, \"iteration\": 1554, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034174072789028287, \"iteration\": 1555, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003870254149660468, \"iteration\": 1556, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00042624332127161324, \"iteration\": 1557, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006036059930920601, \"iteration\": 1558, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003142892092000693, \"iteration\": 1559, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009103132179006934, \"iteration\": 1560, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003618551418185234, \"iteration\": 1561, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005673422710970044, \"iteration\": 1562, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043053776607848704, \"iteration\": 1563, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00032913900213316083, \"iteration\": 1564, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005210049566812813, \"iteration\": 1565, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037757749669253826, \"iteration\": 1566, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002286443195771426, \"iteration\": 1567, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008168776985257864, \"iteration\": 1568, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0069942353293299675, \"iteration\": 1569, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003924841876141727, \"iteration\": 1570, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.013019667938351631, \"iteration\": 1571, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005447273142635822, \"iteration\": 1572, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026813591830432415, \"iteration\": 1573, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004301837761886418, \"iteration\": 1574, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006025422480888665, \"iteration\": 1575, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005312692373991013, \"iteration\": 1576, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005666704382747412, \"iteration\": 1577, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035900837974622846, \"iteration\": 1578, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035163864959031343, \"iteration\": 1579, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005413160542957485, \"iteration\": 1580, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003496584831736982, \"iteration\": 1581, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031863825279287994, \"iteration\": 1582, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005046232836320996, \"iteration\": 1583, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00039896060479804873, \"iteration\": 1584, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034938810858875513, \"iteration\": 1585, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006114537827670574, \"iteration\": 1586, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005342344520613551, \"iteration\": 1587, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006024569156579673, \"iteration\": 1588, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004498671623878181, \"iteration\": 1589, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006062823813408613, \"iteration\": 1590, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004479923809412867, \"iteration\": 1591, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003418895066715777, \"iteration\": 1592, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006338756647892296, \"iteration\": 1593, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00040394789539277554, \"iteration\": 1594, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005085859447717667, \"iteration\": 1595, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005891175242140889, \"iteration\": 1596, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006877811392769217, \"iteration\": 1597, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00039370745071209967, \"iteration\": 1598, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00039714312879368663, \"iteration\": 1599, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003809251938946545, \"iteration\": 1600, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005416203057393432, \"iteration\": 1601, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003746863512787968, \"iteration\": 1602, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005118016269989312, \"iteration\": 1603, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003622192598413676, \"iteration\": 1604, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032439897768199444, \"iteration\": 1605, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004922943189740181, \"iteration\": 1606, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030312855960801244, \"iteration\": 1607, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005606999038718641, \"iteration\": 1608, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003657109336927533, \"iteration\": 1609, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003856947005260736, \"iteration\": 1610, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023839419009163976, \"iteration\": 1611, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002877925871871412, \"iteration\": 1612, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002779275528155267, \"iteration\": 1613, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003354226937517524, \"iteration\": 1614, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00041459413478150964, \"iteration\": 1615, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00033850123872980475, \"iteration\": 1616, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00039904541335999966, \"iteration\": 1617, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031073912396095693, \"iteration\": 1618, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004496432957239449, \"iteration\": 1619, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006142288912087679, \"iteration\": 1620, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002792428422253579, \"iteration\": 1621, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026306993095204234, \"iteration\": 1622, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00040980259655043483, \"iteration\": 1623, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002629094524309039, \"iteration\": 1624, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000430055835749954, \"iteration\": 1625, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00034684830461628735, \"iteration\": 1626, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002673370763659477, \"iteration\": 1627, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002849754528142512, \"iteration\": 1628, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007209415198303759, \"iteration\": 1629, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00042729120468720794, \"iteration\": 1630, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024557908182032406, \"iteration\": 1631, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003279981901869178, \"iteration\": 1632, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027634884463623166, \"iteration\": 1633, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005433664191514254, \"iteration\": 1634, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003734494966920465, \"iteration\": 1635, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005060211988165975, \"iteration\": 1636, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024442054564133286, \"iteration\": 1637, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000304216897347942, \"iteration\": 1638, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029095131321810186, \"iteration\": 1639, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006718570366501808, \"iteration\": 1640, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003278530202805996, \"iteration\": 1641, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004141454410273582, \"iteration\": 1642, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004078519414179027, \"iteration\": 1643, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000285131623968482, \"iteration\": 1644, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031741324346512556, \"iteration\": 1645, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032573804492130876, \"iteration\": 1646, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002921636332757771, \"iteration\": 1647, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002902899868786335, \"iteration\": 1648, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003053594846278429, \"iteration\": 1649, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003771354677155614, \"iteration\": 1650, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00033420350519008934, \"iteration\": 1651, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024085401673801243, \"iteration\": 1652, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024012090580072254, \"iteration\": 1653, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003735686477739364, \"iteration\": 1654, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005135525716468692, \"iteration\": 1655, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003362682182341814, \"iteration\": 1656, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004800079623237252, \"iteration\": 1657, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025729284971021116, \"iteration\": 1658, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00041425132076255977, \"iteration\": 1659, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028422463219612837, \"iteration\": 1660, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003452811506576836, \"iteration\": 1661, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029033090686425567, \"iteration\": 1662, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00041937496280297637, \"iteration\": 1663, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024397618835791945, \"iteration\": 1664, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003995370352640748, \"iteration\": 1665, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004082638770341873, \"iteration\": 1666, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000474108150228858, \"iteration\": 1667, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002984600723721087, \"iteration\": 1668, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00036622927291318774, \"iteration\": 1669, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003268754226155579, \"iteration\": 1670, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029054214246571064, \"iteration\": 1671, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002481807314325124, \"iteration\": 1672, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002909792819991708, \"iteration\": 1673, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029797147726640105, \"iteration\": 1674, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004566654097288847, \"iteration\": 1675, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002893697819672525, \"iteration\": 1676, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004014828591607511, \"iteration\": 1677, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032867398113012314, \"iteration\": 1678, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003030488733202219, \"iteration\": 1679, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022038570023141801, \"iteration\": 1680, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002237144362879917, \"iteration\": 1681, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00039554742397740483, \"iteration\": 1682, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00041208305628970265, \"iteration\": 1683, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027984450571238995, \"iteration\": 1684, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00035106769064441323, \"iteration\": 1685, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029166031163185835, \"iteration\": 1686, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003191690775565803, \"iteration\": 1687, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024960562586784363, \"iteration\": 1688, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003763947752304375, \"iteration\": 1689, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001866841339506209, \"iteration\": 1690, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002547871263232082, \"iteration\": 1691, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005183182074688375, \"iteration\": 1692, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001983021793421358, \"iteration\": 1693, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001699788263067603, \"iteration\": 1694, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003026929043699056, \"iteration\": 1695, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004384406202007085, \"iteration\": 1696, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029224285390228033, \"iteration\": 1697, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002569777425378561, \"iteration\": 1698, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023188049090094864, \"iteration\": 1699, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028757588006556034, \"iteration\": 1700, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024928711354732513, \"iteration\": 1701, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003144232905469835, \"iteration\": 1702, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001984481932595372, \"iteration\": 1703, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003388442564755678, \"iteration\": 1704, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000342903018463403, \"iteration\": 1705, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031237839721143246, \"iteration\": 1706, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027684704400599003, \"iteration\": 1707, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025431867106817663, \"iteration\": 1708, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030289628193713725, \"iteration\": 1709, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028399171424098313, \"iteration\": 1710, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005718368338420987, \"iteration\": 1711, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024248511181212962, \"iteration\": 1712, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025356822879984975, \"iteration\": 1713, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004140538221690804, \"iteration\": 1714, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00039307051338255405, \"iteration\": 1715, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003590629785321653, \"iteration\": 1716, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002319968625670299, \"iteration\": 1717, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029124997672624886, \"iteration\": 1718, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025172322057187557, \"iteration\": 1719, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000250292185228318, \"iteration\": 1720, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031782666337676346, \"iteration\": 1721, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002933973155450076, \"iteration\": 1722, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00034264413989149034, \"iteration\": 1723, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022649511811323464, \"iteration\": 1724, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020920473616570234, \"iteration\": 1725, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022514337615575641, \"iteration\": 1726, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001762760803103447, \"iteration\": 1727, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003407310869079083, \"iteration\": 1728, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020434711768757552, \"iteration\": 1729, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002512088103685528, \"iteration\": 1730, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026970618637278676, \"iteration\": 1731, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003140469780191779, \"iteration\": 1732, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024372903862968087, \"iteration\": 1733, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00037647548015229404, \"iteration\": 1734, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018609345715958625, \"iteration\": 1735, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00034986884566023946, \"iteration\": 1736, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007863917853683233, \"iteration\": 1737, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003197812766302377, \"iteration\": 1738, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002893484488595277, \"iteration\": 1739, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029786903178319335, \"iteration\": 1740, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00037927113589830697, \"iteration\": 1741, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004386046202853322, \"iteration\": 1742, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002802452363539487, \"iteration\": 1743, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002374679606873542, \"iteration\": 1744, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029582928982563317, \"iteration\": 1745, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002568312920629978, \"iteration\": 1746, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003170762211084366, \"iteration\": 1747, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000234184815781191, \"iteration\": 1748, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022774482204113156, \"iteration\": 1749, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016662795678712428, \"iteration\": 1750, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017942985869012773, \"iteration\": 1751, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000353311188519001, \"iteration\": 1752, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006564374780282378, \"iteration\": 1753, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003078070585615933, \"iteration\": 1754, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018354375788476318, \"iteration\": 1755, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029149738838896155, \"iteration\": 1756, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002606562920846045, \"iteration\": 1757, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023011535813566297, \"iteration\": 1758, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002618421567603946, \"iteration\": 1759, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00034725223667919636, \"iteration\": 1760, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001645830343477428, \"iteration\": 1761, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022724343580193818, \"iteration\": 1762, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002974462404381484, \"iteration\": 1763, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002393293980276212, \"iteration\": 1764, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019383782637305558, \"iteration\": 1765, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00039121235022321343, \"iteration\": 1766, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002009557792916894, \"iteration\": 1767, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001692858786555007, \"iteration\": 1768, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018495155381970108, \"iteration\": 1769, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002851554600056261, \"iteration\": 1770, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023831447470001876, \"iteration\": 1771, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004169856838416308, \"iteration\": 1772, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018769284361042082, \"iteration\": 1773, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022869025997351855, \"iteration\": 1774, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025535072200000286, \"iteration\": 1775, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023282910115085542, \"iteration\": 1776, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027051003417000175, \"iteration\": 1777, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020888366270810366, \"iteration\": 1778, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018431778880767524, \"iteration\": 1779, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012222793884575367, \"iteration\": 1780, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\"Prepare data encoder...\")\n",
    "# train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "train_encoder = TfidfVectorizer(max_features=50000, analyzer=\"char\", ngram_range=(3,5))\n",
    "train_encoder.fit(train_raw.texts)\n",
    "print(\"Vocabulary\", len(train_encoder.vocabulary_))\n",
    "\n",
    "print(\"Prepare data...\")\n",
    "train_dataset = encode_data(train_raw, train_encoder)\n",
    "test_dataset = encode_data(test_raw, train_encoder)\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "model_nn_balkan = NeuralNetwork(\n",
    "    input_size=len(train_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "if Path('models/model_nn_balkan.pt').exists() and USE_CACHE:\n",
    "    model_nn_balkan = load_model(model_nn_balkan, 'model_nn_balkan')\n",
    "else:\n",
    "    model_nn_balkan.fit(train_dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn_balkan, \"model_nn_balkan\")\n",
    "\n",
    "model_nn_balkan_results = evaluate_nn_model(model_nn_balkan, test_dataset)\n",
    "np.save('models/model_nn_balkan_results.npy', model_nn_balkan_results)\n",
    "print(model_nn_balkan_results)\n",
    "\n",
    "model_nn_balkan.cpu()\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn_balkan, train_config, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counter class imbalance\n",
    "\n",
    "Possible methods:\n",
    "- Down sampling\n",
    "- Class weight\n",
    "- Change prediction threshold\n",
    "- Change evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import RawDataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22672 5714\n",
      "Percentage of positive: 0.3698394495412844 0.364193209660483\n"
     ]
    }
   ],
   "source": [
    "# POC for Balkan\n",
    "#%%\n",
    "balkan_file_list = [\n",
    "    'power-ba-train.tsv',\n",
    "    'power-rs-train.tsv',\n",
    "    'power-hr-train.tsv',\n",
    "]\n",
    "\n",
    "balkan_data = load_data(folder_path=\"data/train/power/\", file_list=balkan_file_list,text_head='text')\n",
    "train_raw, test_raw = split_data(balkan_data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(len(train_raw), len(test_raw))\n",
    "print(\"Percentage of positive:\", sum(train_raw.labels) / len(train_raw), sum(test_raw.labels) / len(test_raw))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down sampling\n",
    "\n",
    "Downsampling the negative class help to improve Recall, but not precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample 16957\n",
      "Percentage of positive in train set: 0.49448605295748066\n"
     ]
    }
   ],
   "source": [
    "negative_ids = [data[0] for data in train_raw if data[-1] == 0]\n",
    "positive_ids = [data[0] for data in train_raw if data[-1] == 1]\n",
    "negative_ids_sample = random.sample(negative_ids, k = int(len(negative_ids) * 0.6))\n",
    "new_train_ids = positive_ids + negative_ids_sample\n",
    "new_train_indices = [train_raw.ids.index(i) for i in new_train_ids]\n",
    "\n",
    "random.shuffle(new_train_indices)\n",
    "\n",
    "train_raw_sample = RawDataset(\n",
    "    [train_raw.ids[i] for i in new_train_indices],\n",
    "    [train_raw.speakers[i] for i in new_train_indices],\n",
    "    [train_raw.texts[i] for i in new_train_indices],\n",
    "    [train_raw.labels[i] for i in new_train_indices],\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Train sample\", len(train_raw_sample))\n",
    "print(\"Percentage of positive in train set:\", sum(train_raw_sample.labels) / len(train_raw_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data encoder...\n",
      "Vocabulary 50000\n",
      "Prepare data...\n",
      "Train model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 133/133 [00:01<00:00, 66.85batch/s, batch_accuracy=0.721, loss=112]\n",
      "Epoch 2: 100%|██████████| 133/133 [00:01<00:00, 66.81batch/s, batch_accuracy=0.738, loss=81.1]\n",
      "Epoch 3: 100%|██████████| 133/133 [00:02<00:00, 65.59batch/s, batch_accuracy=0.918, loss=107]\n",
      "Epoch 4: 100%|██████████| 133/133 [00:02<00:00, 64.66batch/s, batch_accuracy=0.902, loss=91.4]\n",
      "Epoch 5: 100%|██████████| 133/133 [00:02<00:00, 66.42batch/s, batch_accuracy=0.934, loss=86.9]\n",
      "Epoch 6: 100%|██████████| 133/133 [00:01<00:00, 69.21batch/s, batch_accuracy=0.967, loss=103]\n",
      "Epoch 7: 100%|██████████| 133/133 [00:01<00:00, 68.50batch/s, batch_accuracy=0.984, loss=93.8]\n",
      "Epoch 8: 100%|██████████| 133/133 [00:01<00:00, 67.41batch/s, batch_accuracy=1, loss=120]   \n",
      "Epoch 9: 100%|██████████| 133/133 [00:02<00:00, 65.69batch/s, batch_accuracy=1, loss=115]\n",
      "Epoch 10: 100%|██████████| 133/133 [00:02<00:00, 66.40batch/s, batch_accuracy=1, loss=106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7287364602088928, 0.7419509887695312, 0.6658042073249817)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-439b801eb98946f8a92166577f8d239e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-439b801eb98946f8a92166577f8d239e.vega-embed details,\n",
       "  #altair-viz-439b801eb98946f8a92166577f8d239e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-439b801eb98946f8a92166577f8d239e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-439b801eb98946f8a92166577f8d239e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-439b801eb98946f8a92166577f8d239e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-3fa1f7bdff707344e147c6a7de20b5f0\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-3fa1f7bdff707344e147c6a7de20b5f0\": [{\"training_acc\": 0.484375, \"training_loss\": 300.82769775390625, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.4921875, \"training_loss\": 305.6599426269531, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 334.691162109375, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 358.8376770019531, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.4921875, \"training_loss\": 276.346923828125, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 329.4683532714844, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 256.58154296875, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 256.4269104003906, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 338.8043212890625, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 290.3785400390625, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 323.51824951171875, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 265.3392028808594, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 279.5237731933594, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 303.1114501953125, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 312.8717041015625, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 258.40673828125, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 301.42767333984375, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 312.0679931640625, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 355.0919189453125, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 305.41436767578125, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 304.21630859375, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 317.97314453125, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 318.5384216308594, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 298.0860595703125, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 285.89166259765625, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 292.6042785644531, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 253.7715606689453, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 334.9181823730469, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 288.74932861328125, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 305.4923400878906, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 302.73828125, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 280.0075378417969, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 315.82177734375, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 305.2203369140625, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 332.66680908203125, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 316.7980041503906, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 252.595458984375, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 256.98516845703125, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 237.4530029296875, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 262.7936706542969, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 283.67547607421875, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 319.4034423828125, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 331.77642822265625, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 294.0884704589844, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 333.0079345703125, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 273.9967041015625, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 297.396240234375, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 266.68695068359375, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 284.0986328125, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 287.42340087890625, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 307.4493713378906, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 226.33030700683594, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 327.9912109375, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 299.92950439453125, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 304.2927551269531, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 289.412353515625, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 333.26708984375, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 300.9896240234375, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 307.12939453125, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 274.30206298828125, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 314.75897216796875, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 272.1365661621094, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 319.4641418457031, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 279.35382080078125, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 287.0379638671875, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 328.2665710449219, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 261.28143310546875, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 256.6395568847656, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 272.045166015625, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 260.14105224609375, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 356.11285400390625, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 278.89019775390625, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 264.4256591796875, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 277.5668640136719, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 266.8990173339844, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 301.8919677734375, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 242.79989624023438, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 313.64825439453125, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 287.5713195800781, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 284.2567138671875, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 282.8583984375, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 311.74237060546875, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 332.6260986328125, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 316.095458984375, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 337.0610046386719, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 281.6235656738281, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 238.18817138671875, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 281.7552490234375, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 247.9859161376953, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 317.7012023925781, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 332.303466796875, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 305.1087646484375, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 360.447998046875, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 262.731689453125, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 304.6627197265625, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 313.24853515625, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 316.71636962890625, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 293.16937255859375, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 289.7513427734375, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 342.27862548828125, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 272.51318359375, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 340.80267333984375, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 298.95867919921875, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 297.71832275390625, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 279.73541259765625, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 316.07879638671875, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 261.39813232421875, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 268.8004150390625, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 390.7654113769531, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 325.73358154296875, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 278.7627868652344, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 287.9652099609375, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 244.70840454101562, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 286.40692138671875, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 315.77008056640625, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 288.25335693359375, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 294.51385498046875, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 313.1651306152344, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 306.2056884765625, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 303.7713928222656, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 324.6576232910156, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 318.3060607910156, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 339.0374755859375, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 280.312255859375, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 238.25115966796875, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 318.75543212890625, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 300.64111328125, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 325.20404052734375, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 279.209228515625, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 266.194580078125, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 292.7605285644531, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 278.18670654296875, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.7213114754098361, \"training_loss\": 112.29785919189453, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 272.66973876953125, \"iteration\": 134, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 296.1468505859375, \"iteration\": 135, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 275.20050048828125, \"iteration\": 136, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 290.46600341796875, \"iteration\": 137, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 256.55767822265625, \"iteration\": 138, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 352.6909484863281, \"iteration\": 139, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 289.9676513671875, \"iteration\": 140, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 255.12994384765625, \"iteration\": 141, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 228.29209899902344, \"iteration\": 142, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 281.1761169433594, \"iteration\": 143, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 285.9100341796875, \"iteration\": 144, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 299.3055725097656, \"iteration\": 145, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 306.0909423828125, \"iteration\": 146, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 266.64990234375, \"iteration\": 147, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 305.09967041015625, \"iteration\": 148, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 261.9027404785156, \"iteration\": 149, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 252.27992248535156, \"iteration\": 150, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 262.5654602050781, \"iteration\": 151, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 276.56365966796875, \"iteration\": 152, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 284.2071228027344, \"iteration\": 153, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 266.6986083984375, \"iteration\": 154, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 287.77069091796875, \"iteration\": 155, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 296.04156494140625, \"iteration\": 156, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 273.81011962890625, \"iteration\": 157, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 266.2559814453125, \"iteration\": 158, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 291.98504638671875, \"iteration\": 159, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 305.8814392089844, \"iteration\": 160, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 256.1801452636719, \"iteration\": 161, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 285.98956298828125, \"iteration\": 162, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 324.99139404296875, \"iteration\": 163, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 324.27484130859375, \"iteration\": 164, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 268.470947265625, \"iteration\": 165, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 279.4193115234375, \"iteration\": 166, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 247.44775390625, \"iteration\": 167, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 273.9056701660156, \"iteration\": 168, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 298.40106201171875, \"iteration\": 169, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 271.72760009765625, \"iteration\": 170, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 259.0509338378906, \"iteration\": 171, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 287.05633544921875, \"iteration\": 172, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 231.51425170898438, \"iteration\": 173, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 273.8845520019531, \"iteration\": 174, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 276.0250549316406, \"iteration\": 175, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 292.7681579589844, \"iteration\": 176, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 266.9687194824219, \"iteration\": 177, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 256.51318359375, \"iteration\": 178, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 324.42962646484375, \"iteration\": 179, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 281.048095703125, \"iteration\": 180, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 252.85989379882812, \"iteration\": 181, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 270.827880859375, \"iteration\": 182, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 261.87982177734375, \"iteration\": 183, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 272.9483337402344, \"iteration\": 184, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 256.2118835449219, \"iteration\": 185, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 253.2901611328125, \"iteration\": 186, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 258.77154541015625, \"iteration\": 187, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 204.54025268554688, \"iteration\": 188, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 303.60198974609375, \"iteration\": 189, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 288.68206787109375, \"iteration\": 190, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 314.0032043457031, \"iteration\": 191, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 277.4757080078125, \"iteration\": 192, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 261.4024353027344, \"iteration\": 193, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 290.66009521484375, \"iteration\": 194, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 313.05657958984375, \"iteration\": 195, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 278.8907775878906, \"iteration\": 196, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 349.82476806640625, \"iteration\": 197, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 332.6959228515625, \"iteration\": 198, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 311.4114990234375, \"iteration\": 199, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 292.16204833984375, \"iteration\": 200, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 275.695556640625, \"iteration\": 201, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 321.7740783691406, \"iteration\": 202, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 257.4281311035156, \"iteration\": 203, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 263.915771484375, \"iteration\": 204, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 311.7804870605469, \"iteration\": 205, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 301.6128234863281, \"iteration\": 206, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 295.21295166015625, \"iteration\": 207, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 300.73150634765625, \"iteration\": 208, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 317.0361328125, \"iteration\": 209, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 298.7079772949219, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 319.6739196777344, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 292.9464416503906, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 317.76092529296875, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 281.6758728027344, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 254.0844268798828, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 244.9742431640625, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 264.95452880859375, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 300.8191833496094, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 276.94134521484375, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 269.681396484375, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 291.0298767089844, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 245.10061645507812, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 287.7874755859375, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 271.2628173828125, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 309.43365478515625, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 316.3901062011719, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 305.2974548339844, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 314.74578857421875, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 271.2755126953125, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 294.8873291015625, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 307.35968017578125, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 297.16998291015625, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 263.8790283203125, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 298.30584716796875, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 294.23321533203125, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 242.98605346679688, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 232.6470184326172, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 284.4866943359375, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 301.88348388671875, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 316.9054870605469, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 277.8523864746094, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 264.5702819824219, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 342.4480895996094, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 252.31890869140625, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 247.3999481201172, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 286.88482666015625, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 283.1815185546875, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 255.9378204345703, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 295.193359375, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 269.2916259765625, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 273.58123779296875, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 295.8631591796875, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 336.1612854003906, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 332.25286865234375, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 285.5923767089844, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 306.81890869140625, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 291.58953857421875, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 267.7633056640625, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 317.5301818847656, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 280.18255615234375, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 279.9532470703125, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 276.01031494140625, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 291.8316955566406, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 284.71728515625, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 285.56011962890625, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.7377049180327869, \"training_loss\": 81.14654541015625, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 278.67596435546875, \"iteration\": 267, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 275.63580322265625, \"iteration\": 268, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 251.32772827148438, \"iteration\": 269, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 294.99310302734375, \"iteration\": 270, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 268.167236328125, \"iteration\": 271, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 245.88455200195312, \"iteration\": 272, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 274.1711730957031, \"iteration\": 273, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 271.5718994140625, \"iteration\": 274, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 286.9362487792969, \"iteration\": 275, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 260.44940185546875, \"iteration\": 276, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 287.4969177246094, \"iteration\": 277, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 286.31866455078125, \"iteration\": 278, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 267.6280517578125, \"iteration\": 279, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 304.7735290527344, \"iteration\": 280, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 237.10572814941406, \"iteration\": 281, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 205.22801208496094, \"iteration\": 282, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 261.23992919921875, \"iteration\": 283, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 235.84854125976562, \"iteration\": 284, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 320.49468994140625, \"iteration\": 285, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 295.0477294921875, \"iteration\": 286, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 270.6051940917969, \"iteration\": 287, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 293.2110595703125, \"iteration\": 288, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 288.08984375, \"iteration\": 289, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 286.7251281738281, \"iteration\": 290, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 256.9248962402344, \"iteration\": 291, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 311.34442138671875, \"iteration\": 292, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 303.803955078125, \"iteration\": 293, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 251.59767150878906, \"iteration\": 294, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 283.66925048828125, \"iteration\": 295, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 267.54705810546875, \"iteration\": 296, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 283.412353515625, \"iteration\": 297, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 251.58486938476562, \"iteration\": 298, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 357.75982666015625, \"iteration\": 299, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 333.6669921875, \"iteration\": 300, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 263.3842468261719, \"iteration\": 301, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 314.75909423828125, \"iteration\": 302, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 272.041748046875, \"iteration\": 303, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 222.15841674804688, \"iteration\": 304, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 286.1089782714844, \"iteration\": 305, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 288.88934326171875, \"iteration\": 306, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 294.984375, \"iteration\": 307, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 285.1048583984375, \"iteration\": 308, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 229.6390838623047, \"iteration\": 309, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 285.193115234375, \"iteration\": 310, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 264.186279296875, \"iteration\": 311, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 238.19952392578125, \"iteration\": 312, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 249.83425903320312, \"iteration\": 313, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 319.1961364746094, \"iteration\": 314, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 295.2862243652344, \"iteration\": 315, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 243.116455078125, \"iteration\": 316, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 288.86419677734375, \"iteration\": 317, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 305.7769775390625, \"iteration\": 318, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 231.94369506835938, \"iteration\": 319, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 238.24734497070312, \"iteration\": 320, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 304.5682373046875, \"iteration\": 321, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 265.849609375, \"iteration\": 322, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 309.36700439453125, \"iteration\": 323, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 253.88052368164062, \"iteration\": 324, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 246.23780822753906, \"iteration\": 325, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 316.1250305175781, \"iteration\": 326, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 298.02557373046875, \"iteration\": 327, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 317.46527099609375, \"iteration\": 328, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 245.0248260498047, \"iteration\": 329, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 269.03912353515625, \"iteration\": 330, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 315.72314453125, \"iteration\": 331, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 246.59214782714844, \"iteration\": 332, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 201.9761962890625, \"iteration\": 333, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 278.7301330566406, \"iteration\": 334, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 289.9363098144531, \"iteration\": 335, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 272.6492919921875, \"iteration\": 336, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 281.16156005859375, \"iteration\": 337, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 229.29864501953125, \"iteration\": 338, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 305.4865417480469, \"iteration\": 339, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 210.34207153320312, \"iteration\": 340, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 256.545166015625, \"iteration\": 341, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 312.50286865234375, \"iteration\": 342, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 268.81610107421875, \"iteration\": 343, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 218.74794006347656, \"iteration\": 344, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 291.704345703125, \"iteration\": 345, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 230.06893920898438, \"iteration\": 346, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 270.87677001953125, \"iteration\": 347, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 276.30450439453125, \"iteration\": 348, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 282.87835693359375, \"iteration\": 349, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 256.6455078125, \"iteration\": 350, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 303.2522888183594, \"iteration\": 351, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 234.4279327392578, \"iteration\": 352, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 295.63336181640625, \"iteration\": 353, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 273.39288330078125, \"iteration\": 354, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 278.9757080078125, \"iteration\": 355, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 282.897216796875, \"iteration\": 356, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 298.8565673828125, \"iteration\": 357, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 259.6156005859375, \"iteration\": 358, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 300.306884765625, \"iteration\": 359, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 272.7987365722656, \"iteration\": 360, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 271.6508483886719, \"iteration\": 361, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 246.12083435058594, \"iteration\": 362, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 297.4952697753906, \"iteration\": 363, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 341.4292297363281, \"iteration\": 364, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 318.00994873046875, \"iteration\": 365, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 316.69476318359375, \"iteration\": 366, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 317.3357849121094, \"iteration\": 367, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 274.7783203125, \"iteration\": 368, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 303.9353942871094, \"iteration\": 369, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 263.07086181640625, \"iteration\": 370, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 247.67584228515625, \"iteration\": 371, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 336.68231201171875, \"iteration\": 372, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 233.38339233398438, \"iteration\": 373, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 237.87588500976562, \"iteration\": 374, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 265.7491760253906, \"iteration\": 375, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 266.79876708984375, \"iteration\": 376, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 277.239013671875, \"iteration\": 377, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 304.00323486328125, \"iteration\": 378, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 280.5380859375, \"iteration\": 379, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 323.39691162109375, \"iteration\": 380, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 251.3203125, \"iteration\": 381, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 330.17340087890625, \"iteration\": 382, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 316.80438232421875, \"iteration\": 383, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 295.6019287109375, \"iteration\": 384, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 236.29827880859375, \"iteration\": 385, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 297.88104248046875, \"iteration\": 386, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 264.1670227050781, \"iteration\": 387, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 255.689697265625, \"iteration\": 388, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 240.31715393066406, \"iteration\": 389, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 293.115478515625, \"iteration\": 390, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 304.4840087890625, \"iteration\": 391, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 235.1112823486328, \"iteration\": 392, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 293.3880615234375, \"iteration\": 393, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 257.602783203125, \"iteration\": 394, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 265.9271545410156, \"iteration\": 395, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 260.1961364746094, \"iteration\": 396, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 310.130859375, \"iteration\": 397, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 242.2188262939453, \"iteration\": 398, \"epoch\": 3}, {\"training_acc\": 0.9180327868852459, \"training_loss\": 106.94197082519531, \"iteration\": 399, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 237.72154235839844, \"iteration\": 400, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 262.1836242675781, \"iteration\": 401, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 287.7029724121094, \"iteration\": 402, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 205.7957763671875, \"iteration\": 403, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 257.9760437011719, \"iteration\": 404, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 256.9772644042969, \"iteration\": 405, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 256.14642333984375, \"iteration\": 406, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 294.88568115234375, \"iteration\": 407, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 247.0145721435547, \"iteration\": 408, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 259.35870361328125, \"iteration\": 409, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 287.27801513671875, \"iteration\": 410, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 262.301025390625, \"iteration\": 411, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 306.1720886230469, \"iteration\": 412, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 311.1001892089844, \"iteration\": 413, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 319.5203857421875, \"iteration\": 414, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 320.6258544921875, \"iteration\": 415, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 253.57675170898438, \"iteration\": 416, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 303.43121337890625, \"iteration\": 417, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 216.09109497070312, \"iteration\": 418, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 308.1227722167969, \"iteration\": 419, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 303.14349365234375, \"iteration\": 420, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 252.18524169921875, \"iteration\": 421, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 218.9840545654297, \"iteration\": 422, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 260.47711181640625, \"iteration\": 423, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 249.47830200195312, \"iteration\": 424, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 309.08551025390625, \"iteration\": 425, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 274.7868957519531, \"iteration\": 426, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 260.774658203125, \"iteration\": 427, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 280.49969482421875, \"iteration\": 428, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 276.55474853515625, \"iteration\": 429, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 309.5762939453125, \"iteration\": 430, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 284.2774658203125, \"iteration\": 431, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 252.6895751953125, \"iteration\": 432, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 224.94723510742188, \"iteration\": 433, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 277.89508056640625, \"iteration\": 434, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 246.0841522216797, \"iteration\": 435, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 253.86610412597656, \"iteration\": 436, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 287.1524658203125, \"iteration\": 437, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 273.6582946777344, \"iteration\": 438, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 225.0292510986328, \"iteration\": 439, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 279.03057861328125, \"iteration\": 440, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 268.4575500488281, \"iteration\": 441, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 285.8181457519531, \"iteration\": 442, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 286.05670166015625, \"iteration\": 443, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 231.77951049804688, \"iteration\": 444, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 275.895751953125, \"iteration\": 445, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 273.0164794921875, \"iteration\": 446, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 292.6916809082031, \"iteration\": 447, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 329.53375244140625, \"iteration\": 448, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 227.52882385253906, \"iteration\": 449, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 345.0628356933594, \"iteration\": 450, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 308.83123779296875, \"iteration\": 451, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 282.40631103515625, \"iteration\": 452, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 250.03549194335938, \"iteration\": 453, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 263.6461181640625, \"iteration\": 454, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 267.9629821777344, \"iteration\": 455, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 309.7685546875, \"iteration\": 456, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 222.97329711914062, \"iteration\": 457, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 212.3116455078125, \"iteration\": 458, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 263.2643127441406, \"iteration\": 459, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 220.236083984375, \"iteration\": 460, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 202.10928344726562, \"iteration\": 461, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 295.148193359375, \"iteration\": 462, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 284.51861572265625, \"iteration\": 463, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 273.10107421875, \"iteration\": 464, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 304.5409851074219, \"iteration\": 465, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 289.4134521484375, \"iteration\": 466, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 234.91116333007812, \"iteration\": 467, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 316.3221435546875, \"iteration\": 468, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 247.1318817138672, \"iteration\": 469, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 295.95648193359375, \"iteration\": 470, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 346.2679748535156, \"iteration\": 471, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 304.1158447265625, \"iteration\": 472, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 243.56317138671875, \"iteration\": 473, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 235.52423095703125, \"iteration\": 474, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 262.3021240234375, \"iteration\": 475, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 274.02520751953125, \"iteration\": 476, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 228.6608428955078, \"iteration\": 477, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 326.488037109375, \"iteration\": 478, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 277.3807373046875, \"iteration\": 479, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 313.86651611328125, \"iteration\": 480, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 232.61190795898438, \"iteration\": 481, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 316.07977294921875, \"iteration\": 482, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 293.0245056152344, \"iteration\": 483, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 247.8982696533203, \"iteration\": 484, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 296.3328857421875, \"iteration\": 485, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 285.0924072265625, \"iteration\": 486, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 304.7587890625, \"iteration\": 487, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 266.8928527832031, \"iteration\": 488, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 282.42608642578125, \"iteration\": 489, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 245.97386169433594, \"iteration\": 490, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 334.2965087890625, \"iteration\": 491, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 258.585693359375, \"iteration\": 492, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 231.25912475585938, \"iteration\": 493, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 268.5909118652344, \"iteration\": 494, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 261.4337158203125, \"iteration\": 495, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 300.4745788574219, \"iteration\": 496, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 263.73602294921875, \"iteration\": 497, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 249.1129150390625, \"iteration\": 498, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 256.294921875, \"iteration\": 499, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 237.62936401367188, \"iteration\": 500, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 249.06637573242188, \"iteration\": 501, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 220.55064392089844, \"iteration\": 502, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 278.3471374511719, \"iteration\": 503, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 279.8701171875, \"iteration\": 504, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 272.0902099609375, \"iteration\": 505, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 306.53753662109375, \"iteration\": 506, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 218.70706176757812, \"iteration\": 507, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 295.2489318847656, \"iteration\": 508, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 253.52853393554688, \"iteration\": 509, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 296.0033874511719, \"iteration\": 510, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 228.32907104492188, \"iteration\": 511, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 282.7288513183594, \"iteration\": 512, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 269.9986572265625, \"iteration\": 513, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 259.240478515625, \"iteration\": 514, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 275.54010009765625, \"iteration\": 515, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 278.27294921875, \"iteration\": 516, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 272.744384765625, \"iteration\": 517, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 259.03802490234375, \"iteration\": 518, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 302.4619140625, \"iteration\": 519, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 253.33531188964844, \"iteration\": 520, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 234.422607421875, \"iteration\": 521, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 291.90985107421875, \"iteration\": 522, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 274.081298828125, \"iteration\": 523, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 244.317138671875, \"iteration\": 524, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 250.01522827148438, \"iteration\": 525, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 289.8917541503906, \"iteration\": 526, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 248.061767578125, \"iteration\": 527, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 244.14501953125, \"iteration\": 528, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 253.24990844726562, \"iteration\": 529, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 293.07415771484375, \"iteration\": 530, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 296.16265869140625, \"iteration\": 531, \"epoch\": 4}, {\"training_acc\": 0.9016393442622951, \"training_loss\": 91.41304779052734, \"iteration\": 532, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 219.7514190673828, \"iteration\": 533, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 272.9041748046875, \"iteration\": 534, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 281.9984436035156, \"iteration\": 535, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 313.53021240234375, \"iteration\": 536, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 255.3958740234375, \"iteration\": 537, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 317.5356750488281, \"iteration\": 538, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 290.37640380859375, \"iteration\": 539, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 235.76266479492188, \"iteration\": 540, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 284.42938232421875, \"iteration\": 541, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 243.15200805664062, \"iteration\": 542, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 278.7734375, \"iteration\": 543, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 205.35458374023438, \"iteration\": 544, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 268.6837158203125, \"iteration\": 545, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 268.97052001953125, \"iteration\": 546, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 286.6302795410156, \"iteration\": 547, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 321.7392883300781, \"iteration\": 548, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 273.797607421875, \"iteration\": 549, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 254.66143798828125, \"iteration\": 550, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 249.33238220214844, \"iteration\": 551, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 297.1328125, \"iteration\": 552, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 264.32110595703125, \"iteration\": 553, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 244.0556182861328, \"iteration\": 554, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 280.0534973144531, \"iteration\": 555, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 296.73126220703125, \"iteration\": 556, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 231.45144653320312, \"iteration\": 557, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 264.7030334472656, \"iteration\": 558, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 239.98870849609375, \"iteration\": 559, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 276.0869140625, \"iteration\": 560, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 230.00965881347656, \"iteration\": 561, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 287.55889892578125, \"iteration\": 562, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 224.35171508789062, \"iteration\": 563, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 277.4976501464844, \"iteration\": 564, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 274.27374267578125, \"iteration\": 565, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 265.0958251953125, \"iteration\": 566, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 259.68310546875, \"iteration\": 567, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 292.8906555175781, \"iteration\": 568, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 260.1280517578125, \"iteration\": 569, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 286.0882873535156, \"iteration\": 570, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 271.45855712890625, \"iteration\": 571, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 233.61219787597656, \"iteration\": 572, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 271.7857360839844, \"iteration\": 573, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 295.51837158203125, \"iteration\": 574, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 311.40679931640625, \"iteration\": 575, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 275.18768310546875, \"iteration\": 576, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 271.6590576171875, \"iteration\": 577, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 238.17352294921875, \"iteration\": 578, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 302.4383239746094, \"iteration\": 579, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 325.9848937988281, \"iteration\": 580, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 276.30126953125, \"iteration\": 581, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 239.48094177246094, \"iteration\": 582, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 261.5682067871094, \"iteration\": 583, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 224.1377716064453, \"iteration\": 584, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 285.202392578125, \"iteration\": 585, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 214.60081481933594, \"iteration\": 586, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 270.613037109375, \"iteration\": 587, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 256.6799621582031, \"iteration\": 588, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 250.84466552734375, \"iteration\": 589, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 256.93829345703125, \"iteration\": 590, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 249.3817138671875, \"iteration\": 591, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 258.6766357421875, \"iteration\": 592, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 265.10821533203125, \"iteration\": 593, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 307.52862548828125, \"iteration\": 594, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 264.82293701171875, \"iteration\": 595, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 265.6016540527344, \"iteration\": 596, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 224.55369567871094, \"iteration\": 597, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 271.17877197265625, \"iteration\": 598, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 262.8759765625, \"iteration\": 599, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 327.806640625, \"iteration\": 600, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 258.83349609375, \"iteration\": 601, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 275.8157958984375, \"iteration\": 602, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 273.797607421875, \"iteration\": 603, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 221.4367218017578, \"iteration\": 604, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 308.00823974609375, \"iteration\": 605, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 296.8812561035156, \"iteration\": 606, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 236.28121948242188, \"iteration\": 607, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 274.4302978515625, \"iteration\": 608, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 274.7186584472656, \"iteration\": 609, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 219.58294677734375, \"iteration\": 610, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 321.6411437988281, \"iteration\": 611, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 245.87564086914062, \"iteration\": 612, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 259.99566650390625, \"iteration\": 613, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 245.10293579101562, \"iteration\": 614, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 284.957275390625, \"iteration\": 615, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 258.9867248535156, \"iteration\": 616, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 265.5225830078125, \"iteration\": 617, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 292.11676025390625, \"iteration\": 618, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 264.24395751953125, \"iteration\": 619, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 231.50509643554688, \"iteration\": 620, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 260.3413391113281, \"iteration\": 621, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 265.2765197753906, \"iteration\": 622, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 251.01986694335938, \"iteration\": 623, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 307.2539367675781, \"iteration\": 624, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 239.68984985351562, \"iteration\": 625, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 245.6480712890625, \"iteration\": 626, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 244.98944091796875, \"iteration\": 627, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 238.77902221679688, \"iteration\": 628, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 201.6587371826172, \"iteration\": 629, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 252.01309204101562, \"iteration\": 630, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 237.38856506347656, \"iteration\": 631, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 243.3415985107422, \"iteration\": 632, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 308.7897033691406, \"iteration\": 633, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 292.31451416015625, \"iteration\": 634, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 306.8033752441406, \"iteration\": 635, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 223.667724609375, \"iteration\": 636, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 281.37274169921875, \"iteration\": 637, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 321.83673095703125, \"iteration\": 638, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 299.38006591796875, \"iteration\": 639, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 271.7771301269531, \"iteration\": 640, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 275.74700927734375, \"iteration\": 641, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 229.2120361328125, \"iteration\": 642, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 306.39483642578125, \"iteration\": 643, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 317.8794250488281, \"iteration\": 644, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 215.76913452148438, \"iteration\": 645, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 258.739013671875, \"iteration\": 646, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 308.5316467285156, \"iteration\": 647, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 305.560302734375, \"iteration\": 648, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 246.54766845703125, \"iteration\": 649, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 230.23504638671875, \"iteration\": 650, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 259.9696044921875, \"iteration\": 651, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 277.8078308105469, \"iteration\": 652, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 283.0014953613281, \"iteration\": 653, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 295.8855285644531, \"iteration\": 654, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 272.96832275390625, \"iteration\": 655, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 297.6644287109375, \"iteration\": 656, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 278.45428466796875, \"iteration\": 657, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 277.4450378417969, \"iteration\": 658, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 303.3317565917969, \"iteration\": 659, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 234.9567413330078, \"iteration\": 660, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 239.56056213378906, \"iteration\": 661, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 221.91897583007812, \"iteration\": 662, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 293.07733154296875, \"iteration\": 663, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 276.9698486328125, \"iteration\": 664, \"epoch\": 5}, {\"training_acc\": 0.9344262295081968, \"training_loss\": 86.91697692871094, \"iteration\": 665, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 264.30963134765625, \"iteration\": 666, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 268.48529052734375, \"iteration\": 667, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 263.5334167480469, \"iteration\": 668, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 277.9282531738281, \"iteration\": 669, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 310.1383972167969, \"iteration\": 670, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 237.23757934570312, \"iteration\": 671, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 283.94183349609375, \"iteration\": 672, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 246.7971954345703, \"iteration\": 673, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 314.9610900878906, \"iteration\": 674, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 268.40716552734375, \"iteration\": 675, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 237.6544189453125, \"iteration\": 676, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 268.6016845703125, \"iteration\": 677, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 305.5979309082031, \"iteration\": 678, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 299.5707092285156, \"iteration\": 679, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 238.44613647460938, \"iteration\": 680, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 258.953369140625, \"iteration\": 681, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 275.0938415527344, \"iteration\": 682, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 269.51513671875, \"iteration\": 683, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 218.51705932617188, \"iteration\": 684, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 227.688720703125, \"iteration\": 685, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 304.78826904296875, \"iteration\": 686, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 248.53680419921875, \"iteration\": 687, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 252.97824096679688, \"iteration\": 688, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 263.07928466796875, \"iteration\": 689, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 263.3485107421875, \"iteration\": 690, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 268.53515625, \"iteration\": 691, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 259.4145812988281, \"iteration\": 692, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 268.73785400390625, \"iteration\": 693, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 268.5054931640625, \"iteration\": 694, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 284.586181640625, \"iteration\": 695, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 217.52804565429688, \"iteration\": 696, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 278.1827697753906, \"iteration\": 697, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 278.53204345703125, \"iteration\": 698, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 268.219970703125, \"iteration\": 699, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 275.15478515625, \"iteration\": 700, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 252.66522216796875, \"iteration\": 701, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 294.59197998046875, \"iteration\": 702, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 325.23309326171875, \"iteration\": 703, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 197.35382080078125, \"iteration\": 704, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 269.4949951171875, \"iteration\": 705, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 289.6930847167969, \"iteration\": 706, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 268.1286315917969, \"iteration\": 707, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 283.6754150390625, \"iteration\": 708, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 289.47589111328125, \"iteration\": 709, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 258.4402160644531, \"iteration\": 710, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 278.52618408203125, \"iteration\": 711, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 273.2196350097656, \"iteration\": 712, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 222.36976623535156, \"iteration\": 713, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 248.7236328125, \"iteration\": 714, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 234.4054718017578, \"iteration\": 715, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 326.7584533691406, \"iteration\": 716, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 263.7318420410156, \"iteration\": 717, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 258.01947021484375, \"iteration\": 718, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 242.9800262451172, \"iteration\": 719, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 242.64332580566406, \"iteration\": 720, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 263.445068359375, \"iteration\": 721, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 290.23236083984375, \"iteration\": 722, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 252.7280731201172, \"iteration\": 723, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 325.7274475097656, \"iteration\": 724, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 237.17352294921875, \"iteration\": 725, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 294.85333251953125, \"iteration\": 726, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 246.949462890625, \"iteration\": 727, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 268.41876220703125, \"iteration\": 728, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 288.8797607421875, \"iteration\": 729, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 310.9952392578125, \"iteration\": 730, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 227.5369873046875, \"iteration\": 731, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 252.39402770996094, \"iteration\": 732, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 325.2413024902344, \"iteration\": 733, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 290.24786376953125, \"iteration\": 734, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 221.6885223388672, \"iteration\": 735, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 257.5047912597656, \"iteration\": 736, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 272.6683044433594, \"iteration\": 737, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 236.87167358398438, \"iteration\": 738, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 247.05596923828125, \"iteration\": 739, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 228.42129516601562, \"iteration\": 740, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 248.66690063476562, \"iteration\": 741, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 299.13922119140625, \"iteration\": 742, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 298.98016357421875, \"iteration\": 743, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 319.8873291015625, \"iteration\": 744, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 298.3149719238281, \"iteration\": 745, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 278.0425109863281, \"iteration\": 746, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 279.20709228515625, \"iteration\": 747, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 222.71665954589844, \"iteration\": 748, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 253.4563751220703, \"iteration\": 749, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 247.7589569091797, \"iteration\": 750, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 229.46429443359375, \"iteration\": 751, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 247.56710815429688, \"iteration\": 752, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 267.96966552734375, \"iteration\": 753, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 252.5233917236328, \"iteration\": 754, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 209.71932983398438, \"iteration\": 755, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 274.0167236328125, \"iteration\": 756, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 299.6059875488281, \"iteration\": 757, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 315.17864990234375, \"iteration\": 758, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 208.4391326904297, \"iteration\": 759, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 269.5909118652344, \"iteration\": 760, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 232.20635986328125, \"iteration\": 761, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 273.2374267578125, \"iteration\": 762, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 277.96368408203125, \"iteration\": 763, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 252.56219482421875, \"iteration\": 764, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 262.7464904785156, \"iteration\": 765, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 252.8828125, \"iteration\": 766, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 273.3138427734375, \"iteration\": 767, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 284.0606384277344, \"iteration\": 768, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 237.72091674804688, \"iteration\": 769, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 278.05389404296875, \"iteration\": 770, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 252.5523681640625, \"iteration\": 771, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 299.0666198730469, \"iteration\": 772, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 252.07298278808594, \"iteration\": 773, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 298.58575439453125, \"iteration\": 774, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 298.9354553222656, \"iteration\": 775, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 298.900634765625, \"iteration\": 776, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 253.65870666503906, \"iteration\": 777, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 252.99310302734375, \"iteration\": 778, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 247.11822509765625, \"iteration\": 779, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 305.4761657714844, \"iteration\": 780, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 284.60040283203125, \"iteration\": 781, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 252.6881561279297, \"iteration\": 782, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 217.51119995117188, \"iteration\": 783, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 272.6484069824219, \"iteration\": 784, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 268.38232421875, \"iteration\": 785, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 288.96392822265625, \"iteration\": 786, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 233.03350830078125, \"iteration\": 787, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 203.17880249023438, \"iteration\": 788, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 273.2655029296875, \"iteration\": 789, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 227.04425048828125, \"iteration\": 790, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 217.67691040039062, \"iteration\": 791, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 257.81097412109375, \"iteration\": 792, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 278.55633544921875, \"iteration\": 793, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 279.23297119140625, \"iteration\": 794, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 294.28509521484375, \"iteration\": 795, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 198.2728271484375, \"iteration\": 796, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 236.87911987304688, \"iteration\": 797, \"epoch\": 6}, {\"training_acc\": 0.9672131147540983, \"training_loss\": 103.15011596679688, \"iteration\": 798, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 272.6248779296875, \"iteration\": 799, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 246.46102905273438, \"iteration\": 800, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 226.6879425048828, \"iteration\": 801, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 303.49456787109375, \"iteration\": 802, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 256.65325927734375, \"iteration\": 803, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 314.1514892578125, \"iteration\": 804, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 273.5542297363281, \"iteration\": 805, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 282.800048828125, \"iteration\": 806, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 226.54830932617188, \"iteration\": 807, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 267.08306884765625, \"iteration\": 808, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 241.1634521484375, \"iteration\": 809, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 293.25, \"iteration\": 810, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 303.4665222167969, \"iteration\": 811, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 293.41766357421875, \"iteration\": 812, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 236.50819396972656, \"iteration\": 813, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 262.0318603515625, \"iteration\": 814, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 236.44749450683594, \"iteration\": 815, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 262.31524658203125, \"iteration\": 816, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 336.2142028808594, \"iteration\": 817, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 261.4638671875, \"iteration\": 818, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 271.9358825683594, \"iteration\": 819, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 262.50836181640625, \"iteration\": 820, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 236.34461975097656, \"iteration\": 821, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 262.21966552734375, \"iteration\": 822, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 298.20233154296875, \"iteration\": 823, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 252.15338134765625, \"iteration\": 824, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 211.24038696289062, \"iteration\": 825, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 191.5787353515625, \"iteration\": 826, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 288.34967041015625, \"iteration\": 827, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 277.4332275390625, \"iteration\": 828, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 262.2611999511719, \"iteration\": 829, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 282.648681640625, \"iteration\": 830, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 262.06219482421875, \"iteration\": 831, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 227.13291931152344, \"iteration\": 832, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 256.6063537597656, \"iteration\": 833, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 288.0506286621094, \"iteration\": 834, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 261.86346435546875, \"iteration\": 835, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 314.0133056640625, \"iteration\": 836, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 251.9093780517578, \"iteration\": 837, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 202.299072265625, \"iteration\": 838, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 319.21893310546875, \"iteration\": 839, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 324.79345703125, \"iteration\": 840, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 283.2281494140625, \"iteration\": 841, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 308.46234130859375, \"iteration\": 842, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 262.1852722167969, \"iteration\": 843, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 216.57110595703125, \"iteration\": 844, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 271.8697509765625, \"iteration\": 845, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 221.2246551513672, \"iteration\": 846, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 261.6148986816406, \"iteration\": 847, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 282.72845458984375, \"iteration\": 848, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 272.0897216796875, \"iteration\": 849, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 206.0086669921875, \"iteration\": 850, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 226.0030517578125, \"iteration\": 851, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 287.6422424316406, \"iteration\": 852, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 251.66891479492188, \"iteration\": 853, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 256.83758544921875, \"iteration\": 854, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 266.8228759765625, \"iteration\": 855, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 303.523681640625, \"iteration\": 856, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 256.5522155761719, \"iteration\": 857, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 246.75344848632812, \"iteration\": 858, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 282.5769348144531, \"iteration\": 859, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 319.59124755859375, \"iteration\": 860, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 206.4090576171875, \"iteration\": 861, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 246.2332763671875, \"iteration\": 862, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 293.10736083984375, \"iteration\": 863, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 252.0152587890625, \"iteration\": 864, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 272.2815856933594, \"iteration\": 865, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 261.6674499511719, \"iteration\": 866, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 267.139892578125, \"iteration\": 867, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 282.72601318359375, \"iteration\": 868, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 246.62550354003906, \"iteration\": 869, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 303.5125427246094, \"iteration\": 870, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 262.00860595703125, \"iteration\": 871, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 261.8309326171875, \"iteration\": 872, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 251.35768127441406, \"iteration\": 873, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 282.3085021972656, \"iteration\": 874, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 267.68719482421875, \"iteration\": 875, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 261.8009033203125, \"iteration\": 876, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 215.89349365234375, \"iteration\": 877, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 303.3636779785156, \"iteration\": 878, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 211.46038818359375, \"iteration\": 879, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 221.34121704101562, \"iteration\": 880, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 226.42254638671875, \"iteration\": 881, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 256.4019775390625, \"iteration\": 882, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 271.97943115234375, \"iteration\": 883, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 287.42755126953125, \"iteration\": 884, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 252.08775329589844, \"iteration\": 885, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 277.22808837890625, \"iteration\": 886, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 282.7485046386719, \"iteration\": 887, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 241.29710388183594, \"iteration\": 888, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 267.005859375, \"iteration\": 889, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 221.4767303466797, \"iteration\": 890, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 210.92767333984375, \"iteration\": 891, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 211.3338165283203, \"iteration\": 892, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 272.11090087890625, \"iteration\": 893, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 266.6207275390625, \"iteration\": 894, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 272.2021789550781, \"iteration\": 895, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 272.05023193359375, \"iteration\": 896, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 287.61871337890625, \"iteration\": 897, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 266.8944396972656, \"iteration\": 898, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 246.231201171875, \"iteration\": 899, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 282.21905517578125, \"iteration\": 900, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 226.14865112304688, \"iteration\": 901, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 241.30014038085938, \"iteration\": 902, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 309.02642822265625, \"iteration\": 903, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 256.78094482421875, \"iteration\": 904, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 257.35528564453125, \"iteration\": 905, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 287.7628173828125, \"iteration\": 906, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 261.4754943847656, \"iteration\": 907, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 266.94921875, \"iteration\": 908, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 262.1100769042969, \"iteration\": 909, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 264.16644287109375, \"iteration\": 910, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 246.2057342529297, \"iteration\": 911, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 261.8936462402344, \"iteration\": 912, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 298.68023681640625, \"iteration\": 913, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 261.8194580078125, \"iteration\": 914, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 319.38262939453125, \"iteration\": 915, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 266.79437255859375, \"iteration\": 916, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 297.7950744628906, \"iteration\": 917, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 277.5692138671875, \"iteration\": 918, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 292.59234619140625, \"iteration\": 919, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 282.4195556640625, \"iteration\": 920, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 221.1343994140625, \"iteration\": 921, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 256.6664123535156, \"iteration\": 922, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 256.5604248046875, \"iteration\": 923, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 267.1241760253906, \"iteration\": 924, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 277.19287109375, \"iteration\": 925, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 226.1180419921875, \"iteration\": 926, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 267.2254638671875, \"iteration\": 927, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 274.8477478027344, \"iteration\": 928, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 226.27603149414062, \"iteration\": 929, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 282.1680908203125, \"iteration\": 930, \"epoch\": 7}, {\"training_acc\": 0.9836065573770492, \"training_loss\": 93.84408569335938, \"iteration\": 931, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 245.95648193359375, \"iteration\": 932, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 282.29949951171875, \"iteration\": 933, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 318.8560791015625, \"iteration\": 934, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 220.86968994140625, \"iteration\": 935, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 246.1114501953125, \"iteration\": 936, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 292.58203125, \"iteration\": 937, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 205.71881103515625, \"iteration\": 938, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.9412841796875, \"iteration\": 939, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 276.84283447265625, \"iteration\": 940, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 250.98355102539062, \"iteration\": 941, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.77508544921875, \"iteration\": 942, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 287.40545654296875, \"iteration\": 943, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 240.97222900390625, \"iteration\": 944, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.87799072265625, \"iteration\": 945, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 261.6844787597656, \"iteration\": 946, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 271.84930419921875, \"iteration\": 947, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 256.38067626953125, \"iteration\": 948, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 225.941162109375, \"iteration\": 949, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 241.14727783203125, \"iteration\": 950, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 302.876953125, \"iteration\": 951, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 271.62957763671875, \"iteration\": 952, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 251.08731079101562, \"iteration\": 953, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 313.78631591796875, \"iteration\": 954, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 246.02706909179688, \"iteration\": 955, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.82904052734375, \"iteration\": 956, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 256.0318603515625, \"iteration\": 957, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.66363525390625, \"iteration\": 958, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 245.99810791015625, \"iteration\": 959, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 282.0333251953125, \"iteration\": 960, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.71112060546875, \"iteration\": 961, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 281.9766845703125, \"iteration\": 962, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 251.01516723632812, \"iteration\": 963, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 256.16143798828125, \"iteration\": 964, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.76181030273438, \"iteration\": 965, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 245.90977478027344, \"iteration\": 966, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 276.9075927734375, \"iteration\": 967, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 276.7734375, \"iteration\": 968, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.84869384765625, \"iteration\": 969, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 276.896728515625, \"iteration\": 970, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 261.4389343261719, \"iteration\": 971, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 276.86822509765625, \"iteration\": 972, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 220.65628051757812, \"iteration\": 973, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 246.70675659179688, \"iteration\": 974, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 261.251220703125, \"iteration\": 975, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 261.286376953125, \"iteration\": 976, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 236.04786682128906, \"iteration\": 977, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 241.17124938964844, \"iteration\": 978, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 251.11077880859375, \"iteration\": 979, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.90719604492188, \"iteration\": 980, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.79766845703125, \"iteration\": 981, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 282.1064453125, \"iteration\": 982, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 261.27734375, \"iteration\": 983, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 318.7955322265625, \"iteration\": 984, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 236.05690002441406, \"iteration\": 985, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 292.5663146972656, \"iteration\": 986, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 251.07850646972656, \"iteration\": 987, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 215.84449768066406, \"iteration\": 988, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 240.77835083007812, \"iteration\": 989, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 225.8113250732422, \"iteration\": 990, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.90203857421875, \"iteration\": 991, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 308.15704345703125, \"iteration\": 992, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 245.87985229492188, \"iteration\": 993, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 246.02334594726562, \"iteration\": 994, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.5893249511719, \"iteration\": 995, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 225.53744506835938, \"iteration\": 996, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.642822265625, \"iteration\": 997, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.8002166748047, \"iteration\": 998, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 256.3377685546875, \"iteration\": 999, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 308.3718566894531, \"iteration\": 1000, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.6646728515625, \"iteration\": 1001, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 261.2395935058594, \"iteration\": 1002, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 318.837158203125, \"iteration\": 1003, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 271.5938720703125, \"iteration\": 1004, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 276.78680419921875, \"iteration\": 1005, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 329.4244384765625, \"iteration\": 1006, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.71524047851562, \"iteration\": 1007, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 256.1510314941406, \"iteration\": 1008, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 205.83270263671875, \"iteration\": 1009, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 266.47540283203125, \"iteration\": 1010, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 261.44842529296875, \"iteration\": 1011, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 246.16021728515625, \"iteration\": 1012, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 246.08905029296875, \"iteration\": 1013, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 324.03515625, \"iteration\": 1014, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 277.0047607421875, \"iteration\": 1015, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 251.0968475341797, \"iteration\": 1016, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 266.48095703125, \"iteration\": 1017, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 329.34912109375, \"iteration\": 1018, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 256.13525390625, \"iteration\": 1019, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 251.0863800048828, \"iteration\": 1020, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 245.92483520507812, \"iteration\": 1021, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.84046936035156, \"iteration\": 1022, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 303.0440673828125, \"iteration\": 1023, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 276.80352783203125, \"iteration\": 1024, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 240.83518981933594, \"iteration\": 1025, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 271.6361083984375, \"iteration\": 1026, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 271.6084289550781, \"iteration\": 1027, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 235.6804656982422, \"iteration\": 1028, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 266.4072265625, \"iteration\": 1029, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 235.67080688476562, \"iteration\": 1030, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 282.027587890625, \"iteration\": 1031, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 235.8773956298828, \"iteration\": 1032, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 205.90042114257812, \"iteration\": 1033, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 266.3964538574219, \"iteration\": 1034, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 266.3774719238281, \"iteration\": 1035, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.781982421875, \"iteration\": 1036, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 251.17294311523438, \"iteration\": 1037, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 256.26025390625, \"iteration\": 1038, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 261.3867492675781, \"iteration\": 1039, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 292.4780578613281, \"iteration\": 1040, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 281.9934387207031, \"iteration\": 1041, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 276.8337707519531, \"iteration\": 1042, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 251.09828186035156, \"iteration\": 1043, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 308.26275634765625, \"iteration\": 1044, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 266.4033508300781, \"iteration\": 1045, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.6890563964844, \"iteration\": 1046, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 235.93499755859375, \"iteration\": 1047, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 225.7276611328125, \"iteration\": 1048, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 235.8477325439453, \"iteration\": 1049, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 225.7269287109375, \"iteration\": 1050, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 282.0137023925781, \"iteration\": 1051, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 297.5542297363281, \"iteration\": 1052, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 308.1424255371094, \"iteration\": 1053, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 245.83914184570312, \"iteration\": 1054, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 266.3940124511719, \"iteration\": 1055, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 287.115478515625, \"iteration\": 1056, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 266.334716796875, \"iteration\": 1057, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.99464416503906, \"iteration\": 1058, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 276.65960693359375, \"iteration\": 1059, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 287.1201171875, \"iteration\": 1060, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 271.5015869140625, \"iteration\": 1061, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 235.98785400390625, \"iteration\": 1062, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 266.4265441894531, \"iteration\": 1063, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 119.95387268066406, \"iteration\": 1064, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 271.43634033203125, \"iteration\": 1065, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.14093017578125, \"iteration\": 1066, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 245.8129425048828, \"iteration\": 1067, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 256.0229187011719, \"iteration\": 1068, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.6985168457031, \"iteration\": 1069, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 318.6147766113281, \"iteration\": 1070, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.58517456054688, \"iteration\": 1071, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 266.24310302734375, \"iteration\": 1072, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.49349975585938, \"iteration\": 1073, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 240.70716857910156, \"iteration\": 1074, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 240.70225524902344, \"iteration\": 1075, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 287.0297546386719, \"iteration\": 1076, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.6716613769531, \"iteration\": 1077, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.59649658203125, \"iteration\": 1078, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 281.810302734375, \"iteration\": 1079, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 281.8046875, \"iteration\": 1080, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 308.0141906738281, \"iteration\": 1081, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 281.8564453125, \"iteration\": 1082, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 339.9478759765625, \"iteration\": 1083, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 323.96112060546875, \"iteration\": 1084, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.5679168701172, \"iteration\": 1085, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 250.90939331054688, \"iteration\": 1086, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 271.453369140625, \"iteration\": 1087, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 281.82275390625, \"iteration\": 1088, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 287.0587463378906, \"iteration\": 1089, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 230.51583862304688, \"iteration\": 1090, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.5841979980469, \"iteration\": 1091, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.65069580078125, \"iteration\": 1092, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.66641235351562, \"iteration\": 1093, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 245.76734924316406, \"iteration\": 1094, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 323.9766540527344, \"iteration\": 1095, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.14959716796875, \"iteration\": 1096, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.2335205078125, \"iteration\": 1097, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 281.99176025390625, \"iteration\": 1098, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 334.55718994140625, \"iteration\": 1099, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.1612854003906, \"iteration\": 1100, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 255.96688842773438, \"iteration\": 1101, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 302.7704772949219, \"iteration\": 1102, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.61517333984375, \"iteration\": 1103, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 287.061767578125, \"iteration\": 1104, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 297.44464111328125, \"iteration\": 1105, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.52838134765625, \"iteration\": 1106, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 281.87396240234375, \"iteration\": 1107, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 230.4942626953125, \"iteration\": 1108, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 302.73297119140625, \"iteration\": 1109, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 240.7852783203125, \"iteration\": 1110, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.47906494140625, \"iteration\": 1111, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 287.03271484375, \"iteration\": 1112, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 297.59918212890625, \"iteration\": 1113, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.85723876953125, \"iteration\": 1114, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 287.0250244140625, \"iteration\": 1115, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 307.9847412109375, \"iteration\": 1116, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.1220703125, \"iteration\": 1117, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 240.65533447265625, \"iteration\": 1118, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.2357482910156, \"iteration\": 1119, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 266.31536865234375, \"iteration\": 1120, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.48170471191406, \"iteration\": 1121, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.6062774658203, \"iteration\": 1122, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 240.73751831054688, \"iteration\": 1123, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 245.76559448242188, \"iteration\": 1124, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 292.2348937988281, \"iteration\": 1125, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 195.71957397460938, \"iteration\": 1126, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 230.56048583984375, \"iteration\": 1127, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.50473022460938, \"iteration\": 1128, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 281.7890625, \"iteration\": 1129, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 210.550048828125, \"iteration\": 1130, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.1409912109375, \"iteration\": 1131, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 256.01177978515625, \"iteration\": 1132, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 271.41973876953125, \"iteration\": 1133, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 266.5783996582031, \"iteration\": 1134, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.100341796875, \"iteration\": 1135, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.6841735839844, \"iteration\": 1136, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 245.77432250976562, \"iteration\": 1137, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 230.59815979003906, \"iteration\": 1138, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 266.311279296875, \"iteration\": 1139, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.54342651367188, \"iteration\": 1140, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 287.0315856933594, \"iteration\": 1141, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.589599609375, \"iteration\": 1142, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 281.8325500488281, \"iteration\": 1143, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 271.44268798828125, \"iteration\": 1144, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 250.93832397460938, \"iteration\": 1145, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 240.68588256835938, \"iteration\": 1146, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 266.2603759765625, \"iteration\": 1147, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.73983764648438, \"iteration\": 1148, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 297.53594970703125, \"iteration\": 1149, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.61322021484375, \"iteration\": 1150, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 266.2912292480469, \"iteration\": 1151, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 245.72862243652344, \"iteration\": 1152, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 250.87759399414062, \"iteration\": 1153, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 329.2300109863281, \"iteration\": 1154, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.5261993408203, \"iteration\": 1155, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.5322265625, \"iteration\": 1156, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 308.0938415527344, \"iteration\": 1157, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 292.31768798828125, \"iteration\": 1158, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 245.74563598632812, \"iteration\": 1159, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.51211547851562, \"iteration\": 1160, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 250.937744140625, \"iteration\": 1161, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 245.78128051757812, \"iteration\": 1162, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 297.52117919921875, \"iteration\": 1163, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 307.9891357421875, \"iteration\": 1164, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 308.01715087890625, \"iteration\": 1165, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.09881591796875, \"iteration\": 1166, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 266.2526550292969, \"iteration\": 1167, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.61154174804688, \"iteration\": 1168, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 266.273193359375, \"iteration\": 1169, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 255.93438720703125, \"iteration\": 1170, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.1656494140625, \"iteration\": 1171, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 287.03399658203125, \"iteration\": 1172, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 287.04364013671875, \"iteration\": 1173, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.5957336425781, \"iteration\": 1174, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 266.3656311035156, \"iteration\": 1175, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 245.76577758789062, \"iteration\": 1176, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.56959533691406, \"iteration\": 1177, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.521240234375, \"iteration\": 1178, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 292.2684326171875, \"iteration\": 1179, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.1736755371094, \"iteration\": 1180, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 271.4170227050781, \"iteration\": 1181, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.58941650390625, \"iteration\": 1182, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 271.53143310546875, \"iteration\": 1183, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 271.43023681640625, \"iteration\": 1184, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 250.9205322265625, \"iteration\": 1185, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 281.81488037109375, \"iteration\": 1186, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 271.40887451171875, \"iteration\": 1187, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.53106689453125, \"iteration\": 1188, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.589599609375, \"iteration\": 1189, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.48390197753906, \"iteration\": 1190, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 292.2352600097656, \"iteration\": 1191, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.5801696777344, \"iteration\": 1192, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 271.4530029296875, \"iteration\": 1193, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.0752868652344, \"iteration\": 1194, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 240.6574249267578, \"iteration\": 1195, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 292.2432861328125, \"iteration\": 1196, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 115.40200805664062, \"iteration\": 1197, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 240.61489868164062, \"iteration\": 1198, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.49929809570312, \"iteration\": 1199, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 297.42474365234375, \"iteration\": 1200, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 323.8682861328125, \"iteration\": 1201, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 292.228759765625, \"iteration\": 1202, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 266.22796630859375, \"iteration\": 1203, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.57093811035156, \"iteration\": 1204, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 302.74908447265625, \"iteration\": 1205, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.84548950195312, \"iteration\": 1206, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 266.2350158691406, \"iteration\": 1207, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 261.0455322265625, \"iteration\": 1208, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 245.7742919921875, \"iteration\": 1209, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 281.7657470703125, \"iteration\": 1210, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.51467895507812, \"iteration\": 1211, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 281.76739501953125, \"iteration\": 1212, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 292.2020263671875, \"iteration\": 1213, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 245.76271057128906, \"iteration\": 1214, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 345.26617431640625, \"iteration\": 1215, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.87449645996094, \"iteration\": 1216, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.6282958984375, \"iteration\": 1217, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 297.4642639160156, \"iteration\": 1218, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.47360229492188, \"iteration\": 1219, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 266.20672607421875, \"iteration\": 1220, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 276.579345703125, \"iteration\": 1221, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.51837158203125, \"iteration\": 1222, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 245.69100952148438, \"iteration\": 1223, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 261.07574462890625, \"iteration\": 1224, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.8180694580078, \"iteration\": 1225, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 266.26959228515625, \"iteration\": 1226, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.45831298828125, \"iteration\": 1227, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 318.566162109375, \"iteration\": 1228, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 261.0626525878906, \"iteration\": 1229, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 255.93936157226562, \"iteration\": 1230, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.47596740722656, \"iteration\": 1231, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.60723876953125, \"iteration\": 1232, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.58258056640625, \"iteration\": 1233, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 345.2327575683594, \"iteration\": 1234, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 297.4518737792969, \"iteration\": 1235, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.43479919433594, \"iteration\": 1236, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.64926147460938, \"iteration\": 1237, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.82040405273438, \"iteration\": 1238, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 276.5687255859375, \"iteration\": 1239, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.51414489746094, \"iteration\": 1240, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 266.21063232421875, \"iteration\": 1241, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 286.9658203125, \"iteration\": 1242, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.4589385986328, \"iteration\": 1243, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 286.98724365234375, \"iteration\": 1244, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 266.2159729003906, \"iteration\": 1245, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 245.74285888671875, \"iteration\": 1246, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 302.709716796875, \"iteration\": 1247, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 292.20068359375, \"iteration\": 1248, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.8096466064453, \"iteration\": 1249, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 276.5848083496094, \"iteration\": 1250, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 266.2055358886719, \"iteration\": 1251, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.49163818359375, \"iteration\": 1252, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 281.7563781738281, \"iteration\": 1253, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 255.91136169433594, \"iteration\": 1254, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 281.7576904296875, \"iteration\": 1255, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 276.5714111328125, \"iteration\": 1256, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.64242553710938, \"iteration\": 1257, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 245.73974609375, \"iteration\": 1258, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 292.23248291015625, \"iteration\": 1259, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 245.7264404296875, \"iteration\": 1260, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.82376098632812, \"iteration\": 1261, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 276.5502624511719, \"iteration\": 1262, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 276.56060791015625, \"iteration\": 1263, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 334.5213928222656, \"iteration\": 1264, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.60305786132812, \"iteration\": 1265, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.80947875976562, \"iteration\": 1266, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 281.775634765625, \"iteration\": 1267, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 276.55780029296875, \"iteration\": 1268, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.65652465820312, \"iteration\": 1269, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 261.06982421875, \"iteration\": 1270, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 281.78851318359375, \"iteration\": 1271, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 261.0587158203125, \"iteration\": 1272, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 261.0677795410156, \"iteration\": 1273, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 307.9486083984375, \"iteration\": 1274, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.80508422851562, \"iteration\": 1275, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.47760009765625, \"iteration\": 1276, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.78704833984375, \"iteration\": 1277, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.4974365234375, \"iteration\": 1278, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 292.1891174316406, \"iteration\": 1279, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 286.96417236328125, \"iteration\": 1280, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.60572814941406, \"iteration\": 1281, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 245.7093048095703, \"iteration\": 1282, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.45846557617188, \"iteration\": 1283, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 255.93124389648438, \"iteration\": 1284, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 302.6765441894531, \"iteration\": 1285, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 308.04376220703125, \"iteration\": 1286, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 255.9224853515625, \"iteration\": 1287, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 297.436279296875, \"iteration\": 1288, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.48455810546875, \"iteration\": 1289, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 255.91690063476562, \"iteration\": 1290, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.4825439453125, \"iteration\": 1291, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 271.382568359375, \"iteration\": 1292, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 245.72312927246094, \"iteration\": 1293, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.5131378173828, \"iteration\": 1294, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 276.57659912109375, \"iteration\": 1295, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 345.24432373046875, \"iteration\": 1296, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.53050231933594, \"iteration\": 1297, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.50682067871094, \"iteration\": 1298, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 245.7227783203125, \"iteration\": 1299, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 276.5623779296875, \"iteration\": 1300, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.44168090820312, \"iteration\": 1301, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 281.8003234863281, \"iteration\": 1302, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 266.23486328125, \"iteration\": 1303, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 302.696044921875, \"iteration\": 1304, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 271.38580322265625, \"iteration\": 1305, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 276.55511474609375, \"iteration\": 1306, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 292.223876953125, \"iteration\": 1307, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 255.92605590820312, \"iteration\": 1308, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 286.9794006347656, \"iteration\": 1309, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 297.43194580078125, \"iteration\": 1310, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 271.35906982421875, \"iteration\": 1311, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 292.1871032714844, \"iteration\": 1312, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.81275939941406, \"iteration\": 1313, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.53958129882812, \"iteration\": 1314, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 255.91098022460938, \"iteration\": 1315, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.7945556640625, \"iteration\": 1316, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 255.94834899902344, \"iteration\": 1317, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.52175903320312, \"iteration\": 1318, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.47406005859375, \"iteration\": 1319, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 286.96942138671875, \"iteration\": 1320, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.4595489501953, \"iteration\": 1321, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 307.964111328125, \"iteration\": 1322, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 307.9569091796875, \"iteration\": 1323, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 255.9241943359375, \"iteration\": 1324, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 261.0669250488281, \"iteration\": 1325, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.81021118164062, \"iteration\": 1326, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.59060668945312, \"iteration\": 1327, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 250.81243896484375, \"iteration\": 1328, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 266.20025634765625, \"iteration\": 1329, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 106.46849060058594, \"iteration\": 1330, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\"Prepare data encoder...\")\n",
    "# train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "train_encoder = TfidfVectorizer(max_features=50000, analyzer=\"char\", ngram_range=(3,5))\n",
    "train_encoder.fit(train_raw_sample.texts)\n",
    "print(\"Vocabulary\", len(train_encoder.vocabulary_))\n",
    "\n",
    "print(\"Prepare data...\")\n",
    "train_dataset = encode_data(train_raw_sample, train_encoder)\n",
    "test_dataset = encode_data(test_raw, train_encoder)\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "model_nn_balkan_downsample = NeuralNetwork(\n",
    "    input_size=len(train_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "if Path('models/model_nn_balkan_downsample.pt').exists() and USE_CACHE:\n",
    "    model_nn_balkan_downsample = load_model(model_nn_balkan_downsample, 'model_nn_balkan_downsample')\n",
    "else:\n",
    "    model_nn_balkan_downsample.fit(train_dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn_balkan_downsample, \"model_nn_balkan_downsample\")\n",
    "\n",
    "model_nn_balkan_downsample_results = evaluate_nn_model(model_nn_balkan_downsample, test_dataset)\n",
    "np.save('models/model_nn_balkan_downsample_results.npy', model_nn_balkan_downsample_results)\n",
    "print(model_nn_balkan_downsample_results)\n",
    "\n",
    "model_nn_balkan_downsample.cpu()\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn_balkan_downsample, train_config, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change threshold\n",
    "\n",
    "Making it easier to predict positie (minority) class also help with recall - basically easier to capture more positive classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22672 5714\n",
      "Percentage of positive: 0.3698394495412844 0.364193209660483\n",
      "Prepare data encoder...\n",
      "Vocabulary 50000\n",
      "Prepare data...\n",
      "Train model\n"
     ]
    }
   ],
   "source": [
    "# POC for croatian\n",
    "#%%\n",
    "croatian_file_list = [\n",
    "    'power-ba-train.tsv',\n",
    "    'power-rs-train.tsv',\n",
    "    'power-hr-train.tsv',\n",
    "]\n",
    "\n",
    "croatian_data = load_data(folder_path=\"data/train/power/\", file_list=croatian_file_list,text_head='text')\n",
    "train_raw, test_raw = split_data(croatian_data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(len(train_raw), len(test_raw))\n",
    "print(\"Percentage of positive:\", sum(train_raw.labels) / len(train_raw), sum(test_raw.labels) / len(test_raw))\n",
    "\n",
    "\n",
    "print(\"Prepare data encoder...\")\n",
    "# train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "train_encoder = TfidfVectorizer(max_features=50000, analyzer=\"char\", ngram_range=(3,5))\n",
    "train_encoder.fit(train_raw.texts)\n",
    "print(\"Vocabulary\", len(train_encoder.vocabulary_))\n",
    "\n",
    "print(\"Prepare data...\")\n",
    "train_dataset = encode_data(train_raw, train_encoder)\n",
    "test_dataset = encode_data(test_raw, train_encoder)\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 178/178 [00:02<00:00, 68.53batch/s, batch_accuracy=0.688, loss=19] \n",
      "Epoch 2: 100%|██████████| 178/178 [00:02<00:00, 67.70batch/s, batch_accuracy=0.688, loss=11.4]\n",
      "Epoch 3: 100%|██████████| 178/178 [00:02<00:00, 64.09batch/s, batch_accuracy=0.688, loss=3.21]\n",
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 69.33batch/s, batch_accuracy=0.875, loss=8.67]\n",
      "Epoch 5: 100%|██████████| 178/178 [00:02<00:00, 69.57batch/s, batch_accuracy=1, loss=10.9]   \n",
      "Epoch 6: 100%|██████████| 178/178 [00:02<00:00, 69.87batch/s, batch_accuracy=1, loss=19.9]   \n",
      "Epoch 7: 100%|██████████| 178/178 [00:02<00:00, 68.37batch/s, batch_accuracy=1, loss=10.8]   \n",
      "Epoch 8: 100%|██████████| 178/178 [00:02<00:00, 67.03batch/s, batch_accuracy=1, loss=8.12]   \n",
      "Epoch 9: 100%|██████████| 178/178 [00:02<00:00, 65.77batch/s, batch_accuracy=1, loss=10.8]   \n",
      "Epoch 10: 100%|██████████| 178/178 [00:02<00:00, 69.31batch/s, batch_accuracy=1, loss=13.6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7423871159553528, 0.6703507900238037, 0.6546222567558289, 0.44938806916532914)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3585f699704441aca2de1a76d1a780d2.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3585f699704441aca2de1a76d1a780d2.vega-embed details,\n",
       "  #altair-viz-3585f699704441aca2de1a76d1a780d2.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3585f699704441aca2de1a76d1a780d2\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3585f699704441aca2de1a76d1a780d2\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3585f699704441aca2de1a76d1a780d2\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-14b23449697aad37cd0074a1986d46a2\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-14b23449697aad37cd0074a1986d46a2\": [{\"training_acc\": 0.3671875, \"training_loss\": 228.04742431640625, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.3203125, \"training_loss\": 198.89556884765625, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.390625, \"training_loss\": 242.4659423828125, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.3359375, \"training_loss\": 208.451171875, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.3984375, \"training_loss\": 246.99449157714844, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.3671875, \"training_loss\": 227.61325073242188, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.3828125, \"training_loss\": 236.83517456054688, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.328125, \"training_loss\": 202.69384765625, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 251.64846801757812, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 251.26629638671875, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.390625, \"training_loss\": 241.07713317871094, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.390625, \"training_loss\": 241.6381072998047, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 250.4000244140625, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.359375, \"training_loss\": 220.40945434570312, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.3359375, \"training_loss\": 205.68612670898438, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.3671875, \"training_loss\": 224.9544677734375, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.4453125, \"training_loss\": 272.1249084472656, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.34375, \"training_loss\": 209.59332275390625, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.390625, \"training_loss\": 238.1183624267578, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.375, \"training_loss\": 226.458740234375, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.3125, \"training_loss\": 189.93350219726562, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.3984375, \"training_loss\": 241.5453643798828, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.34375, \"training_loss\": 206.34815979003906, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.34375, \"training_loss\": 207.91061401367188, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.296875, \"training_loss\": 178.77767944335938, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.3671875, \"training_loss\": 222.0897216796875, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.3359375, \"training_loss\": 199.8681640625, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.3125, \"training_loss\": 186.21188354492188, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.3671875, \"training_loss\": 217.76296997070312, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.3828125, \"training_loss\": 228.73568725585938, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.375, \"training_loss\": 224.29931640625, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.3984375, \"training_loss\": 236.99240112304688, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.3671875, \"training_loss\": 219.04864501953125, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 240.85232543945312, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.3203125, \"training_loss\": 187.26904296875, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.375, \"training_loss\": 223.57244873046875, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.453125, \"training_loss\": 269.4510192871094, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.4375, \"training_loss\": 244.24911499023438, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.390625, \"training_loss\": 214.1693115234375, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.34375, \"training_loss\": 193.2742919921875, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.390625, \"training_loss\": 226.04971313476562, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.375, \"training_loss\": 210.2923583984375, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.28125, \"training_loss\": 163.977294921875, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 287.6025695800781, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.28125, \"training_loss\": 134.34225463867188, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.3828125, \"training_loss\": 221.3311309814453, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.4296875, \"training_loss\": 224.37924194335938, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.421875, \"training_loss\": 208.55142211914062, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.46875, \"training_loss\": 234.63148498535156, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 201.0130157470703, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.4375, \"training_loss\": 213.28660583496094, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 227.6660919189453, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 261.2503662109375, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.3046875, \"training_loss\": 164.18661499023438, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.375, \"training_loss\": 199.33543395996094, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 237.8921356201172, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.4453125, \"training_loss\": 241.82049560546875, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.4609375, \"training_loss\": 208.06936645507812, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 193.67556762695312, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 259.6709289550781, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 255.07859802246094, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 249.26962280273438, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.453125, \"training_loss\": 213.7099609375, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.484375, \"training_loss\": 248.93006896972656, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.3984375, \"training_loss\": 200.759521484375, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 186.87799072265625, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.4296875, \"training_loss\": 209.45960998535156, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.4453125, \"training_loss\": 211.87344360351562, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.4609375, \"training_loss\": 226.06704711914062, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 176.76104736328125, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.4375, \"training_loss\": 215.208984375, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.4921875, \"training_loss\": 210.7752227783203, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.4375, \"training_loss\": 192.65101623535156, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.4921875, \"training_loss\": 262.18511962890625, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.46875, \"training_loss\": 177.341796875, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.484375, \"training_loss\": 238.00775146484375, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.421875, \"training_loss\": 213.03216552734375, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.453125, \"training_loss\": 210.8817596435547, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 229.04592895507812, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.4453125, \"training_loss\": 206.1568603515625, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 216.17779541015625, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 234.45590209960938, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.4609375, \"training_loss\": 216.07456970214844, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 248.67355346679688, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 262.386474609375, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.375, \"training_loss\": 169.34310913085938, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 202.82461547851562, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.34375, \"training_loss\": 195.65423583984375, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.3984375, \"training_loss\": 171.44415283203125, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 201.42422485351562, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.453125, \"training_loss\": 221.39010620117188, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 239.3995819091797, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 235.60891723632812, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.4375, \"training_loss\": 192.5391845703125, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 243.67367553710938, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.46875, \"training_loss\": 214.1926727294922, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 251.38540649414062, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 194.67417907714844, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 215.30612182617188, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.46875, \"training_loss\": 214.50006103515625, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.484375, \"training_loss\": 196.31307983398438, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.4453125, \"training_loss\": 201.92617797851562, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.453125, \"training_loss\": 245.47943115234375, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 208.97772216796875, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.3984375, \"training_loss\": 196.8764190673828, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.4609375, \"training_loss\": 226.59390258789062, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.453125, \"training_loss\": 217.00289916992188, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.4296875, \"training_loss\": 210.95883178710938, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.4453125, \"training_loss\": 184.0933074951172, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 209.6841278076172, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 212.70248413085938, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 239.23611450195312, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.453125, \"training_loss\": 197.3703155517578, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 218.89805603027344, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 250.94497680664062, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 179.28213500976562, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.4921875, \"training_loss\": 216.2945556640625, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.46875, \"training_loss\": 214.56356811523438, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 257.33856201171875, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 202.00106811523438, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 219.80587768554688, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 213.87245178222656, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.4453125, \"training_loss\": 218.4774932861328, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.4921875, \"training_loss\": 207.78060913085938, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 184.8382568359375, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 203.90591430664062, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 201.52691650390625, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 179.2506561279297, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 222.70523071289062, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 242.43893432617188, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.484375, \"training_loss\": 214.28607177734375, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.421875, \"training_loss\": 158.8975067138672, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 244.55267333984375, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.484375, \"training_loss\": 179.80784606933594, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 193.30258178710938, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 208.08013916015625, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 252.6558837890625, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 199.52525329589844, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 240.90750122070312, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 226.0177459716797, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 188.03109741210938, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.4375, \"training_loss\": 220.18116760253906, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 251.08938598632812, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 241.99440002441406, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 228.38009643554688, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.421875, \"training_loss\": 205.13417053222656, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 187.7303924560547, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 245.0856170654297, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 200.51510620117188, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 214.69268798828125, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 242.33157348632812, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 211.73867797851562, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 210.76235961914062, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 216.53172302246094, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 157.3506317138672, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 237.26844787597656, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 245.32147216796875, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.4921875, \"training_loss\": 231.68917846679688, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.4609375, \"training_loss\": 185.49481201171875, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 224.69436645507812, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 212.73806762695312, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.421875, \"training_loss\": 223.00677490234375, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 223.96575927734375, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 278.1016845703125, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.4296875, \"training_loss\": 170.15467834472656, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 242.66546630859375, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.4609375, \"training_loss\": 223.29452514648438, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 255.539794921875, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 218.4928741455078, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.484375, \"training_loss\": 212.1468963623047, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 176.60911560058594, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 242.50042724609375, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 220.87918090820312, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 242.12208557128906, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.4296875, \"training_loss\": 185.74188232421875, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 234.87237548828125, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 185.9786376953125, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 19.026012420654297, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 186.82261657714844, \"iteration\": 179, \"epoch\": 2}, {\"training_acc\": 0.578125, \"training_loss\": 179.71954345703125, \"iteration\": 180, \"epoch\": 2}, {\"training_acc\": 0.5859375, \"training_loss\": 228.9927978515625, \"iteration\": 181, \"epoch\": 2}, {\"training_acc\": 0.609375, \"training_loss\": 245.0457763671875, \"iteration\": 182, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 225.04290771484375, \"iteration\": 183, \"epoch\": 2}, {\"training_acc\": 0.671875, \"training_loss\": 222.08816528320312, \"iteration\": 184, \"epoch\": 2}, {\"training_acc\": 0.640625, \"training_loss\": 200.60128784179688, \"iteration\": 185, \"epoch\": 2}, {\"training_acc\": 0.625, \"training_loss\": 168.87692260742188, \"iteration\": 186, \"epoch\": 2}, {\"training_acc\": 0.625, \"training_loss\": 176.79940795898438, \"iteration\": 187, \"epoch\": 2}, {\"training_acc\": 0.59375, \"training_loss\": 221.59173583984375, \"iteration\": 188, \"epoch\": 2}, {\"training_acc\": 0.5859375, \"training_loss\": 177.05682373046875, \"iteration\": 189, \"epoch\": 2}, {\"training_acc\": 0.59375, \"training_loss\": 186.56288146972656, \"iteration\": 190, \"epoch\": 2}, {\"training_acc\": 0.5390625, \"training_loss\": 213.68902587890625, \"iteration\": 191, \"epoch\": 2}, {\"training_acc\": 0.578125, \"training_loss\": 222.8850555419922, \"iteration\": 192, \"epoch\": 2}, {\"training_acc\": 0.546875, \"training_loss\": 227.27566528320312, \"iteration\": 193, \"epoch\": 2}, {\"training_acc\": 0.5390625, \"training_loss\": 205.33456420898438, \"iteration\": 194, \"epoch\": 2}, {\"training_acc\": 0.5625, \"training_loss\": 206.25201416015625, \"iteration\": 195, \"epoch\": 2}, {\"training_acc\": 0.640625, \"training_loss\": 217.84268188476562, \"iteration\": 196, \"epoch\": 2}, {\"training_acc\": 0.671875, \"training_loss\": 213.20005798339844, \"iteration\": 197, \"epoch\": 2}, {\"training_acc\": 0.6015625, \"training_loss\": 176.88467407226562, \"iteration\": 198, \"epoch\": 2}, {\"training_acc\": 0.578125, \"training_loss\": 174.338134765625, \"iteration\": 199, \"epoch\": 2}, {\"training_acc\": 0.6171875, \"training_loss\": 244.61485290527344, \"iteration\": 200, \"epoch\": 2}, {\"training_acc\": 0.578125, \"training_loss\": 178.89190673828125, \"iteration\": 201, \"epoch\": 2}, {\"training_acc\": 0.5234375, \"training_loss\": 161.47975158691406, \"iteration\": 202, \"epoch\": 2}, {\"training_acc\": 0.5703125, \"training_loss\": 147.84849548339844, \"iteration\": 203, \"epoch\": 2}, {\"training_acc\": 0.65625, \"training_loss\": 177.44522094726562, \"iteration\": 204, \"epoch\": 2}, {\"training_acc\": 0.65625, \"training_loss\": 196.87086486816406, \"iteration\": 205, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 245.88287353515625, \"iteration\": 206, \"epoch\": 2}, {\"training_acc\": 0.6328125, \"training_loss\": 186.21865844726562, \"iteration\": 207, \"epoch\": 2}, {\"training_acc\": 0.6640625, \"training_loss\": 189.85093688964844, \"iteration\": 208, \"epoch\": 2}, {\"training_acc\": 0.6328125, \"training_loss\": 186.97695922851562, \"iteration\": 209, \"epoch\": 2}, {\"training_acc\": 0.703125, \"training_loss\": 238.394775390625, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.65625, \"training_loss\": 212.89801025390625, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.609375, \"training_loss\": 157.0552520751953, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.6015625, \"training_loss\": 177.80584716796875, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.609375, \"training_loss\": 183.14927673339844, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 204.94268798828125, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 215.3422088623047, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 201.06082153320312, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 236.4805908203125, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.6484375, \"training_loss\": 237.69244384765625, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.65625, \"training_loss\": 172.48228454589844, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.6953125, \"training_loss\": 189.67852783203125, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.6484375, \"training_loss\": 204.87359619140625, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.6640625, \"training_loss\": 230.23341369628906, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.671875, \"training_loss\": 228.49002075195312, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.65625, \"training_loss\": 229.51962280273438, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.6953125, \"training_loss\": 222.62100219726562, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 198.47715759277344, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 216.54214477539062, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 219.68006896972656, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.671875, \"training_loss\": 179.8623809814453, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 219.03636169433594, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.6484375, \"training_loss\": 182.15798950195312, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.609375, \"training_loss\": 161.50616455078125, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 259.4646911621094, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.609375, \"training_loss\": 202.23635864257812, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 230.8330535888672, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.703125, \"training_loss\": 254.24302673339844, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.703125, \"training_loss\": 234.0467987060547, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 212.34042358398438, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 253.3660888671875, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.5390625, \"training_loss\": 204.84561157226562, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.6328125, \"training_loss\": 150.05613708496094, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 178.4197235107422, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 199.56378173828125, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 214.6485595703125, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 159.3770294189453, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.6953125, \"training_loss\": 202.29656982421875, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.6953125, \"training_loss\": 244.75128173828125, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.671875, \"training_loss\": 209.9700469970703, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.625, \"training_loss\": 170.47271728515625, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 204.04750061035156, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.671875, \"training_loss\": 192.16778564453125, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.6640625, \"training_loss\": 199.10818481445312, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 153.56692504882812, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 216.76852416992188, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.6484375, \"training_loss\": 232.2633056640625, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 203.31143188476562, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 248.9793701171875, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 193.4196014404297, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.6171875, \"training_loss\": 208.1831512451172, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 192.9080047607422, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.6640625, \"training_loss\": 239.85830688476562, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.65625, \"training_loss\": 175.86582946777344, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.6171875, \"training_loss\": 187.81854248046875, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.640625, \"training_loss\": 185.69793701171875, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 212.84130859375, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.65625, \"training_loss\": 210.53048706054688, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.6328125, \"training_loss\": 189.2237548828125, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.6171875, \"training_loss\": 229.34548950195312, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.6953125, \"training_loss\": 215.19091796875, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.609375, \"training_loss\": 180.07269287109375, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.703125, \"training_loss\": 212.7991485595703, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.7109375, \"training_loss\": 232.05828857421875, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 157.0888214111328, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.65625, \"training_loss\": 172.7335968017578, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.6328125, \"training_loss\": 228.21368408203125, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.5859375, \"training_loss\": 149.49380493164062, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.625, \"training_loss\": 222.49208068847656, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.609375, \"training_loss\": 161.01565551757812, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 215.298095703125, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.6953125, \"training_loss\": 173.70355224609375, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.6171875, \"training_loss\": 213.6678466796875, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.5703125, \"training_loss\": 185.43524169921875, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 234.15493774414062, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 198.17303466796875, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 232.5758056640625, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 229.97317504882812, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.6953125, \"training_loss\": 159.03936767578125, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 187.2952880859375, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.703125, \"training_loss\": 211.37783813476562, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.609375, \"training_loss\": 192.9432373046875, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.6484375, \"training_loss\": 157.27508544921875, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.671875, \"training_loss\": 186.3218994140625, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.6484375, \"training_loss\": 199.44479370117188, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.640625, \"training_loss\": 192.6264190673828, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 230.83082580566406, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.7109375, \"training_loss\": 243.7733917236328, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 242.3503875732422, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.6640625, \"training_loss\": 228.9676055908203, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.671875, \"training_loss\": 167.92776489257812, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 209.89817810058594, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 190.13861083984375, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 211.8257598876953, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 232.60440063476562, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 249.3736572265625, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 199.80599975585938, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.6484375, \"training_loss\": 198.61508178710938, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.640625, \"training_loss\": 221.64102172851562, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.6328125, \"training_loss\": 199.24107360839844, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.6171875, \"training_loss\": 185.09548950195312, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 213.59738159179688, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 232.67556762695312, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 248.33035278320312, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 199.4561767578125, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 227.38693237304688, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 241.69940185546875, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.578125, \"training_loss\": 221.18429565429688, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.5546875, \"training_loss\": 209.6786651611328, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.5703125, \"training_loss\": 169.36712646484375, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.5234375, \"training_loss\": 162.935791015625, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.6015625, \"training_loss\": 203.5711212158203, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.5859375, \"training_loss\": 195.06239318847656, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.6640625, \"training_loss\": 203.50152587890625, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 223.5897216796875, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 176.09393310546875, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 214.8094024658203, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 191.88510131835938, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 185.441162109375, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.703125, \"training_loss\": 172.2480010986328, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 221.64865112304688, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.65625, \"training_loss\": 210.6497344970703, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.59375, \"training_loss\": 223.67636108398438, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.6015625, \"training_loss\": 187.28494262695312, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.6328125, \"training_loss\": 236.0902099609375, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.640625, \"training_loss\": 197.75148010253906, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.5703125, \"training_loss\": 172.39761352539062, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 186.19091796875, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.7109375, \"training_loss\": 227.23135375976562, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 237.60028076171875, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.6015625, \"training_loss\": 204.8128662109375, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.609375, \"training_loss\": 193.98468017578125, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 198.95980834960938, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.59375, \"training_loss\": 192.49050903320312, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.6328125, \"training_loss\": 217.9566650390625, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 236.2828369140625, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.6640625, \"training_loss\": 216.53311157226562, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.640625, \"training_loss\": 290.61968994140625, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 213.51010131835938, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.6328125, \"training_loss\": 199.85684204101562, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 221.76065063476562, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 240.2633056640625, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.640625, \"training_loss\": 189.0370635986328, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.671875, \"training_loss\": 227.18136596679688, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.640625, \"training_loss\": 179.0004119873047, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.6484375, \"training_loss\": 219.18331909179688, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 11.42757797241211, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.6953125, \"training_loss\": 205.60952758789062, \"iteration\": 357, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 191.9275665283203, \"iteration\": 358, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 227.96713256835938, \"iteration\": 359, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 171.7369384765625, \"iteration\": 360, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 184.2960205078125, \"iteration\": 361, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 229.67332458496094, \"iteration\": 362, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 221.28944396972656, \"iteration\": 363, \"epoch\": 3}, {\"training_acc\": 0.7421875, \"training_loss\": 188.36639404296875, \"iteration\": 364, \"epoch\": 3}, {\"training_acc\": 0.6875, \"training_loss\": 217.74790954589844, \"iteration\": 365, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 177.2613525390625, \"iteration\": 366, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 163.93731689453125, \"iteration\": 367, \"epoch\": 3}, {\"training_acc\": 0.734375, \"training_loss\": 167.23492431640625, \"iteration\": 368, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 149.90798950195312, \"iteration\": 369, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 239.63037109375, \"iteration\": 370, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 173.47593688964844, \"iteration\": 371, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 230.25439453125, \"iteration\": 372, \"epoch\": 3}, {\"training_acc\": 0.7578125, \"training_loss\": 185.87109375, \"iteration\": 373, \"epoch\": 3}, {\"training_acc\": 0.7109375, \"training_loss\": 155.02383422851562, \"iteration\": 374, \"epoch\": 3}, {\"training_acc\": 0.7109375, \"training_loss\": 200.02706909179688, \"iteration\": 375, \"epoch\": 3}, {\"training_acc\": 0.6875, \"training_loss\": 159.5888214111328, \"iteration\": 376, \"epoch\": 3}, {\"training_acc\": 0.7421875, \"training_loss\": 192.09498596191406, \"iteration\": 377, \"epoch\": 3}, {\"training_acc\": 0.6796875, \"training_loss\": 198.17071533203125, \"iteration\": 378, \"epoch\": 3}, {\"training_acc\": 0.71875, \"training_loss\": 147.7193603515625, \"iteration\": 379, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 190.87802124023438, \"iteration\": 380, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 176.90882873535156, \"iteration\": 381, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 222.60580444335938, \"iteration\": 382, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 219.59457397460938, \"iteration\": 383, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 188.72740173339844, \"iteration\": 384, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 167.88723754882812, \"iteration\": 385, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 230.93801879882812, \"iteration\": 386, \"epoch\": 3}, {\"training_acc\": 0.703125, \"training_loss\": 189.18353271484375, \"iteration\": 387, \"epoch\": 3}, {\"training_acc\": 0.734375, \"training_loss\": 201.95648193359375, \"iteration\": 388, \"epoch\": 3}, {\"training_acc\": 0.7578125, \"training_loss\": 197.9578094482422, \"iteration\": 389, \"epoch\": 3}, {\"training_acc\": 0.765625, \"training_loss\": 183.22235107421875, \"iteration\": 390, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 204.21844482421875, \"iteration\": 391, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 197.46270751953125, \"iteration\": 392, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 170.26702880859375, \"iteration\": 393, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 198.21466064453125, \"iteration\": 394, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 200.83763122558594, \"iteration\": 395, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 181.12734985351562, \"iteration\": 396, \"epoch\": 3}, {\"training_acc\": 0.7109375, \"training_loss\": 194.57814025878906, \"iteration\": 397, \"epoch\": 3}, {\"training_acc\": 0.7578125, \"training_loss\": 202.44078063964844, \"iteration\": 398, \"epoch\": 3}, {\"training_acc\": 0.7421875, \"training_loss\": 176.5560302734375, \"iteration\": 399, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 214.32449340820312, \"iteration\": 400, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 189.0626220703125, \"iteration\": 401, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 187.537109375, \"iteration\": 402, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 191.301025390625, \"iteration\": 403, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 172.41427612304688, \"iteration\": 404, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 176.11614990234375, \"iteration\": 405, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 201.5883331298828, \"iteration\": 406, \"epoch\": 3}, {\"training_acc\": 0.7578125, \"training_loss\": 243.23692321777344, \"iteration\": 407, \"epoch\": 3}, {\"training_acc\": 0.6796875, \"training_loss\": 167.95611572265625, \"iteration\": 408, \"epoch\": 3}, {\"training_acc\": 0.7578125, \"training_loss\": 204.91651916503906, \"iteration\": 409, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 203.69198608398438, \"iteration\": 410, \"epoch\": 3}, {\"training_acc\": 0.6875, \"training_loss\": 208.01441955566406, \"iteration\": 411, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 217.44583129882812, \"iteration\": 412, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 213.19854736328125, \"iteration\": 413, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 213.3880157470703, \"iteration\": 414, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 211.4588623046875, \"iteration\": 415, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 241.38726806640625, \"iteration\": 416, \"epoch\": 3}, {\"training_acc\": 0.734375, \"training_loss\": 168.25863647460938, \"iteration\": 417, \"epoch\": 3}, {\"training_acc\": 0.765625, \"training_loss\": 237.66543579101562, \"iteration\": 418, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 214.2646026611328, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.7265625, \"training_loss\": 180.50732421875, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 156.36141967773438, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 168.2889862060547, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 211.91754150390625, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 160.2589111328125, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 207.08572387695312, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 169.8012237548828, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 183.88726806640625, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.7265625, \"training_loss\": 161.78390502929688, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 192.24072265625, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.7734375, \"training_loss\": 197.05230712890625, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 190.26885986328125, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 205.4087677001953, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.765625, \"training_loss\": 220.89610290527344, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 192.4986114501953, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 273.17498779296875, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 165.20729064941406, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 196.65609741210938, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 156.76821899414062, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 241.29226684570312, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 201.5607147216797, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 215.68081665039062, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 196.9520263671875, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 167.03030395507812, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 213.40655517578125, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 205.0182647705078, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.7421875, \"training_loss\": 151.65478515625, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.7734375, \"training_loss\": 179.8776397705078, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.7578125, \"training_loss\": 206.4647979736328, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.7265625, \"training_loss\": 175.50975036621094, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 189.2064971923828, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 182.82696533203125, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 197.7625732421875, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 189.34410095214844, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 210.30978393554688, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 183.17788696289062, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 223.97207641601562, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 188.81227111816406, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 179.23663330078125, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 206.45697021484375, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.6875, \"training_loss\": 160.15975952148438, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.6640625, \"training_loss\": 150.15252685546875, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.6953125, \"training_loss\": 201.04843139648438, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 182.09461975097656, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 159.3114013671875, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 186.10133361816406, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 220.9061737060547, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.765625, \"training_loss\": 204.91897583007812, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 159.3179931640625, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.7578125, \"training_loss\": 200.40966796875, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 209.4724884033203, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 236.03762817382812, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.7421875, \"training_loss\": 215.5004119873047, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 166.02670288085938, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 178.25950622558594, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 215.52264404296875, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 216.0145263671875, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 235.23922729492188, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 191.88600158691406, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 161.1126708984375, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 175.26791381835938, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 230.23260498046875, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 221.7277374267578, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 184.47103881835938, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.7109375, \"training_loss\": 188.34390258789062, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 210.910400390625, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 175.49588012695312, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 209.86898803710938, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 182.2432098388672, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 200.14886474609375, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.7734375, \"training_loss\": 223.66278076171875, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 171.26483154296875, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 260.9161376953125, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 197.82113647460938, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 187.77642822265625, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 207.85769653320312, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 211.51031494140625, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 207.65174865722656, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 195.73043823242188, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 143.02545166015625, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 207.61602783203125, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 218.53466796875, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 193.39967346191406, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 174.31088256835938, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.765625, \"training_loss\": 168.4237060546875, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 201.66671752929688, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 180.9848175048828, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.7578125, \"training_loss\": 184.00839233398438, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 211.6797637939453, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.7578125, \"training_loss\": 205.22305297851562, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.765625, \"training_loss\": 220.8615264892578, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 185.70179748535156, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 213.45867919921875, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 175.14791870117188, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 233.1807403564453, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 223.15850830078125, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 258.1182556152344, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 239.396728515625, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 225.32115173339844, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.7734375, \"training_loss\": 241.39480590820312, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 189.30380249023438, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 231.26177978515625, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 254.74050903320312, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 266.51690673828125, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 162.50953674316406, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.7265625, \"training_loss\": 111.84432983398438, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.765625, \"training_loss\": 224.04571533203125, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 183.95631408691406, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.734375, \"training_loss\": 187.0367431640625, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.7578125, \"training_loss\": 186.71759033203125, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.7265625, \"training_loss\": 229.2760009765625, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 238.00787353515625, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.7421875, \"training_loss\": 154.67677307128906, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 196.43377685546875, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.6875, \"training_loss\": 3.2074899673461914, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 208.11827087402344, \"iteration\": 535, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 166.00473022460938, \"iteration\": 536, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 254.36541748046875, \"iteration\": 537, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 188.23886108398438, \"iteration\": 538, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 181.81942749023438, \"iteration\": 539, \"epoch\": 4}, {\"training_acc\": 0.8203125, \"training_loss\": 195.86367797851562, \"iteration\": 540, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 243.4202880859375, \"iteration\": 541, \"epoch\": 4}, {\"training_acc\": 0.78125, \"training_loss\": 205.59146118164062, \"iteration\": 542, \"epoch\": 4}, {\"training_acc\": 0.734375, \"training_loss\": 201.2744903564453, \"iteration\": 543, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 149.7928466796875, \"iteration\": 544, \"epoch\": 4}, {\"training_acc\": 0.8125, \"training_loss\": 218.62039184570312, \"iteration\": 545, \"epoch\": 4}, {\"training_acc\": 0.8125, \"training_loss\": 157.35244750976562, \"iteration\": 546, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 188.56370544433594, \"iteration\": 547, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 241.77049255371094, \"iteration\": 548, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 218.401611328125, \"iteration\": 549, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 166.8645477294922, \"iteration\": 550, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 222.90687561035156, \"iteration\": 551, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 208.68560791015625, \"iteration\": 552, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 210.89892578125, \"iteration\": 553, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 181.16458129882812, \"iteration\": 554, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 210.8330078125, \"iteration\": 555, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 169.1250457763672, \"iteration\": 556, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 179.66162109375, \"iteration\": 557, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 185.61180114746094, \"iteration\": 558, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 198.3555908203125, \"iteration\": 559, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 154.00946044921875, \"iteration\": 560, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 215.57151794433594, \"iteration\": 561, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 207.4773712158203, \"iteration\": 562, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 218.04287719726562, \"iteration\": 563, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 173.27490234375, \"iteration\": 564, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 163.78076171875, \"iteration\": 565, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 228.58047485351562, \"iteration\": 566, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 172.10845947265625, \"iteration\": 567, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 184.75775146484375, \"iteration\": 568, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 194.4130859375, \"iteration\": 569, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 198.4744873046875, \"iteration\": 570, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 212.31065368652344, \"iteration\": 571, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 182.7327880859375, \"iteration\": 572, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 175.533203125, \"iteration\": 573, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 197.4453125, \"iteration\": 574, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 181.75076293945312, \"iteration\": 575, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 194.27667236328125, \"iteration\": 576, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 198.05186462402344, \"iteration\": 577, \"epoch\": 4}, {\"training_acc\": 0.8046875, \"training_loss\": 195.57577514648438, \"iteration\": 578, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 206.29568481445312, \"iteration\": 579, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 203.8158721923828, \"iteration\": 580, \"epoch\": 4}, {\"training_acc\": 0.8203125, \"training_loss\": 157.2145538330078, \"iteration\": 581, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 159.26498413085938, \"iteration\": 582, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 189.54473876953125, \"iteration\": 583, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 182.2984619140625, \"iteration\": 584, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 185.08975219726562, \"iteration\": 585, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 195.15081787109375, \"iteration\": 586, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 179.9348907470703, \"iteration\": 587, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 194.85848999023438, \"iteration\": 588, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 208.7735595703125, \"iteration\": 589, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 130.3146209716797, \"iteration\": 590, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 155.5044708251953, \"iteration\": 591, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 227.14280700683594, \"iteration\": 592, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 197.86813354492188, \"iteration\": 593, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 209.3255615234375, \"iteration\": 594, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 159.05784606933594, \"iteration\": 595, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 189.8350830078125, \"iteration\": 596, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 184.52789306640625, \"iteration\": 597, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 220.00076293945312, \"iteration\": 598, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 217.1026611328125, \"iteration\": 599, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 200.70631408691406, \"iteration\": 600, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 223.16192626953125, \"iteration\": 601, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 187.9952850341797, \"iteration\": 602, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 169.80567932128906, \"iteration\": 603, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 163.68304443359375, \"iteration\": 604, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 181.47164916992188, \"iteration\": 605, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 213.16172790527344, \"iteration\": 606, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 151.98379516601562, \"iteration\": 607, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 188.3350067138672, \"iteration\": 608, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 202.53143310546875, \"iteration\": 609, \"epoch\": 4}, {\"training_acc\": 0.796875, \"training_loss\": 172.1111602783203, \"iteration\": 610, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 145.26150512695312, \"iteration\": 611, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 227.53936767578125, \"iteration\": 612, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 169.97412109375, \"iteration\": 613, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 186.86376953125, \"iteration\": 614, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 205.4508056640625, \"iteration\": 615, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 184.84378051757812, \"iteration\": 616, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 198.0516357421875, \"iteration\": 617, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 211.89320373535156, \"iteration\": 618, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 186.60073852539062, \"iteration\": 619, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 220.6514892578125, \"iteration\": 620, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 178.91567993164062, \"iteration\": 621, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 215.23880004882812, \"iteration\": 622, \"epoch\": 4}, {\"training_acc\": 0.8125, \"training_loss\": 140.783935546875, \"iteration\": 623, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 182.17703247070312, \"iteration\": 624, \"epoch\": 4}, {\"training_acc\": 0.796875, \"training_loss\": 176.78976440429688, \"iteration\": 625, \"epoch\": 4}, {\"training_acc\": 0.8125, \"training_loss\": 181.2477569580078, \"iteration\": 626, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 192.71592712402344, \"iteration\": 627, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 167.7198486328125, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 208.31326293945312, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 186.66403198242188, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 179.6427459716797, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 203.78570556640625, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.796875, \"training_loss\": 151.51202392578125, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.8203125, \"training_loss\": 198.40478515625, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 188.36575317382812, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 185.0218505859375, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 200.3457489013672, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 205.48828125, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 187.21868896484375, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 216.29505920410156, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 179.16705322265625, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 167.31719970703125, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 268.33856201171875, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 178.81312561035156, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 213.37493896484375, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 180.5569305419922, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 191.8922119140625, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.8046875, \"training_loss\": 144.40945434570312, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 165.39218139648438, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 179.7967071533203, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 212.23233032226562, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 179.16055297851562, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 174.30917358398438, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 163.41830444335938, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 162.6848907470703, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 233.7722625732422, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 242.03292846679688, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.796875, \"training_loss\": 183.19357299804688, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 208.36734008789062, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.7734375, \"training_loss\": 186.8778076171875, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 181.64202880859375, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 179.64105224609375, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 169.85403442382812, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 199.77728271484375, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 215.72142028808594, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 201.51797485351562, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 201.99172973632812, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 208.600341796875, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.71875, \"training_loss\": 191.209716796875, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.7890625, \"training_loss\": 258.2150573730469, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.7578125, \"training_loss\": 209.5093994140625, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.8203125, \"training_loss\": 172.18185424804688, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 159.25967407226562, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 140.1047821044922, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 247.24615478515625, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 182.56494140625, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 219.8738555908203, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 210.90325927734375, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 241.60169982910156, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 197.74977111816406, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 151.47982788085938, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 176.60963439941406, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 158.6114501953125, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 201.5849609375, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 211.07669067382812, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 201.54360961914062, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 185.48928833007812, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 148.79229736328125, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 203.48318481445312, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 191.47389221191406, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.8125, \"training_loss\": 152.207275390625, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 211.65789794921875, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 0.7578125, \"training_loss\": 179.0693359375, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 183.8499755859375, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 169.54449462890625, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 163.37278747558594, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 197.5198516845703, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 215.4103546142578, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 176.572509765625, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 197.53195190429688, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 283.8212890625, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.7890625, \"training_loss\": 196.19049072265625, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.7890625, \"training_loss\": 148.82603454589844, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 151.56410217285156, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 158.79405212402344, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 170.44943237304688, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 190.76931762695312, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 239.12876892089844, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 146.91909790039062, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 164.13894653320312, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 243.66375732421875, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 8.67268180847168, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 179.00669860839844, \"iteration\": 713, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 147.17251586914062, \"iteration\": 714, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 230.21060180664062, \"iteration\": 715, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 184.793212890625, \"iteration\": 716, \"epoch\": 5}, {\"training_acc\": 0.8359375, \"training_loss\": 164.47665405273438, \"iteration\": 717, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 230.41455078125, \"iteration\": 718, \"epoch\": 5}, {\"training_acc\": 0.8125, \"training_loss\": 172.99034118652344, \"iteration\": 719, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 187.91339111328125, \"iteration\": 720, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 201.9610137939453, \"iteration\": 721, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 195.072509765625, \"iteration\": 722, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 209.527099609375, \"iteration\": 723, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 196.39491271972656, \"iteration\": 724, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 126.64517211914062, \"iteration\": 725, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 207.3983154296875, \"iteration\": 726, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 170.41712951660156, \"iteration\": 727, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 167.41616821289062, \"iteration\": 728, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 220.38711547851562, \"iteration\": 729, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 207.02957153320312, \"iteration\": 730, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 176.99395751953125, \"iteration\": 731, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 176.59634399414062, \"iteration\": 732, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 200.02645874023438, \"iteration\": 733, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 205.8383026123047, \"iteration\": 734, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 176.3884735107422, \"iteration\": 735, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 210.3822021484375, \"iteration\": 736, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 231.76937866210938, \"iteration\": 737, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 232.74398803710938, \"iteration\": 738, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 224.22613525390625, \"iteration\": 739, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 198.3530731201172, \"iteration\": 740, \"epoch\": 5}, {\"training_acc\": 0.8359375, \"training_loss\": 126.05767822265625, \"iteration\": 741, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 151.6883544921875, \"iteration\": 742, \"epoch\": 5}, {\"training_acc\": 0.859375, \"training_loss\": 192.62680053710938, \"iteration\": 743, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 222.1815185546875, \"iteration\": 744, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 148.5538330078125, \"iteration\": 745, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 171.4101104736328, \"iteration\": 746, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 160.275390625, \"iteration\": 747, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 206.001220703125, \"iteration\": 748, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 205.5625, \"iteration\": 749, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 170.36534118652344, \"iteration\": 750, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 195.1348876953125, \"iteration\": 751, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 161.30535888671875, \"iteration\": 752, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 193.04025268554688, \"iteration\": 753, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 196.44883728027344, \"iteration\": 754, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 187.2158203125, \"iteration\": 755, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 205.30499267578125, \"iteration\": 756, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 175.79782104492188, \"iteration\": 757, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 204.2234649658203, \"iteration\": 758, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 132.70565795898438, \"iteration\": 759, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 196.16419982910156, \"iteration\": 760, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 186.326904296875, \"iteration\": 761, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 204.81044006347656, \"iteration\": 762, \"epoch\": 5}, {\"training_acc\": 0.8515625, \"training_loss\": 191.5684051513672, \"iteration\": 763, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 133.59609985351562, \"iteration\": 764, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 157.16204833984375, \"iteration\": 765, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 134.49569702148438, \"iteration\": 766, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 230.61227416992188, \"iteration\": 767, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 115.02397918701172, \"iteration\": 768, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 179.6949462890625, \"iteration\": 769, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 235.78746032714844, \"iteration\": 770, \"epoch\": 5}, {\"training_acc\": 0.859375, \"training_loss\": 166.2711181640625, \"iteration\": 771, \"epoch\": 5}, {\"training_acc\": 0.8359375, \"training_loss\": 197.22537231445312, \"iteration\": 772, \"epoch\": 5}, {\"training_acc\": 0.78125, \"training_loss\": 168.44635009765625, \"iteration\": 773, \"epoch\": 5}, {\"training_acc\": 0.796875, \"training_loss\": 198.8509521484375, \"iteration\": 774, \"epoch\": 5}, {\"training_acc\": 0.8125, \"training_loss\": 151.5575408935547, \"iteration\": 775, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 225.90838623046875, \"iteration\": 776, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 196.9097442626953, \"iteration\": 777, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 146.22804260253906, \"iteration\": 778, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 166.94924926757812, \"iteration\": 779, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 254.13995361328125, \"iteration\": 780, \"epoch\": 5}, {\"training_acc\": 0.84375, \"training_loss\": 177.43246459960938, \"iteration\": 781, \"epoch\": 5}, {\"training_acc\": 0.8359375, \"training_loss\": 180.599365234375, \"iteration\": 782, \"epoch\": 5}, {\"training_acc\": 0.8046875, \"training_loss\": 169.2132568359375, \"iteration\": 783, \"epoch\": 5}, {\"training_acc\": 0.8046875, \"training_loss\": 211.83685302734375, \"iteration\": 784, \"epoch\": 5}, {\"training_acc\": 0.8125, \"training_loss\": 183.68153381347656, \"iteration\": 785, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 157.80630493164062, \"iteration\": 786, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 158.70947265625, \"iteration\": 787, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 184.33741760253906, \"iteration\": 788, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 206.75546264648438, \"iteration\": 789, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 180.85923767089844, \"iteration\": 790, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 227.43157958984375, \"iteration\": 791, \"epoch\": 5}, {\"training_acc\": 0.859375, \"training_loss\": 197.02944946289062, \"iteration\": 792, \"epoch\": 5}, {\"training_acc\": 0.7890625, \"training_loss\": 164.21923828125, \"iteration\": 793, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 195.5033721923828, \"iteration\": 794, \"epoch\": 5}, {\"training_acc\": 0.859375, \"training_loss\": 206.36228942871094, \"iteration\": 795, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 177.31216430664062, \"iteration\": 796, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 162.76205444335938, \"iteration\": 797, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 161.48406982421875, \"iteration\": 798, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 185.58509826660156, \"iteration\": 799, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 206.9402313232422, \"iteration\": 800, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 186.696533203125, \"iteration\": 801, \"epoch\": 5}, {\"training_acc\": 0.859375, \"training_loss\": 175.7049560546875, \"iteration\": 802, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 181.0169219970703, \"iteration\": 803, \"epoch\": 5}, {\"training_acc\": 0.8515625, \"training_loss\": 171.9639129638672, \"iteration\": 804, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 191.88360595703125, \"iteration\": 805, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 155.63803100585938, \"iteration\": 806, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 181.68695068359375, \"iteration\": 807, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 175.3695068359375, \"iteration\": 808, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 244.627685546875, \"iteration\": 809, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 236.79632568359375, \"iteration\": 810, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 209.93345642089844, \"iteration\": 811, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 225.8909454345703, \"iteration\": 812, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 224.54531860351562, \"iteration\": 813, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 144.85650634765625, \"iteration\": 814, \"epoch\": 5}, {\"training_acc\": 0.8203125, \"training_loss\": 159.31576538085938, \"iteration\": 815, \"epoch\": 5}, {\"training_acc\": 0.8046875, \"training_loss\": 172.96109008789062, \"iteration\": 816, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 170.82444763183594, \"iteration\": 817, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 212.10401916503906, \"iteration\": 818, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 211.4718017578125, \"iteration\": 819, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 225.1222381591797, \"iteration\": 820, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 175.81561279296875, \"iteration\": 821, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 173.49017333984375, \"iteration\": 822, \"epoch\": 5}, {\"training_acc\": 0.8515625, \"training_loss\": 221.26002502441406, \"iteration\": 823, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 154.35400390625, \"iteration\": 824, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 168.2067413330078, \"iteration\": 825, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 166.591796875, \"iteration\": 826, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 218.00721740722656, \"iteration\": 827, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 199.69561767578125, \"iteration\": 828, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 246.2152099609375, \"iteration\": 829, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 161.90890502929688, \"iteration\": 830, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 211.06723022460938, \"iteration\": 831, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 225.8974609375, \"iteration\": 832, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 247.48028564453125, \"iteration\": 833, \"epoch\": 5}, {\"training_acc\": 0.859375, \"training_loss\": 211.45681762695312, \"iteration\": 834, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 170.35891723632812, \"iteration\": 835, \"epoch\": 5}, {\"training_acc\": 0.84375, \"training_loss\": 140.0472412109375, \"iteration\": 836, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 209.5593719482422, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 214.8750762939453, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 120.4056625366211, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 200.4778289794922, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 138.30349731445312, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 0.84375, \"training_loss\": 135.73300170898438, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 187.00830078125, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 190.63363647460938, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 200.14918518066406, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 189.03868103027344, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 186.28689575195312, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 194.8226318359375, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 201.3970947265625, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 225.86056518554688, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 214.98733520507812, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 162.8516845703125, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 156.17625427246094, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 185.58119201660156, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 164.92892456054688, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 179.27395629882812, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 235.41354370117188, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 183.78167724609375, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 198.99363708496094, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 173.6332550048828, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 199.2450408935547, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 175.62240600585938, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 156.54908752441406, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 151.19430541992188, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 174.8846435546875, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 193.83062744140625, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 190.7142333984375, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 209.7021942138672, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 214.3157958984375, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 215.70144653320312, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 0.8359375, \"training_loss\": 196.25643920898438, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 0.8046875, \"training_loss\": 163.76898193359375, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 0.8515625, \"training_loss\": 221.90545654296875, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 181.1136474609375, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 224.9019775390625, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 178.5111083984375, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 199.47140502929688, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 218.58267211914062, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 225.2763671875, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 205.86965942382812, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 181.88619995117188, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 199.88978576660156, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 190.03793334960938, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 207.87339782714844, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 189.78359985351562, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 152.52894592285156, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 187.45086669921875, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.8515625, \"training_loss\": 203.55950927734375, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 170.63796997070312, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 10.884570121765137, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 137.07559204101562, \"iteration\": 891, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 164.61279296875, \"iteration\": 892, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 192.65054321289062, \"iteration\": 893, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 223.6063995361328, \"iteration\": 894, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 163.2645263671875, \"iteration\": 895, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 163.6991729736328, \"iteration\": 896, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 169.25555419921875, \"iteration\": 897, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 233.31167602539062, \"iteration\": 898, \"epoch\": 6}, {\"training_acc\": 0.890625, \"training_loss\": 165.89474487304688, \"iteration\": 899, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 159.08041381835938, \"iteration\": 900, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 212.1663360595703, \"iteration\": 901, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 223.0614013671875, \"iteration\": 902, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 198.38818359375, \"iteration\": 903, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 173.1575469970703, \"iteration\": 904, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 194.0819091796875, \"iteration\": 905, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 222.8852996826172, \"iteration\": 906, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 243.06312561035156, \"iteration\": 907, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 202.03179931640625, \"iteration\": 908, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 201.833740234375, \"iteration\": 909, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 193.19424438476562, \"iteration\": 910, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 193.4921875, \"iteration\": 911, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 155.766357421875, \"iteration\": 912, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 179.88461303710938, \"iteration\": 913, \"epoch\": 6}, {\"training_acc\": 0.890625, \"training_loss\": 184.70162963867188, \"iteration\": 914, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 233.18496704101562, \"iteration\": 915, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 202.76712036132812, \"iteration\": 916, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 169.135498046875, \"iteration\": 917, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 178.38702392578125, \"iteration\": 918, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 170.9470977783203, \"iteration\": 919, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 232.4496612548828, \"iteration\": 920, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 185.03298950195312, \"iteration\": 921, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 159.69992065429688, \"iteration\": 922, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 203.39344787597656, \"iteration\": 923, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 173.57505798339844, \"iteration\": 924, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 194.44021606445312, \"iteration\": 925, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 198.64012145996094, \"iteration\": 926, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 203.50132751464844, \"iteration\": 927, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 214.66909790039062, \"iteration\": 928, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 187.8756103515625, \"iteration\": 929, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 207.91183471679688, \"iteration\": 930, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 180.10540771484375, \"iteration\": 931, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 232.067626953125, \"iteration\": 932, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 136.0876922607422, \"iteration\": 933, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 188.7325439453125, \"iteration\": 934, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 198.54116821289062, \"iteration\": 935, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 156.2715301513672, \"iteration\": 936, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 162.24916076660156, \"iteration\": 937, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 183.23870849609375, \"iteration\": 938, \"epoch\": 6}, {\"training_acc\": 0.8515625, \"training_loss\": 147.92892456054688, \"iteration\": 939, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 164.79864501953125, \"iteration\": 940, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 175.20469665527344, \"iteration\": 941, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 197.18211364746094, \"iteration\": 942, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 207.769775390625, \"iteration\": 943, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 214.84796142578125, \"iteration\": 944, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 194.20404052734375, \"iteration\": 945, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 118.62322998046875, \"iteration\": 946, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 194.36410522460938, \"iteration\": 947, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 200.11346435546875, \"iteration\": 948, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 192.4502410888672, \"iteration\": 949, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 163.93971252441406, \"iteration\": 950, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 149.4331817626953, \"iteration\": 951, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 163.69448852539062, \"iteration\": 952, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 183.09815979003906, \"iteration\": 953, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 223.4027099609375, \"iteration\": 954, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 178.70272827148438, \"iteration\": 955, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 173.69541931152344, \"iteration\": 956, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 209.01800537109375, \"iteration\": 957, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 165.09080505371094, \"iteration\": 958, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 203.6745147705078, \"iteration\": 959, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 193.6707763671875, \"iteration\": 960, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 218.202392578125, \"iteration\": 961, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 195.25779724121094, \"iteration\": 962, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 189.00582885742188, \"iteration\": 963, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 168.0714874267578, \"iteration\": 964, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 159.78919982910156, \"iteration\": 965, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 149.9578857421875, \"iteration\": 966, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 180.3947296142578, \"iteration\": 967, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 220.7420196533203, \"iteration\": 968, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 193.69320678710938, \"iteration\": 969, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 182.7223663330078, \"iteration\": 970, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 233.3639373779297, \"iteration\": 971, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 174.184814453125, \"iteration\": 972, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 188.39303588867188, \"iteration\": 973, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 169.46067810058594, \"iteration\": 974, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 189.00381469726562, \"iteration\": 975, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 193.71051025390625, \"iteration\": 976, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 208.39096069335938, \"iteration\": 977, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 197.24282836914062, \"iteration\": 978, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 173.54226684570312, \"iteration\": 979, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 217.28396606445312, \"iteration\": 980, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 175.04550170898438, \"iteration\": 981, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 188.767333984375, \"iteration\": 982, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 157.13601684570312, \"iteration\": 983, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 179.5738525390625, \"iteration\": 984, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 209.51246643066406, \"iteration\": 985, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 204.64540100097656, \"iteration\": 986, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 173.43731689453125, \"iteration\": 987, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 149.17938232421875, \"iteration\": 988, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 222.77748107910156, \"iteration\": 989, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 182.99636840820312, \"iteration\": 990, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 182.59494018554688, \"iteration\": 991, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 164.5670166015625, \"iteration\": 992, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 169.22232055664062, \"iteration\": 993, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 169.385498046875, \"iteration\": 994, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 203.45928955078125, \"iteration\": 995, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 203.62985229492188, \"iteration\": 996, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 178.11708068847656, \"iteration\": 997, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 187.78973388671875, \"iteration\": 998, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 163.3475341796875, \"iteration\": 999, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 173.5830535888672, \"iteration\": 1000, \"epoch\": 6}, {\"training_acc\": 0.8828125, \"training_loss\": 194.78807067871094, \"iteration\": 1001, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 187.65261840820312, \"iteration\": 1002, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 193.08917236328125, \"iteration\": 1003, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 198.61895751953125, \"iteration\": 1004, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 184.16748046875, \"iteration\": 1005, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 173.98512268066406, \"iteration\": 1006, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 198.25608825683594, \"iteration\": 1007, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 165.08184814453125, \"iteration\": 1008, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 193.31581115722656, \"iteration\": 1009, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 193.29763793945312, \"iteration\": 1010, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 154.9788055419922, \"iteration\": 1011, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 218.28477478027344, \"iteration\": 1012, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 170.60787963867188, \"iteration\": 1013, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 155.45892333984375, \"iteration\": 1014, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 178.99549865722656, \"iteration\": 1015, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 217.39166259765625, \"iteration\": 1016, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 146.0765838623047, \"iteration\": 1017, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 208.87484741210938, \"iteration\": 1018, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 202.24380493164062, \"iteration\": 1019, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 168.7757568359375, \"iteration\": 1020, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 189.35455322265625, \"iteration\": 1021, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 210.5804443359375, \"iteration\": 1022, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 238.26187133789062, \"iteration\": 1023, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 159.64559936523438, \"iteration\": 1024, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 164.87063598632812, \"iteration\": 1025, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 149.2851104736328, \"iteration\": 1026, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 192.93472290039062, \"iteration\": 1027, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 207.7122802734375, \"iteration\": 1028, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 164.26687622070312, \"iteration\": 1029, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 178.62191772460938, \"iteration\": 1030, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 160.3262481689453, \"iteration\": 1031, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 188.0923309326172, \"iteration\": 1032, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 238.46865844726562, \"iteration\": 1033, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 121.75790405273438, \"iteration\": 1034, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 202.30108642578125, \"iteration\": 1035, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 146.2378387451172, \"iteration\": 1036, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 218.26889038085938, \"iteration\": 1037, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 183.509033203125, \"iteration\": 1038, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 174.04583740234375, \"iteration\": 1039, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 155.17428588867188, \"iteration\": 1040, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 207.12205505371094, \"iteration\": 1041, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 199.94821166992188, \"iteration\": 1042, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 164.88650512695312, \"iteration\": 1043, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 166.8546142578125, \"iteration\": 1044, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 198.05691528320312, \"iteration\": 1045, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 193.5541534423828, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 193.91726684570312, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 197.67294311523438, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 140.81588745117188, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 207.73049926757812, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 187.90721130371094, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 188.80380249023438, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 167.78436279296875, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 192.44772338867188, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 223.3472137451172, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 135.49551391601562, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 196.95455932617188, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 169.2773895263672, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 159.9392547607422, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 198.50091552734375, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 188.30946350097656, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 184.18389892578125, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 202.77349853515625, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 158.83514404296875, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 189.13739013671875, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 188.91651916503906, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 154.7603759765625, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 19.885812759399414, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 196.77940368652344, \"iteration\": 1069, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 187.32785034179688, \"iteration\": 1070, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 196.91818237304688, \"iteration\": 1071, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 177.0576934814453, \"iteration\": 1072, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 172.77081298828125, \"iteration\": 1073, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 216.4109649658203, \"iteration\": 1074, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 134.3987579345703, \"iteration\": 1075, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 163.62217712402344, \"iteration\": 1076, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 158.13967895507812, \"iteration\": 1077, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 182.70028686523438, \"iteration\": 1078, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 221.5914306640625, \"iteration\": 1079, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 211.2032012939453, \"iteration\": 1080, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 186.46888732910156, \"iteration\": 1081, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 197.09759521484375, \"iteration\": 1082, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 206.47579956054688, \"iteration\": 1083, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 174.24484252929688, \"iteration\": 1084, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 172.3173828125, \"iteration\": 1085, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 217.33352661132812, \"iteration\": 1086, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 167.61911010742188, \"iteration\": 1087, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 167.53390502929688, \"iteration\": 1088, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 187.3403778076172, \"iteration\": 1089, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 177.74481201171875, \"iteration\": 1090, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 187.62977600097656, \"iteration\": 1091, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 172.9660186767578, \"iteration\": 1092, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 168.6226043701172, \"iteration\": 1093, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 139.073486328125, \"iteration\": 1094, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 144.3116455078125, \"iteration\": 1095, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 172.70545959472656, \"iteration\": 1096, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 201.38995361328125, \"iteration\": 1097, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 135.31988525390625, \"iteration\": 1098, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 196.83680725097656, \"iteration\": 1099, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 177.03189086914062, \"iteration\": 1100, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 212.95870971679688, \"iteration\": 1101, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 182.7608642578125, \"iteration\": 1102, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 172.24365234375, \"iteration\": 1103, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 153.33999633789062, \"iteration\": 1104, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 182.17263793945312, \"iteration\": 1105, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 172.88241577148438, \"iteration\": 1106, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 187.74111938476562, \"iteration\": 1107, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 212.1125946044922, \"iteration\": 1108, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 191.4739227294922, \"iteration\": 1109, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 191.77142333984375, \"iteration\": 1110, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 186.77084350585938, \"iteration\": 1111, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 167.60113525390625, \"iteration\": 1112, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 144.85174560546875, \"iteration\": 1113, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 172.53309631347656, \"iteration\": 1114, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 172.34336853027344, \"iteration\": 1115, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 167.64706420898438, \"iteration\": 1116, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 237.1807861328125, \"iteration\": 1117, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 126.06646728515625, \"iteration\": 1118, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 201.69432067871094, \"iteration\": 1119, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 201.65740966796875, \"iteration\": 1120, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 252.066650390625, \"iteration\": 1121, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 221.61936950683594, \"iteration\": 1122, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 197.2100830078125, \"iteration\": 1123, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 182.427001953125, \"iteration\": 1124, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 212.91232299804688, \"iteration\": 1125, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 153.34982299804688, \"iteration\": 1126, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 172.6485595703125, \"iteration\": 1127, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 196.88897705078125, \"iteration\": 1128, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 144.08331298828125, \"iteration\": 1129, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 206.66604614257812, \"iteration\": 1130, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 187.73251342773438, \"iteration\": 1131, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 162.56182861328125, \"iteration\": 1132, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 167.60179138183594, \"iteration\": 1133, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 207.16665649414062, \"iteration\": 1134, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 149.28704833984375, \"iteration\": 1135, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 212.12413024902344, \"iteration\": 1136, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 148.35426330566406, \"iteration\": 1137, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 176.89706420898438, \"iteration\": 1138, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 187.81442260742188, \"iteration\": 1139, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 176.87159729003906, \"iteration\": 1140, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 153.0216064453125, \"iteration\": 1141, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 218.7217559814453, \"iteration\": 1142, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 217.02499389648438, \"iteration\": 1143, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 186.4537353515625, \"iteration\": 1144, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 158.39515686035156, \"iteration\": 1145, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 162.53219604492188, \"iteration\": 1146, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 148.92886352539062, \"iteration\": 1147, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 192.39990234375, \"iteration\": 1148, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 162.4463653564453, \"iteration\": 1149, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 158.82632446289062, \"iteration\": 1150, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 237.03335571289062, \"iteration\": 1151, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 167.7683868408203, \"iteration\": 1152, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 178.48760986328125, \"iteration\": 1153, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 140.19329833984375, \"iteration\": 1154, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 236.27508544921875, \"iteration\": 1155, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 211.46945190429688, \"iteration\": 1156, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 231.71041870117188, \"iteration\": 1157, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 177.0995635986328, \"iteration\": 1158, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 163.31558227539062, \"iteration\": 1159, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 182.4872589111328, \"iteration\": 1160, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 192.75462341308594, \"iteration\": 1161, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 108.97357177734375, \"iteration\": 1162, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 186.4486541748047, \"iteration\": 1163, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 197.03253173828125, \"iteration\": 1164, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 193.31524658203125, \"iteration\": 1165, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 228.17196655273438, \"iteration\": 1166, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 197.05352783203125, \"iteration\": 1167, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 153.41961669921875, \"iteration\": 1168, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 167.73548889160156, \"iteration\": 1169, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 159.70233154296875, \"iteration\": 1170, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 183.8468017578125, \"iteration\": 1171, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 148.91006469726562, \"iteration\": 1172, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 217.09803771972656, \"iteration\": 1173, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 231.8839874267578, \"iteration\": 1174, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 207.51559448242188, \"iteration\": 1175, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 182.76351928710938, \"iteration\": 1176, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 186.70077514648438, \"iteration\": 1177, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 231.41571044921875, \"iteration\": 1178, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 177.19000244140625, \"iteration\": 1179, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 162.7082061767578, \"iteration\": 1180, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 178.40313720703125, \"iteration\": 1181, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 231.72023010253906, \"iteration\": 1182, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 237.05364990234375, \"iteration\": 1183, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 196.42575073242188, \"iteration\": 1184, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 191.59524536132812, \"iteration\": 1185, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 203.13824462890625, \"iteration\": 1186, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 172.29986572265625, \"iteration\": 1187, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 130.6125030517578, \"iteration\": 1188, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 158.21652221679688, \"iteration\": 1189, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 173.24859619140625, \"iteration\": 1190, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 187.04083251953125, \"iteration\": 1191, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 143.88986206054688, \"iteration\": 1192, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 206.8485107421875, \"iteration\": 1193, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 187.77487182617188, \"iteration\": 1194, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.449951171875, \"iteration\": 1195, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 134.04136657714844, \"iteration\": 1196, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 162.5157470703125, \"iteration\": 1197, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 233.0118408203125, \"iteration\": 1198, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 162.95816040039062, \"iteration\": 1199, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 187.0926513671875, \"iteration\": 1200, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 221.69265747070312, \"iteration\": 1201, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 182.1416015625, \"iteration\": 1202, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 169.07420349121094, \"iteration\": 1203, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 172.92359924316406, \"iteration\": 1204, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 143.74468994140625, \"iteration\": 1205, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 139.52734375, \"iteration\": 1206, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 236.52626037597656, \"iteration\": 1207, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 155.11361694335938, \"iteration\": 1208, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 172.21749877929688, \"iteration\": 1209, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 206.4090576171875, \"iteration\": 1210, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 177.36227416992188, \"iteration\": 1211, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 148.94491577148438, \"iteration\": 1212, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 173.01873779296875, \"iteration\": 1213, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 211.38648986816406, \"iteration\": 1214, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 202.68731689453125, \"iteration\": 1215, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 167.28921508789062, \"iteration\": 1216, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 203.33689880371094, \"iteration\": 1217, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 191.61289978027344, \"iteration\": 1218, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 172.1221160888672, \"iteration\": 1219, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 172.23886108398438, \"iteration\": 1220, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 178.0491485595703, \"iteration\": 1221, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 216.63504028320312, \"iteration\": 1222, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 221.8653564453125, \"iteration\": 1223, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 216.8762664794922, \"iteration\": 1224, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 172.59046936035156, \"iteration\": 1225, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 177.20883178710938, \"iteration\": 1226, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 177.46795654296875, \"iteration\": 1227, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 201.72694396972656, \"iteration\": 1228, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 187.3363037109375, \"iteration\": 1229, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 162.64036560058594, \"iteration\": 1230, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 191.83082580566406, \"iteration\": 1231, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 257.850830078125, \"iteration\": 1232, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 196.71075439453125, \"iteration\": 1233, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 196.7156524658203, \"iteration\": 1234, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 192.36175537109375, \"iteration\": 1235, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 167.68666076660156, \"iteration\": 1236, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 186.7736053466797, \"iteration\": 1237, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 163.0219268798828, \"iteration\": 1238, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 202.24740600585938, \"iteration\": 1239, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 201.6317138671875, \"iteration\": 1240, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 148.79595947265625, \"iteration\": 1241, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 211.71922302246094, \"iteration\": 1242, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 217.4718017578125, \"iteration\": 1243, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 172.98806762695312, \"iteration\": 1244, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 202.54962158203125, \"iteration\": 1245, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 10.767489433288574, \"iteration\": 1246, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 211.1297607421875, \"iteration\": 1247, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 162.64637756347656, \"iteration\": 1248, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 216.18145751953125, \"iteration\": 1249, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 216.13363647460938, \"iteration\": 1250, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 157.71054077148438, \"iteration\": 1251, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 196.30389404296875, \"iteration\": 1252, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 162.58004760742188, \"iteration\": 1253, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 171.92254638671875, \"iteration\": 1254, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 226.1049041748047, \"iteration\": 1255, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 202.10211181640625, \"iteration\": 1256, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 241.175048828125, \"iteration\": 1257, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 167.66757202148438, \"iteration\": 1258, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 181.4986114501953, \"iteration\": 1259, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 201.40707397460938, \"iteration\": 1260, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 211.051513671875, \"iteration\": 1261, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.92762756347656, \"iteration\": 1262, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 125.009765625, \"iteration\": 1263, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 201.1831512451172, \"iteration\": 1264, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 201.37869262695312, \"iteration\": 1265, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.94613647460938, \"iteration\": 1266, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.99578857421875, \"iteration\": 1267, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 191.0620574951172, \"iteration\": 1268, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 201.6752471923828, \"iteration\": 1269, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 201.18551635742188, \"iteration\": 1270, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 162.34945678710938, \"iteration\": 1271, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.64761352539062, \"iteration\": 1272, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.50399780273438, \"iteration\": 1273, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 261.74285888671875, \"iteration\": 1274, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 191.42691040039062, \"iteration\": 1275, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 138.535400390625, \"iteration\": 1276, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.89053344726562, \"iteration\": 1277, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 162.0979461669922, \"iteration\": 1278, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 181.5782012939453, \"iteration\": 1279, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 186.80523681640625, \"iteration\": 1280, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.2778778076172, \"iteration\": 1281, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 138.9305419921875, \"iteration\": 1282, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 158.0194091796875, \"iteration\": 1283, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 176.6669464111328, \"iteration\": 1284, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 162.65206909179688, \"iteration\": 1285, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 148.03720092773438, \"iteration\": 1286, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.21087646484375, \"iteration\": 1287, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 162.19046020507812, \"iteration\": 1288, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.83387756347656, \"iteration\": 1289, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 148.521728515625, \"iteration\": 1290, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 196.47872924804688, \"iteration\": 1291, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.98428344726562, \"iteration\": 1292, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 230.97576904296875, \"iteration\": 1293, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 171.8273468017578, \"iteration\": 1294, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.37200927734375, \"iteration\": 1295, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.89349365234375, \"iteration\": 1296, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 225.85870361328125, \"iteration\": 1297, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 177.044189453125, \"iteration\": 1298, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 177.48834228515625, \"iteration\": 1299, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 211.01620483398438, \"iteration\": 1300, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 200.991455078125, \"iteration\": 1301, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 195.96493530273438, \"iteration\": 1302, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 138.55120849609375, \"iteration\": 1303, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.288330078125, \"iteration\": 1304, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 235.92608642578125, \"iteration\": 1305, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.91604614257812, \"iteration\": 1306, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 220.7382354736328, \"iteration\": 1307, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 162.28671264648438, \"iteration\": 1308, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 256.4912414550781, \"iteration\": 1309, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 172.20950317382812, \"iteration\": 1310, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 215.84359741210938, \"iteration\": 1311, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 171.885009765625, \"iteration\": 1312, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.38473510742188, \"iteration\": 1313, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 153.0108642578125, \"iteration\": 1314, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 157.71487426757812, \"iteration\": 1315, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 167.14158630371094, \"iteration\": 1316, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 152.6723175048828, \"iteration\": 1317, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.33197021484375, \"iteration\": 1318, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 220.72923278808594, \"iteration\": 1319, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 191.05160522460938, \"iteration\": 1320, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 152.6986846923828, \"iteration\": 1321, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 181.3990020751953, \"iteration\": 1322, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.20420837402344, \"iteration\": 1323, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 206.59642028808594, \"iteration\": 1324, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 231.07379150390625, \"iteration\": 1325, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.71060180664062, \"iteration\": 1326, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 196.20956420898438, \"iteration\": 1327, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 215.83334350585938, \"iteration\": 1328, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 162.51992797851562, \"iteration\": 1329, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 186.41831970214844, \"iteration\": 1330, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 148.0958251953125, \"iteration\": 1331, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 210.85012817382812, \"iteration\": 1332, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.8075408935547, \"iteration\": 1333, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 191.29037475585938, \"iteration\": 1334, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 201.4062042236328, \"iteration\": 1335, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 129.3658447265625, \"iteration\": 1336, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 191.23291015625, \"iteration\": 1337, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 181.33544921875, \"iteration\": 1338, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 167.19720458984375, \"iteration\": 1339, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.55247497558594, \"iteration\": 1340, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 177.1600799560547, \"iteration\": 1341, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 205.74972534179688, \"iteration\": 1342, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 157.85560607910156, \"iteration\": 1343, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 148.01870727539062, \"iteration\": 1344, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 152.62274169921875, \"iteration\": 1345, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 181.33065795898438, \"iteration\": 1346, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 201.9964599609375, \"iteration\": 1347, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 210.7928466796875, \"iteration\": 1348, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.82244873046875, \"iteration\": 1349, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 153.3340606689453, \"iteration\": 1350, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 176.80789184570312, \"iteration\": 1351, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.68255615234375, \"iteration\": 1352, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 216.07266235351562, \"iteration\": 1353, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 177.0784912109375, \"iteration\": 1354, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 152.97348022460938, \"iteration\": 1355, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 211.18356323242188, \"iteration\": 1356, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 181.627197265625, \"iteration\": 1357, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 143.517822265625, \"iteration\": 1358, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.91207885742188, \"iteration\": 1359, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 172.16004943847656, \"iteration\": 1360, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.92547607421875, \"iteration\": 1361, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 186.73477172851562, \"iteration\": 1362, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 220.9175567626953, \"iteration\": 1363, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 143.37527465820312, \"iteration\": 1364, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 225.95703125, \"iteration\": 1365, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 176.79403686523438, \"iteration\": 1366, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.46095275878906, \"iteration\": 1367, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 201.08973693847656, \"iteration\": 1368, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 187.1820831298828, \"iteration\": 1369, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 201.42648315429688, \"iteration\": 1370, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 196.01278686523438, \"iteration\": 1371, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 186.93862915039062, \"iteration\": 1372, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 152.58242797851562, \"iteration\": 1373, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 143.35369873046875, \"iteration\": 1374, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 152.7337646484375, \"iteration\": 1375, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 148.20008850097656, \"iteration\": 1376, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 216.27210998535156, \"iteration\": 1377, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.75994873046875, \"iteration\": 1378, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.21951293945312, \"iteration\": 1379, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.7803192138672, \"iteration\": 1380, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.46298217773438, \"iteration\": 1381, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 182.0446319580078, \"iteration\": 1382, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 171.9565887451172, \"iteration\": 1383, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 186.4175262451172, \"iteration\": 1384, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.85183715820312, \"iteration\": 1385, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.37142944335938, \"iteration\": 1386, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 196.0963592529297, \"iteration\": 1387, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 162.06600952148438, \"iteration\": 1388, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 200.9237060546875, \"iteration\": 1389, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.84564208984375, \"iteration\": 1390, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.38229370117188, \"iteration\": 1391, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.354248046875, \"iteration\": 1392, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 201.0508575439453, \"iteration\": 1393, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 177.16854858398438, \"iteration\": 1394, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.72518920898438, \"iteration\": 1395, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 186.21951293945312, \"iteration\": 1396, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 129.55845642089844, \"iteration\": 1397, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 220.98052978515625, \"iteration\": 1398, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 147.83985900878906, \"iteration\": 1399, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 201.14010620117188, \"iteration\": 1400, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 196.03558349609375, \"iteration\": 1401, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 206.62611389160156, \"iteration\": 1402, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 225.875244140625, \"iteration\": 1403, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 201.23382568359375, \"iteration\": 1404, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.05043029785156, \"iteration\": 1405, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.86114501953125, \"iteration\": 1406, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 143.162353515625, \"iteration\": 1407, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 148.08267211914062, \"iteration\": 1408, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 166.83168029785156, \"iteration\": 1409, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 143.42584228515625, \"iteration\": 1410, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 201.1602783203125, \"iteration\": 1411, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 186.763916015625, \"iteration\": 1412, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 166.80746459960938, \"iteration\": 1413, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 177.24232482910156, \"iteration\": 1414, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 162.07290649414062, \"iteration\": 1415, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.82113647460938, \"iteration\": 1416, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 124.76898193359375, \"iteration\": 1417, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 152.8803253173828, \"iteration\": 1418, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 157.7464599609375, \"iteration\": 1419, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 120.15235137939453, \"iteration\": 1420, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.853515625, \"iteration\": 1421, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 167.02561950683594, \"iteration\": 1422, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.99948120117188, \"iteration\": 1423, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.123554229736328, \"iteration\": 1424, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.69131469726562, \"iteration\": 1425, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 161.98019409179688, \"iteration\": 1426, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.47113037109375, \"iteration\": 1427, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.0125732421875, \"iteration\": 1428, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.51263427734375, \"iteration\": 1429, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 133.87269592285156, \"iteration\": 1430, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.61349487304688, \"iteration\": 1431, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 210.80209350585938, \"iteration\": 1432, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 181.42433166503906, \"iteration\": 1433, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.80252075195312, \"iteration\": 1434, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.7862854003906, \"iteration\": 1435, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 97.91181945800781, \"iteration\": 1436, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.7918243408203, \"iteration\": 1437, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.6009979248047, \"iteration\": 1438, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.72332763671875, \"iteration\": 1439, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 186.21435546875, \"iteration\": 1440, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.7266845703125, \"iteration\": 1441, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 230.7359619140625, \"iteration\": 1442, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 162.22555541992188, \"iteration\": 1443, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 206.08761596679688, \"iteration\": 1444, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.05020141601562, \"iteration\": 1445, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 147.68104553222656, \"iteration\": 1446, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.47378540039062, \"iteration\": 1447, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.23741149902344, \"iteration\": 1448, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.8283233642578, \"iteration\": 1449, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.55242919921875, \"iteration\": 1450, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 138.7041473388672, \"iteration\": 1451, \"epoch\": 9}, {\"training_acc\": 0.984375, \"training_loss\": 210.82095336914062, \"iteration\": 1452, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.36158752441406, \"iteration\": 1453, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.85452270507812, \"iteration\": 1454, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 152.67782592773438, \"iteration\": 1455, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.61007690429688, \"iteration\": 1456, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 124.89067077636719, \"iteration\": 1457, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.162353515625, \"iteration\": 1458, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 166.9412841796875, \"iteration\": 1459, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.82962036132812, \"iteration\": 1460, \"epoch\": 9}, {\"training_acc\": 0.984375, \"training_loss\": 176.87493896484375, \"iteration\": 1461, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.4236602783203, \"iteration\": 1462, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 133.72763061523438, \"iteration\": 1463, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 152.51817321777344, \"iteration\": 1464, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.8321533203125, \"iteration\": 1465, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.64453125, \"iteration\": 1466, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.23556518554688, \"iteration\": 1467, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 230.97314453125, \"iteration\": 1468, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 185.94778442382812, \"iteration\": 1469, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 115.58898162841797, \"iteration\": 1470, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.90216064453125, \"iteration\": 1471, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.22882080078125, \"iteration\": 1472, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.67678833007812, \"iteration\": 1473, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 143.08956909179688, \"iteration\": 1474, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 210.63682556152344, \"iteration\": 1475, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.09539794921875, \"iteration\": 1476, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.04180908203125, \"iteration\": 1477, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 147.7320098876953, \"iteration\": 1478, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.59228515625, \"iteration\": 1479, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.34820556640625, \"iteration\": 1480, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.73049926757812, \"iteration\": 1481, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.58621215820312, \"iteration\": 1482, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 230.89877319335938, \"iteration\": 1483, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.69888305664062, \"iteration\": 1484, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.30593872070312, \"iteration\": 1485, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.69259643554688, \"iteration\": 1486, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.1622772216797, \"iteration\": 1487, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.89857482910156, \"iteration\": 1488, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 171.5927276611328, \"iteration\": 1489, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.12548828125, \"iteration\": 1490, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.53109741210938, \"iteration\": 1491, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 230.78359985351562, \"iteration\": 1492, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.37588500976562, \"iteration\": 1493, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.22044372558594, \"iteration\": 1494, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.11083984375, \"iteration\": 1495, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 143.14236450195312, \"iteration\": 1496, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.07916259765625, \"iteration\": 1497, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 147.94232177734375, \"iteration\": 1498, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.6005859375, \"iteration\": 1499, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 186.1375732421875, \"iteration\": 1500, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 129.40965270996094, \"iteration\": 1501, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 195.9068603515625, \"iteration\": 1502, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.28529357910156, \"iteration\": 1503, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 186.14776611328125, \"iteration\": 1504, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 161.97314453125, \"iteration\": 1505, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.4681396484375, \"iteration\": 1506, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.98585510253906, \"iteration\": 1507, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.38653564453125, \"iteration\": 1508, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.87130737304688, \"iteration\": 1509, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.56918334960938, \"iteration\": 1510, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 143.00704956054688, \"iteration\": 1511, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 161.8842010498047, \"iteration\": 1512, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 133.7410888671875, \"iteration\": 1513, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 210.61993408203125, \"iteration\": 1514, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 171.65753173828125, \"iteration\": 1515, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 195.98760986328125, \"iteration\": 1516, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.73526000976562, \"iteration\": 1517, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.4268798828125, \"iteration\": 1518, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 185.96914672851562, \"iteration\": 1519, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.28292846679688, \"iteration\": 1520, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 134.0631103515625, \"iteration\": 1521, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 215.76513671875, \"iteration\": 1522, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.58706665039062, \"iteration\": 1523, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.9443817138672, \"iteration\": 1524, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 195.98171997070312, \"iteration\": 1525, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 246.11587524414062, \"iteration\": 1526, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.14013671875, \"iteration\": 1527, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.10891723632812, \"iteration\": 1528, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.6845703125, \"iteration\": 1529, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.0821533203125, \"iteration\": 1530, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.57876586914062, \"iteration\": 1531, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.29116821289062, \"iteration\": 1532, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 195.79019165039062, \"iteration\": 1533, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 266.3123779296875, \"iteration\": 1534, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.05633544921875, \"iteration\": 1535, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 185.95176696777344, \"iteration\": 1536, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.96868896484375, \"iteration\": 1537, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.73265075683594, \"iteration\": 1538, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 161.86154174804688, \"iteration\": 1539, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.9709014892578, \"iteration\": 1540, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.59371948242188, \"iteration\": 1541, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 185.97073364257812, \"iteration\": 1542, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 133.79150390625, \"iteration\": 1543, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 161.93707275390625, \"iteration\": 1544, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.702392578125, \"iteration\": 1545, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 152.43849182128906, \"iteration\": 1546, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 111.01007080078125, \"iteration\": 1547, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 230.59693908691406, \"iteration\": 1548, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 138.5558319091797, \"iteration\": 1549, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 161.866943359375, \"iteration\": 1550, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 133.79908752441406, \"iteration\": 1551, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.08456420898438, \"iteration\": 1552, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.62689208984375, \"iteration\": 1553, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.93679809570312, \"iteration\": 1554, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.70098876953125, \"iteration\": 1555, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.09365844726562, \"iteration\": 1556, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.2762451171875, \"iteration\": 1557, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 143.01364135742188, \"iteration\": 1558, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.5408935546875, \"iteration\": 1559, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.5392303466797, \"iteration\": 1560, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 195.7790069580078, \"iteration\": 1561, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 230.5908966064453, \"iteration\": 1562, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.76849365234375, \"iteration\": 1563, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 161.8175048828125, \"iteration\": 1564, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.07077026367188, \"iteration\": 1565, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.76109313964844, \"iteration\": 1566, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.861328125, \"iteration\": 1567, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.21377563476562, \"iteration\": 1568, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 143.00799560546875, \"iteration\": 1569, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 210.51898193359375, \"iteration\": 1570, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.19155883789062, \"iteration\": 1571, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.70562744140625, \"iteration\": 1572, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 196.36117553710938, \"iteration\": 1573, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 210.64056396484375, \"iteration\": 1574, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.63926696777344, \"iteration\": 1575, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 276.6767883300781, \"iteration\": 1576, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.09771728515625, \"iteration\": 1577, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 162.0988006591797, \"iteration\": 1578, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 195.80975341796875, \"iteration\": 1579, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 152.42825317382812, \"iteration\": 1580, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.58261108398438, \"iteration\": 1581, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.00765991210938, \"iteration\": 1582, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.48574829101562, \"iteration\": 1583, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.23175048828125, \"iteration\": 1584, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.85198974609375, \"iteration\": 1585, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 143.21664428710938, \"iteration\": 1586, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.6833038330078, \"iteration\": 1587, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 129.12876892089844, \"iteration\": 1588, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.36854553222656, \"iteration\": 1589, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.10446166992188, \"iteration\": 1590, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 210.7753143310547, \"iteration\": 1591, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.24485778808594, \"iteration\": 1592, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.6910400390625, \"iteration\": 1593, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.18780517578125, \"iteration\": 1594, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.84246826171875, \"iteration\": 1595, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 147.81439208984375, \"iteration\": 1596, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.69338989257812, \"iteration\": 1597, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.0740966796875, \"iteration\": 1598, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.18002319335938, \"iteration\": 1599, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.61265563964844, \"iteration\": 1600, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 220.92422485351562, \"iteration\": 1601, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 10.775240898132324, \"iteration\": 1602, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 195.71780395507812, \"iteration\": 1603, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.58969116210938, \"iteration\": 1604, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.94708251953125, \"iteration\": 1605, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.59413146972656, \"iteration\": 1606, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.510498046875, \"iteration\": 1607, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.76431274414062, \"iteration\": 1608, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.19583129882812, \"iteration\": 1609, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 152.3797149658203, \"iteration\": 1610, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.20367431640625, \"iteration\": 1611, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 142.9556121826172, \"iteration\": 1612, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.79946899414062, \"iteration\": 1613, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.53720092773438, \"iteration\": 1614, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.10910034179688, \"iteration\": 1615, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.80410766601562, \"iteration\": 1616, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.10003662109375, \"iteration\": 1617, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.28590393066406, \"iteration\": 1618, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.90855407714844, \"iteration\": 1619, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 142.97857666015625, \"iteration\": 1620, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.86276245117188, \"iteration\": 1621, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.506103515625, \"iteration\": 1622, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.92922973632812, \"iteration\": 1623, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.63275146484375, \"iteration\": 1624, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.78396606445312, \"iteration\": 1625, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 210.67210388183594, \"iteration\": 1626, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.04031372070312, \"iteration\": 1627, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 133.724365234375, \"iteration\": 1628, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 210.51071166992188, \"iteration\": 1629, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 142.96209716796875, \"iteration\": 1630, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.1094207763672, \"iteration\": 1631, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 195.900634765625, \"iteration\": 1632, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 161.8507537841797, \"iteration\": 1633, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 147.8306121826172, \"iteration\": 1634, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.1742706298828, \"iteration\": 1635, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.4887237548828, \"iteration\": 1636, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.6417999267578, \"iteration\": 1637, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.278076171875, \"iteration\": 1638, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.6715087890625, \"iteration\": 1639, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 133.83767700195312, \"iteration\": 1640, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.46139526367188, \"iteration\": 1641, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.87728881835938, \"iteration\": 1642, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.08641052246094, \"iteration\": 1643, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 171.45419311523438, \"iteration\": 1644, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.2125244140625, \"iteration\": 1645, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 235.5675048828125, \"iteration\": 1646, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.0126495361328, \"iteration\": 1647, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 195.67984008789062, \"iteration\": 1648, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.56561279296875, \"iteration\": 1649, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.79928588867188, \"iteration\": 1650, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 147.6136474609375, \"iteration\": 1651, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.60305786132812, \"iteration\": 1652, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.90878295898438, \"iteration\": 1653, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.77481079101562, \"iteration\": 1654, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.5175018310547, \"iteration\": 1655, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.95675659179688, \"iteration\": 1656, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.24813842773438, \"iteration\": 1657, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.54150390625, \"iteration\": 1658, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.88848876953125, \"iteration\": 1659, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 195.71951293945312, \"iteration\": 1660, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.14955139160156, \"iteration\": 1661, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.97640991210938, \"iteration\": 1662, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.557373046875, \"iteration\": 1663, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 171.4054412841797, \"iteration\": 1664, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.20028686523438, \"iteration\": 1665, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 138.33489990234375, \"iteration\": 1666, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.46914672851562, \"iteration\": 1667, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 195.7247314453125, \"iteration\": 1668, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 147.90721130371094, \"iteration\": 1669, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.03396606445312, \"iteration\": 1670, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 171.36585998535156, \"iteration\": 1671, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.51564025878906, \"iteration\": 1672, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.19537353515625, \"iteration\": 1673, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.5774688720703, \"iteration\": 1674, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.5915985107422, \"iteration\": 1675, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.58175659179688, \"iteration\": 1676, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.46690368652344, \"iteration\": 1677, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.51072692871094, \"iteration\": 1678, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.57789611816406, \"iteration\": 1679, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.03256225585938, \"iteration\": 1680, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 180.99490356445312, \"iteration\": 1681, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 138.3978729248047, \"iteration\": 1682, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 171.39019775390625, \"iteration\": 1683, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.63339233398438, \"iteration\": 1684, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 152.31407165527344, \"iteration\": 1685, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.16244506835938, \"iteration\": 1686, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 142.960693359375, \"iteration\": 1687, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.85757446289062, \"iteration\": 1688, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.84799194335938, \"iteration\": 1689, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 147.62026977539062, \"iteration\": 1690, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.48577880859375, \"iteration\": 1691, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.7698516845703, \"iteration\": 1692, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.77969360351562, \"iteration\": 1693, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.58511352539062, \"iteration\": 1694, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.60348510742188, \"iteration\": 1695, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 129.07666015625, \"iteration\": 1696, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.75332641601562, \"iteration\": 1697, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.5496368408203, \"iteration\": 1698, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.06402587890625, \"iteration\": 1699, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 180.99697875976562, \"iteration\": 1700, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.55523681640625, \"iteration\": 1701, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.51559448242188, \"iteration\": 1702, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.04861450195312, \"iteration\": 1703, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.55967712402344, \"iteration\": 1704, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 195.63352966308594, \"iteration\": 1705, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.93142700195312, \"iteration\": 1706, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.03326416015625, \"iteration\": 1707, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 171.35308837890625, \"iteration\": 1708, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 152.36245727539062, \"iteration\": 1709, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.55313110351562, \"iteration\": 1710, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 138.3596649169922, \"iteration\": 1711, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.55673217773438, \"iteration\": 1712, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 230.50791931152344, \"iteration\": 1713, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.89923095703125, \"iteration\": 1714, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.52999877929688, \"iteration\": 1715, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.75933837890625, \"iteration\": 1716, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.5270538330078, \"iteration\": 1717, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 152.2877960205078, \"iteration\": 1718, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.519287109375, \"iteration\": 1719, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.5570831298828, \"iteration\": 1720, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.19918823242188, \"iteration\": 1721, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.62332153320312, \"iteration\": 1722, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.4862060546875, \"iteration\": 1723, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.79380798339844, \"iteration\": 1724, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.7742919921875, \"iteration\": 1725, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.0800018310547, \"iteration\": 1726, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.02984619140625, \"iteration\": 1727, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 129.20887756347656, \"iteration\": 1728, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.6617889404297, \"iteration\": 1729, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 147.68829345703125, \"iteration\": 1730, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.66851806640625, \"iteration\": 1731, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.02694702148438, \"iteration\": 1732, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.9472198486328, \"iteration\": 1733, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.67190551757812, \"iteration\": 1734, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 195.83172607421875, \"iteration\": 1735, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.50033569335938, \"iteration\": 1736, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 171.34042358398438, \"iteration\": 1737, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.59518432617188, \"iteration\": 1738, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.60867309570312, \"iteration\": 1739, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.54298400878906, \"iteration\": 1740, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.48403930664062, \"iteration\": 1741, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.65597534179688, \"iteration\": 1742, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 210.5254669189453, \"iteration\": 1743, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.06924438476562, \"iteration\": 1744, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 133.73455810546875, \"iteration\": 1745, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 142.97889709472656, \"iteration\": 1746, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 195.7427520751953, \"iteration\": 1747, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 171.34844970703125, \"iteration\": 1748, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 143.0270538330078, \"iteration\": 1749, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.62863159179688, \"iteration\": 1750, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 210.633544921875, \"iteration\": 1751, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.52825927734375, \"iteration\": 1752, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.0554656982422, \"iteration\": 1753, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.10292053222656, \"iteration\": 1754, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 161.8211669921875, \"iteration\": 1755, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 142.9901123046875, \"iteration\": 1756, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.51104736328125, \"iteration\": 1757, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.202880859375, \"iteration\": 1758, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.85205078125, \"iteration\": 1759, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.27345275878906, \"iteration\": 1760, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 161.86788940429688, \"iteration\": 1761, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.55349731445312, \"iteration\": 1762, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.62457275390625, \"iteration\": 1763, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.15052795410156, \"iteration\": 1764, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 210.5009002685547, \"iteration\": 1765, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.49453735351562, \"iteration\": 1766, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.6686248779297, \"iteration\": 1767, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.1915283203125, \"iteration\": 1768, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 185.87460327148438, \"iteration\": 1769, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.17141723632812, \"iteration\": 1770, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.62001037597656, \"iteration\": 1771, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 119.93782806396484, \"iteration\": 1772, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 147.63531494140625, \"iteration\": 1773, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.55133056640625, \"iteration\": 1774, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.02870178222656, \"iteration\": 1775, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.76657104492188, \"iteration\": 1776, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.59347534179688, \"iteration\": 1777, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.7842559814453, \"iteration\": 1778, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 245.7317352294922, \"iteration\": 1779, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 13.623488426208496, \"iteration\": 1780, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_nn_threshold = NeuralNetwork(\n",
    "    input_size=len(train_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    positive_pred_threshold=0.2,  # makes it easier to predict positive\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "if Path('models/model_nn_threshold.pt').exists() and USE_CACHE:\n",
    "    model_nn_threshold = load_model(model_nn_threshold, 'model_nn_threshold')\n",
    "else:\n",
    "    model_nn_threshold.fit(train_dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn_threshold, \"model_nn_threshold\")\n",
    "\n",
    "model_nn_threshold_results = evaluate_nn_model(model_nn_threshold, test_dataset)\n",
    "np.save('models/model_nn_threshold_results.npy', model_nn_threshold_results)\n",
    "print(model_nn_threshold_results)\n",
    "\n",
    "model_nn_threshold.cpu()\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn_threshold, train_config, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 178/178 [00:02<00:00, 66.54batch/s, batch_accuracy=0.688, loss=11.3]\n",
      "Epoch 2: 100%|██████████| 178/178 [00:02<00:00, 67.39batch/s, batch_accuracy=0.938, loss=12.7]\n",
      "Epoch 3: 100%|██████████| 178/178 [00:02<00:00, 64.77batch/s, batch_accuracy=1, loss=14.6]   \n",
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 65.31batch/s, batch_accuracy=1, loss=20]     \n",
      "Epoch 5: 100%|██████████| 178/178 [00:02<00:00, 65.27batch/s, batch_accuracy=1, loss=13.8]   \n",
      "Epoch 6: 100%|██████████| 178/178 [00:02<00:00, 61.22batch/s, batch_accuracy=1, loss=8.22]   \n",
      "Epoch 7: 100%|██████████| 178/178 [00:03<00:00, 54.27batch/s, batch_accuracy=1, loss=10.8]   \n",
      "Epoch 8: 100%|██████████| 178/178 [00:02<00:00, 62.36batch/s, batch_accuracy=1, loss=16.6]   \n",
      "Epoch 9: 100%|██████████| 178/178 [00:02<00:00, 67.46batch/s, batch_accuracy=1, loss=13.7]   \n",
      "Epoch 10: 100%|██████████| 178/178 [00:02<00:00, 64.77batch/s, batch_accuracy=1, loss=5.56]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7474623918533325, 0.5939452052116394, 0.6314176321029663, 0.4405110278056852)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-df916e5e17be4c0b83146d23d0a26fad.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-df916e5e17be4c0b83146d23d0a26fad.vega-embed details,\n",
       "  #altair-viz-df916e5e17be4c0b83146d23d0a26fad.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-df916e5e17be4c0b83146d23d0a26fad\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-df916e5e17be4c0b83146d23d0a26fad\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-df916e5e17be4c0b83146d23d0a26fad\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-a81b4ee475a15a06ed849002649090f3\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-a81b4ee475a15a06ed849002649090f3\": [{\"training_acc\": 0.3984375, \"training_loss\": 247.45220947265625, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.3203125, \"training_loss\": 198.84341430664062, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.3984375, \"training_loss\": 247.35311889648438, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.390625, \"training_loss\": 227.814453125, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 261.6947021484375, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 227.55760192871094, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 232.35484313964844, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 183.56979370117188, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 246.12930297851562, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 226.98593139648438, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 226.6609344482422, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 201.90916442871094, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 216.1228485107422, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 206.4394989013672, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 264.06005859375, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 228.89320373535156, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 210.75616455078125, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 176.26202392578125, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 232.70431518554688, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 251.91787719726562, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 280.95263671875, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 207.38433837890625, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 239.75856018066406, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 259.03778076171875, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 212.69522094726562, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 215.60018920898438, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 183.00357055664062, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 234.93045043945312, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 246.1470947265625, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 193.74105834960938, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 230.09361267089844, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 205.0341796875, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 200.19711303710938, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 232.68792724609375, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 218.1036376953125, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 252.77723693847656, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 219.95196533203125, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 217.22637939453125, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 235.120849609375, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 178.5330810546875, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 264.32965087890625, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 255.604736328125, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 183.7808074951172, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 231.9169158935547, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 264.33367919921875, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 211.23580932617188, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 211.89492797851562, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 266.630126953125, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 231.89370727539062, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 241.2701873779297, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 216.35467529296875, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 215.67330932617188, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 278.32086181640625, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 228.3409423828125, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 222.15386962890625, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 250.5865936279297, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 211.0645751953125, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 232.139892578125, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 198.50074768066406, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 203.20811462402344, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 215.66563415527344, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 177.53883361816406, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 193.14085388183594, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 227.5024871826172, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 276.2989501953125, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 222.5875244140625, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 231.3194122314453, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 215.08233642578125, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 198.4893341064453, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 219.7986602783203, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 227.29226684570312, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 226.65078735351562, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 250.96011352539062, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 198.921875, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 223.04495239257812, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 187.18048095703125, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 196.54559326171875, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 189.27072143554688, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 205.60215759277344, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 197.7126007080078, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 219.19480895996094, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 224.40841674804688, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 208.00538635253906, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 218.7118682861328, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 213.1149139404297, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 209.83493041992188, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 218.959716796875, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 167.23458862304688, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 266.18463134765625, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 198.23895263671875, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 216.9338836669922, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 266.41937255859375, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 208.97604370117188, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 213.9901123046875, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 241.22572326660156, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 216.29330444335938, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 178.57235717773438, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 274.9466247558594, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 230.99984741210938, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 202.42138671875, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 196.18954467773438, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 195.5489501953125, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 217.14344787597656, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 172.0696258544922, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 221.48526000976562, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 233.6304931640625, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 197.52517700195312, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 237.83457946777344, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 154.0521697998047, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 239.92791748046875, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 184.412353515625, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 196.42527770996094, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 227.4491729736328, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 234.7957305908203, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 188.4998016357422, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 180.3206329345703, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 228.59933471679688, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 134.60333251953125, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 188.49505615234375, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 209.53167724609375, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 204.34323120117188, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 187.0865478515625, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 192.44418334960938, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 191.11569213867188, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 218.27337646484375, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 156.60865783691406, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 170.56503295898438, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 196.85935974121094, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 192.579833984375, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 224.6844024658203, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 285.79278564453125, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 211.77980041503906, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 231.37478637695312, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 199.66845703125, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 213.46426391601562, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 181.48367309570312, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 209.673095703125, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 184.279296875, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 241.99325561523438, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 213.98141479492188, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 223.78610229492188, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 251.11952209472656, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 252.79959106445312, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 213.8476104736328, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 215.68960571289062, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 234.9173583984375, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 243.86463928222656, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 244.00875854492188, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 181.70626831054688, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 195.73300170898438, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 215.52743530273438, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 231.17584228515625, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 185.98959350585938, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 226.88967895507812, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 195.0044708251953, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 206.8090057373047, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 216.26229858398438, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 245.9398956298828, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 205.76296997070312, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 225.37158203125, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 165.49099731445312, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 203.07171630859375, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 186.15997314453125, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 194.80267333984375, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 266.08251953125, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 208.97286987304688, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 266.4716796875, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 212.6984100341797, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 214.67970275878906, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 211.47283935546875, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 231.551513671875, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 199.92337036132812, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 189.44268798828125, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 276.9862060546875, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 218.65830993652344, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 265.6720275878906, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 206.1439208984375, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 11.267038345336914, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 201.74749755859375, \"iteration\": 179, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 218.06236267089844, \"iteration\": 180, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 218.9427490234375, \"iteration\": 181, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 186.30050659179688, \"iteration\": 182, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 184.69488525390625, \"iteration\": 183, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 206.8450469970703, \"iteration\": 184, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 232.17510986328125, \"iteration\": 185, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 201.3667755126953, \"iteration\": 186, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 215.21658325195312, \"iteration\": 187, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 256.99652099609375, \"iteration\": 188, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 218.99957275390625, \"iteration\": 189, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 216.9027099609375, \"iteration\": 190, \"epoch\": 2}, {\"training_acc\": 0.6875, \"training_loss\": 234.81507873535156, \"iteration\": 191, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 228.25405883789062, \"iteration\": 192, \"epoch\": 2}, {\"training_acc\": 0.65625, \"training_loss\": 224.0926055908203, \"iteration\": 193, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 175.61666870117188, \"iteration\": 194, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 201.10498046875, \"iteration\": 195, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 193.86953735351562, \"iteration\": 196, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 207.709228515625, \"iteration\": 197, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 251.13543701171875, \"iteration\": 198, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 184.44952392578125, \"iteration\": 199, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 194.7578125, \"iteration\": 200, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 267.8472900390625, \"iteration\": 201, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 191.45867919921875, \"iteration\": 202, \"epoch\": 2}, {\"training_acc\": 0.671875, \"training_loss\": 166.9633331298828, \"iteration\": 203, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 203.21942138671875, \"iteration\": 204, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 158.8304443359375, \"iteration\": 205, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 248.0331268310547, \"iteration\": 206, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 256.3660888671875, \"iteration\": 207, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 213.41036987304688, \"iteration\": 208, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 188.37844848632812, \"iteration\": 209, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 220.94229125976562, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 178.30508422851562, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 205.97915649414062, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 209.70623779296875, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 255.79080200195312, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 174.0318603515625, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 214.1256561279297, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 180.8218994140625, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 233.43141174316406, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 244.004638671875, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 164.40411376953125, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 174.2767333984375, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 180.5113525390625, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 195.58706665039062, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 185.27427673339844, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 206.69107055664062, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 214.18141174316406, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 164.00990295410156, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 206.58590698242188, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 240.02273559570312, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 195.20700073242188, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 152.5312042236328, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 262.2283020019531, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 234.193603515625, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 183.8958740234375, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 146.616943359375, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 213.14120483398438, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 218.56057739257812, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 210.24923706054688, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 202.7107696533203, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 200.380859375, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 250.00616455078125, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 217.20828247070312, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 235.68716430664062, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 169.30978393554688, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 155.95870971679688, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 187.07290649414062, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 186.16140747070312, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 191.3468017578125, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 218.8450927734375, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 241.84600830078125, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 210.4464569091797, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 188.9969024658203, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 165.9397735595703, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 227.29776000976562, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 236.65072631835938, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 202.87374877929688, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 200.0177001953125, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 202.85479736328125, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 173.55950927734375, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 170.57810974121094, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 210.0248565673828, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 253.32691955566406, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 234.28506469726562, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 223.07846069335938, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 204.49700927734375, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 226.74163818359375, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 212.43728637695312, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.703125, \"training_loss\": 187.18106079101562, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 213.11871337890625, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 147.0841522216797, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 188.89268493652344, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 203.7309112548828, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 178.72512817382812, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 207.06309509277344, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 244.09471130371094, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 206.69442749023438, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 208.61602783203125, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 196.03536987304688, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 244.71884155273438, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 185.933349609375, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 214.59185791015625, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 198.23233032226562, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 176.20779418945312, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 211.66043090820312, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 203.86253356933594, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 170.03497314453125, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 198.4849853515625, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 201.8070526123047, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 152.04287719726562, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 237.2529754638672, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 187.55630493164062, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 158.515625, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 196.42474365234375, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 218.9311981201172, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.703125, \"training_loss\": 201.72360229492188, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 234.61370849609375, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 232.390869140625, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 213.40127563476562, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 228.2733612060547, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 194.94931030273438, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 239.45803833007812, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 192.72325134277344, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 202.3634796142578, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 193.89620971679688, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 216.18907165527344, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 154.96226501464844, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 150.0958709716797, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 213.41073608398438, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 185.6663818359375, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 167.60223388671875, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 205.70822143554688, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 222.30557250976562, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 212.37802124023438, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 226.5740966796875, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 182.68325805664062, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 175.55625915527344, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 228.74183654785156, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 134.24758911132812, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 210.96438598632812, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 222.24053955078125, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 212.79385375976562, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 236.64178466796875, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 207.937744140625, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 163.12548828125, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 197.27159118652344, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 200.58216857910156, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 224.29736328125, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.6953125, \"training_loss\": 210.04930114746094, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 246.70623779296875, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 225.86740112304688, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 235.44476318359375, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 161.58096313476562, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 199.11221313476562, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 198.789794921875, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 211.5648956298828, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 264.8235168457031, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 206.59400939941406, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 178.36602783203125, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 202.8572998046875, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 186.6241455078125, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 221.83395385742188, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 219.35382080078125, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 198.21141052246094, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 200.6399688720703, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 195.27386474609375, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 194.0904998779297, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 205.10023498535156, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 198.31985473632812, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 198.83241271972656, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 200.13824462890625, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 243.22824096679688, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 257.4668273925781, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 241.1844482421875, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 159.70150756835938, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 182.79637145996094, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 12.660102844238281, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 185.14312744140625, \"iteration\": 357, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 183.3553009033203, \"iteration\": 358, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 154.267578125, \"iteration\": 359, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 203.91946411132812, \"iteration\": 360, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 203.08309936523438, \"iteration\": 361, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 204.7574920654297, \"iteration\": 362, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 201.25909423828125, \"iteration\": 363, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 158.56854248046875, \"iteration\": 364, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 247.4031219482422, \"iteration\": 365, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 192.24710083007812, \"iteration\": 366, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 210.13467407226562, \"iteration\": 367, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 223.26974487304688, \"iteration\": 368, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 212.05712890625, \"iteration\": 369, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 251.23666381835938, \"iteration\": 370, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 155.73031616210938, \"iteration\": 371, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 200.11520385742188, \"iteration\": 372, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 187.99392700195312, \"iteration\": 373, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 205.81015014648438, \"iteration\": 374, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 207.7052764892578, \"iteration\": 375, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 212.08949279785156, \"iteration\": 376, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 203.37396240234375, \"iteration\": 377, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 218.8145294189453, \"iteration\": 378, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 187.61611938476562, \"iteration\": 379, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 185.68458557128906, \"iteration\": 380, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 216.46649169921875, \"iteration\": 381, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 212.39202880859375, \"iteration\": 382, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 192.156005859375, \"iteration\": 383, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 202.33316040039062, \"iteration\": 384, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 181.42872619628906, \"iteration\": 385, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 175.08779907226562, \"iteration\": 386, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 189.06463623046875, \"iteration\": 387, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 173.57388305664062, \"iteration\": 388, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 167.30532836914062, \"iteration\": 389, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 202.25958251953125, \"iteration\": 390, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 195.61758422851562, \"iteration\": 391, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 208.03085327148438, \"iteration\": 392, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 208.094970703125, \"iteration\": 393, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 231.9387664794922, \"iteration\": 394, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 224.09896850585938, \"iteration\": 395, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 216.932373046875, \"iteration\": 396, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 200.03150939941406, \"iteration\": 397, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 164.69729614257812, \"iteration\": 398, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 206.74508666992188, \"iteration\": 399, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 143.79443359375, \"iteration\": 400, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 165.40184020996094, \"iteration\": 401, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 241.4967041015625, \"iteration\": 402, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 174.5018310546875, \"iteration\": 403, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 208.21554565429688, \"iteration\": 404, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 150.3778076171875, \"iteration\": 405, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 192.69818115234375, \"iteration\": 406, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 193.47906494140625, \"iteration\": 407, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 217.04583740234375, \"iteration\": 408, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 181.56918334960938, \"iteration\": 409, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 182.62623596191406, \"iteration\": 410, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 188.49337768554688, \"iteration\": 411, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 196.2008056640625, \"iteration\": 412, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 181.73043823242188, \"iteration\": 413, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 200.884521484375, \"iteration\": 414, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 196.71478271484375, \"iteration\": 415, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 239.58094787597656, \"iteration\": 416, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 223.4805908203125, \"iteration\": 417, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 147.26419067382812, \"iteration\": 418, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 186.0380401611328, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 215.10501098632812, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 181.83773803710938, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 178.4461212158203, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 164.6192169189453, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 184.76876831054688, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 221.16087341308594, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 174.99844360351562, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 212.88848876953125, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 226.80467224121094, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 185.32420349121094, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 230.17318725585938, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 159.4801025390625, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 198.36949157714844, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 166.29429626464844, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 197.94122314453125, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 207.75308227539062, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 158.09915161132812, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 206.72232055664062, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 196.5113983154297, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 222.52406311035156, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 177.76522827148438, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 224.399169921875, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 211.54800415039062, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 205.95982360839844, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 168.24176025390625, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 232.1011199951172, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 230.0042266845703, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 226.28759765625, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 207.39385986328125, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 211.30123901367188, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 147.6341552734375, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 216.24195861816406, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 223.14529418945312, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 160.49371337890625, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 214.07147216796875, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 215.83901977539062, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 226.4410858154297, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 223.074951171875, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 188.74346923828125, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 180.11050415039062, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 204.846923828125, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 186.44834899902344, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 172.196533203125, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 165.37191772460938, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 177.48373413085938, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 159.71925354003906, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 159.6297607421875, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 251.11569213867188, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 197.9962158203125, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 187.69859313964844, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 139.52536010742188, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 199.8787841796875, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 191.90419006347656, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 238.83224487304688, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 217.21917724609375, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 214.89239501953125, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 173.86123657226562, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 225.19021606445312, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 173.65435791015625, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 140.347900390625, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 170.7395477294922, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 215.05361938476562, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 206.8953857421875, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 201.87054443359375, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 177.53274536132812, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 174.50656127929688, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 215.08221435546875, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 191.94808959960938, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 188.6356201171875, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 219.76937866210938, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 158.49472045898438, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 189.42791748046875, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 215.79666137695312, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 199.72244262695312, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 256.0534362792969, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 203.6098175048828, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 177.79672241210938, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 209.13710021972656, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 213.5339813232422, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 187.59205627441406, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 172.4737548828125, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 216.27099609375, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 196.195068359375, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 185.34335327148438, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 216.49205017089844, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 213.6015625, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 173.24192810058594, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 191.396728515625, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 178.74993896484375, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 209.46922302246094, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 176.12161254882812, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 179.312255859375, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 156.13079833984375, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 213.81361389160156, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 168.01390075683594, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 222.62757873535156, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 180.23602294921875, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 233.8524169921875, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 222.86749267578125, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 159.8878936767578, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 228.05877685546875, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 259.77978515625, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 230.2989501953125, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 161.02914428710938, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 235.7651824951172, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 202.38339233398438, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 226.33798217773438, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 153.0728302001953, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 207.12954711914062, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 184.75918579101562, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 180.10121154785156, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 184.05410766601562, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 191.49313354492188, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 183.19126892089844, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 14.646004676818848, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 199.98388671875, \"iteration\": 535, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 216.40139770507812, \"iteration\": 536, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 187.90731811523438, \"iteration\": 537, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 186.01788330078125, \"iteration\": 538, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 157.551513671875, \"iteration\": 539, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 167.69989013671875, \"iteration\": 540, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 189.67503356933594, \"iteration\": 541, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 182.96380615234375, \"iteration\": 542, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 170.53689575195312, \"iteration\": 543, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 136.40753173828125, \"iteration\": 544, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 176.91452026367188, \"iteration\": 545, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 195.49159240722656, \"iteration\": 546, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 155.9354248046875, \"iteration\": 547, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 188.9741668701172, \"iteration\": 548, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 157.6495361328125, \"iteration\": 549, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 189.47708129882812, \"iteration\": 550, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 173.6251983642578, \"iteration\": 551, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 155.7660369873047, \"iteration\": 552, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 196.5704345703125, \"iteration\": 553, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 177.05189514160156, \"iteration\": 554, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 143.1519317626953, \"iteration\": 555, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 208.12863159179688, \"iteration\": 556, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 223.56016540527344, \"iteration\": 557, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 172.32843017578125, \"iteration\": 558, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 220.07720947265625, \"iteration\": 559, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 181.70809936523438, \"iteration\": 560, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 184.1168975830078, \"iteration\": 561, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 182.1576690673828, \"iteration\": 562, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 222.56915283203125, \"iteration\": 563, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 187.23257446289062, \"iteration\": 564, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 154.66696166992188, \"iteration\": 565, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 235.38723754882812, \"iteration\": 566, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 196.98593139648438, \"iteration\": 567, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 220.81932067871094, \"iteration\": 568, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 143.10414123535156, \"iteration\": 569, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 211.76730346679688, \"iteration\": 570, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 198.00643920898438, \"iteration\": 571, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 148.86569213867188, \"iteration\": 572, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 171.7470703125, \"iteration\": 573, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 213.2243194580078, \"iteration\": 574, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 129.38616943359375, \"iteration\": 575, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 168.83843994140625, \"iteration\": 576, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 226.8332977294922, \"iteration\": 577, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 126.88839721679688, \"iteration\": 578, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 196.35562133789062, \"iteration\": 579, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 205.72662353515625, \"iteration\": 580, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 235.39022827148438, \"iteration\": 581, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 186.5528564453125, \"iteration\": 582, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 237.98568725585938, \"iteration\": 583, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 226.7086639404297, \"iteration\": 584, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 172.0454559326172, \"iteration\": 585, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 228.70751953125, \"iteration\": 586, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 155.0236358642578, \"iteration\": 587, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 144.83273315429688, \"iteration\": 588, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 242.25424194335938, \"iteration\": 589, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 171.13775634765625, \"iteration\": 590, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 200.95703125, \"iteration\": 591, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 177.49815368652344, \"iteration\": 592, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 196.38916015625, \"iteration\": 593, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 200.45367431640625, \"iteration\": 594, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 235.02976989746094, \"iteration\": 595, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 192.39784240722656, \"iteration\": 596, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 170.84495544433594, \"iteration\": 597, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 173.33602905273438, \"iteration\": 598, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 203.83746337890625, \"iteration\": 599, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 168.58963012695312, \"iteration\": 600, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 236.51144409179688, \"iteration\": 601, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 187.27001953125, \"iteration\": 602, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 207.43746948242188, \"iteration\": 603, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 211.96292114257812, \"iteration\": 604, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 197.65289306640625, \"iteration\": 605, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 172.00421142578125, \"iteration\": 606, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 199.54458618164062, \"iteration\": 607, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 174.02320861816406, \"iteration\": 608, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 180.17510986328125, \"iteration\": 609, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 201.32989501953125, \"iteration\": 610, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 177.84718322753906, \"iteration\": 611, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 212.3660125732422, \"iteration\": 612, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 226.43214416503906, \"iteration\": 613, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 187.91029357910156, \"iteration\": 614, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 170.43235778808594, \"iteration\": 615, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 177.60635375976562, \"iteration\": 616, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 153.18075561523438, \"iteration\": 617, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 192.74798583984375, \"iteration\": 618, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 154.56271362304688, \"iteration\": 619, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 187.11920166015625, \"iteration\": 620, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 188.26983642578125, \"iteration\": 621, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 256.79718017578125, \"iteration\": 622, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 185.92266845703125, \"iteration\": 623, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 153.08590698242188, \"iteration\": 624, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 193.74069213867188, \"iteration\": 625, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 201.00942993164062, \"iteration\": 626, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 176.89581298828125, \"iteration\": 627, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 206.44676208496094, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 149.4893798828125, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 167.45523071289062, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 156.34222412109375, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 217.59054565429688, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 173.24803161621094, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 200.17227172851562, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 197.0152130126953, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 168.74403381347656, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 204.49224853515625, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 207.326171875, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 211.43670654296875, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 181.58154296875, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 266.265869140625, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 178.90618896484375, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 210.23312377929688, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 182.00619506835938, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 206.49896240234375, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 165.2476348876953, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 145.89952087402344, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 172.46998596191406, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 179.4292449951172, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 187.55072021484375, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 225.336669921875, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 222.88180541992188, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 205.97018432617188, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 197.77487182617188, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 232.9996337890625, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 218.12066650390625, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 184.10006713867188, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 205.60894775390625, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 208.07318115234375, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 207.80191040039062, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 212.26687622070312, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 158.03956604003906, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 210.14231872558594, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 208.55123901367188, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 198.55679321289062, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 221.23101806640625, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 198.1138916015625, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 180.6231231689453, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 184.00160217285156, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 187.583740234375, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 165.59213256835938, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 180.28982543945312, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 193.45928955078125, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 158.834716796875, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 173.60940551757812, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 128.5478515625, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 200.99488830566406, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 227.50375366210938, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 198.82080078125, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 172.73660278320312, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 155.49391174316406, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 208.45852661132812, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 145.1951446533203, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 193.2034912109375, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 230.64720153808594, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 148.3620147705078, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 227.18710327148438, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 209.15481567382812, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 231.89422607421875, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 148.8290252685547, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 200.40792846679688, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 204.0078582763672, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 162.82028198242188, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 192.9492645263672, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 184.0029296875, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 213.76129150390625, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 121.56133270263672, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 181.3320770263672, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 234.51373291015625, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 207.68051147460938, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 208.13095092773438, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 188.8611602783203, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 228.17434692382812, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 150.72994995117188, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 231.9202117919922, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 157.1693115234375, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 191.56666564941406, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 225.29132080078125, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 198.54478454589844, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 201.53497314453125, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 184.78793334960938, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 20.026613235473633, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 161.51321411132812, \"iteration\": 713, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 179.90298461914062, \"iteration\": 714, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 182.66415405273438, \"iteration\": 715, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 240.55950927734375, \"iteration\": 716, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 162.49099731445312, \"iteration\": 717, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 155.56619262695312, \"iteration\": 718, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 180.398193359375, \"iteration\": 719, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 212.73655700683594, \"iteration\": 720, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 174.45364379882812, \"iteration\": 721, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 235.479248046875, \"iteration\": 722, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 182.52206420898438, \"iteration\": 723, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 187.97238159179688, \"iteration\": 724, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 190.5106201171875, \"iteration\": 725, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 229.48477172851562, \"iteration\": 726, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 204.428955078125, \"iteration\": 727, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 171.105224609375, \"iteration\": 728, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 185.89138793945312, \"iteration\": 729, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 174.67140197753906, \"iteration\": 730, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 190.57177734375, \"iteration\": 731, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 206.47412109375, \"iteration\": 732, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 189.74290466308594, \"iteration\": 733, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 186.37966918945312, \"iteration\": 734, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 215.14068603515625, \"iteration\": 735, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 196.4304656982422, \"iteration\": 736, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 215.34243774414062, \"iteration\": 737, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 214.34092712402344, \"iteration\": 738, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 162.5283660888672, \"iteration\": 739, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 185.25091552734375, \"iteration\": 740, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 166.68775939941406, \"iteration\": 741, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 155.79782104492188, \"iteration\": 742, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 165.67471313476562, \"iteration\": 743, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 235.43453979492188, \"iteration\": 744, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 200.03793334960938, \"iteration\": 745, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 203.57257080078125, \"iteration\": 746, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 175.41961669921875, \"iteration\": 747, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 159.56613159179688, \"iteration\": 748, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 179.91387939453125, \"iteration\": 749, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 195.1575927734375, \"iteration\": 750, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 157.04388427734375, \"iteration\": 751, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 146.61981201171875, \"iteration\": 752, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 166.59130859375, \"iteration\": 753, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 225.0941162109375, \"iteration\": 754, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 214.3487091064453, \"iteration\": 755, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 219.2698974609375, \"iteration\": 756, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 164.86178588867188, \"iteration\": 757, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 179.5006103515625, \"iteration\": 758, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 136.89382934570312, \"iteration\": 759, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 185.44955444335938, \"iteration\": 760, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 170.32614135742188, \"iteration\": 761, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 152.01193237304688, \"iteration\": 762, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 189.75076293945312, \"iteration\": 763, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 150.06634521484375, \"iteration\": 764, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 227.34768676757812, \"iteration\": 765, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 193.0988006591797, \"iteration\": 766, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 199.34637451171875, \"iteration\": 767, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 165.13746643066406, \"iteration\": 768, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 190.207763671875, \"iteration\": 769, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 213.35736083984375, \"iteration\": 770, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 199.08160400390625, \"iteration\": 771, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 188.77566528320312, \"iteration\": 772, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 235.73233032226562, \"iteration\": 773, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 170.32815551757812, \"iteration\": 774, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 155.81494140625, \"iteration\": 775, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 189.75674438476562, \"iteration\": 776, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 190.04452514648438, \"iteration\": 777, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 198.7388916015625, \"iteration\": 778, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 155.61410522460938, \"iteration\": 779, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 155.58544921875, \"iteration\": 780, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 171.35614013671875, \"iteration\": 781, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 171.44659423828125, \"iteration\": 782, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 198.1361083984375, \"iteration\": 783, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 174.0238037109375, \"iteration\": 784, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 160.13328552246094, \"iteration\": 785, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 142.11038208007812, \"iteration\": 786, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 189.26812744140625, \"iteration\": 787, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 166.33963012695312, \"iteration\": 788, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 212.49649047851562, \"iteration\": 789, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 214.76693725585938, \"iteration\": 790, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 199.65264892578125, \"iteration\": 791, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 231.33103942871094, \"iteration\": 792, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 168.6332244873047, \"iteration\": 793, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 199.49391174316406, \"iteration\": 794, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 238.42718505859375, \"iteration\": 795, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 169.68386840820312, \"iteration\": 796, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 182.59881591796875, \"iteration\": 797, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 178.725341796875, \"iteration\": 798, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 204.62911987304688, \"iteration\": 799, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 205.115234375, \"iteration\": 800, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 165.22943115234375, \"iteration\": 801, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 203.10653686523438, \"iteration\": 802, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 235.27243041992188, \"iteration\": 803, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 138.73562622070312, \"iteration\": 804, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 179.73663330078125, \"iteration\": 805, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 200.39073181152344, \"iteration\": 806, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 153.12901306152344, \"iteration\": 807, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 208.92385864257812, \"iteration\": 808, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 174.94561767578125, \"iteration\": 809, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 175.6453857421875, \"iteration\": 810, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 142.9856719970703, \"iteration\": 811, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 184.1068572998047, \"iteration\": 812, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 187.76336669921875, \"iteration\": 813, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 209.087158203125, \"iteration\": 814, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 220.70413208007812, \"iteration\": 815, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 168.9634552001953, \"iteration\": 816, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 154.75897216796875, \"iteration\": 817, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 190.4730224609375, \"iteration\": 818, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 179.996826171875, \"iteration\": 819, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 187.3349151611328, \"iteration\": 820, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 194.69168090820312, \"iteration\": 821, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 178.47250366210938, \"iteration\": 822, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 179.09188842773438, \"iteration\": 823, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 176.08412170410156, \"iteration\": 824, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 196.18104553222656, \"iteration\": 825, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 184.31219482421875, \"iteration\": 826, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 248.72132873535156, \"iteration\": 827, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 197.93252563476562, \"iteration\": 828, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 141.5154266357422, \"iteration\": 829, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 150.32296752929688, \"iteration\": 830, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 184.20452880859375, \"iteration\": 831, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 249.08721923828125, \"iteration\": 832, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 237.21527099609375, \"iteration\": 833, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 170.4812469482422, \"iteration\": 834, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 210.05169677734375, \"iteration\": 835, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 170.50106811523438, \"iteration\": 836, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 123.21749877929688, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 210.7501220703125, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 257.99212646484375, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 201.9186248779297, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 246.04147338867188, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 183.65582275390625, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 192.12240600585938, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 246.3016357421875, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 224.2790985107422, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 192.88522338867188, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 159.08428955078125, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 170.0226593017578, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 155.20245361328125, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 226.77780151367188, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 193.92669677734375, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 219.55264282226562, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 203.0758819580078, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 180.05099487304688, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 154.68984985351562, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 173.84976196289062, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 195.42889404296875, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 192.73193359375, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 149.34835815429688, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 183.52706909179688, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 158.71786499023438, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 189.32708740234375, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 151.18881225585938, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 198.84854125976562, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 162.13082885742188, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 224.30068969726562, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 165.6638641357422, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 142.56802368164062, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 159.4662628173828, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 170.12184143066406, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 155.10617065429688, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 213.3231658935547, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 258.771240234375, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 218.7586212158203, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 209.60479736328125, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 186.48095703125, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 159.47576904296875, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 159.68685913085938, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 180.84483337402344, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 168.84518432617188, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 171.96005249023438, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 174.03668212890625, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 159.80712890625, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 180.07406616210938, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 169.10379028320312, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 164.412353515625, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 174.56655883789062, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 203.3963623046875, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 190.29002380371094, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 13.796714782714844, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 163.5623321533203, \"iteration\": 891, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 193.65472412109375, \"iteration\": 892, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 202.16104125976562, \"iteration\": 893, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 192.08001708984375, \"iteration\": 894, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 201.51254272460938, \"iteration\": 895, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 197.42745971679688, \"iteration\": 896, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 206.45547485351562, \"iteration\": 897, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 173.29974365234375, \"iteration\": 898, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 191.98785400390625, \"iteration\": 899, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 158.97817993164062, \"iteration\": 900, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 153.1538543701172, \"iteration\": 901, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 167.91258239746094, \"iteration\": 902, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 236.86415100097656, \"iteration\": 903, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 159.91392517089844, \"iteration\": 904, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 197.95098876953125, \"iteration\": 905, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 247.24725341796875, \"iteration\": 906, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 154.3887481689453, \"iteration\": 907, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 168.240478515625, \"iteration\": 908, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 178.10455322265625, \"iteration\": 909, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 163.15403747558594, \"iteration\": 910, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 226.99896240234375, \"iteration\": 911, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 192.7386474609375, \"iteration\": 912, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 115.86111450195312, \"iteration\": 913, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 149.19680786132812, \"iteration\": 914, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 197.79771423339844, \"iteration\": 915, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 247.18045043945312, \"iteration\": 916, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 158.20587158203125, \"iteration\": 917, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 173.01214599609375, \"iteration\": 918, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 207.06951904296875, \"iteration\": 919, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 182.64022827148438, \"iteration\": 920, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 143.63929748535156, \"iteration\": 921, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 144.15045166015625, \"iteration\": 922, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 163.11441040039062, \"iteration\": 923, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 202.25970458984375, \"iteration\": 924, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 206.67083740234375, \"iteration\": 925, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 187.23880004882812, \"iteration\": 926, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 172.56039428710938, \"iteration\": 927, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 172.627685546875, \"iteration\": 928, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 182.5068359375, \"iteration\": 929, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 163.22488403320312, \"iteration\": 930, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 201.36160278320312, \"iteration\": 931, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 181.57444763183594, \"iteration\": 932, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 182.52899169921875, \"iteration\": 933, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 167.63214111328125, \"iteration\": 934, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 167.52581787109375, \"iteration\": 935, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 182.57711791992188, \"iteration\": 936, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 222.4256134033203, \"iteration\": 937, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 158.5306396484375, \"iteration\": 938, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 148.41317749023438, \"iteration\": 939, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 192.0322723388672, \"iteration\": 940, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 186.52798461914062, \"iteration\": 941, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 182.40695190429688, \"iteration\": 942, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 176.89466857910156, \"iteration\": 943, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 186.95152282714844, \"iteration\": 944, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 183.45164489746094, \"iteration\": 945, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 192.13262939453125, \"iteration\": 946, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 187.057861328125, \"iteration\": 947, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 125.99622344970703, \"iteration\": 948, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 191.54248046875, \"iteration\": 949, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 181.69442749023438, \"iteration\": 950, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 201.38775634765625, \"iteration\": 951, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 202.29844665527344, \"iteration\": 952, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 186.7842254638672, \"iteration\": 953, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 177.07469177246094, \"iteration\": 954, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 182.12911987304688, \"iteration\": 955, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 168.1098175048828, \"iteration\": 956, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 206.11004638671875, \"iteration\": 957, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 246.75119018554688, \"iteration\": 958, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 172.15145874023438, \"iteration\": 959, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 167.9482879638672, \"iteration\": 960, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 148.74017333984375, \"iteration\": 961, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 206.43667602539062, \"iteration\": 962, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 216.61721801757812, \"iteration\": 963, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 167.39382934570312, \"iteration\": 964, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 167.4763946533203, \"iteration\": 965, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 202.19808959960938, \"iteration\": 966, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 178.3344268798828, \"iteration\": 967, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 172.74072265625, \"iteration\": 968, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 187.3018798828125, \"iteration\": 969, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 202.79420471191406, \"iteration\": 970, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 177.72686767578125, \"iteration\": 971, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 178.295654296875, \"iteration\": 972, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 182.5579833984375, \"iteration\": 973, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 178.51315307617188, \"iteration\": 974, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 182.16738891601562, \"iteration\": 975, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 202.34799194335938, \"iteration\": 976, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 157.94329833984375, \"iteration\": 977, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 140.63417053222656, \"iteration\": 978, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 183.10755920410156, \"iteration\": 979, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 177.38259887695312, \"iteration\": 980, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 167.4030303955078, \"iteration\": 981, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 162.55953979492188, \"iteration\": 982, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 202.72845458984375, \"iteration\": 983, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 162.7269744873047, \"iteration\": 984, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 192.19247436523438, \"iteration\": 985, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 206.87295532226562, \"iteration\": 986, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 201.69058227539062, \"iteration\": 987, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 148.15615844726562, \"iteration\": 988, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 201.10406494140625, \"iteration\": 989, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 237.3330078125, \"iteration\": 990, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 184.05096435546875, \"iteration\": 991, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 202.13946533203125, \"iteration\": 992, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 187.7084197998047, \"iteration\": 993, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 196.33724975585938, \"iteration\": 994, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 131.60325622558594, \"iteration\": 995, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 182.570068359375, \"iteration\": 996, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 232.3972625732422, \"iteration\": 997, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 193.8717041015625, \"iteration\": 998, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 212.93846130371094, \"iteration\": 999, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 167.82244873046875, \"iteration\": 1000, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 191.76193237304688, \"iteration\": 1001, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 212.03024291992188, \"iteration\": 1002, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 130.2092742919922, \"iteration\": 1003, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 193.1101531982422, \"iteration\": 1004, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 211.46368408203125, \"iteration\": 1005, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 192.4051513671875, \"iteration\": 1006, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 187.24368286132812, \"iteration\": 1007, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 191.18328857421875, \"iteration\": 1008, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 144.14207458496094, \"iteration\": 1009, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 271.903076171875, \"iteration\": 1010, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 182.16290283203125, \"iteration\": 1011, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 177.9384765625, \"iteration\": 1012, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 196.7642822265625, \"iteration\": 1013, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 191.26080322265625, \"iteration\": 1014, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 211.0518035888672, \"iteration\": 1015, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 206.62367248535156, \"iteration\": 1016, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 148.67971801757812, \"iteration\": 1017, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 143.75250244140625, \"iteration\": 1018, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 191.72544860839844, \"iteration\": 1019, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 213.09796142578125, \"iteration\": 1020, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 221.34384155273438, \"iteration\": 1021, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 192.58859252929688, \"iteration\": 1022, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 187.03912353515625, \"iteration\": 1023, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 182.52621459960938, \"iteration\": 1024, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 172.971923828125, \"iteration\": 1025, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 221.6690216064453, \"iteration\": 1026, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 149.86053466796875, \"iteration\": 1027, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 172.40902709960938, \"iteration\": 1028, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 221.94436645507812, \"iteration\": 1029, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 197.66683959960938, \"iteration\": 1030, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 148.49459838867188, \"iteration\": 1031, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 201.5507049560547, \"iteration\": 1032, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 148.64993286132812, \"iteration\": 1033, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 221.46115112304688, \"iteration\": 1034, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 196.80360412597656, \"iteration\": 1035, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 130.41786193847656, \"iteration\": 1036, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 173.08847045898438, \"iteration\": 1037, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 181.9010467529297, \"iteration\": 1038, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 172.30836486816406, \"iteration\": 1039, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 168.10397338867188, \"iteration\": 1040, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 219.8304443359375, \"iteration\": 1041, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 171.85910034179688, \"iteration\": 1042, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 148.8878173828125, \"iteration\": 1043, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 206.5841827392578, \"iteration\": 1044, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 182.68435668945312, \"iteration\": 1045, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 164.1044921875, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 248.24765014648438, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 157.97866821289062, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 153.55459594726562, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 192.79319763183594, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 197.37411499023438, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 167.04637145996094, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 167.93397521972656, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 216.80857849121094, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 201.28919982910156, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 177.46832275390625, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 221.46224975585938, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 182.3567657470703, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 216.65365600585938, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 186.62255859375, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 162.74942016601562, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 167.9117431640625, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 158.40382385253906, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 168.0790557861328, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 163.37652587890625, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 182.18511962890625, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 206.21456909179688, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 8.21825122833252, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 186.17591857910156, \"iteration\": 1069, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 171.782470703125, \"iteration\": 1070, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 171.60133361816406, \"iteration\": 1071, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 143.53036499023438, \"iteration\": 1072, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 181.49005126953125, \"iteration\": 1073, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 167.34542846679688, \"iteration\": 1074, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 205.77149963378906, \"iteration\": 1075, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 206.89175415039062, \"iteration\": 1076, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 171.9959716796875, \"iteration\": 1077, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 177.02670288085938, \"iteration\": 1078, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 162.85919189453125, \"iteration\": 1079, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 162.58155822753906, \"iteration\": 1080, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 157.9766387939453, \"iteration\": 1081, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 181.16848754882812, \"iteration\": 1082, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 195.9053497314453, \"iteration\": 1083, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 172.19171142578125, \"iteration\": 1084, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 167.32972717285156, \"iteration\": 1085, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 177.19981384277344, \"iteration\": 1086, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 210.66299438476562, \"iteration\": 1087, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 205.99609375, \"iteration\": 1088, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 143.0332489013672, \"iteration\": 1089, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 196.1063232421875, \"iteration\": 1090, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 191.48770141601562, \"iteration\": 1091, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 147.95938110351562, \"iteration\": 1092, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 177.4234619140625, \"iteration\": 1093, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 167.4888916015625, \"iteration\": 1094, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 147.87921142578125, \"iteration\": 1095, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 143.1986083984375, \"iteration\": 1096, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 166.7191925048828, \"iteration\": 1097, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 195.84616088867188, \"iteration\": 1098, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 201.18051147460938, \"iteration\": 1099, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 201.97695922851562, \"iteration\": 1100, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 187.33583068847656, \"iteration\": 1101, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 200.6824951171875, \"iteration\": 1102, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 187.11514282226562, \"iteration\": 1103, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 187.2738800048828, \"iteration\": 1104, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 177.1714630126953, \"iteration\": 1105, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 177.5694580078125, \"iteration\": 1106, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 196.33035278320312, \"iteration\": 1107, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 158.85995483398438, \"iteration\": 1108, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 191.09262084960938, \"iteration\": 1109, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 196.13800048828125, \"iteration\": 1110, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 226.37371826171875, \"iteration\": 1111, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 159.84539794921875, \"iteration\": 1112, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.89105224609375, \"iteration\": 1113, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 241.04461669921875, \"iteration\": 1114, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 196.32803344726562, \"iteration\": 1115, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 211.36282348632812, \"iteration\": 1116, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 176.4841766357422, \"iteration\": 1117, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 196.33363342285156, \"iteration\": 1118, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 157.2461395263672, \"iteration\": 1119, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 200.78509521484375, \"iteration\": 1120, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 176.47901916503906, \"iteration\": 1121, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 216.6283721923828, \"iteration\": 1122, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 178.9434814453125, \"iteration\": 1123, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 176.758056640625, \"iteration\": 1124, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 211.28143310546875, \"iteration\": 1125, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 174.24209594726562, \"iteration\": 1126, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 195.7285919189453, \"iteration\": 1127, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 152.76214599609375, \"iteration\": 1128, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 162.57534790039062, \"iteration\": 1129, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 206.3341522216797, \"iteration\": 1130, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 134.98800659179688, \"iteration\": 1131, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.6146240234375, \"iteration\": 1132, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 148.51931762695312, \"iteration\": 1133, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 89.48167419433594, \"iteration\": 1134, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 177.18255615234375, \"iteration\": 1135, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 201.58848571777344, \"iteration\": 1136, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 167.3780059814453, \"iteration\": 1137, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 181.4630126953125, \"iteration\": 1138, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.34320068359375, \"iteration\": 1139, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.5508575439453, \"iteration\": 1140, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 201.818603515625, \"iteration\": 1141, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 167.56179809570312, \"iteration\": 1142, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 191.26123046875, \"iteration\": 1143, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 124.97907257080078, \"iteration\": 1144, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 200.98397827148438, \"iteration\": 1145, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 176.99266052246094, \"iteration\": 1146, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 205.8105926513672, \"iteration\": 1147, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 197.48822021484375, \"iteration\": 1148, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 158.54452514648438, \"iteration\": 1149, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 205.8649139404297, \"iteration\": 1150, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 162.14932250976562, \"iteration\": 1151, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 192.8074493408203, \"iteration\": 1152, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 163.2698974609375, \"iteration\": 1153, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 171.93856811523438, \"iteration\": 1154, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 162.30572509765625, \"iteration\": 1155, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 181.57815551757812, \"iteration\": 1156, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 225.96478271484375, \"iteration\": 1157, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 162.70950317382812, \"iteration\": 1158, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.8363037109375, \"iteration\": 1159, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 191.44601440429688, \"iteration\": 1160, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 167.02804565429688, \"iteration\": 1161, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 148.0528106689453, \"iteration\": 1162, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.7632598876953, \"iteration\": 1163, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 221.548828125, \"iteration\": 1164, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 176.3935546875, \"iteration\": 1165, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 213.13601684570312, \"iteration\": 1166, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 211.27621459960938, \"iteration\": 1167, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 216.07522583007812, \"iteration\": 1168, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 162.46243286132812, \"iteration\": 1169, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 172.022705078125, \"iteration\": 1170, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 172.30702209472656, \"iteration\": 1171, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 173.48419189453125, \"iteration\": 1172, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 205.86032104492188, \"iteration\": 1173, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 201.63644409179688, \"iteration\": 1174, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 176.64309692382812, \"iteration\": 1175, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 162.03363037109375, \"iteration\": 1176, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 191.05117797851562, \"iteration\": 1177, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 196.77862548828125, \"iteration\": 1178, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 201.55801391601562, \"iteration\": 1179, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 171.75440979003906, \"iteration\": 1180, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 187.12498474121094, \"iteration\": 1181, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.75694274902344, \"iteration\": 1182, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 163.2496337890625, \"iteration\": 1183, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 235.96221923828125, \"iteration\": 1184, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 167.7294921875, \"iteration\": 1185, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 182.2349853515625, \"iteration\": 1186, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 216.197021484375, \"iteration\": 1187, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 134.31829833984375, \"iteration\": 1188, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 167.86581420898438, \"iteration\": 1189, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 148.24853515625, \"iteration\": 1190, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 211.20286560058594, \"iteration\": 1191, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 162.5338592529297, \"iteration\": 1192, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 173.45248413085938, \"iteration\": 1193, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 211.15785217285156, \"iteration\": 1194, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 134.96389770507812, \"iteration\": 1195, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 191.1534423828125, \"iteration\": 1196, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 206.56370544433594, \"iteration\": 1197, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 206.29061889648438, \"iteration\": 1198, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 221.93038940429688, \"iteration\": 1199, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 172.87339782714844, \"iteration\": 1200, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 187.65899658203125, \"iteration\": 1201, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 191.57418823242188, \"iteration\": 1202, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 171.43722534179688, \"iteration\": 1203, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 205.96939086914062, \"iteration\": 1204, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 162.69808959960938, \"iteration\": 1205, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 205.69027709960938, \"iteration\": 1206, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 191.4674530029297, \"iteration\": 1207, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 215.6869659423828, \"iteration\": 1208, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 171.65438842773438, \"iteration\": 1209, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 177.03292846679688, \"iteration\": 1210, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.46038818359375, \"iteration\": 1211, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 177.02252197265625, \"iteration\": 1212, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.10792541503906, \"iteration\": 1213, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 177.07382202148438, \"iteration\": 1214, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 171.643310546875, \"iteration\": 1215, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.5112762451172, \"iteration\": 1216, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.7683868408203, \"iteration\": 1217, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 207.11314392089844, \"iteration\": 1218, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 211.22195434570312, \"iteration\": 1219, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 261.48175048828125, \"iteration\": 1220, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 191.8443145751953, \"iteration\": 1221, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 177.580078125, \"iteration\": 1222, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 212.20068359375, \"iteration\": 1223, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 177.2849884033203, \"iteration\": 1224, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 200.98487854003906, \"iteration\": 1225, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 232.03167724609375, \"iteration\": 1226, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 186.5723876953125, \"iteration\": 1227, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 166.88848876953125, \"iteration\": 1228, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 176.59075927734375, \"iteration\": 1229, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 206.15716552734375, \"iteration\": 1230, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 221.6121826171875, \"iteration\": 1231, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 172.00399780273438, \"iteration\": 1232, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 134.6270751953125, \"iteration\": 1233, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 158.34368896484375, \"iteration\": 1234, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 163.092529296875, \"iteration\": 1235, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 225.91952514648438, \"iteration\": 1236, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 201.06463623046875, \"iteration\": 1237, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 167.68435668945312, \"iteration\": 1238, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 181.7415313720703, \"iteration\": 1239, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 162.12173461914062, \"iteration\": 1240, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 191.202392578125, \"iteration\": 1241, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 177.32284545898438, \"iteration\": 1242, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 201.212890625, \"iteration\": 1243, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 171.5985107421875, \"iteration\": 1244, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 205.72227478027344, \"iteration\": 1245, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 10.813362121582031, \"iteration\": 1246, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 210.6732177734375, \"iteration\": 1247, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 171.61734008789062, \"iteration\": 1248, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.7432861328125, \"iteration\": 1249, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.96566772460938, \"iteration\": 1250, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.76400756835938, \"iteration\": 1251, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 143.0109405517578, \"iteration\": 1252, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 240.91722106933594, \"iteration\": 1253, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.0491943359375, \"iteration\": 1254, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.6365966796875, \"iteration\": 1255, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 221.0655059814453, \"iteration\": 1256, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 152.44195556640625, \"iteration\": 1257, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.2606201171875, \"iteration\": 1258, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.64974975585938, \"iteration\": 1259, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 240.78248596191406, \"iteration\": 1260, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.2076873779297, \"iteration\": 1261, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.84375, \"iteration\": 1262, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 171.72857666015625, \"iteration\": 1263, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 191.13232421875, \"iteration\": 1264, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 129.48782348632812, \"iteration\": 1265, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.16311645507812, \"iteration\": 1266, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 225.53746032714844, \"iteration\": 1267, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.80563354492188, \"iteration\": 1268, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.05470275878906, \"iteration\": 1269, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.901611328125, \"iteration\": 1270, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 147.93295288085938, \"iteration\": 1271, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.806884765625, \"iteration\": 1272, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.13534545898438, \"iteration\": 1273, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.64718627929688, \"iteration\": 1274, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 148.41683959960938, \"iteration\": 1275, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 205.6630859375, \"iteration\": 1276, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 205.580810546875, \"iteration\": 1277, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 266.402587890625, \"iteration\": 1278, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.3470458984375, \"iteration\": 1279, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.433837890625, \"iteration\": 1280, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 191.4864044189453, \"iteration\": 1281, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 133.80699157714844, \"iteration\": 1282, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.48541259765625, \"iteration\": 1283, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 236.49087524414062, \"iteration\": 1284, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.94488525390625, \"iteration\": 1285, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.3918914794922, \"iteration\": 1286, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 162.07537841796875, \"iteration\": 1287, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.86727905273438, \"iteration\": 1288, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 153.0700225830078, \"iteration\": 1289, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.89418029785156, \"iteration\": 1290, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.68972778320312, \"iteration\": 1291, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 129.50962829589844, \"iteration\": 1292, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 211.44427490234375, \"iteration\": 1293, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.45326232910156, \"iteration\": 1294, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.950927734375, \"iteration\": 1295, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.07196044921875, \"iteration\": 1296, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 143.36944580078125, \"iteration\": 1297, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.7933349609375, \"iteration\": 1298, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 240.99093627929688, \"iteration\": 1299, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 171.661376953125, \"iteration\": 1300, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 147.93038940429688, \"iteration\": 1301, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 162.03829956054688, \"iteration\": 1302, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.5690155029297, \"iteration\": 1303, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.23104858398438, \"iteration\": 1304, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 220.60646057128906, \"iteration\": 1305, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 205.63687133789062, \"iteration\": 1306, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.82534790039062, \"iteration\": 1307, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.90155029296875, \"iteration\": 1308, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 171.50933837890625, \"iteration\": 1309, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.53817749023438, \"iteration\": 1310, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 162.2776641845703, \"iteration\": 1311, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 225.61537170410156, \"iteration\": 1312, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 205.61685180664062, \"iteration\": 1313, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.0998992919922, \"iteration\": 1314, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.22702026367188, \"iteration\": 1315, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.61122131347656, \"iteration\": 1316, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.6502685546875, \"iteration\": 1317, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 125.23245239257812, \"iteration\": 1318, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 220.65000915527344, \"iteration\": 1319, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.7399139404297, \"iteration\": 1320, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 162.68508911132812, \"iteration\": 1321, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.04531860351562, \"iteration\": 1322, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 129.6209716796875, \"iteration\": 1323, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.97332763671875, \"iteration\": 1324, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.34481811523438, \"iteration\": 1325, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.10289001464844, \"iteration\": 1326, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 185.88851928710938, \"iteration\": 1327, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 185.9981689453125, \"iteration\": 1328, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 162.03387451171875, \"iteration\": 1329, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 235.65966796875, \"iteration\": 1330, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.90084838867188, \"iteration\": 1331, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.71292114257812, \"iteration\": 1332, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.74441528320312, \"iteration\": 1333, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 129.5460205078125, \"iteration\": 1334, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.05665588378906, \"iteration\": 1335, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 161.97650146484375, \"iteration\": 1336, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 231.10696411132812, \"iteration\": 1337, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.27938842773438, \"iteration\": 1338, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.77908325195312, \"iteration\": 1339, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 185.93310546875, \"iteration\": 1340, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 191.08270263671875, \"iteration\": 1341, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 191.9065399169922, \"iteration\": 1342, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 143.08058166503906, \"iteration\": 1343, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.93386840820312, \"iteration\": 1344, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.85983276367188, \"iteration\": 1345, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 152.67864990234375, \"iteration\": 1346, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.28976440429688, \"iteration\": 1347, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 185.94644165039062, \"iteration\": 1348, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.54763793945312, \"iteration\": 1349, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 138.3320770263672, \"iteration\": 1350, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.6818389892578, \"iteration\": 1351, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 148.3394775390625, \"iteration\": 1352, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.59396362304688, \"iteration\": 1353, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.96844482421875, \"iteration\": 1354, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 129.10885620117188, \"iteration\": 1355, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 143.78466796875, \"iteration\": 1356, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.5121307373047, \"iteration\": 1357, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 161.9463348388672, \"iteration\": 1358, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.84718322753906, \"iteration\": 1359, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.16769409179688, \"iteration\": 1360, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.0904083251953, \"iteration\": 1361, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.90811157226562, \"iteration\": 1362, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.97532653808594, \"iteration\": 1363, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.6892547607422, \"iteration\": 1364, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.64724731445312, \"iteration\": 1365, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.21380615234375, \"iteration\": 1366, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 235.61795043945312, \"iteration\": 1367, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 152.40379333496094, \"iteration\": 1368, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.99508666992188, \"iteration\": 1369, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 187.01995849609375, \"iteration\": 1370, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.03497314453125, \"iteration\": 1371, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.26718139648438, \"iteration\": 1372, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 220.557861328125, \"iteration\": 1373, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 176.25062561035156, \"iteration\": 1374, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.04067993164062, \"iteration\": 1375, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 220.52113342285156, \"iteration\": 1376, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 230.55398559570312, \"iteration\": 1377, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.90493774414062, \"iteration\": 1378, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.053466796875, \"iteration\": 1379, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.129150390625, \"iteration\": 1380, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 185.9423370361328, \"iteration\": 1381, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 143.02731323242188, \"iteration\": 1382, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 210.51394653320312, \"iteration\": 1383, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 215.43568420410156, \"iteration\": 1384, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.88722229003906, \"iteration\": 1385, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 206.8681640625, \"iteration\": 1386, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 205.58958435058594, \"iteration\": 1387, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.19276428222656, \"iteration\": 1388, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.88922119140625, \"iteration\": 1389, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 215.66879272460938, \"iteration\": 1390, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 215.63458251953125, \"iteration\": 1391, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 162.1907501220703, \"iteration\": 1392, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.02438354492188, \"iteration\": 1393, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 215.7263641357422, \"iteration\": 1394, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 147.84768676757812, \"iteration\": 1395, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 162.0193634033203, \"iteration\": 1396, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 157.4113006591797, \"iteration\": 1397, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 161.79539489746094, \"iteration\": 1398, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 215.51620483398438, \"iteration\": 1399, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 185.8526611328125, \"iteration\": 1400, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.99127197265625, \"iteration\": 1401, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 182.25083923339844, \"iteration\": 1402, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.697998046875, \"iteration\": 1403, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 181.728759765625, \"iteration\": 1404, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 191.0884246826172, \"iteration\": 1405, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 162.01824951171875, \"iteration\": 1406, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.8397674560547, \"iteration\": 1407, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 138.68850708007812, \"iteration\": 1408, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 166.7188262939453, \"iteration\": 1409, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.82748413085938, \"iteration\": 1410, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 134.73153686523438, \"iteration\": 1411, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.7832489013672, \"iteration\": 1412, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 185.96868896484375, \"iteration\": 1413, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 149.39048767089844, \"iteration\": 1414, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 186.1492156982422, \"iteration\": 1415, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 201.31277465820312, \"iteration\": 1416, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 138.4576416015625, \"iteration\": 1417, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 171.87716674804688, \"iteration\": 1418, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 200.82159423828125, \"iteration\": 1419, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 126.42288970947266, \"iteration\": 1420, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 171.97044372558594, \"iteration\": 1421, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 190.96881103515625, \"iteration\": 1422, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 195.89247131347656, \"iteration\": 1423, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 16.641098022460938, \"iteration\": 1424, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 182.36419677734375, \"iteration\": 1425, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 220.47091674804688, \"iteration\": 1426, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.76535034179688, \"iteration\": 1427, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 142.92945861816406, \"iteration\": 1428, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 147.9297637939453, \"iteration\": 1429, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.10836791992188, \"iteration\": 1430, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 138.6063690185547, \"iteration\": 1431, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 152.4553680419922, \"iteration\": 1432, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 161.81243896484375, \"iteration\": 1433, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.0394287109375, \"iteration\": 1434, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.56341552734375, \"iteration\": 1435, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.59307861328125, \"iteration\": 1436, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.3218994140625, \"iteration\": 1437, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 129.20787048339844, \"iteration\": 1438, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 148.40762329101562, \"iteration\": 1439, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.32374572753906, \"iteration\": 1440, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.00875854492188, \"iteration\": 1441, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 152.69943237304688, \"iteration\": 1442, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 161.97238159179688, \"iteration\": 1443, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 148.28909301757812, \"iteration\": 1444, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 152.52520751953125, \"iteration\": 1445, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 130.2232208251953, \"iteration\": 1446, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.80059814453125, \"iteration\": 1447, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 216.6012420654297, \"iteration\": 1448, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.56150817871094, \"iteration\": 1449, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 182.13829040527344, \"iteration\": 1450, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.50967407226562, \"iteration\": 1451, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 210.93154907226562, \"iteration\": 1452, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 152.6605224609375, \"iteration\": 1453, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.63430786132812, \"iteration\": 1454, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.5951385498047, \"iteration\": 1455, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.91265869140625, \"iteration\": 1456, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.64927673339844, \"iteration\": 1457, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.79306030273438, \"iteration\": 1458, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.28994750976562, \"iteration\": 1459, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 191.2524871826172, \"iteration\": 1460, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.45523071289062, \"iteration\": 1461, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 172.22654724121094, \"iteration\": 1462, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 236.2159881591797, \"iteration\": 1463, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 152.65748596191406, \"iteration\": 1464, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.61810302734375, \"iteration\": 1465, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.20852661132812, \"iteration\": 1466, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.09307861328125, \"iteration\": 1467, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 195.78651428222656, \"iteration\": 1468, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.58401489257812, \"iteration\": 1469, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 201.0164794921875, \"iteration\": 1470, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 261.32647705078125, \"iteration\": 1471, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.7489471435547, \"iteration\": 1472, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 162.00241088867188, \"iteration\": 1473, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 196.56881713867188, \"iteration\": 1474, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 162.64459228515625, \"iteration\": 1475, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.87136840820312, \"iteration\": 1476, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.8249053955078, \"iteration\": 1477, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.49331665039062, \"iteration\": 1478, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.24256896972656, \"iteration\": 1479, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.34609985351562, \"iteration\": 1480, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 182.07440185546875, \"iteration\": 1481, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.739013671875, \"iteration\": 1482, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.55435180664062, \"iteration\": 1483, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.11083984375, \"iteration\": 1484, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.82867431640625, \"iteration\": 1485, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.46006774902344, \"iteration\": 1486, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.7403106689453, \"iteration\": 1487, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 195.93853759765625, \"iteration\": 1488, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 162.3939208984375, \"iteration\": 1489, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.66427612304688, \"iteration\": 1490, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 211.11312866210938, \"iteration\": 1491, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.69737243652344, \"iteration\": 1492, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 236.01026916503906, \"iteration\": 1493, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.4996337890625, \"iteration\": 1494, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 151.896484375, \"iteration\": 1495, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 210.63162231445312, \"iteration\": 1496, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.2106475830078, \"iteration\": 1497, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.97776794433594, \"iteration\": 1498, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.59732055664062, \"iteration\": 1499, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.15577697753906, \"iteration\": 1500, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.14987182617188, \"iteration\": 1501, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 211.0335693359375, \"iteration\": 1502, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 171.94912719726562, \"iteration\": 1503, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 201.09500122070312, \"iteration\": 1504, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.88388061523438, \"iteration\": 1505, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 153.21621704101562, \"iteration\": 1506, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.75729370117188, \"iteration\": 1507, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 182.08555603027344, \"iteration\": 1508, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.12551879882812, \"iteration\": 1509, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.92251586914062, \"iteration\": 1510, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.7292022705078, \"iteration\": 1511, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.46978759765625, \"iteration\": 1512, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.02423095703125, \"iteration\": 1513, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.8271484375, \"iteration\": 1514, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 172.90936279296875, \"iteration\": 1515, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 196.22988891601562, \"iteration\": 1516, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.35997009277344, \"iteration\": 1517, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 226.2906494140625, \"iteration\": 1518, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.95570373535156, \"iteration\": 1519, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.68548583984375, \"iteration\": 1520, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.97523498535156, \"iteration\": 1521, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 240.78692626953125, \"iteration\": 1522, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 211.23733520507812, \"iteration\": 1523, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.6815185546875, \"iteration\": 1524, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 205.99725341796875, \"iteration\": 1525, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 210.81793212890625, \"iteration\": 1526, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 206.01950073242188, \"iteration\": 1527, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.8733367919922, \"iteration\": 1528, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.71664428710938, \"iteration\": 1529, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 172.17872619628906, \"iteration\": 1530, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.10379028320312, \"iteration\": 1531, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 172.38192749023438, \"iteration\": 1532, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.5377197265625, \"iteration\": 1533, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 158.12521362304688, \"iteration\": 1534, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.832763671875, \"iteration\": 1535, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 121.22569274902344, \"iteration\": 1536, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.05807495117188, \"iteration\": 1537, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.89425659179688, \"iteration\": 1538, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.24627685546875, \"iteration\": 1539, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.66990661621094, \"iteration\": 1540, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.74049377441406, \"iteration\": 1541, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 172.03733825683594, \"iteration\": 1542, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 217.240478515625, \"iteration\": 1543, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.78244018554688, \"iteration\": 1544, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 163.92803955078125, \"iteration\": 1545, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.32228088378906, \"iteration\": 1546, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.84603881835938, \"iteration\": 1547, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.6016387939453, \"iteration\": 1548, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 158.27545166015625, \"iteration\": 1549, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 151.14736938476562, \"iteration\": 1550, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 246.01828002929688, \"iteration\": 1551, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 235.76223754882812, \"iteration\": 1552, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.754150390625, \"iteration\": 1553, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.25296020507812, \"iteration\": 1554, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 210.99072265625, \"iteration\": 1555, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 203.64596557617188, \"iteration\": 1556, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.25064086914062, \"iteration\": 1557, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 200.9307861328125, \"iteration\": 1558, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 184.84909057617188, \"iteration\": 1559, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 211.1568145751953, \"iteration\": 1560, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 204.01968383789062, \"iteration\": 1561, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 157.7655029296875, \"iteration\": 1562, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 168.47921752929688, \"iteration\": 1563, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 144.9193115234375, \"iteration\": 1564, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 177.06655883789062, \"iteration\": 1565, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 134.73817443847656, \"iteration\": 1566, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.09214782714844, \"iteration\": 1567, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 198.66387939453125, \"iteration\": 1568, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 176.3884735107422, \"iteration\": 1569, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 193.3111572265625, \"iteration\": 1570, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 177.16726684570312, \"iteration\": 1571, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.47100830078125, \"iteration\": 1572, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 192.60592651367188, \"iteration\": 1573, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 183.41586303710938, \"iteration\": 1574, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 251.22714233398438, \"iteration\": 1575, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.14727783203125, \"iteration\": 1576, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.71975708007812, \"iteration\": 1577, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 129.37185668945312, \"iteration\": 1578, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 211.2443389892578, \"iteration\": 1579, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 203.40121459960938, \"iteration\": 1580, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.88893127441406, \"iteration\": 1581, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 246.21031188964844, \"iteration\": 1582, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 190.96014404296875, \"iteration\": 1583, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 225.79940795898438, \"iteration\": 1584, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 211.5806884765625, \"iteration\": 1585, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 150.5098876953125, \"iteration\": 1586, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 191.82379150390625, \"iteration\": 1587, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 192.89703369140625, \"iteration\": 1588, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.82229614257812, \"iteration\": 1589, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 181.45370483398438, \"iteration\": 1590, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 169.69866943359375, \"iteration\": 1591, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 215.89205932617188, \"iteration\": 1592, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 167.1911163330078, \"iteration\": 1593, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.83470153808594, \"iteration\": 1594, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 186.99237060546875, \"iteration\": 1595, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 167.89193725585938, \"iteration\": 1596, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 192.579833984375, \"iteration\": 1597, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 206.83380126953125, \"iteration\": 1598, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 125.23518371582031, \"iteration\": 1599, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 173.42633056640625, \"iteration\": 1600, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 157.09713745117188, \"iteration\": 1601, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 13.672622680664062, \"iteration\": 1602, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 166.75009155273438, \"iteration\": 1603, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 195.91513061523438, \"iteration\": 1604, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 206.62554931640625, \"iteration\": 1605, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 201.4585418701172, \"iteration\": 1606, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 143.412109375, \"iteration\": 1607, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.50238037109375, \"iteration\": 1608, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 143.9161376953125, \"iteration\": 1609, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 201.228515625, \"iteration\": 1610, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 195.88504028320312, \"iteration\": 1611, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.89230346679688, \"iteration\": 1612, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 196.3665771484375, \"iteration\": 1613, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.34869384765625, \"iteration\": 1614, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 240.68394470214844, \"iteration\": 1615, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 143.8466796875, \"iteration\": 1616, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.97323608398438, \"iteration\": 1617, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.58688354492188, \"iteration\": 1618, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.96920776367188, \"iteration\": 1619, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 211.50210571289062, \"iteration\": 1620, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 162.216552734375, \"iteration\": 1621, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.89303588867188, \"iteration\": 1622, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.29034423828125, \"iteration\": 1623, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 162.70654296875, \"iteration\": 1624, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 162.051513671875, \"iteration\": 1625, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 210.7403564453125, \"iteration\": 1626, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 163.2667236328125, \"iteration\": 1627, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.90548706054688, \"iteration\": 1628, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 143.05589294433594, \"iteration\": 1629, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.8066864013672, \"iteration\": 1630, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.59872436523438, \"iteration\": 1631, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.9461669921875, \"iteration\": 1632, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.97930908203125, \"iteration\": 1633, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.802734375, \"iteration\": 1634, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 187.3439178466797, \"iteration\": 1635, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.0543212890625, \"iteration\": 1636, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.42076110839844, \"iteration\": 1637, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 196.4697723388672, \"iteration\": 1638, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.8018035888672, \"iteration\": 1639, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 182.06117248535156, \"iteration\": 1640, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 191.67242431640625, \"iteration\": 1641, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.69927978515625, \"iteration\": 1642, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 129.74176025390625, \"iteration\": 1643, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 191.13522338867188, \"iteration\": 1644, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.7311248779297, \"iteration\": 1645, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 112.97411346435547, \"iteration\": 1646, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 251.13250732421875, \"iteration\": 1647, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 205.72418212890625, \"iteration\": 1648, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 177.18092346191406, \"iteration\": 1649, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 201.0450439453125, \"iteration\": 1650, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.67051696777344, \"iteration\": 1651, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.95079040527344, \"iteration\": 1652, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.86354064941406, \"iteration\": 1653, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 143.18817138671875, \"iteration\": 1654, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.92616271972656, \"iteration\": 1655, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.43280029296875, \"iteration\": 1656, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 196.44854736328125, \"iteration\": 1657, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 152.74322509765625, \"iteration\": 1658, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.38970947265625, \"iteration\": 1659, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 191.03102111816406, \"iteration\": 1660, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.7252197265625, \"iteration\": 1661, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 216.3876953125, \"iteration\": 1662, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 148.23272705078125, \"iteration\": 1663, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 211.39663696289062, \"iteration\": 1664, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 210.6021728515625, \"iteration\": 1665, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.19192504882812, \"iteration\": 1666, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.8623504638672, \"iteration\": 1667, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 154.07638549804688, \"iteration\": 1668, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 208.0628204345703, \"iteration\": 1669, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.62545776367188, \"iteration\": 1670, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 134.45220947265625, \"iteration\": 1671, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 172.89138793945312, \"iteration\": 1672, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 195.85748291015625, \"iteration\": 1673, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.4367218017578, \"iteration\": 1674, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.89974975585938, \"iteration\": 1675, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 162.40560913085938, \"iteration\": 1676, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.9443359375, \"iteration\": 1677, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 161.1057891845703, \"iteration\": 1678, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 196.69671630859375, \"iteration\": 1679, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.1023712158203, \"iteration\": 1680, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 226.44821166992188, \"iteration\": 1681, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 218.15089416503906, \"iteration\": 1682, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.46835327148438, \"iteration\": 1683, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 256.66766357421875, \"iteration\": 1684, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.94651794433594, \"iteration\": 1685, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 162.42648315429688, \"iteration\": 1686, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 167.08035278320312, \"iteration\": 1687, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 171.51254272460938, \"iteration\": 1688, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 166.63076782226562, \"iteration\": 1689, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 162.01287841796875, \"iteration\": 1690, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 231.98611450195312, \"iteration\": 1691, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.8646240234375, \"iteration\": 1692, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 206.20236206054688, \"iteration\": 1693, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.0945281982422, \"iteration\": 1694, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.5574188232422, \"iteration\": 1695, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 145.01480102539062, \"iteration\": 1696, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 153.19740295410156, \"iteration\": 1697, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.59579467773438, \"iteration\": 1698, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 201.02188110351562, \"iteration\": 1699, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.0810546875, \"iteration\": 1700, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 206.52548217773438, \"iteration\": 1701, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 134.06886291503906, \"iteration\": 1702, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 206.02651977539062, \"iteration\": 1703, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 191.0325927734375, \"iteration\": 1704, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 163.16964721679688, \"iteration\": 1705, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 162.3857421875, \"iteration\": 1706, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.9808349609375, \"iteration\": 1707, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 143.2801513671875, \"iteration\": 1708, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.16439819335938, \"iteration\": 1709, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.85205078125, \"iteration\": 1710, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 210.69097900390625, \"iteration\": 1711, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.64617919921875, \"iteration\": 1712, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.11959838867188, \"iteration\": 1713, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 215.95004272460938, \"iteration\": 1714, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 152.62451171875, \"iteration\": 1715, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.19818115234375, \"iteration\": 1716, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 211.2777862548828, \"iteration\": 1717, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 143.15780639648438, \"iteration\": 1718, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 147.77545166015625, \"iteration\": 1719, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.13772583007812, \"iteration\": 1720, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.9962615966797, \"iteration\": 1721, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.26161193847656, \"iteration\": 1722, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 171.69845581054688, \"iteration\": 1723, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 206.04901123046875, \"iteration\": 1724, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 172.15625, \"iteration\": 1725, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 210.6007080078125, \"iteration\": 1726, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 206.26300048828125, \"iteration\": 1727, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 153.1627960205078, \"iteration\": 1728, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 191.97682189941406, \"iteration\": 1729, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.58480834960938, \"iteration\": 1730, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 211.75985717773438, \"iteration\": 1731, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 171.85057067871094, \"iteration\": 1732, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 200.63653564453125, \"iteration\": 1733, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 176.50057983398438, \"iteration\": 1734, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.26519775390625, \"iteration\": 1735, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 220.5274658203125, \"iteration\": 1736, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 208.16409301757812, \"iteration\": 1737, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 210.4785919189453, \"iteration\": 1738, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.7653045654297, \"iteration\": 1739, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 167.19760131835938, \"iteration\": 1740, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 201.40155029296875, \"iteration\": 1741, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 153.4748992919922, \"iteration\": 1742, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 157.744873046875, \"iteration\": 1743, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 153.7479248046875, \"iteration\": 1744, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.3621826171875, \"iteration\": 1745, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 191.9700927734375, \"iteration\": 1746, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 181.0222930908203, \"iteration\": 1747, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 162.56704711914062, \"iteration\": 1748, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 189.7530517578125, \"iteration\": 1749, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 235.85848999023438, \"iteration\": 1750, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 186.65045166015625, \"iteration\": 1751, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 163.05482482910156, \"iteration\": 1752, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 167.64804077148438, \"iteration\": 1753, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 162.28890991210938, \"iteration\": 1754, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 191.8934326171875, \"iteration\": 1755, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 225.98776245117188, \"iteration\": 1756, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 167.20481872558594, \"iteration\": 1757, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 190.88543701171875, \"iteration\": 1758, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 191.87777709960938, \"iteration\": 1759, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 201.78321838378906, \"iteration\": 1760, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 277.23626708984375, \"iteration\": 1761, \"epoch\": 10}, {\"training_acc\": 0.9765625, \"training_loss\": 236.27479553222656, \"iteration\": 1762, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 128.931396484375, \"iteration\": 1763, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 181.1717987060547, \"iteration\": 1764, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 203.76304626464844, \"iteration\": 1765, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 181.07147216796875, \"iteration\": 1766, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 158.39508056640625, \"iteration\": 1767, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 170.64773559570312, \"iteration\": 1768, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 219.91624450683594, \"iteration\": 1769, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 173.222900390625, \"iteration\": 1770, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 187.59107971191406, \"iteration\": 1771, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 172.52578735351562, \"iteration\": 1772, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 206.492919921875, \"iteration\": 1773, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 148.8182373046875, \"iteration\": 1774, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 209.10861206054688, \"iteration\": 1775, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 171.68190002441406, \"iteration\": 1776, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 168.81900024414062, \"iteration\": 1777, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 253.14002990722656, \"iteration\": 1778, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 168.18246459960938, \"iteration\": 1779, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.55545711517334, \"iteration\": 1780, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normal threshold\n",
    "model_nn_threshold_05 = NeuralNetwork(\n",
    "    input_size=len(train_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    positive_pred_threshold=0.5,  # makes it easier to predict positive\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "if Path('models/model_nn_threshold_05.pt').exists() and USE_CACHE:\n",
    "    model_nn_threshold_05 = load_model(model_nn_threshold_05, 'model_nn_threshold_05')\n",
    "else:\n",
    "    model_nn_threshold_05.fit(train_dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn_threshold_05, \"model_nn_threshold_05\")\n",
    "\n",
    "model_nn_threshold_05_results = evaluate_nn_model(model_nn_threshold_05, test_dataset)\n",
    "np.save('models/model_nn_threshold_05_results.npy', model_nn_threshold_05_results)\n",
    "print(model_nn_threshold_05_results)\n",
    "\n",
    "model_nn_threshold_05.cpu()\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn_threshold_05, train_config, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose decision threshold according to ROC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-weight the classes\n",
    "Seems to be less effective than changing decision threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1498704663212436 0.8846920470400638\n"
     ]
    }
   ],
   "source": [
    "weight_0 = len(train_raw) / (2 * sum(np.array(train_raw.labels) == 0))\n",
    "weight_1 = len(train_raw) / (2 * sum(np.array(train_raw.labels) == 1))\n",
    "\n",
    "print(weight_0, weight_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data encoder...\n",
      "Vocabulary 50000\n",
      "Prepare data...\n",
      "Train model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/178 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cross_entropy: weight tensor should be defined either for all 128 classes or no classes but got weight tensor of shape: [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m     model_nn_balkan \u001b[38;5;241m=\u001b[39m load_model(model_nn_balkan, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_nn_balkan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mmodel_nn_balkan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     save_model(model_nn_balkan, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_nn_balkan\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m model_nn_balkan_results \u001b[38;5;241m=\u001b[39m evaluate_nn_model(model_nn_balkan, test_dataset)\n",
      "File \u001b[0;32m/media/hapham/Work/study/power-identification/models.py:138\u001b[0m, in \u001b[0;36mNeuralNetwork.fit\u001b[0;34m(self, train_dataloader, train_config, disable_progress_bar)\u001b[0m\n\u001b[1;32m    135\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(X_train)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# print(logits.shape, y_train.shape)\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    140\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/power/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/power/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/power/lib/python3.11/site-packages/torch/nn/modules/loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/power/lib/python3.11/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cross_entropy: weight tensor should be defined either for all 128 classes or no classes but got weight tensor of shape: [2]"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Prepare data encoder...\")\n",
    "# train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "train_encoder = TfidfVectorizer(max_features=50000, analyzer=\"char\", ngram_range=(3,5))\n",
    "train_encoder.fit(train_raw.texts)\n",
    "print(\"Vocabulary\", len(train_encoder.vocabulary_))\n",
    "\n",
    "print(\"Prepare data...\")\n",
    "train_dataset = encode_data(train_raw, train_encoder)\n",
    "test_dataset = encode_data(test_raw, train_encoder)\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 178/178 [00:02<00:00, 66.37batch/s, batch_accuracy=0.75, loss=0.926] \n",
      "Epoch 2: 100%|██████████| 178/178 [00:02<00:00, 67.02batch/s, batch_accuracy=1, loss=0.432]    \n",
      "Epoch 3: 100%|██████████| 178/178 [00:02<00:00, 67.29batch/s, batch_accuracy=0.938, loss=0.536]\n",
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 68.55batch/s, batch_accuracy=1, loss=0.166]    \n",
      "Epoch 5: 100%|██████████| 178/178 [00:02<00:00, 70.06batch/s, batch_accuracy=1, loss=0.0298]    \n",
      "Epoch 6: 100%|██████████| 178/178 [00:02<00:00, 67.30batch/s, batch_accuracy=1, loss=0.104]     \n",
      "Epoch 7: 100%|██████████| 178/178 [00:02<00:00, 66.14batch/s, batch_accuracy=1, loss=0.00704]   \n",
      "Epoch 8: 100%|██████████| 178/178 [00:02<00:00, 67.52batch/s, batch_accuracy=1, loss=0.0407]    \n",
      "Epoch 9: 100%|██████████| 178/178 [00:02<00:00, 67.77batch/s, batch_accuracy=1, loss=0.0017]    \n",
      "Epoch 10: 100%|██████████| 178/178 [00:02<00:00, 68.01batch/s, batch_accuracy=1, loss=0.00155]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7430871725082397, 0.6112446188926697, 0.634097695350647, 0.4365734074184232)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1b6db69ebcdc4473b5f05a91965ac038.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1b6db69ebcdc4473b5f05a91965ac038.vega-embed details,\n",
       "  #altair-viz-1b6db69ebcdc4473b5f05a91965ac038.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1b6db69ebcdc4473b5f05a91965ac038\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1b6db69ebcdc4473b5f05a91965ac038\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1b6db69ebcdc4473b5f05a91965ac038\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-fa751e9d25e1f4e9b9f535aba4f7604f\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-fa751e9d25e1f4e9b9f535aba4f7604f\": [{\"training_acc\": 0.5703125, \"training_loss\": 0.9968422651290894, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.9429190158843994, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.390625, \"training_loss\": 0.9250450134277344, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 0.9778231382369995, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.390625, \"training_loss\": 0.9587699770927429, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.375, \"training_loss\": 0.9478086233139038, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.3828125, \"training_loss\": 0.9480594396591187, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.265625, \"training_loss\": 0.8890591859817505, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.3828125, \"training_loss\": 0.9470521807670593, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 0.958121657371521, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.3671875, \"training_loss\": 0.9365062117576599, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.390625, \"training_loss\": 0.9485819339752197, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.3203125, \"training_loss\": 0.8997881412506104, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.34375, \"training_loss\": 0.9101145267486572, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 0.9197193384170532, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 0.9382786154747009, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 0.9235104322433472, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.46875, \"training_loss\": 0.9466041326522827, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 0.9241138696670532, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 0.9300811290740967, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.4453125, \"training_loss\": 0.9203652739524841, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.4453125, \"training_loss\": 0.911628782749176, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.4296875, \"training_loss\": 0.9209108948707581, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.375, \"training_loss\": 0.8884296417236328, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 0.8711308240890503, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.8798485994338989, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.8677158355712891, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.8904961347579956, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.9073270559310913, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.9053988456726074, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.8572789430618286, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.9018633961677551, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.8841534852981567, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 0.8628407716751099, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.8589632511138916, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.858605146408081, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.8430149555206299, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.8381233215332031, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.844591498374939, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.8536317348480225, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.8138130903244019, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.840217113494873, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.8071261644363403, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.8010441064834595, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.8239814043045044, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.8371588587760925, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.7735066413879395, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.7902374267578125, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.790483295917511, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.8264171481132507, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.7538939714431763, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.8154415488243103, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.7662299871444702, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.7975897192955017, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.7970575094223022, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.7321915626525879, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.8108103275299072, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.7043554782867432, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.7654632925987244, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.7328022122383118, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.7555635571479797, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.7103298902511597, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.7071624398231506, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.6743969917297363, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.7585344910621643, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.6746020317077637, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.7350397109985352, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6645009517669678, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.6976655721664429, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.7585767507553101, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.7076901197433472, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.7326455116271973, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.7635928392410278, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.8420472145080566, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.6243549585342407, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.7432924509048462, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.7195488214492798, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.6660779714584351, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.6978250741958618, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.6363056302070618, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.8188418745994568, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.7724157571792603, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.68172287940979, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.7377393245697021, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.7491346001625061, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.7554570436477661, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.7459805011749268, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.6794177889823914, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.7585119009017944, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.820387065410614, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.741561233997345, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.7843658924102783, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.6726138591766357, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.7925775647163391, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.7877846956253052, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.6219936609268188, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.6758812665939331, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.8597104549407959, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.7507083415985107, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.8474395275115967, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.7234846949577332, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6974869966506958, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.7079624533653259, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.6317394971847534, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.6693733930587769, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.6534532904624939, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.7784867286682129, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.7013124227523804, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.8145385980606079, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.6841915845870972, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.7125775814056396, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.748881995677948, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.7331748008728027, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.7244859337806702, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.651267409324646, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.6149028539657593, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.637826681137085, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.7703303694725037, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.7123721241950989, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.679052472114563, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5897173881530762, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.7524089813232422, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6587237119674683, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.7288520932197571, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5655139684677124, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.7444864511489868, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.7159837484359741, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.6083760261535645, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.6781879663467407, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.7249464988708496, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.6329099535942078, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5443098545074463, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6566075086593628, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.7339664697647095, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.6803670525550842, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.731932520866394, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.7511751651763916, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.8428873419761658, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.584134578704834, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5174418687820435, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.6687133312225342, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.8043824434280396, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.6008000373840332, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.7005854845046997, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5797269940376282, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6220705509185791, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.6218420267105103, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.679088830947876, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.7163487672805786, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.7232573628425598, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.5474295020103455, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.6463977098464966, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5473533868789673, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.6690758466720581, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.8343113660812378, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6172788143157959, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.6638438701629639, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6691182255744934, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5769984722137451, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.644237220287323, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.6090037822723389, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.6842532157897949, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6563714742660522, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.6889355778694153, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.7227041721343994, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.6733174324035645, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.655627429485321, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.7521296739578247, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.6189569234848022, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.7223236560821533, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5717693567276001, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5995303392410278, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5985740423202515, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.6936440467834473, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.7203700542449951, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.6780270338058472, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5826311111450195, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.9261247515678406, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5864629745483398, \"iteration\": 179, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.4510454535484314, \"iteration\": 180, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.4599204361438751, \"iteration\": 181, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.5556491613388062, \"iteration\": 182, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.5539949536323547, \"iteration\": 183, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.5700043439865112, \"iteration\": 184, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5472683906555176, \"iteration\": 185, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.4707569479942322, \"iteration\": 186, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3983684778213501, \"iteration\": 187, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5371308326721191, \"iteration\": 188, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.5117576122283936, \"iteration\": 189, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.3980877995491028, \"iteration\": 190, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4567376971244812, \"iteration\": 191, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5154474973678589, \"iteration\": 192, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5546005964279175, \"iteration\": 193, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.6206109523773193, \"iteration\": 194, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.5588706731796265, \"iteration\": 195, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.46525853872299194, \"iteration\": 196, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.47397106885910034, \"iteration\": 197, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5451545715332031, \"iteration\": 198, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.47607043385505676, \"iteration\": 199, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.49974316358566284, \"iteration\": 200, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.47641587257385254, \"iteration\": 201, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5137425661087036, \"iteration\": 202, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.5377198457717896, \"iteration\": 203, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.45806872844696045, \"iteration\": 204, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.589828372001648, \"iteration\": 205, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.528794527053833, \"iteration\": 206, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.4398317337036133, \"iteration\": 207, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.519385039806366, \"iteration\": 208, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 0.5650537610054016, \"iteration\": 209, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5307020545005798, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.537238597869873, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.4851195812225342, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.41309428215026855, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.47513553500175476, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5431788563728333, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5197653770446777, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.47732415795326233, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.43775367736816406, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4184165298938751, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5291208028793335, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.5150650143623352, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.4621395170688629, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.5653313398361206, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.43693381547927856, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5175530910491943, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.4679792523384094, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.5071626901626587, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4521282911300659, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.46952784061431885, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.4668238162994385, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.4661461412906647, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5183648467063904, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.46228206157684326, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.5389260649681091, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.40598779916763306, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.5052989721298218, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.43147796392440796, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.519662082195282, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5158280730247498, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.4319317936897278, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.46656686067581177, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5718696713447571, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5920863151550293, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5426572561264038, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4517781734466553, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.34926676750183105, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.4774185121059418, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.5708150267601013, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4985780417919159, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5425204634666443, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5023226737976074, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5146566033363342, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5978304743766785, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.4786897897720337, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.37285396456718445, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.5228018760681152, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.5431081056594849, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.38719648122787476, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.4590824842453003, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.419497013092041, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.5032176375389099, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.4452531635761261, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4759472608566284, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5300374627113342, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.4259049892425537, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 0.7107628583908081, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.5495357513427734, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 0.5140995383262634, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4557158052921295, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5825580954551697, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.5393968224525452, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.56601482629776, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.4531781077384949, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.6172892451286316, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.5747019052505493, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5315457582473755, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.47684627771377563, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.49674785137176514, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.5566365718841553, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5987857580184937, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.5851215720176697, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.589210569858551, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.4369230270385742, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.45868802070617676, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.5160804986953735, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.562027096748352, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.6715918779373169, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 0.44532936811447144, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.5566951632499695, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 0.7307261228561401, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.4925006330013275, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.45837199687957764, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5415132641792297, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.3980276584625244, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.6577569246292114, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5478780269622803, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5102362632751465, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4284211993217468, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3979473114013672, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5561784505844116, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5242918729782104, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5508261919021606, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.5816667079925537, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.6315510272979736, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.48764050006866455, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.4714318513870239, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5309058427810669, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.4144163727760315, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.6324726343154907, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.5071990489959717, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5957174301147461, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4725390374660492, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.5385257601737976, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.5342196226119995, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.42469340562820435, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4819580912590027, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.4947274923324585, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.47305819392204285, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.5326957702636719, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.4957035183906555, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5394400358200073, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.44775626063346863, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.41119062900543213, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.42999184131622314, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.41852450370788574, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.47142845392227173, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4739055633544922, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.41727057099342346, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.5337389707565308, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.5330077409744263, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5606751441955566, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.6056821942329407, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.44916388392448425, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5315631628036499, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.5131133794784546, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5611550211906433, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.48466604948043823, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.396064817905426, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.5420185327529907, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4923011064529419, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4989941716194153, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.40218472480773926, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4857786297798157, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.5021544694900513, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.49707749485969543, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.5376588106155396, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.5185251235961914, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.44437482953071594, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.5371863842010498, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5388997197151184, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5101583003997803, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.46444231271743774, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5277423858642578, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.6599412560462952, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3533564507961273, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 1.0, \"training_loss\": 0.4318855106830597, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4368744194507599, \"iteration\": 357, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.3251084089279175, \"iteration\": 358, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3333400785923004, \"iteration\": 359, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.38969963788986206, \"iteration\": 360, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.28079813718795776, \"iteration\": 361, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.3783038854598999, \"iteration\": 362, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.36350375413894653, \"iteration\": 363, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.39515894651412964, \"iteration\": 364, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.37965887784957886, \"iteration\": 365, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40999865531921387, \"iteration\": 366, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.30225276947021484, \"iteration\": 367, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.34464001655578613, \"iteration\": 368, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.288196325302124, \"iteration\": 369, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3882201910018921, \"iteration\": 370, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.259001761674881, \"iteration\": 371, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.28252652287483215, \"iteration\": 372, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3214912712574005, \"iteration\": 373, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3512284755706787, \"iteration\": 374, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3430285155773163, \"iteration\": 375, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.28441959619522095, \"iteration\": 376, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32117778062820435, \"iteration\": 377, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3385452926158905, \"iteration\": 378, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.31425973773002625, \"iteration\": 379, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.359164297580719, \"iteration\": 380, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3318794369697571, \"iteration\": 381, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3598860502243042, \"iteration\": 382, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.40107929706573486, \"iteration\": 383, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3666818141937256, \"iteration\": 384, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3374457061290741, \"iteration\": 385, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.42352330684661865, \"iteration\": 386, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3557601571083069, \"iteration\": 387, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.27167606353759766, \"iteration\": 388, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.35723876953125, \"iteration\": 389, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3021814227104187, \"iteration\": 390, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.4222765266895294, \"iteration\": 391, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.24575382471084595, \"iteration\": 392, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.29281705617904663, \"iteration\": 393, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.3083122670650482, \"iteration\": 394, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3450279235839844, \"iteration\": 395, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.337643027305603, \"iteration\": 396, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3670866787433624, \"iteration\": 397, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.28621429204940796, \"iteration\": 398, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2717971205711365, \"iteration\": 399, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.3066835403442383, \"iteration\": 400, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3928591012954712, \"iteration\": 401, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.34080392122268677, \"iteration\": 402, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3049171566963196, \"iteration\": 403, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.32254576683044434, \"iteration\": 404, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.24595987796783447, \"iteration\": 405, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1519375741481781, \"iteration\": 406, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.20569950342178345, \"iteration\": 407, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3561054766178131, \"iteration\": 408, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.3365707993507385, \"iteration\": 409, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.4139237403869629, \"iteration\": 410, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.4189167618751526, \"iteration\": 411, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3979818522930145, \"iteration\": 412, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.2364230453968048, \"iteration\": 413, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.33975034952163696, \"iteration\": 414, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5590522289276123, \"iteration\": 415, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.48563215136528015, \"iteration\": 416, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.45959290862083435, \"iteration\": 417, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.39481019973754883, \"iteration\": 418, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.27667760848999023, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.34388431906700134, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.38069579005241394, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.4321955442428589, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.33594489097595215, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.32049569487571716, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3832458257675171, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3435620069503784, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3288741409778595, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2990191876888275, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2882934808731079, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.4456174373626709, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.44159945845603943, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.36483389139175415, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3083110749721527, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34583860635757446, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24400675296783447, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3130512833595276, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.35709381103515625, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.4034852385520935, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.30302631855010986, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.4821705222129822, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2700321078300476, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3435751497745514, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3977152705192566, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3684411942958832, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3931475281715393, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.25496578216552734, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3770406246185303, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.4021133780479431, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2934533357620239, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.2862899899482727, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28392308950424194, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.45494306087493896, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3090183138847351, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.35442614555358887, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.374272882938385, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.25816699862480164, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.46474894881248474, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3112621307373047, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3245090842247009, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3968278765678406, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.4666036367416382, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3814827799797058, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.4007241725921631, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3784528970718384, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.3781011998653412, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5050086975097656, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.5011003613471985, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.34931308031082153, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2379389852285385, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.35731810331344604, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2962336242198944, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.4406379461288452, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.3038691282272339, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.3188016414642334, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.36343029141426086, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.378496915102005, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.33595946431159973, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2949841022491455, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4383401870727539, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.42530936002731323, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2819695472717285, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33146893978118896, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.377299427986145, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.4011695384979248, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3703421652317047, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3422369062900543, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3348349630832672, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.28564634919166565, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.5178055763244629, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.41490593552589417, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31816574931144714, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.29657211899757385, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3666672110557556, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.2816513776779175, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.38041532039642334, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4863339066505432, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.43010780215263367, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4708546996116638, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.31480592489242554, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.37982648611068726, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.36818408966064453, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3841405510902405, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3905434310436249, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.37792181968688965, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.42587020993232727, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.38277527689933777, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4674425423145294, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3446419835090637, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.4121721684932709, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.33514127135276794, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3583719730377197, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.3029538094997406, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.39897283911705017, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.41863226890563965, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3610674738883972, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.37458616495132446, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.3927662670612335, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.29969522356987, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.32326292991638184, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3515664339065552, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3317069411277771, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2715010643005371, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.4600290060043335, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.4152681231498718, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.4370662569999695, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.4829893708229065, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3758046627044678, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 0.5860744118690491, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4821193218231201, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.32907548546791077, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.30641061067581177, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.3554036021232605, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3573318123817444, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.5362695455551147, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24734221398830414, \"iteration\": 535, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27176928520202637, \"iteration\": 536, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.322267085313797, \"iteration\": 537, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3538740873336792, \"iteration\": 538, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.2316761463880539, \"iteration\": 539, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.20007982850074768, \"iteration\": 540, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.21515820920467377, \"iteration\": 541, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.25587180256843567, \"iteration\": 542, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.23103195428848267, \"iteration\": 543, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19018584489822388, \"iteration\": 544, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.21652856469154358, \"iteration\": 545, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.204448401927948, \"iteration\": 546, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21228763461112976, \"iteration\": 547, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.34367480874061584, \"iteration\": 548, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.29537108540534973, \"iteration\": 549, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.2221861183643341, \"iteration\": 550, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.20639583468437195, \"iteration\": 551, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.21660861372947693, \"iteration\": 552, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.21174339950084686, \"iteration\": 553, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20739838480949402, \"iteration\": 554, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20881903171539307, \"iteration\": 555, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24401690065860748, \"iteration\": 556, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20222917199134827, \"iteration\": 557, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.16168728470802307, \"iteration\": 558, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.2849915325641632, \"iteration\": 559, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.2358705699443817, \"iteration\": 560, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.21729201078414917, \"iteration\": 561, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1912354677915573, \"iteration\": 562, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.1246989443898201, \"iteration\": 563, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.20376025140285492, \"iteration\": 564, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.2051989734172821, \"iteration\": 565, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21832787990570068, \"iteration\": 566, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.18185624480247498, \"iteration\": 567, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.31739678978919983, \"iteration\": 568, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.12321178615093231, \"iteration\": 569, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.20533853769302368, \"iteration\": 570, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.2762400507926941, \"iteration\": 571, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.2265065312385559, \"iteration\": 572, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.15745943784713745, \"iteration\": 573, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1965876668691635, \"iteration\": 574, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.18206354975700378, \"iteration\": 575, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2238546758890152, \"iteration\": 576, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26029545068740845, \"iteration\": 577, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.24447226524353027, \"iteration\": 578, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.20303402841091156, \"iteration\": 579, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.228904128074646, \"iteration\": 580, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.15086351335048676, \"iteration\": 581, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2270408272743225, \"iteration\": 582, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.22118058800697327, \"iteration\": 583, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2175348699092865, \"iteration\": 584, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1936185359954834, \"iteration\": 585, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.20636144280433655, \"iteration\": 586, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.19989214837551117, \"iteration\": 587, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10727947950363159, \"iteration\": 588, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.30690276622772217, \"iteration\": 589, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.22004206478595734, \"iteration\": 590, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.27388107776641846, \"iteration\": 591, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.25886815786361694, \"iteration\": 592, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24729067087173462, \"iteration\": 593, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1952441930770874, \"iteration\": 594, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20995499193668365, \"iteration\": 595, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.22189295291900635, \"iteration\": 596, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1947592943906784, \"iteration\": 597, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18627960979938507, \"iteration\": 598, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.19012536108493805, \"iteration\": 599, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.21612736582756042, \"iteration\": 600, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1858399212360382, \"iteration\": 601, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.18131285905838013, \"iteration\": 602, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21480542421340942, \"iteration\": 603, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21705329418182373, \"iteration\": 604, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.1009245365858078, \"iteration\": 605, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1774948239326477, \"iteration\": 606, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19773709774017334, \"iteration\": 607, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14683648943901062, \"iteration\": 608, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1882927119731903, \"iteration\": 609, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1939786821603775, \"iteration\": 610, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.22633053362369537, \"iteration\": 611, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.26855671405792236, \"iteration\": 612, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.16637390851974487, \"iteration\": 613, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20203283429145813, \"iteration\": 614, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.22629782557487488, \"iteration\": 615, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.27441346645355225, \"iteration\": 616, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2854977250099182, \"iteration\": 617, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3051549196243286, \"iteration\": 618, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.205095574259758, \"iteration\": 619, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.26546016335487366, \"iteration\": 620, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.194477379322052, \"iteration\": 621, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.25089526176452637, \"iteration\": 622, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12991581857204437, \"iteration\": 623, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.22333142161369324, \"iteration\": 624, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16407547891139984, \"iteration\": 625, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18214993178844452, \"iteration\": 626, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.22283697128295898, \"iteration\": 627, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.10829956829547882, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.19758716225624084, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.28905969858169556, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.21443653106689453, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.177127867937088, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.315110445022583, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14873507618904114, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1821879893541336, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23156967759132385, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.22191163897514343, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.20373399555683136, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1895444095134735, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.3414725661277771, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20537269115447998, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.19978779554367065, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.37564146518707275, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.18962903320789337, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.28645944595336914, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2509598731994629, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15370586514472961, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.20167481899261475, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18916308879852295, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1792038083076477, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.30878108739852905, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19984742999076843, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.3432748317718506, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.2377249002456665, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.17445959150791168, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1487506628036499, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.270793616771698, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17609408497810364, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24658113718032837, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.31679749488830566, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.23391342163085938, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.17239871621131897, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1527947634458542, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.35068175196647644, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.36230796575546265, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.21194200217723846, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.35894083976745605, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.2666681408882141, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.376081645488739, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.21890807151794434, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.2311037927865982, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2865653336048126, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.2676447033882141, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.27570754289627075, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3019905090332031, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2709175646305084, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3600645959377289, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.33117228746414185, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.27996307611465454, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2935589849948883, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.21969491243362427, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.22399353981018066, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.3464963734149933, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2634621560573578, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.20475822687149048, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.36513984203338623, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.40456366539001465, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2753421664237976, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.13122451305389404, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.269162654876709, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.3610254228115082, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3615405857563019, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15853086113929749, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.33056509494781494, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.36391955614089966, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2560349702835083, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.24199248850345612, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.21560636162757874, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.24973537027835846, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.22503191232681274, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.21314027905464172, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.3425160050392151, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3051377534866333, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.3313383162021637, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.25180402398109436, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23251822590827942, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.29739946126937866, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21443097293376923, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.26193922758102417, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.2148924171924591, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.17161887884140015, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.16642963886260986, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.12513598799705505, \"iteration\": 713, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.10044226795434952, \"iteration\": 714, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1545594185590744, \"iteration\": 715, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.11490535736083984, \"iteration\": 716, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.14561012387275696, \"iteration\": 717, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.11617738008499146, \"iteration\": 718, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10023754835128784, \"iteration\": 719, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13735221326351166, \"iteration\": 720, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10836721211671829, \"iteration\": 721, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.26063233613967896, \"iteration\": 722, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1464950293302536, \"iteration\": 723, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0933767706155777, \"iteration\": 724, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.14980433881282806, \"iteration\": 725, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.21888157725334167, \"iteration\": 726, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09960193932056427, \"iteration\": 727, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.1153140738606453, \"iteration\": 728, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08695361018180847, \"iteration\": 729, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.21981504559516907, \"iteration\": 730, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.21650558710098267, \"iteration\": 731, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13106490671634674, \"iteration\": 732, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1303115338087082, \"iteration\": 733, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1119103953242302, \"iteration\": 734, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10406796634197235, \"iteration\": 735, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.16476458311080933, \"iteration\": 736, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.12447887659072876, \"iteration\": 737, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.15082813799381256, \"iteration\": 738, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11233438551425934, \"iteration\": 739, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.16892948746681213, \"iteration\": 740, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10140848159790039, \"iteration\": 741, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08615216612815857, \"iteration\": 742, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11525537818670273, \"iteration\": 743, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10305961966514587, \"iteration\": 744, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.12186942994594574, \"iteration\": 745, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.18270455300807953, \"iteration\": 746, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.09145639836788177, \"iteration\": 747, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14055532217025757, \"iteration\": 748, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.14298202097415924, \"iteration\": 749, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10741794109344482, \"iteration\": 750, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.21218836307525635, \"iteration\": 751, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13002407550811768, \"iteration\": 752, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0904461145401001, \"iteration\": 753, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12856493890285492, \"iteration\": 754, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.13260863721370697, \"iteration\": 755, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09358972311019897, \"iteration\": 756, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09300059080123901, \"iteration\": 757, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10310511291027069, \"iteration\": 758, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11503548920154572, \"iteration\": 759, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.16631072759628296, \"iteration\": 760, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08357705920934677, \"iteration\": 761, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.06181460991501808, \"iteration\": 762, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.07452915608882904, \"iteration\": 763, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.285538911819458, \"iteration\": 764, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07572877407073975, \"iteration\": 765, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1120702251791954, \"iteration\": 766, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.10183476656675339, \"iteration\": 767, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.16984733939170837, \"iteration\": 768, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15885204076766968, \"iteration\": 769, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1636987179517746, \"iteration\": 770, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07178255915641785, \"iteration\": 771, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.11565952003002167, \"iteration\": 772, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.19785624742507935, \"iteration\": 773, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1490972489118576, \"iteration\": 774, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09493398666381836, \"iteration\": 775, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.10136666893959045, \"iteration\": 776, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.16525940597057343, \"iteration\": 777, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12450844049453735, \"iteration\": 778, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1771712303161621, \"iteration\": 779, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15850390493869781, \"iteration\": 780, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.12949314713478088, \"iteration\": 781, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.3094979524612427, \"iteration\": 782, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.18428248167037964, \"iteration\": 783, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14873158931732178, \"iteration\": 784, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.17971237003803253, \"iteration\": 785, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.15353940427303314, \"iteration\": 786, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11799301207065582, \"iteration\": 787, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1862093210220337, \"iteration\": 788, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10570868849754333, \"iteration\": 789, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.256140798330307, \"iteration\": 790, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1945062130689621, \"iteration\": 791, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1200147345662117, \"iteration\": 792, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11662223190069199, \"iteration\": 793, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1890023946762085, \"iteration\": 794, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1344689130783081, \"iteration\": 795, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16733989119529724, \"iteration\": 796, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1629278063774109, \"iteration\": 797, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11045129597187042, \"iteration\": 798, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.17856928706169128, \"iteration\": 799, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0913534015417099, \"iteration\": 800, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.11256413161754608, \"iteration\": 801, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.11797986179590225, \"iteration\": 802, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.09312938153743744, \"iteration\": 803, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09362034499645233, \"iteration\": 804, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.23022568225860596, \"iteration\": 805, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.10417026281356812, \"iteration\": 806, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0878320038318634, \"iteration\": 807, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.19411972165107727, \"iteration\": 808, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0901632010936737, \"iteration\": 809, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.06090506166219711, \"iteration\": 810, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11916711926460266, \"iteration\": 811, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11291596293449402, \"iteration\": 812, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.09338115155696869, \"iteration\": 813, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13641417026519775, \"iteration\": 814, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.16908839344978333, \"iteration\": 815, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14248016476631165, \"iteration\": 816, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09321127086877823, \"iteration\": 817, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1553746461868286, \"iteration\": 818, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.08553601801395416, \"iteration\": 819, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09419213235378265, \"iteration\": 820, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11849962174892426, \"iteration\": 821, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1207653135061264, \"iteration\": 822, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09984104335308075, \"iteration\": 823, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1841525435447693, \"iteration\": 824, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.19983547925949097, \"iteration\": 825, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.24758774042129517, \"iteration\": 826, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18880602717399597, \"iteration\": 827, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.12032138556241989, \"iteration\": 828, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.16728812456130981, \"iteration\": 829, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07840710878372192, \"iteration\": 830, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14842572808265686, \"iteration\": 831, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11704142391681671, \"iteration\": 832, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10904280841350555, \"iteration\": 833, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.10812117159366608, \"iteration\": 834, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.07351629436016083, \"iteration\": 835, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1667063683271408, \"iteration\": 836, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11101093888282776, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0861385241150856, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11325033009052277, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1907641589641571, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.21193048357963562, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08870196342468262, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14163388311862946, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1226363331079483, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.119685098528862, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.08277962356805801, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.16650399565696716, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.11753851175308228, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14795012772083282, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11630182713270187, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13787317276000977, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1697167605161667, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08753195405006409, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11722299456596375, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07647036015987396, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1082504466176033, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18858447670936584, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14091552793979645, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10818485915660858, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13104625046253204, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15143956243991852, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08661825954914093, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1833692044019699, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1453121304512024, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10346793383359909, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.2692244052886963, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1167650818824768, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.2115372121334076, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14844051003456116, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.14047805964946747, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.07963582128286362, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0872693732380867, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.12886211276054382, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08761577308177948, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11092468351125717, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.14363673329353333, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0948297381401062, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10918031632900238, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.07034197449684143, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.176548033952713, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15625999867916107, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.16974122822284698, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.22472146153450012, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.21405687928199768, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09995301067829132, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.13228784501552582, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09656409919261932, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08617114275693893, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.11909215152263641, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02979474700987339, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09294998645782471, \"iteration\": 891, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06447531282901764, \"iteration\": 892, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04421578347682953, \"iteration\": 893, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.1087648794054985, \"iteration\": 894, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08401812613010406, \"iteration\": 895, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09012868255376816, \"iteration\": 896, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03938703238964081, \"iteration\": 897, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.045475948601961136, \"iteration\": 898, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.035325054079294205, \"iteration\": 899, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.07076680660247803, \"iteration\": 900, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.033258795738220215, \"iteration\": 901, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.043617770075798035, \"iteration\": 902, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11249474436044693, \"iteration\": 903, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06283298134803772, \"iteration\": 904, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07532033324241638, \"iteration\": 905, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08747917413711548, \"iteration\": 906, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.039397746324539185, \"iteration\": 907, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08888447284698486, \"iteration\": 908, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05444074049592018, \"iteration\": 909, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040061745792627335, \"iteration\": 910, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04038631170988083, \"iteration\": 911, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07940982282161713, \"iteration\": 912, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07132996618747711, \"iteration\": 913, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.040524110198020935, \"iteration\": 914, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07720544934272766, \"iteration\": 915, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026912230998277664, \"iteration\": 916, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07380715012550354, \"iteration\": 917, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022974522784352303, \"iteration\": 918, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08511851727962494, \"iteration\": 919, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0836714655160904, \"iteration\": 920, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06793195754289627, \"iteration\": 921, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031747519969940186, \"iteration\": 922, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06785140186548233, \"iteration\": 923, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05302504822611809, \"iteration\": 924, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.07472597062587738, \"iteration\": 925, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02970775216817856, \"iteration\": 926, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.043389901518821716, \"iteration\": 927, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06797640770673752, \"iteration\": 928, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07616455107927322, \"iteration\": 929, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07252704352140427, \"iteration\": 930, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04465939849615097, \"iteration\": 931, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0847252607345581, \"iteration\": 932, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.07121849060058594, \"iteration\": 933, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03690943121910095, \"iteration\": 934, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0359819158911705, \"iteration\": 935, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0539843924343586, \"iteration\": 936, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06845208257436752, \"iteration\": 937, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03187699243426323, \"iteration\": 938, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.05736050009727478, \"iteration\": 939, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05802548676729202, \"iteration\": 940, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.033370837569236755, \"iteration\": 941, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02513449639081955, \"iteration\": 942, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06441237777471542, \"iteration\": 943, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.058448635041713715, \"iteration\": 944, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06272479891777039, \"iteration\": 945, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.060499001294374466, \"iteration\": 946, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03255999833345413, \"iteration\": 947, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.046653471887111664, \"iteration\": 948, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05234242230653763, \"iteration\": 949, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06197220832109451, \"iteration\": 950, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11056679487228394, \"iteration\": 951, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09546223282814026, \"iteration\": 952, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046389609575271606, \"iteration\": 953, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0726144015789032, \"iteration\": 954, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05362512171268463, \"iteration\": 955, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0695984959602356, \"iteration\": 956, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0537247397005558, \"iteration\": 957, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10775133967399597, \"iteration\": 958, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.030201813206076622, \"iteration\": 959, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07318872958421707, \"iteration\": 960, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.035232000052928925, \"iteration\": 961, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03270182013511658, \"iteration\": 962, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03567836433649063, \"iteration\": 963, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.07529626786708832, \"iteration\": 964, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.025999411940574646, \"iteration\": 965, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11028709262609482, \"iteration\": 966, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07469526678323746, \"iteration\": 967, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03315526992082596, \"iteration\": 968, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.056184422224760056, \"iteration\": 969, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.047147370874881744, \"iteration\": 970, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07620801031589508, \"iteration\": 971, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02686268836259842, \"iteration\": 972, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07900088280439377, \"iteration\": 973, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039863064885139465, \"iteration\": 974, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07366727292537689, \"iteration\": 975, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.050176963210105896, \"iteration\": 976, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04455504193902016, \"iteration\": 977, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08200637996196747, \"iteration\": 978, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.028889156877994537, \"iteration\": 979, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03763355314731598, \"iteration\": 980, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04145314544439316, \"iteration\": 981, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04069281369447708, \"iteration\": 982, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05158360302448273, \"iteration\": 983, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06697433441877365, \"iteration\": 984, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.040478527545928955, \"iteration\": 985, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11263447254896164, \"iteration\": 986, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.024961229413747787, \"iteration\": 987, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04868315905332565, \"iteration\": 988, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08127979189157486, \"iteration\": 989, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03273674473166466, \"iteration\": 990, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.07668426632881165, \"iteration\": 991, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07794979214668274, \"iteration\": 992, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03164141625165939, \"iteration\": 993, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04710971564054489, \"iteration\": 994, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03535741567611694, \"iteration\": 995, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05255667492747307, \"iteration\": 996, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.10972192138433456, \"iteration\": 997, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0376642569899559, \"iteration\": 998, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03126361966133118, \"iteration\": 999, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06683483719825745, \"iteration\": 1000, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03966350853443146, \"iteration\": 1001, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054473381489515305, \"iteration\": 1002, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.14643320441246033, \"iteration\": 1003, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023019060492515564, \"iteration\": 1004, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04354727640748024, \"iteration\": 1005, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05184527859091759, \"iteration\": 1006, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09056134521961212, \"iteration\": 1007, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10206338763237, \"iteration\": 1008, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06496094167232513, \"iteration\": 1009, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.060221828520298004, \"iteration\": 1010, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.057145893573760986, \"iteration\": 1011, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10902685672044754, \"iteration\": 1012, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07877252250909805, \"iteration\": 1013, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.07086817175149918, \"iteration\": 1014, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10305512696504593, \"iteration\": 1015, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10561317205429077, \"iteration\": 1016, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.029708223417401314, \"iteration\": 1017, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0788511112332344, \"iteration\": 1018, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0334843248128891, \"iteration\": 1019, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020682072266936302, \"iteration\": 1020, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07086502015590668, \"iteration\": 1021, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07707471400499344, \"iteration\": 1022, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06804174184799194, \"iteration\": 1023, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.033516183495521545, \"iteration\": 1024, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.1150551289319992, \"iteration\": 1025, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.021896900609135628, \"iteration\": 1026, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10767217725515366, \"iteration\": 1027, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.053273364901542664, \"iteration\": 1028, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.1249193325638771, \"iteration\": 1029, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07569366693496704, \"iteration\": 1030, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03291204199194908, \"iteration\": 1031, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0803789347410202, \"iteration\": 1032, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05958891287446022, \"iteration\": 1033, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09537762403488159, \"iteration\": 1034, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.031214602291584015, \"iteration\": 1035, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06003369018435478, \"iteration\": 1036, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11037417501211166, \"iteration\": 1037, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07822597026824951, \"iteration\": 1038, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.077945277094841, \"iteration\": 1039, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06868801265954971, \"iteration\": 1040, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10317356139421463, \"iteration\": 1041, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06871914863586426, \"iteration\": 1042, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05102872848510742, \"iteration\": 1043, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08804672211408615, \"iteration\": 1044, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06983363628387451, \"iteration\": 1045, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04311864450573921, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02735099382698536, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10082060843706131, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02831743285059929, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.07554575800895691, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.047626398503780365, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.024140994995832443, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11277756094932556, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09133477509021759, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05538744479417801, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09908605366945267, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05097365751862526, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.1447938084602356, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.04741216078400612, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09630857408046722, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.13679659366607666, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.16846752166748047, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04808223247528076, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12756718695163727, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0846293494105339, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07637350261211395, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.18693798780441284, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.10395254194736481, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05511198192834854, \"iteration\": 1069, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04028264060616493, \"iteration\": 1070, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03328540548682213, \"iteration\": 1071, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.027433406561613083, \"iteration\": 1072, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044567257165908813, \"iteration\": 1073, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.019478531554341316, \"iteration\": 1074, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02535140886902809, \"iteration\": 1075, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.050322048366069794, \"iteration\": 1076, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04733259975910187, \"iteration\": 1077, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024302814155817032, \"iteration\": 1078, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04957466572523117, \"iteration\": 1079, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07352444529533386, \"iteration\": 1080, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08879140019416809, \"iteration\": 1081, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.023066464811563492, \"iteration\": 1082, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02941140905022621, \"iteration\": 1083, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04282993823289871, \"iteration\": 1084, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05424794554710388, \"iteration\": 1085, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.056390997022390366, \"iteration\": 1086, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0234834011644125, \"iteration\": 1087, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024436645209789276, \"iteration\": 1088, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013452872633934021, \"iteration\": 1089, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0903787836432457, \"iteration\": 1090, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04334980994462967, \"iteration\": 1091, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.020270872861146927, \"iteration\": 1092, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014065481722354889, \"iteration\": 1093, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.027353065088391304, \"iteration\": 1094, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.05614021420478821, \"iteration\": 1095, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.05430826172232628, \"iteration\": 1096, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015364403836429119, \"iteration\": 1097, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09247948229312897, \"iteration\": 1098, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.10708209127187729, \"iteration\": 1099, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.020533043891191483, \"iteration\": 1100, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00990731455385685, \"iteration\": 1101, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04224470257759094, \"iteration\": 1102, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03369184210896492, \"iteration\": 1103, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03339829295873642, \"iteration\": 1104, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06184884533286095, \"iteration\": 1105, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06595686823129654, \"iteration\": 1106, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03139667212963104, \"iteration\": 1107, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.03602198511362076, \"iteration\": 1108, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07194748520851135, \"iteration\": 1109, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.025021180510520935, \"iteration\": 1110, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02923646755516529, \"iteration\": 1111, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012921343557536602, \"iteration\": 1112, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02053600177168846, \"iteration\": 1113, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.039394561201334, \"iteration\": 1114, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0168641097843647, \"iteration\": 1115, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04636786878108978, \"iteration\": 1116, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02108778804540634, \"iteration\": 1117, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013749870471656322, \"iteration\": 1118, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0188804529607296, \"iteration\": 1119, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04246387630701065, \"iteration\": 1120, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.08054588735103607, \"iteration\": 1121, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.05788712948560715, \"iteration\": 1122, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01777120679616928, \"iteration\": 1123, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07723070681095123, \"iteration\": 1124, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.025376658886671066, \"iteration\": 1125, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014866807498037815, \"iteration\": 1126, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.020912524312734604, \"iteration\": 1127, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.029789291322231293, \"iteration\": 1128, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.025520864874124527, \"iteration\": 1129, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.08213464915752411, \"iteration\": 1130, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01992807537317276, \"iteration\": 1131, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07885290682315826, \"iteration\": 1132, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04055946320295334, \"iteration\": 1133, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.020214678719639778, \"iteration\": 1134, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.019453290849924088, \"iteration\": 1135, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04892412945628166, \"iteration\": 1136, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.028167493641376495, \"iteration\": 1137, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.073282890021801, \"iteration\": 1138, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.054322998970746994, \"iteration\": 1139, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07270921766757965, \"iteration\": 1140, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013334954157471657, \"iteration\": 1141, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07307572662830353, \"iteration\": 1142, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01700018160045147, \"iteration\": 1143, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.049816641956567764, \"iteration\": 1144, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04022405669093132, \"iteration\": 1145, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028196286410093307, \"iteration\": 1146, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.025402050465345383, \"iteration\": 1147, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06323979794979095, \"iteration\": 1148, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022743111476302147, \"iteration\": 1149, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03895450010895729, \"iteration\": 1150, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.042152807116508484, \"iteration\": 1151, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03128059580922127, \"iteration\": 1152, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02843748778104782, \"iteration\": 1153, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.018646690994501114, \"iteration\": 1154, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022585097700357437, \"iteration\": 1155, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013977140188217163, \"iteration\": 1156, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.030784647911787033, \"iteration\": 1157, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06599058210849762, \"iteration\": 1158, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.019704202190041542, \"iteration\": 1159, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03469710797071457, \"iteration\": 1160, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.023833075538277626, \"iteration\": 1161, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.023114588111639023, \"iteration\": 1162, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.10374246537685394, \"iteration\": 1163, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08775071799755096, \"iteration\": 1164, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024171598255634308, \"iteration\": 1165, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07348078489303589, \"iteration\": 1166, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00948999635875225, \"iteration\": 1167, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.09091367572546005, \"iteration\": 1168, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02705465629696846, \"iteration\": 1169, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.018043220043182373, \"iteration\": 1170, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.053061842918395996, \"iteration\": 1171, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.027698593214154243, \"iteration\": 1172, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02315909042954445, \"iteration\": 1173, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015829645097255707, \"iteration\": 1174, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04430903494358063, \"iteration\": 1175, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.036749787628650665, \"iteration\": 1176, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.018049566075205803, \"iteration\": 1177, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0283145010471344, \"iteration\": 1178, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024325624108314514, \"iteration\": 1179, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01830141991376877, \"iteration\": 1180, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01288643479347229, \"iteration\": 1181, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.030767731368541718, \"iteration\": 1182, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012142812833189964, \"iteration\": 1183, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07102043926715851, \"iteration\": 1184, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06106942892074585, \"iteration\": 1185, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013198579661548138, \"iteration\": 1186, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015943579375743866, \"iteration\": 1187, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07839177548885345, \"iteration\": 1188, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03272666037082672, \"iteration\": 1189, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.019783450290560722, \"iteration\": 1190, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.034205690026283264, \"iteration\": 1191, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022947948426008224, \"iteration\": 1192, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007294831331819296, \"iteration\": 1193, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.034351080656051636, \"iteration\": 1194, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.021978765726089478, \"iteration\": 1195, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.028754618018865585, \"iteration\": 1196, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02253742143511772, \"iteration\": 1197, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015735026448965073, \"iteration\": 1198, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05731431394815445, \"iteration\": 1199, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0209711492061615, \"iteration\": 1200, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02076624520123005, \"iteration\": 1201, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04640951007604599, \"iteration\": 1202, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01831413432955742, \"iteration\": 1203, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0656077116727829, \"iteration\": 1204, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010950845666229725, \"iteration\": 1205, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03416983410716057, \"iteration\": 1206, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016988689079880714, \"iteration\": 1207, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015103636309504509, \"iteration\": 1208, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009734917432069778, \"iteration\": 1209, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03053002990782261, \"iteration\": 1210, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05251976102590561, \"iteration\": 1211, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06818915158510208, \"iteration\": 1212, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024275686591863632, \"iteration\": 1213, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.017754528671503067, \"iteration\": 1214, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04621414095163345, \"iteration\": 1215, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02485169656574726, \"iteration\": 1216, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02069568634033203, \"iteration\": 1217, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022023798897862434, \"iteration\": 1218, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04496965557336807, \"iteration\": 1219, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.046602409332990646, \"iteration\": 1220, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02193337120115757, \"iteration\": 1221, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.025920772925019264, \"iteration\": 1222, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011282416991889477, \"iteration\": 1223, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04039490222930908, \"iteration\": 1224, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0133061483502388, \"iteration\": 1225, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016622237861156464, \"iteration\": 1226, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02585216984152794, \"iteration\": 1227, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.021241579204797745, \"iteration\": 1228, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024643998593091965, \"iteration\": 1229, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012502744793891907, \"iteration\": 1230, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.019267084077000618, \"iteration\": 1231, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02471684291958809, \"iteration\": 1232, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04303430765867233, \"iteration\": 1233, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02153809182345867, \"iteration\": 1234, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04692137986421585, \"iteration\": 1235, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.030152056366205215, \"iteration\": 1236, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04364646226167679, \"iteration\": 1237, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012458069249987602, \"iteration\": 1238, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01696484349668026, \"iteration\": 1239, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012150315567851067, \"iteration\": 1240, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04728623852133751, \"iteration\": 1241, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.017790772020816803, \"iteration\": 1242, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01915203407406807, \"iteration\": 1243, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03387356922030449, \"iteration\": 1244, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02948937751352787, \"iteration\": 1245, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0070376768708229065, \"iteration\": 1246, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005953503306955099, \"iteration\": 1247, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007086270954459906, \"iteration\": 1248, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.018056225031614304, \"iteration\": 1249, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.019455473870038986, \"iteration\": 1250, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013353670947253704, \"iteration\": 1251, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01042888406664133, \"iteration\": 1252, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00835219956934452, \"iteration\": 1253, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04185258597135544, \"iteration\": 1254, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016612790524959564, \"iteration\": 1255, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0077292099595069885, \"iteration\": 1256, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007501048035919666, \"iteration\": 1257, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01684436947107315, \"iteration\": 1258, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031363263726234436, \"iteration\": 1259, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007809067144989967, \"iteration\": 1260, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007669215556234121, \"iteration\": 1261, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023570090532302856, \"iteration\": 1262, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007012277841567993, \"iteration\": 1263, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004943938460201025, \"iteration\": 1264, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006452262867242098, \"iteration\": 1265, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00790589302778244, \"iteration\": 1266, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007719621993601322, \"iteration\": 1267, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007074263412505388, \"iteration\": 1268, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007667033467441797, \"iteration\": 1269, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009324033744633198, \"iteration\": 1270, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008275903761386871, \"iteration\": 1271, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03630249202251434, \"iteration\": 1272, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.017865147441625595, \"iteration\": 1273, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0113792410120368, \"iteration\": 1274, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003927574027329683, \"iteration\": 1275, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01597442291676998, \"iteration\": 1276, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009907571598887444, \"iteration\": 1277, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010625751689076424, \"iteration\": 1278, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0070791165344417095, \"iteration\": 1279, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03238583728671074, \"iteration\": 1280, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005448687821626663, \"iteration\": 1281, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.015713566914200783, \"iteration\": 1282, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008311211131513119, \"iteration\": 1283, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00809243880212307, \"iteration\": 1284, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004716990049928427, \"iteration\": 1285, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02342548780143261, \"iteration\": 1286, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009458526037633419, \"iteration\": 1287, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01300690695643425, \"iteration\": 1288, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004108816850930452, \"iteration\": 1289, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012503382749855518, \"iteration\": 1290, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008324554190039635, \"iteration\": 1291, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008222012780606747, \"iteration\": 1292, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011239181272685528, \"iteration\": 1293, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0057503762654960155, \"iteration\": 1294, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010247382335364819, \"iteration\": 1295, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010029781609773636, \"iteration\": 1296, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008361618965864182, \"iteration\": 1297, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023207468912005424, \"iteration\": 1298, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005780464503914118, \"iteration\": 1299, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008613675832748413, \"iteration\": 1300, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01913224346935749, \"iteration\": 1301, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01343175582587719, \"iteration\": 1302, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0038667130284011364, \"iteration\": 1303, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005920969415456057, \"iteration\": 1304, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.018764346837997437, \"iteration\": 1305, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009719878435134888, \"iteration\": 1306, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013684387318789959, \"iteration\": 1307, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0066916849464178085, \"iteration\": 1308, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006016175262629986, \"iteration\": 1309, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006164644844830036, \"iteration\": 1310, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009590581059455872, \"iteration\": 1311, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009439628571271896, \"iteration\": 1312, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012768689543008804, \"iteration\": 1313, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014653978869318962, \"iteration\": 1314, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005456652492284775, \"iteration\": 1315, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.021158939227461815, \"iteration\": 1316, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012703469954431057, \"iteration\": 1317, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04824001342058182, \"iteration\": 1318, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.02495194412767887, \"iteration\": 1319, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00789052527397871, \"iteration\": 1320, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007398489862680435, \"iteration\": 1321, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.051392920315265656, \"iteration\": 1322, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006268691271543503, \"iteration\": 1323, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008327292278409004, \"iteration\": 1324, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01613229140639305, \"iteration\": 1325, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0065188719891011715, \"iteration\": 1326, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007536459248512983, \"iteration\": 1327, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026844989508390427, \"iteration\": 1328, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012655463069677353, \"iteration\": 1329, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00599338673055172, \"iteration\": 1330, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008177727460861206, \"iteration\": 1331, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006182977929711342, \"iteration\": 1332, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04328140243887901, \"iteration\": 1333, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006812134757637978, \"iteration\": 1334, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.019285183399915695, \"iteration\": 1335, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009988414123654366, \"iteration\": 1336, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014424541965126991, \"iteration\": 1337, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008299827575683594, \"iteration\": 1338, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027582287788391113, \"iteration\": 1339, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009569844231009483, \"iteration\": 1340, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01584351249039173, \"iteration\": 1341, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011677635833621025, \"iteration\": 1342, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005297677591443062, \"iteration\": 1343, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008481472730636597, \"iteration\": 1344, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01285407692193985, \"iteration\": 1345, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01067834161221981, \"iteration\": 1346, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01139709260314703, \"iteration\": 1347, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008786944672465324, \"iteration\": 1348, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011927569285035133, \"iteration\": 1349, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04134773090481758, \"iteration\": 1350, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003278563730418682, \"iteration\": 1351, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0067339446395635605, \"iteration\": 1352, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0069915843196213245, \"iteration\": 1353, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011827876791357994, \"iteration\": 1354, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016921795904636383, \"iteration\": 1355, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007040542084723711, \"iteration\": 1356, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004212190397083759, \"iteration\": 1357, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023185398429632187, \"iteration\": 1358, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004977388773113489, \"iteration\": 1359, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006508063990622759, \"iteration\": 1360, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010775205679237843, \"iteration\": 1361, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00560946948826313, \"iteration\": 1362, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0065654125064611435, \"iteration\": 1363, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010983576998114586, \"iteration\": 1364, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0075218346901237965, \"iteration\": 1365, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01871448941528797, \"iteration\": 1366, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003957481123507023, \"iteration\": 1367, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00233469158411026, \"iteration\": 1368, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014901112765073776, \"iteration\": 1369, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01446724496781826, \"iteration\": 1370, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.022426415234804153, \"iteration\": 1371, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.055434972047805786, \"iteration\": 1372, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004267647862434387, \"iteration\": 1373, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008640671148896217, \"iteration\": 1374, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010751266032457352, \"iteration\": 1375, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.034609224647283554, \"iteration\": 1376, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03473509103059769, \"iteration\": 1377, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04510727524757385, \"iteration\": 1378, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007886570878326893, \"iteration\": 1379, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007910789921879768, \"iteration\": 1380, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.045291103422641754, \"iteration\": 1381, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010493427515029907, \"iteration\": 1382, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005673429928719997, \"iteration\": 1383, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009146376512944698, \"iteration\": 1384, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005267394706606865, \"iteration\": 1385, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0076238010078668594, \"iteration\": 1386, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.047878239303827286, \"iteration\": 1387, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011055182665586472, \"iteration\": 1388, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007356756366789341, \"iteration\": 1389, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006189907900989056, \"iteration\": 1390, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010268826968967915, \"iteration\": 1391, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07748942077159882, \"iteration\": 1392, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009672563523054123, \"iteration\": 1393, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006287004798650742, \"iteration\": 1394, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008831391111016273, \"iteration\": 1395, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008854136802256107, \"iteration\": 1396, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005317332223057747, \"iteration\": 1397, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009733486920595169, \"iteration\": 1398, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004309232346713543, \"iteration\": 1399, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 0.03342519327998161, \"iteration\": 1400, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008159388788044453, \"iteration\": 1401, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004794306121766567, \"iteration\": 1402, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03205297142267227, \"iteration\": 1403, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009447641670703888, \"iteration\": 1404, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.027995526790618896, \"iteration\": 1405, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.03016670234501362, \"iteration\": 1406, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008146369829773903, \"iteration\": 1407, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01830316334962845, \"iteration\": 1408, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05047841742634773, \"iteration\": 1409, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003750644624233246, \"iteration\": 1410, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0074037290178239346, \"iteration\": 1411, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010551083832979202, \"iteration\": 1412, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.017697175964713097, \"iteration\": 1413, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.018083982169628143, \"iteration\": 1414, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.015449875965714455, \"iteration\": 1415, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00870884396135807, \"iteration\": 1416, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01268905121833086, \"iteration\": 1417, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007156165316700935, \"iteration\": 1418, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004953613504767418, \"iteration\": 1419, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0037479810416698456, \"iteration\": 1420, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011003728024661541, \"iteration\": 1421, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013368707150220871, \"iteration\": 1422, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.024295732378959656, \"iteration\": 1423, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.04073379188776016, \"iteration\": 1424, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005442602559924126, \"iteration\": 1425, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004759722389280796, \"iteration\": 1426, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.011145480908453465, \"iteration\": 1427, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003921816125512123, \"iteration\": 1428, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.015351266600191593, \"iteration\": 1429, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005706158932298422, \"iteration\": 1430, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0034785522148013115, \"iteration\": 1431, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005056887865066528, \"iteration\": 1432, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.013467228040099144, \"iteration\": 1433, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003925196826457977, \"iteration\": 1434, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.010153733193874359, \"iteration\": 1435, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.018012482672929764, \"iteration\": 1436, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.01025349460542202, \"iteration\": 1437, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.015047052875161171, \"iteration\": 1438, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005267713218927383, \"iteration\": 1439, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0031886552460491657, \"iteration\": 1440, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00882821436971426, \"iteration\": 1441, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008338511921465397, \"iteration\": 1442, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.022839942947030067, \"iteration\": 1443, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007991740480065346, \"iteration\": 1444, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005770167335867882, \"iteration\": 1445, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00511039886623621, \"iteration\": 1446, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00930099654942751, \"iteration\": 1447, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004287173971533775, \"iteration\": 1448, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002792615909129381, \"iteration\": 1449, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004275500774383545, \"iteration\": 1450, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003167445072904229, \"iteration\": 1451, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003380129812285304, \"iteration\": 1452, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.009107587859034538, \"iteration\": 1453, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.009089055471122265, \"iteration\": 1454, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008160408586263657, \"iteration\": 1455, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0036267992109060287, \"iteration\": 1456, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003923360724002123, \"iteration\": 1457, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00248246849514544, \"iteration\": 1458, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004932893440127373, \"iteration\": 1459, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005263467784970999, \"iteration\": 1460, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0036383881233632565, \"iteration\": 1461, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006025490816682577, \"iteration\": 1462, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006978754885494709, \"iteration\": 1463, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.014935661107301712, \"iteration\": 1464, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002748641185462475, \"iteration\": 1465, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005210711620748043, \"iteration\": 1466, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029142515268176794, \"iteration\": 1467, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008579338900744915, \"iteration\": 1468, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004503372125327587, \"iteration\": 1469, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005883112084120512, \"iteration\": 1470, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004123419988900423, \"iteration\": 1471, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01970754563808441, \"iteration\": 1472, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004032422322779894, \"iteration\": 1473, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003872920759022236, \"iteration\": 1474, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0030074366368353367, \"iteration\": 1475, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0023924666456878185, \"iteration\": 1476, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0024117478169500828, \"iteration\": 1477, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00843085628002882, \"iteration\": 1478, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004683299455791712, \"iteration\": 1479, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005849822890013456, \"iteration\": 1480, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0034559268970042467, \"iteration\": 1481, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003846133593469858, \"iteration\": 1482, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003690708428621292, \"iteration\": 1483, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025169826112687588, \"iteration\": 1484, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004568052943795919, \"iteration\": 1485, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0038279378786683083, \"iteration\": 1486, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0027564556803554296, \"iteration\": 1487, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008403457701206207, \"iteration\": 1488, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007394871674478054, \"iteration\": 1489, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003619487164542079, \"iteration\": 1490, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008611245080828667, \"iteration\": 1491, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0037170976866036654, \"iteration\": 1492, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0047174738720059395, \"iteration\": 1493, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003972637467086315, \"iteration\": 1494, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004874791018664837, \"iteration\": 1495, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003496932564303279, \"iteration\": 1496, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0037017790600657463, \"iteration\": 1497, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025484561920166016, \"iteration\": 1498, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0024430248886346817, \"iteration\": 1499, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.018717115744948387, \"iteration\": 1500, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025103013031184673, \"iteration\": 1501, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04350950941443443, \"iteration\": 1502, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005379839800298214, \"iteration\": 1503, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0030791815370321274, \"iteration\": 1504, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004839420784264803, \"iteration\": 1505, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005567687097936869, \"iteration\": 1506, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005904264748096466, \"iteration\": 1507, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002988498192280531, \"iteration\": 1508, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0028061417397111654, \"iteration\": 1509, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0037244423292577267, \"iteration\": 1510, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004031332675367594, \"iteration\": 1511, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003920508548617363, \"iteration\": 1512, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002422511810436845, \"iteration\": 1513, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0035609425976872444, \"iteration\": 1514, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00348338158801198, \"iteration\": 1515, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0032248192001134157, \"iteration\": 1516, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001693430938757956, \"iteration\": 1517, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0038777743466198444, \"iteration\": 1518, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021009616553783417, \"iteration\": 1519, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.009294788353145123, \"iteration\": 1520, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0022564169485121965, \"iteration\": 1521, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0037995786406099796, \"iteration\": 1522, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029936928767710924, \"iteration\": 1523, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004259105306118727, \"iteration\": 1524, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003320347284898162, \"iteration\": 1525, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003250495996326208, \"iteration\": 1526, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020938178058713675, \"iteration\": 1527, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00345136527903378, \"iteration\": 1528, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00438897218555212, \"iteration\": 1529, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002320394152775407, \"iteration\": 1530, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003258117940276861, \"iteration\": 1531, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0026513512711972, \"iteration\": 1532, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003051623934879899, \"iteration\": 1533, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016838329611346126, \"iteration\": 1534, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002625771565362811, \"iteration\": 1535, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029246786143630743, \"iteration\": 1536, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002716896589845419, \"iteration\": 1537, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001841047895140946, \"iteration\": 1538, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002485062461346388, \"iteration\": 1539, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0026232830714434385, \"iteration\": 1540, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002397779142484069, \"iteration\": 1541, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003224449697881937, \"iteration\": 1542, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003799036145210266, \"iteration\": 1543, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.015280777588486671, \"iteration\": 1544, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002799669746309519, \"iteration\": 1545, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029465515166521072, \"iteration\": 1546, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0023446064442396164, \"iteration\": 1547, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0033480683341622353, \"iteration\": 1548, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0028174337930977345, \"iteration\": 1549, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00590532599017024, \"iteration\": 1550, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017770553240552545, \"iteration\": 1551, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0030677863396704197, \"iteration\": 1552, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004615314304828644, \"iteration\": 1553, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004522986710071564, \"iteration\": 1554, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016167996218428016, \"iteration\": 1555, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0027635195292532444, \"iteration\": 1556, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0042644282802939415, \"iteration\": 1557, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005526059772819281, \"iteration\": 1558, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0036884001456201077, \"iteration\": 1559, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002643707673996687, \"iteration\": 1560, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003588279476389289, \"iteration\": 1561, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004215658642351627, \"iteration\": 1562, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003188452683389187, \"iteration\": 1563, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.010497248731553555, \"iteration\": 1564, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0032694931142032146, \"iteration\": 1565, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004318286664783955, \"iteration\": 1566, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003364989999681711, \"iteration\": 1567, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0033031331840902567, \"iteration\": 1568, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003473162418231368, \"iteration\": 1569, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.015910113230347633, \"iteration\": 1570, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0026873170863837004, \"iteration\": 1571, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0023233704268932343, \"iteration\": 1572, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005390435457229614, \"iteration\": 1573, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005135646089911461, \"iteration\": 1574, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0022197517100721598, \"iteration\": 1575, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004685151390731335, \"iteration\": 1576, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002039853483438492, \"iteration\": 1577, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004616482183337212, \"iteration\": 1578, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0032963515259325504, \"iteration\": 1579, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0033096293918788433, \"iteration\": 1580, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007230017799884081, \"iteration\": 1581, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004287215415388346, \"iteration\": 1582, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002378721721470356, \"iteration\": 1583, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007693727500736713, \"iteration\": 1584, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002341462764889002, \"iteration\": 1585, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0032864853274077177, \"iteration\": 1586, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0034808306954801083, \"iteration\": 1587, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006802165415138006, \"iteration\": 1588, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0022836122661828995, \"iteration\": 1589, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004592947196215391, \"iteration\": 1590, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005739490035921335, \"iteration\": 1591, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0035789322573691607, \"iteration\": 1592, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004602715373039246, \"iteration\": 1593, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0063493745401501656, \"iteration\": 1594, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0033854893408715725, \"iteration\": 1595, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002093302085995674, \"iteration\": 1596, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0063618021085858345, \"iteration\": 1597, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003926290664821863, \"iteration\": 1598, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019828658550977707, \"iteration\": 1599, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021155637223273516, \"iteration\": 1600, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0027390741743147373, \"iteration\": 1601, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001698935404419899, \"iteration\": 1602, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011505596339702606, \"iteration\": 1603, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013281613355502486, \"iteration\": 1604, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015536530409008265, \"iteration\": 1605, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.006367041729390621, \"iteration\": 1606, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011765735689550638, \"iteration\": 1607, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014402719680219889, \"iteration\": 1608, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013524475507438183, \"iteration\": 1609, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003429314587265253, \"iteration\": 1610, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001427048584446311, \"iteration\": 1611, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001824729610234499, \"iteration\": 1612, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002276145853102207, \"iteration\": 1613, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017056758515536785, \"iteration\": 1614, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00211207359097898, \"iteration\": 1615, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002179862232878804, \"iteration\": 1616, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017195317195728421, \"iteration\": 1617, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011632072273641825, \"iteration\": 1618, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014666174538433552, \"iteration\": 1619, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00142282887827605, \"iteration\": 1620, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013812071410939097, \"iteration\": 1621, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015508083160966635, \"iteration\": 1622, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012804045109078288, \"iteration\": 1623, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018686422845348716, \"iteration\": 1624, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013905389932915568, \"iteration\": 1625, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001263557467609644, \"iteration\": 1626, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011768306139856577, \"iteration\": 1627, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0029145521111786366, \"iteration\": 1628, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016108141280710697, \"iteration\": 1629, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001224449952133, \"iteration\": 1630, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014386165421456099, \"iteration\": 1631, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001467000925913453, \"iteration\": 1632, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000968181760981679, \"iteration\": 1633, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021027508191764355, \"iteration\": 1634, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010941845830529928, \"iteration\": 1635, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0020987193565815687, \"iteration\": 1636, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018583956407383084, \"iteration\": 1637, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003053581342101097, \"iteration\": 1638, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021424531005322933, \"iteration\": 1639, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0019430213142186403, \"iteration\": 1640, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002092253416776657, \"iteration\": 1641, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011326828971505165, \"iteration\": 1642, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017277810256928205, \"iteration\": 1643, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001806007232517004, \"iteration\": 1644, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002093091607093811, \"iteration\": 1645, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021381366532295942, \"iteration\": 1646, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013932520523667336, \"iteration\": 1647, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011275841388851404, \"iteration\": 1648, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008836338529363275, \"iteration\": 1649, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013730749487876892, \"iteration\": 1650, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012386669404804707, \"iteration\": 1651, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013546973932534456, \"iteration\": 1652, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009532409603707492, \"iteration\": 1653, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021151332184672356, \"iteration\": 1654, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013458954636007547, \"iteration\": 1655, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014039978850632906, \"iteration\": 1656, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000990999978967011, \"iteration\": 1657, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012127782683819532, \"iteration\": 1658, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010860019829124212, \"iteration\": 1659, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001502485596574843, \"iteration\": 1660, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0020441520027816296, \"iteration\": 1661, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001171677140519023, \"iteration\": 1662, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014106249436736107, \"iteration\": 1663, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007756188861094415, \"iteration\": 1664, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015217508189380169, \"iteration\": 1665, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011324960505589843, \"iteration\": 1666, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008118897094391286, \"iteration\": 1667, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011919669341295958, \"iteration\": 1668, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011866233544424176, \"iteration\": 1669, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011631387751549482, \"iteration\": 1670, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009125551441684365, \"iteration\": 1671, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012159745674580336, \"iteration\": 1672, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006662615342065692, \"iteration\": 1673, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001754654454998672, \"iteration\": 1674, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009630959248170257, \"iteration\": 1675, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010557137429714203, \"iteration\": 1676, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013037092285230756, \"iteration\": 1677, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03691079467535019, \"iteration\": 1678, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011631117668002844, \"iteration\": 1679, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016989207360893488, \"iteration\": 1680, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015848542097955942, \"iteration\": 1681, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017783018993213773, \"iteration\": 1682, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010963971726596355, \"iteration\": 1683, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002452936489135027, \"iteration\": 1684, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011520270491018891, \"iteration\": 1685, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011057567317038774, \"iteration\": 1686, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.007144852541387081, \"iteration\": 1687, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009225851390510798, \"iteration\": 1688, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016653079073876143, \"iteration\": 1689, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018477619159966707, \"iteration\": 1690, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0020636427216231823, \"iteration\": 1691, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012095924466848373, \"iteration\": 1692, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021479129791259766, \"iteration\": 1693, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013011726550757885, \"iteration\": 1694, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013114053290337324, \"iteration\": 1695, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00221068924292922, \"iteration\": 1696, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012121315812692046, \"iteration\": 1697, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00107546616345644, \"iteration\": 1698, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001039140042848885, \"iteration\": 1699, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009974458953365684, \"iteration\": 1700, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009925293270498514, \"iteration\": 1701, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010165057610720396, \"iteration\": 1702, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00108955183532089, \"iteration\": 1703, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011643568286672235, \"iteration\": 1704, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010606554569676518, \"iteration\": 1705, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0020072609186172485, \"iteration\": 1706, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006021340959705412, \"iteration\": 1707, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001404575421474874, \"iteration\": 1708, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010452796705067158, \"iteration\": 1709, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021062600426375866, \"iteration\": 1710, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006451352965086699, \"iteration\": 1711, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012036875123158097, \"iteration\": 1712, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015779940877109766, \"iteration\": 1713, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0022877734154462814, \"iteration\": 1714, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010376150021329522, \"iteration\": 1715, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001335386885330081, \"iteration\": 1716, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011878479272127151, \"iteration\": 1717, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002442443510517478, \"iteration\": 1718, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015341304242610931, \"iteration\": 1719, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014259847812354565, \"iteration\": 1720, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001909566344693303, \"iteration\": 1721, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012979864841327071, \"iteration\": 1722, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.006703100632876158, \"iteration\": 1723, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009290426969528198, \"iteration\": 1724, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008944764267653227, \"iteration\": 1725, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006543573690578341, \"iteration\": 1726, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015426799654960632, \"iteration\": 1727, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001091579906642437, \"iteration\": 1728, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002755121560767293, \"iteration\": 1729, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009412843501195312, \"iteration\": 1730, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012586431112140417, \"iteration\": 1731, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005129281198605895, \"iteration\": 1732, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008855214109644294, \"iteration\": 1733, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001838579773902893, \"iteration\": 1734, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009888738859444857, \"iteration\": 1735, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010371801909059286, \"iteration\": 1736, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006582563510164618, \"iteration\": 1737, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012012228835374117, \"iteration\": 1738, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007228778558783233, \"iteration\": 1739, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014484657440334558, \"iteration\": 1740, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016736156539991498, \"iteration\": 1741, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007107966230250895, \"iteration\": 1742, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007063988596200943, \"iteration\": 1743, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010411490220576525, \"iteration\": 1744, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011359903728589416, \"iteration\": 1745, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010407345835119486, \"iteration\": 1746, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009939954616129398, \"iteration\": 1747, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010775347473099828, \"iteration\": 1748, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008275919826701283, \"iteration\": 1749, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010035824961960316, \"iteration\": 1750, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008911797776818275, \"iteration\": 1751, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012157880701124668, \"iteration\": 1752, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017481485847383738, \"iteration\": 1753, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007122767856344581, \"iteration\": 1754, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010779374279081821, \"iteration\": 1755, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008468813030049205, \"iteration\": 1756, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007930387509986758, \"iteration\": 1757, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011114075314253569, \"iteration\": 1758, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014441623352468014, \"iteration\": 1759, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007651313208043575, \"iteration\": 1760, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008641858585178852, \"iteration\": 1761, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006872679805383086, \"iteration\": 1762, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011440981179475784, \"iteration\": 1763, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007769311196170747, \"iteration\": 1764, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008302558562718332, \"iteration\": 1765, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009365822188556194, \"iteration\": 1766, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007896350580267608, \"iteration\": 1767, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011190155055373907, \"iteration\": 1768, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007305435137823224, \"iteration\": 1769, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013194393832236528, \"iteration\": 1770, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016287995968014002, \"iteration\": 1771, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015366855077445507, \"iteration\": 1772, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008617370622232556, \"iteration\": 1773, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010024410439655185, \"iteration\": 1774, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009331356268376112, \"iteration\": 1775, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000833262107335031, \"iteration\": 1776, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000982572790235281, \"iteration\": 1777, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012220425996929407, \"iteration\": 1778, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015480886213481426, \"iteration\": 1779, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015502448659390211, \"iteration\": 1780, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import models\n",
    "from importlib import reload\n",
    "\n",
    "reload(models)\n",
    "\n",
    "model_nn_balkan = models.NeuralNetwork(\n",
    "    input_size=len(train_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cuda',\n",
    "    # class_weights=torch.Tensor([weight_0, weight_1])\n",
    "    pos_weight=weight_1\n",
    ")\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "if Path('models/model_nn_balkan.pt').exists() and USE_CACHE:\n",
    "    model_nn_balkan = load_model(model_nn_balkan, 'model_nn_balkan')\n",
    "else:\n",
    "    model_nn_balkan.fit(train_dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn_balkan, \"model_nn_balkan\")\n",
    "\n",
    "model_nn_balkan_results = evaluate_nn_model(model_nn_balkan, test_dataset)\n",
    "np.save('models/model_nn_balkan_results.npy', model_nn_balkan_results)\n",
    "print(model_nn_balkan_results)\n",
    "\n",
    "model_nn_balkan.cpu()\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn_balkan, train_config, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose threshold according to AOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 178/178 [00:02<00:00, 70.46batch/s, batch_accuracy=0.812, loss=0.371]\n",
      "Epoch 2: 100%|██████████| 178/178 [00:02<00:00, 71.71batch/s, batch_accuracy=0.875, loss=0.435]\n",
      "Epoch 3: 100%|██████████| 178/178 [00:02<00:00, 72.63batch/s, batch_accuracy=1, loss=0.205]    \n",
      "Epoch 4: 100%|██████████| 178/178 [00:02<00:00, 71.11batch/s, batch_accuracy=1, loss=0.214]     \n",
      "Epoch 5: 100%|██████████| 178/178 [00:02<00:00, 71.61batch/s, batch_accuracy=1, loss=0.0426]    \n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import models\n",
    "reload(models)\n",
    "\n",
    "model_nn_balkan = models.NeuralNetwork(\n",
    "    input_size=len(train_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 5,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "\n",
    "model_nn_balkan.fit(train_dataloader, train_config, disable_progress_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, roc_curve, roc_auc_score\n",
    "\n",
    "y_pred = model_nn_balkan.predict(torch.stack([dta[0] for dta in test_dataset])).long().to('cpu')\n",
    "y_true = torch.stack([dta[1] for dta in test_dataset]).to('cpu')\n",
    "\n",
    "y_logits = model_nn_balkan.forward(torch.stack([dta[0] for dta in test_dataset])).to('cpu')\n",
    "y_scores = torch.sigmoid(y_logits).detach().numpy()\n",
    "\n",
    "\n",
    "roc = roc_curve(y_true, y_scores, pos_label=1)\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "good_tpr = np.array([range(len(roc[1]))])[:, np.logical_and(roc[1] >= 0.7, roc[1] <= 0.8)]\n",
    "\n",
    "print(\"Threshold:\\t\\t\", roc[2][good_tpr][0][0], '\\t', roc[2][good_tpr][0][-1])\n",
    "print(\"False alarm rate:\\t\", roc[0][good_tpr].min(), roc[0][good_tpr].max())\n",
    "print(\"True positive rate:\\t\", roc[1][good_tpr].min(), roc[1][good_tpr].max())\n",
    "print(\"AUC:\\t\\t\\t\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "array1 = roc[0]\n",
    "array2 = roc[1]\n",
    "array3 = roc[2]\n",
    "\n",
    "# Create two subplots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6, 9))\n",
    "\n",
    "# Plot array1 and array2 together\n",
    "axs[0].plot(array1, array2)\n",
    "axs[0].set_xlabel('FPR')\n",
    "axs[0].set_ylabel('TPR')\n",
    "axs[0].set_title('TPR vs. FPR')\n",
    "\n",
    "# Plot array3 on top with a different scale\n",
    "axs[1].plot(array3)\n",
    "# axs[1].set_xlabel('X')\n",
    "axs[1].set_ylabel('Threshold')\n",
    "# axs[1].set_yscale('log')\n",
    "axs[1].set_title('Decision threshold')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other classifiers\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "\"Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC, SVM\n",
    "Effective in high dimensional spaces.\n",
    "\n",
    "Still effective in cases where number of dimensions is greater than the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit count vectorizer\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "file_list = [\n",
    "    # 'power-ba-train.tsv',\n",
    "    # 'power-rs-train.tsv',\n",
    "    # 'power-hr-train.tsv',\n",
    "    'power-gb-train.tsv'\n",
    "]\n",
    "\n",
    "data = load_data(folder_path=\"data/train/power/\", file_list=file_list,text_head='text')\n",
    "train_raw, test_raw = split_data(data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"fit count vectorizer\")\n",
    "# count_vectorizer = CountVectorizer().fit(train_raw.texts)\n",
    "tfidf_vectorizer = TfidfVectorizer().fit(train_raw.texts)\n",
    "\n",
    "# X_count = count_vectorizer.transform(train_raw.texts)\n",
    "X_tfidf = tfidf_vectorizer.transform(train_raw.texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC, count, very slow\n",
    "# print(\"fit model\")\n",
    "# model_svc_count = SVC()\n",
    "# model_svc_count.fit(X_count, train_raw.labels)\n",
    "\n",
    "# pred_svc_count = model_svc_count.predict(count_vectorizer.transform(test_raw.texts))\n",
    "\n",
    "# precision_recall_fscore_support(test_raw.labels, pred_svc_count, average='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC, tfidf\n",
    "print(\"fit model\")\n",
    "model_svc_tfidf = SVC()\n",
    "model_svc_tfidf.fit(X_tfidf, train_raw.labels)\n",
    "\n",
    "pred_svc_tfidf = model_svc_tfidf.predict(tfidf_vectorizer.transform(test_raw.texts))\n",
    "\n",
    "precision_recall_fscore_support(test_raw.labels, pred_svc_tfidf, average='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC with TfIdf did good on balanced English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LinearSVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# LinearSVC, tfidf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model_LinearSVC_tfidf \u001b[38;5;241m=\u001b[39m \u001b[43mLinearSVC\u001b[49m()\n\u001b[1;32m      4\u001b[0m model_LinearSVC_tfidf\u001b[38;5;241m.\u001b[39mfit(X_tfidf, train_raw\u001b[38;5;241m.\u001b[39mlabels)\n\u001b[1;32m      6\u001b[0m pred_LinearSVC_tfidf \u001b[38;5;241m=\u001b[39m model_LinearSVC_tfidf\u001b[38;5;241m.\u001b[39mpredict(tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(test_raw\u001b[38;5;241m.\u001b[39mtexts))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearSVC' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# LinearSVC, tfidf\n",
    "print(\"fit model\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_tfidf, train_raw.labels)\n",
    "\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(tfidf_vectorizer.transform(test_raw.texts))\n",
    "\n",
    "precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test this fast method with balkan data. Looks like by default, even with rebalancing, neural network model performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ratio: 0.3698394495412844\n",
      "0.7934485896269335 1.3519379844961241\n",
      "fit vectorizer\n",
      "fit model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hapham/.pyenv/versions/3.11.5/envs/power/lib/python3.11/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6140350877192983, 0.6054781355117732, 0.6097265908541012, None)\n",
      "(0.6483568075117371, 0.6636232580490149, 0.6559012111137497, None)\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC, tfidf, balkan\n",
    "\n",
    "file_list = [\n",
    "    'power-ba-train.tsv',\n",
    "    'power-rs-train.tsv',\n",
    "    'power-hr-train.tsv',\n",
    "    # 'power-gb-train.tsv'\n",
    "]\n",
    "\n",
    "data = load_data(folder_path=\"data/train/power/\", file_list=file_list,text_head='text')\n",
    "train_raw, test_raw = split_data(data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Positive ratio:\", sum(train_raw.labels) / len(train_raw))\n",
    "\n",
    "weight_0 = len(train_raw) / (2 * sum(np.array(train_raw.labels) == 0))\n",
    "weight_1 = len(train_raw) / (2 * sum(np.array(train_raw.labels) == 1))\n",
    "\n",
    "print(weight_0, weight_1)\n",
    "\n",
    "print(\"fit vectorizer\")\n",
    "count_vectorizer = CountVectorizer().fit(train_raw.texts)\n",
    "tfidf_vectorizer = TfidfVectorizer().fit(train_raw.texts)\n",
    "\n",
    "X_count = count_vectorizer.transform(train_raw.texts)\n",
    "X_tfidf = tfidf_vectorizer.transform(train_raw.texts)\n",
    "\n",
    "print(\"fit model\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_count.fit(X_count, train_raw.labels, sample_weight=[weight_0 if i == 0 else weight_1 for i in train_raw.labels])\n",
    "model_LinearSVC_tfidf.fit(X_tfidf, train_raw.labels, sample_weight=[weight_0 if i == 0 else weight_1 for i in train_raw.labels])\n",
    "\n",
    "pred_LinearSVC_count = model_LinearSVC_count.predict(count_vectorizer.transform(test_raw.texts))\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(tfidf_vectorizer.transform(test_raw.texts))\n",
    "\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_count, average='binary'))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier\n",
    "SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "\n",
    "SGD is sensitive to feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ratio: 0.5651684127520559\n",
      "1.1498704663212436 0.8846920470400638\n",
      "fit vectorizer\n",
      "fit model\n",
      "(0.7389128951557881, 0.8778708457173737, 0.8024203507038775, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7426961066193706"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "file_list = [\n",
    "    # 'power-ba-train.tsv',\n",
    "    # 'power-rs-train.tsv',\n",
    "    # 'power-hr-train.tsv',\n",
    "    'power-gb-train.tsv'\n",
    "]\n",
    "\n",
    "data = load_data(folder_path=\"data/train/power/\", file_list=file_list,text_head='text')\n",
    "train_raw, test_raw = split_data(data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Positive ratio:\", sum(train_raw.labels) / len(train_raw))\n",
    "\n",
    "weight_0 = len(train_raw) / (2 * sum(np.array(train_raw.labels) == 0))\n",
    "weight_1 = len(train_raw) / (2 * sum(np.array(train_raw.labels) == 1))\n",
    "\n",
    "print(weight_0, weight_1)\n",
    "\n",
    "print(\"fit vectorizer\")\n",
    "tfidf_vectorizer = TfidfVectorizer().fit(train_raw.texts)\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.transform(train_raw.texts)\n",
    "\n",
    "print(\"fit model\")\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_tfidf, train_raw.labels)\n",
    "\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(tfidf_vectorizer.transform(test_raw.texts))\n",
    "\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on balkan, not so good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ratio: 0.3698394495412844\n",
      "0.7934485896269335 1.3519379844961241\n",
      "fit vectorizer\n",
      "fit model\n",
      "(0.7608261159227182, 0.5487746275828929, 0.6376326074818537, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7249791112040531"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "file_list = [\n",
    "    'power-ba-train.tsv',\n",
    "    'power-rs-train.tsv',\n",
    "    'power-hr-train.tsv',\n",
    "    # 'power-gb-train.tsv'\n",
    "]\n",
    "\n",
    "data = load_data(folder_path=\"data/train/power/\", file_list=file_list,text_head='text')\n",
    "train_raw, test_raw = split_data(data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Positive ratio:\", sum(train_raw.labels) / len(train_raw))\n",
    "\n",
    "weight_0 = len(train_raw) / (2 * sum(np.array(train_raw.labels) == 0))\n",
    "weight_1 = len(train_raw) / (2 * sum(np.array(train_raw.labels) == 1))\n",
    "\n",
    "print(weight_0, weight_1)\n",
    "\n",
    "print(\"fit vectorizer\")\n",
    "tfidf_vectorizer = TfidfVectorizer().fit(train_raw.texts)\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.transform(train_raw.texts)\n",
    "\n",
    "print(\"fit model\")\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_tfidf, train_raw.labels)\n",
    "\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(tfidf_vectorizer.transform(test_raw.texts))\n",
    "\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Overall bad performance, not worth pursuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ratio: 0.5651684127520559\n",
      "1.1498704663212436 0.8846920470400638\n",
      "fit vectorizer\n",
      "fit model\n",
      "(0.6212948517940717, 0.43042420967306133, 0.5085395051875499, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5492291988536246"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "file_list = [\n",
    "    # 'power-ba-train.tsv',\n",
    "    # 'power-rs-train.tsv',\n",
    "    # 'power-hr-train.tsv',\n",
    "    'power-gb-train.tsv'\n",
    "]\n",
    "\n",
    "data = load_data(folder_path=\"data/train/power/\", file_list=file_list,text_head='text')\n",
    "train_raw, test_raw = split_data(data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Positive ratio:\", sum(train_raw.labels) / len(train_raw))\n",
    "\n",
    "weight_0 = len(train_raw) / (2 * sum(np.array(train_raw.labels) == 0))\n",
    "weight_1 = len(train_raw) / (2 * sum(np.array(train_raw.labels) == 1))\n",
    "\n",
    "print(weight_0, weight_1)\n",
    "\n",
    "print(\"fit vectorizer\")\n",
    "tfidf_vectorizer = TfidfVectorizer().fit(train_raw.texts)\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.transform(train_raw.texts)\n",
    "\n",
    "print(\"fit model\")\n",
    "model_GaussianNB_tfidf = GaussianNB()\n",
    "model_GaussianNB_tfidf.fit(X_tfidf.toarray(), train_raw.labels)\n",
    "\n",
    "pred_GaussianNB_tfidf = model_GaussianNB_tfidf.predict(tfidf_vectorizer.transform(test_raw.texts).toarray())\n",
    "\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_GaussianNB_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_GaussianNB_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "- Neural network is still a good option\n",
    "- sklearn's SGD is also good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power-identification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
