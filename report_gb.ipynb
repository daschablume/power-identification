{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "\n",
    "from models import NeuralNetwork, TrainConfig, evaluate_nn_model, save_model, load_model, plot_results\n",
    "from utils import load_data, split_data, encode_data, mapping_dict\n",
    "from pathlib import Path\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"Device: cuda\")\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"Device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(folder_path=\"data/train/power/\", file_list=['power-gb-train.tsv'],text_head='text_en')\n",
    "train_raw, test_raw = split_data(data, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data encoder...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=50000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_features=50000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=50000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Prepare data encoder...\")\n",
    "word_encoder = TfidfVectorizer(max_features=50000)\n",
    "word_encoder.fit(train_raw.texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:05<00:00, 40.12batch/s, batch_accuracy=1, loss=0.22]     \n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 42.84batch/s, batch_accuracy=1, loss=0.28]     \n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 42.65batch/s, batch_accuracy=1, loss=0.127]    \n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 44.02batch/s, batch_accuracy=1, loss=0.0512]    \n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 43.34batch/s, batch_accuracy=1, loss=0.00795]   \n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 43.90batch/s, batch_accuracy=1, loss=0.281]     \n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:05<00:00, 41.06batch/s, batch_accuracy=1, loss=0.000372]  \n",
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:05<00:00, 41.46batch/s, batch_accuracy=1, loss=0.000976]   \n",
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 42.94batch/s, batch_accuracy=1, loss=9.73e-5]    \n",
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:05<00:00, 40.96batch/s, batch_accuracy=1, loss=0.000106]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7205994411988824, 0.7665495811942719, 0.7428646242471851, None)\n",
      "AUC 0.6952406025629478\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-f85d32e63d2849d1970593240d2c893d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-f85d32e63d2849d1970593240d2c893d.vega-embed details,\n",
       "  #altair-viz-f85d32e63d2849d1970593240d2c893d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-f85d32e63d2849d1970593240d2c893d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f85d32e63d2849d1970593240d2c893d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f85d32e63d2849d1970593240d2c893d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-cbd34f50413a9e287387c923c41b30ff\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-cbd34f50413a9e287387c923c41b30ff\": [{\"training_acc\": 0.859375, \"training_loss\": 0.6931428909301758, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6927586197853088, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6917918920516968, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.6918730139732361, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6857491731643677, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6896712779998779, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.690157413482666, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6887363195419312, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 0.691718578338623, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.685137927532196, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6764506697654724, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.6868734955787659, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6880989670753479, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6868470907211304, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 0.6896741986274719, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6862469911575317, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.484375, \"training_loss\": 0.6917738914489746, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6686626076698303, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.673922598361969, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6829148530960083, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.669314444065094, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6795490384101868, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6774521470069885, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6791489124298096, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6777425408363342, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6578258275985718, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6625698804855347, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6598673462867737, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6589841842651367, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6519326567649841, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6581659913063049, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6503175497055054, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6336691975593567, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6522182822227478, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6477469205856323, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6717374324798584, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6476649045944214, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.652427077293396, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.666348397731781, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.6152617931365967, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.6297811269760132, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6445325613021851, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.6352722644805908, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.6242358088493347, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.6197714805603027, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.6112228631973267, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.6163744926452637, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6022830605506897, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5959658622741699, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6143316030502319, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5772485733032227, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5859435796737671, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.6081819534301758, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.6128960251808167, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5903984308242798, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5584427118301392, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.6125569939613342, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5802267789840698, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5918570756912231, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5238462090492249, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.5190442800521851, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5701308250427246, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5563359260559082, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.49700433015823364, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.46744459867477417, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5437164902687073, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6181821227073669, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.577619731426239, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5711698532104492, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5443736910820007, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5398814082145691, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5538849234580994, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5973154306411743, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5282024145126343, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5094322562217712, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4788874089717865, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5611749887466431, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5637407302856445, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.49671053886413574, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5516713261604309, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5426487326622009, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.49536460638046265, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4911355674266815, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.45412036776542664, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4512919485569, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5129318237304688, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5181176066398621, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4872329831123352, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5308793783187866, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5259519219398499, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4727849066257477, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5117588043212891, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4872371554374695, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.488240122795105, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.48063936829566956, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4727272093296051, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4773385226726532, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.63974529504776, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.49091050028800964, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.46332263946533203, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5207005739212036, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5268610715866089, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.4865558445453644, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4413268268108368, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5145605802536011, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4492183029651642, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.43827247619628906, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.519805371761322, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4703250527381897, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5309603810310364, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4622131586074829, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5571611523628235, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5203670263290405, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4575064778327942, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.49100548028945923, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4462825357913971, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.4682668447494507, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5121011734008789, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.4887886047363281, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4787966012954712, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.47375619411468506, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5091255903244019, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5592846870422363, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.4794643223285675, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.48251521587371826, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4866577982902527, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.48127150535583496, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5063077211380005, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.48607319593429565, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.48179900646209717, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4716998338699341, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40512901544570923, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4580540359020233, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4254305064678192, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5163344144821167, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4866023361682892, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4370211064815521, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5025922656059265, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.45925116539001465, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5122341513633728, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.48488283157348633, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.48608019948005676, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4705584645271301, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.42359864711761475, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4838889539241791, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4796610474586487, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5343672037124634, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4885619878768921, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.440638929605484, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5188855528831482, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.552983283996582, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5122255682945251, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4953150749206543, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5083793997764587, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4732794463634491, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5348591804504395, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.49418991804122925, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4386735260486603, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.46605169773101807, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5298862457275391, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.44243407249450684, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.45239830017089844, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.43454107642173767, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4130427837371826, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5255338549613953, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5060577392578125, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5989236831665039, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.49120020866394043, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4120106101036072, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5112378597259521, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4950699508190155, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.46422964334487915, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5006478428840637, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4512653350830078, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4525262713432312, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4650454521179199, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.468544602394104, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.47797060012817383, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.43150946497917175, \"iteration\": 179, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.47030144929885864, \"iteration\": 180, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5052908062934875, \"iteration\": 181, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.44437676668167114, \"iteration\": 182, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.38923215866088867, \"iteration\": 183, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6314986944198608, \"iteration\": 184, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.43874382972717285, \"iteration\": 185, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5397500395774841, \"iteration\": 186, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5493624806404114, \"iteration\": 187, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.42099741101264954, \"iteration\": 188, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5509909987449646, \"iteration\": 189, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4036693572998047, \"iteration\": 190, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.43866774439811707, \"iteration\": 191, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4116707742214203, \"iteration\": 192, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.4823664128780365, \"iteration\": 193, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.46879494190216064, \"iteration\": 194, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.46814361214637756, \"iteration\": 195, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5162268877029419, \"iteration\": 196, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.48011547327041626, \"iteration\": 197, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.47127923369407654, \"iteration\": 198, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.49110642075538635, \"iteration\": 199, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.48423582315444946, \"iteration\": 200, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4821465313434601, \"iteration\": 201, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.512322187423706, \"iteration\": 202, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4889099895954132, \"iteration\": 203, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3825113773345947, \"iteration\": 204, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.45149722695350647, \"iteration\": 205, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4665137529373169, \"iteration\": 206, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.46976029872894287, \"iteration\": 207, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.3939981460571289, \"iteration\": 208, \"epoch\": 1}, {\"training_acc\": 1.0, \"training_loss\": 0.2195054292678833, \"iteration\": 209, \"epoch\": 1}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27531349658966064, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.34133946895599365, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3629770278930664, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2721480429172516, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3242076635360718, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2660192847251892, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3177611529827118, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.31115400791168213, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3561974763870239, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2770938277244568, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3273043930530548, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2754369378089905, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.24011848866939545, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.35470718145370483, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3420773148536682, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.31072986125946045, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2711500823497772, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30117085576057434, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2999725639820099, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23413442075252533, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3048466444015503, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3119047284126282, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.29908251762390137, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2350711226463318, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2763373553752899, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3141334056854248, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3532034456729889, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2646369934082031, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3151240944862366, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2941739857196808, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.27086976170539856, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2872411906719208, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2392185926437378, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3031804859638214, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32440900802612305, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2682967483997345, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28113219141960144, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2553684115409851, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.256628155708313, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2345099002122879, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.32688432931900024, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.27201616764068604, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2262488454580307, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3432454466819763, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.21354568004608154, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.27406322956085205, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28238505125045776, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2880268394947052, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2870113253593445, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.21564286947250366, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.27088284492492676, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23291735351085663, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3228280246257782, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.29687443375587463, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21105200052261353, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.311259388923645, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3309963345527649, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29701516032218933, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3565916121006012, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.1990300714969635, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29941028356552124, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24808454513549805, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3009936809539795, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3175179660320282, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.21507683396339417, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3036390244960785, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3548562824726105, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25991901755332947, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26120105385780334, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.26158607006073, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33058109879493713, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27808260917663574, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.24111519753932953, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32594960927963257, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2509004771709442, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.20277927815914154, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.30595827102661133, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.31158891320228577, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24456533789634705, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24344979226589203, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.36243894696235657, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3055999279022217, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4292525351047516, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28123003244400024, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29410263895988464, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30469810962677, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30042919516563416, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3556837737560272, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2891938090324402, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3658180236816406, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.21198789775371552, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.27309978008270264, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.28980395197868347, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26047012209892273, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.30713433027267456, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2715141773223877, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1987377405166626, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3291940987110138, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.293118953704834, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.41031014919281006, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2672860622406006, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32666194438934326, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34563636779785156, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2872796952724457, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.26093804836273193, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2095273733139038, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.39796099066734314, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.28004035353660583, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3272125720977783, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.28659960627555847, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2815675735473633, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2819839119911194, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.44463491439819336, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3143838942050934, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.22832994163036346, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3695312738418579, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3946470022201538, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.32457974553108215, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3522903323173523, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26788097620010376, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.31265878677368164, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.36815372109413147, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2975558042526245, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3217087686061859, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.34449464082717896, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.31689032912254333, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30921250581741333, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.28588706254959106, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3588050603866577, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3642973303794861, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2811001241207123, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2847590744495392, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.24818702042102814, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2596378028392792, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23957517743110657, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3427729606628418, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3220510184764862, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2396479696035385, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2867063283920288, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2619800567626953, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.40538930892944336, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.26033803820610046, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2736101746559143, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3146297037601471, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2543712556362152, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.321705162525177, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26503533124923706, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4114822447299957, \"iteration\": 357, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24620378017425537, \"iteration\": 358, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3117993474006653, \"iteration\": 359, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.29565805196762085, \"iteration\": 360, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4343559145927429, \"iteration\": 361, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2820758819580078, \"iteration\": 362, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3675016164779663, \"iteration\": 363, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28791746497154236, \"iteration\": 364, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40271490812301636, \"iteration\": 365, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.34256330132484436, \"iteration\": 366, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.42994406819343567, \"iteration\": 367, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.27044373750686646, \"iteration\": 368, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.38309580087661743, \"iteration\": 369, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3384677767753601, \"iteration\": 370, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.35875627398490906, \"iteration\": 371, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3734089136123657, \"iteration\": 372, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.374980628490448, \"iteration\": 373, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33477845788002014, \"iteration\": 374, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2975206971168518, \"iteration\": 375, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.30591389536857605, \"iteration\": 376, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3478005826473236, \"iteration\": 377, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2432701289653778, \"iteration\": 378, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3326794505119324, \"iteration\": 379, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.30110058188438416, \"iteration\": 380, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.35615500807762146, \"iteration\": 381, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22886651754379272, \"iteration\": 382, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.30152443051338196, \"iteration\": 383, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.27132126688957214, \"iteration\": 384, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2861669659614563, \"iteration\": 385, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31354060769081116, \"iteration\": 386, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3744157552719116, \"iteration\": 387, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3839881420135498, \"iteration\": 388, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.38948631286621094, \"iteration\": 389, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29667729139328003, \"iteration\": 390, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.25328540802001953, \"iteration\": 391, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3371058702468872, \"iteration\": 392, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3093300461769104, \"iteration\": 393, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.35992875695228577, \"iteration\": 394, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3038178086280823, \"iteration\": 395, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.29551661014556885, \"iteration\": 396, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2951645851135254, \"iteration\": 397, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2665744721889496, \"iteration\": 398, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.32289552688598633, \"iteration\": 399, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3248719274997711, \"iteration\": 400, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3066430687904358, \"iteration\": 401, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3706625699996948, \"iteration\": 402, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21463972330093384, \"iteration\": 403, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24856282770633698, \"iteration\": 404, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.31682896614074707, \"iteration\": 405, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2967795431613922, \"iteration\": 406, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.2930830121040344, \"iteration\": 407, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2579471170902252, \"iteration\": 408, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3954787850379944, \"iteration\": 409, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28479287028312683, \"iteration\": 410, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.33909985423088074, \"iteration\": 411, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31281277537345886, \"iteration\": 412, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4270825982093811, \"iteration\": 413, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3302718997001648, \"iteration\": 414, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.30177271366119385, \"iteration\": 415, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27911317348480225, \"iteration\": 416, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2986776530742645, \"iteration\": 417, \"epoch\": 2}, {\"training_acc\": 1.0, \"training_loss\": 0.28048744797706604, \"iteration\": 418, \"epoch\": 2}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18169328570365906, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.1148066520690918, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.19059088826179504, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14417102932929993, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20543807744979858, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.15493589639663696, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13222818076610565, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18266478180885315, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.22757989168167114, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20130354166030884, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13562805950641632, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16560128331184387, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12370871752500534, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14110572636127472, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11669301986694336, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2555145025253296, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.17910560965538025, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.13051974773406982, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.13205143809318542, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11152496188879013, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.09328707307577133, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10430614650249481, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.14228756725788116, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.17872467637062073, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.14944319427013397, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1281297355890274, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2209055870771408, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.15302743017673492, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.20217740535736084, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21415215730667114, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18920257687568665, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.17624422907829285, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1451232135295868, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16262364387512207, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15861880779266357, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1722169667482376, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12644459307193756, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2308053821325302, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.15446975827217102, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18043549358844757, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.129471555352211, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14689169824123383, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18062666058540344, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.19871166348457336, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10964669287204742, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1901545524597168, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15963099896907806, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10880492627620697, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23046857118606567, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08598653972148895, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16564461588859558, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18484799563884735, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09295456111431122, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.21052655577659607, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.15748828649520874, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.138347789645195, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08232617378234863, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14234739542007446, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1753171980381012, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.19036130607128143, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1473643034696579, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15747475624084473, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12907712161540985, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1632470339536667, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12468591332435608, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1792917549610138, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15209221839904785, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1304236799478531, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12227768450975418, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.21127372980117798, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.20159128308296204, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12375207245349884, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.05560632422566414, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14838889241218567, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18222935497760773, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11482756584882736, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13416145741939545, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17136025428771973, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2028833031654358, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1370755285024643, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15731780230998993, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15271678566932678, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1477806121110916, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1666804999113083, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.14754703640937805, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21715176105499268, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.17702387273311615, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13507795333862305, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1944701373577118, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14836139976978302, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10950037837028503, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17473788559436798, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22871187329292297, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12605036795139313, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.13773784041404724, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.222854882478714, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20202544331550598, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18132317066192627, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22256922721862793, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1189141497015953, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12572702765464783, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.21125610172748566, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18935036659240723, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.14694654941558838, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.25088778138160706, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2304011583328247, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15893064439296722, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18535356223583221, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.19911706447601318, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14268241822719574, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18799935281276703, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1513802409172058, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2229110151529312, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.21515676379203796, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12989480793476105, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1563480794429779, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1127219945192337, \"iteration\": 535, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17587976157665253, \"iteration\": 536, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16285844147205353, \"iteration\": 537, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.17258083820343018, \"iteration\": 538, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1423807442188263, \"iteration\": 539, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09098073840141296, \"iteration\": 540, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14836455881595612, \"iteration\": 541, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14835034310817719, \"iteration\": 542, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.17973941564559937, \"iteration\": 543, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12816853821277618, \"iteration\": 544, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19271686673164368, \"iteration\": 545, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.21507424116134644, \"iteration\": 546, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.19752904772758484, \"iteration\": 547, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1742938756942749, \"iteration\": 548, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.26493391394615173, \"iteration\": 549, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.25272321701049805, \"iteration\": 550, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.21240681409835815, \"iteration\": 551, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.21946346759796143, \"iteration\": 552, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2429289072751999, \"iteration\": 553, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24836036562919617, \"iteration\": 554, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17152848839759827, \"iteration\": 555, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18123158812522888, \"iteration\": 556, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.11693213880062103, \"iteration\": 557, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19507062435150146, \"iteration\": 558, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16302379965782166, \"iteration\": 559, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16813237965106964, \"iteration\": 560, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1613098382949829, \"iteration\": 561, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.19340980052947998, \"iteration\": 562, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13898517191410065, \"iteration\": 563, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1287636160850525, \"iteration\": 564, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17936712503433228, \"iteration\": 565, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1822495311498642, \"iteration\": 566, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22610288858413696, \"iteration\": 567, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21508969366550446, \"iteration\": 568, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.27885374426841736, \"iteration\": 569, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2569985091686249, \"iteration\": 570, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.30906257033348083, \"iteration\": 571, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1794738918542862, \"iteration\": 572, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1931142508983612, \"iteration\": 573, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.22834251821041107, \"iteration\": 574, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18565912544727325, \"iteration\": 575, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.19486774504184723, \"iteration\": 576, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2427554577589035, \"iteration\": 577, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1633342057466507, \"iteration\": 578, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2340603470802307, \"iteration\": 579, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.203119695186615, \"iteration\": 580, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14081363379955292, \"iteration\": 581, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2581595182418823, \"iteration\": 582, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.17658531665802002, \"iteration\": 583, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22231744229793549, \"iteration\": 584, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2697041928768158, \"iteration\": 585, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20634320378303528, \"iteration\": 586, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.20251263678073883, \"iteration\": 587, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16873520612716675, \"iteration\": 588, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.30212610960006714, \"iteration\": 589, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16044573485851288, \"iteration\": 590, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1782987117767334, \"iteration\": 591, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3141945004463196, \"iteration\": 592, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19065305590629578, \"iteration\": 593, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.22107450664043427, \"iteration\": 594, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.19061218202114105, \"iteration\": 595, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2360031008720398, \"iteration\": 596, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.25398051738739014, \"iteration\": 597, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.26496604084968567, \"iteration\": 598, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.21066106855869293, \"iteration\": 599, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20302999019622803, \"iteration\": 600, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18040381371974945, \"iteration\": 601, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2310824692249298, \"iteration\": 602, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18196041882038116, \"iteration\": 603, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2106034904718399, \"iteration\": 604, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.20225049555301666, \"iteration\": 605, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.26429420709609985, \"iteration\": 606, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23184777796268463, \"iteration\": 607, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18371227383613586, \"iteration\": 608, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.17904862761497498, \"iteration\": 609, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16937866806983948, \"iteration\": 610, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.16887234151363373, \"iteration\": 611, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2808458209037781, \"iteration\": 612, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.26440271735191345, \"iteration\": 613, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1883004903793335, \"iteration\": 614, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.13921019434928894, \"iteration\": 615, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.28294503688812256, \"iteration\": 616, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26962149143218994, \"iteration\": 617, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2707216441631317, \"iteration\": 618, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1762254387140274, \"iteration\": 619, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2760462164878845, \"iteration\": 620, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2260306477546692, \"iteration\": 621, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17842316627502441, \"iteration\": 622, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12409526854753494, \"iteration\": 623, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.15997469425201416, \"iteration\": 624, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2503146231174469, \"iteration\": 625, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18028734624385834, \"iteration\": 626, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.12719905376434326, \"iteration\": 627, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09126213192939758, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07362645119428635, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07084448635578156, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09052407741546631, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11071079224348068, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09336573630571365, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08400113880634308, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10159962624311447, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.12727148830890656, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07615361362695694, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.12808868288993835, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06469912081956863, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05757744610309601, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07448958605527878, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16160324215888977, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06872493028640747, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07273741066455841, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.07554449886083603, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06820762157440186, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.08897286653518677, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09152263402938843, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1015332043170929, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.0894618034362793, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07525936514139175, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10035768151283264, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12216019630432129, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06700742989778519, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07163377851247787, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08323831856250763, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06832444667816162, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.11187555640935898, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.059107985347509384, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06019018217921257, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14166958630084991, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1141120046377182, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15587885677814484, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12484031915664673, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08417849987745285, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07570604979991913, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05392109602689743, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.03999350965023041, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.059070948511362076, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09354373812675476, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15051032602787018, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05277811363339424, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09366220235824585, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05311930552124977, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07660406827926636, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11458823084831238, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0526391938328743, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06778302788734436, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05130276829004288, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09055497497320175, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10811801999807358, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07783327996730804, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08384738862514496, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0673006922006607, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.053016819059848785, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07694540172815323, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.049102019518613815, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07346437871456146, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05570204183459282, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.055044569075107574, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05380774289369583, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.056745611131191254, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.048701345920562744, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06971661001443863, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07792997360229492, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08878529071807861, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07437923550605774, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06489689648151398, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.04711788520216942, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08654864877462387, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06867482513189316, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.09127453714609146, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040696971118450165, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09895194321870804, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09277509152889252, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08342983573675156, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11007346957921982, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.03148166835308075, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08295142650604248, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11129125952720642, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08587221801280975, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15613731741905212, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09941218048334122, \"iteration\": 713, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12830860912799835, \"iteration\": 714, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10383010655641556, \"iteration\": 715, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13803796470165253, \"iteration\": 716, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09232720732688904, \"iteration\": 717, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.059621844440698624, \"iteration\": 718, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.088191919028759, \"iteration\": 719, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08318964391946793, \"iteration\": 720, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1448950171470642, \"iteration\": 721, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06267182528972626, \"iteration\": 722, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.12713763117790222, \"iteration\": 723, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11740785837173462, \"iteration\": 724, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06730081140995026, \"iteration\": 725, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12378143519163132, \"iteration\": 726, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09993652999401093, \"iteration\": 727, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07849819958209991, \"iteration\": 728, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15296003222465515, \"iteration\": 729, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05942981317639351, \"iteration\": 730, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0870051234960556, \"iteration\": 731, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08943542838096619, \"iteration\": 732, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11325009167194366, \"iteration\": 733, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.05584957078099251, \"iteration\": 734, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13718841969966888, \"iteration\": 735, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12131047993898392, \"iteration\": 736, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05978590250015259, \"iteration\": 737, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0869750827550888, \"iteration\": 738, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.113838329911232, \"iteration\": 739, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07823796570301056, \"iteration\": 740, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08103513717651367, \"iteration\": 741, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08931814134120941, \"iteration\": 742, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07091587036848068, \"iteration\": 743, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11058831214904785, \"iteration\": 744, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.17779459059238434, \"iteration\": 745, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12771372497081757, \"iteration\": 746, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10438767820596695, \"iteration\": 747, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.027849838137626648, \"iteration\": 748, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13144953548908234, \"iteration\": 749, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13509917259216309, \"iteration\": 750, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11470188945531845, \"iteration\": 751, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14203287661075592, \"iteration\": 752, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13488627970218658, \"iteration\": 753, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09063786268234253, \"iteration\": 754, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10939738154411316, \"iteration\": 755, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11395872384309769, \"iteration\": 756, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09013275057077408, \"iteration\": 757, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10032989829778671, \"iteration\": 758, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11657121032476425, \"iteration\": 759, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11465038359165192, \"iteration\": 760, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0877126082777977, \"iteration\": 761, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08050112426280975, \"iteration\": 762, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12213417142629623, \"iteration\": 763, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1493995189666748, \"iteration\": 764, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08882533758878708, \"iteration\": 765, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12925268709659576, \"iteration\": 766, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11955483257770538, \"iteration\": 767, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1419229358434677, \"iteration\": 768, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10464608669281006, \"iteration\": 769, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05582165718078613, \"iteration\": 770, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08871356397867203, \"iteration\": 771, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.03975542262196541, \"iteration\": 772, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10071646422147751, \"iteration\": 773, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14148658514022827, \"iteration\": 774, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.06916247308254242, \"iteration\": 775, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.03838435560464859, \"iteration\": 776, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06802359223365784, \"iteration\": 777, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.066140316426754, \"iteration\": 778, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.062018148601055145, \"iteration\": 779, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06378360092639923, \"iteration\": 780, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09572730958461761, \"iteration\": 781, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11319785565137863, \"iteration\": 782, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11093604564666748, \"iteration\": 783, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12796823680400848, \"iteration\": 784, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12770773470401764, \"iteration\": 785, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1749913990497589, \"iteration\": 786, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10256296396255493, \"iteration\": 787, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1019112765789032, \"iteration\": 788, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08369672298431396, \"iteration\": 789, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15892262756824493, \"iteration\": 790, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09220649302005768, \"iteration\": 791, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.09525243937969208, \"iteration\": 792, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0794762670993805, \"iteration\": 793, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1200072392821312, \"iteration\": 794, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06582295149564743, \"iteration\": 795, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.16615788638591766, \"iteration\": 796, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13994385302066803, \"iteration\": 797, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.058820486068725586, \"iteration\": 798, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1084895133972168, \"iteration\": 799, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.16310131549835205, \"iteration\": 800, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.116689532995224, \"iteration\": 801, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11028452962636948, \"iteration\": 802, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07959183305501938, \"iteration\": 803, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0709792897105217, \"iteration\": 804, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12369053065776825, \"iteration\": 805, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12957094609737396, \"iteration\": 806, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10164845734834671, \"iteration\": 807, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09383101761341095, \"iteration\": 808, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.13357631862163544, \"iteration\": 809, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13119816780090332, \"iteration\": 810, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10977546870708466, \"iteration\": 811, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.18649257719516754, \"iteration\": 812, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10785802453756332, \"iteration\": 813, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11520408093929291, \"iteration\": 814, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11762656271457672, \"iteration\": 815, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09679678082466125, \"iteration\": 816, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08634908497333527, \"iteration\": 817, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.161826491355896, \"iteration\": 818, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09440348297357559, \"iteration\": 819, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1211610734462738, \"iteration\": 820, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10422264039516449, \"iteration\": 821, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2740813195705414, \"iteration\": 822, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15617671608924866, \"iteration\": 823, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.21573486924171448, \"iteration\": 824, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06597943603992462, \"iteration\": 825, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11203748732805252, \"iteration\": 826, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.10923993587493896, \"iteration\": 827, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12608660757541656, \"iteration\": 828, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2186933159828186, \"iteration\": 829, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10937003791332245, \"iteration\": 830, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1425655037164688, \"iteration\": 831, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.13399679958820343, \"iteration\": 832, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15800566971302032, \"iteration\": 833, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09190234541893005, \"iteration\": 834, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1530909389257431, \"iteration\": 835, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0511835478246212, \"iteration\": 836, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05586722493171692, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.031603313982486725, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.026419607922434807, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.042445551604032516, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05497602000832558, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06153958663344383, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03552045300602913, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.019563209265470505, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08235298842191696, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06019052118062973, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02783893048763275, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06692805886268616, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07436217367649078, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.036089442670345306, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04005047678947449, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01650478132069111, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0438556894659996, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04016965627670288, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05294712632894516, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06394921988248825, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0299946591258049, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054176073521375656, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05150427669286728, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12713128328323364, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.035011377185583115, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05639468878507614, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04019321873784065, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.020393595099449158, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03308507800102234, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.029591968283057213, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04290373623371124, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04047843813896179, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.019557729363441467, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04187193140387535, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.032533783465623856, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05265619978308678, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.036358557641506195, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03446567803621292, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06587354093790054, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.036941930651664734, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07754526287317276, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03065831959247589, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02217726595699787, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02169463224709034, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03869660943746567, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03306157514452934, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.060026492923498154, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05868060141801834, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04632304608821869, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028191158547997475, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021092962473630905, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.04466496780514717, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03308351710438728, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.012615738436579704, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04568483680486679, \"iteration\": 891, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.016948726028203964, \"iteration\": 892, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.026550553739070892, \"iteration\": 893, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.056202564388513565, \"iteration\": 894, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028334524482488632, \"iteration\": 895, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02748863957822323, \"iteration\": 896, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.014633087441325188, \"iteration\": 897, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04801580309867859, \"iteration\": 898, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025907032191753387, \"iteration\": 899, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03739456832408905, \"iteration\": 900, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02478889189660549, \"iteration\": 901, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05709094554185867, \"iteration\": 902, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021296247839927673, \"iteration\": 903, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025289257988333702, \"iteration\": 904, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05541351065039635, \"iteration\": 905, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05231098458170891, \"iteration\": 906, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04323607683181763, \"iteration\": 907, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08693311363458633, \"iteration\": 908, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025054818019270897, \"iteration\": 909, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.022639233618974686, \"iteration\": 910, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09140005707740784, \"iteration\": 911, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05388309061527252, \"iteration\": 912, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.023603755980730057, \"iteration\": 913, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06100272014737129, \"iteration\": 914, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.033677149564027786, \"iteration\": 915, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01720990426838398, \"iteration\": 916, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0749247744679451, \"iteration\": 917, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.011646188795566559, \"iteration\": 918, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.095277801156044, \"iteration\": 919, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0785709023475647, \"iteration\": 920, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02470991015434265, \"iteration\": 921, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06546860933303833, \"iteration\": 922, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025951137766242027, \"iteration\": 923, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040691912174224854, \"iteration\": 924, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05251241475343704, \"iteration\": 925, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04214715585112572, \"iteration\": 926, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.023153284564614296, \"iteration\": 927, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06461641937494278, \"iteration\": 928, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05268719792366028, \"iteration\": 929, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028340131044387817, \"iteration\": 930, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.047611214220523834, \"iteration\": 931, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03740697354078293, \"iteration\": 932, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03614267334342003, \"iteration\": 933, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.041291363537311554, \"iteration\": 934, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.024348221719264984, \"iteration\": 935, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03870115056633949, \"iteration\": 936, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.042745787650346756, \"iteration\": 937, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07379569113254547, \"iteration\": 938, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027948379516601562, \"iteration\": 939, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04017870873212814, \"iteration\": 940, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05535731464624405, \"iteration\": 941, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12875531613826752, \"iteration\": 942, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.014034651219844818, \"iteration\": 943, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06097346171736717, \"iteration\": 944, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03329918161034584, \"iteration\": 945, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.016080668196082115, \"iteration\": 946, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03657262399792671, \"iteration\": 947, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04229032248258591, \"iteration\": 948, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0359421968460083, \"iteration\": 949, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.047779977321624756, \"iteration\": 950, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04006247594952583, \"iteration\": 951, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07162743806838989, \"iteration\": 952, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04208773002028465, \"iteration\": 953, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03035801835358143, \"iteration\": 954, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02504114620387554, \"iteration\": 955, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0731799378991127, \"iteration\": 956, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04678937420248985, \"iteration\": 957, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.039987944066524506, \"iteration\": 958, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.020658932626247406, \"iteration\": 959, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.034367021173238754, \"iteration\": 960, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07090024650096893, \"iteration\": 961, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03184720128774643, \"iteration\": 962, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021697742864489555, \"iteration\": 963, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04169373959302902, \"iteration\": 964, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07545913755893707, \"iteration\": 965, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039584968239068985, \"iteration\": 966, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044971391558647156, \"iteration\": 967, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04501118138432503, \"iteration\": 968, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05126696452498436, \"iteration\": 969, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02297758124768734, \"iteration\": 970, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06293752789497375, \"iteration\": 971, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.11222574859857559, \"iteration\": 972, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10230018198490143, \"iteration\": 973, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03659152612090111, \"iteration\": 974, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.031000714749097824, \"iteration\": 975, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021090958267450333, \"iteration\": 976, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01949537731707096, \"iteration\": 977, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04604711756110191, \"iteration\": 978, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.037202782928943634, \"iteration\": 979, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.046145807951688766, \"iteration\": 980, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04307080805301666, \"iteration\": 981, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07270882278680801, \"iteration\": 982, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03993090242147446, \"iteration\": 983, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07829676568508148, \"iteration\": 984, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.026151208207011223, \"iteration\": 985, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021439680829644203, \"iteration\": 986, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032947737723588943, \"iteration\": 987, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.032479964196681976, \"iteration\": 988, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.012956427410244942, \"iteration\": 989, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08054358512163162, \"iteration\": 990, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.036396317183971405, \"iteration\": 991, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030593208968639374, \"iteration\": 992, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.022917408496141434, \"iteration\": 993, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.026966288685798645, \"iteration\": 994, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.053139761090278625, \"iteration\": 995, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.058284636586904526, \"iteration\": 996, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07065623253583908, \"iteration\": 997, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028765352442860603, \"iteration\": 998, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.045716818422079086, \"iteration\": 999, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028370559215545654, \"iteration\": 1000, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05136619135737419, \"iteration\": 1001, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02806328795850277, \"iteration\": 1002, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08884759992361069, \"iteration\": 1003, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04215588420629501, \"iteration\": 1004, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.018106061965227127, \"iteration\": 1005, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030337011441588402, \"iteration\": 1006, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030853301286697388, \"iteration\": 1007, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05394482612609863, \"iteration\": 1008, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05930405110120773, \"iteration\": 1009, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.033146172761917114, \"iteration\": 1010, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.022918539121747017, \"iteration\": 1011, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.017201270908117294, \"iteration\": 1012, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05649454891681671, \"iteration\": 1013, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.040743637830019, \"iteration\": 1014, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044342461973428726, \"iteration\": 1015, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03867582604289055, \"iteration\": 1016, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0686047300696373, \"iteration\": 1017, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05931686609983444, \"iteration\": 1018, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08814927190542221, \"iteration\": 1019, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08968891948461533, \"iteration\": 1020, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03853220492601395, \"iteration\": 1021, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01900147646665573, \"iteration\": 1022, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05478080362081528, \"iteration\": 1023, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06200024113059044, \"iteration\": 1024, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028418567031621933, \"iteration\": 1025, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0880405604839325, \"iteration\": 1026, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04349915683269501, \"iteration\": 1027, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03877148777246475, \"iteration\": 1028, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.005110011901706457, \"iteration\": 1029, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.031969375908374786, \"iteration\": 1030, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07645344734191895, \"iteration\": 1031, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08354208618402481, \"iteration\": 1032, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.018404904752969742, \"iteration\": 1033, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06498284637928009, \"iteration\": 1034, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0618690587580204, \"iteration\": 1035, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0396316722035408, \"iteration\": 1036, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07461974769830704, \"iteration\": 1037, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.033494412899017334, \"iteration\": 1038, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.045718349516391754, \"iteration\": 1039, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03380437567830086, \"iteration\": 1040, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.018412631005048752, \"iteration\": 1041, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06787149608135223, \"iteration\": 1042, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05154098942875862, \"iteration\": 1043, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05930035933852196, \"iteration\": 1044, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00795038603246212, \"iteration\": 1045, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.007321115583181381, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013989734463393688, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019674768671393394, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011170050129294395, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006496028043329716, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013027733191847801, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01680624485015869, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.025310520082712173, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012097923085093498, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023118216544389725, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009162315167486668, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010684970766305923, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00768269831314683, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02345702052116394, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013101714663207531, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006873992271721363, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008894868195056915, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015130378305912018, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021713104099035263, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012755069881677628, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027028556913137436, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019858140498399734, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006740651559084654, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007259616162627935, \"iteration\": 1069, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012856442481279373, \"iteration\": 1070, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00912887416779995, \"iteration\": 1071, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021831680089235306, \"iteration\": 1072, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006910732015967369, \"iteration\": 1073, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007435651030391455, \"iteration\": 1074, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004753585904836655, \"iteration\": 1075, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020745256915688515, \"iteration\": 1076, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00873669795691967, \"iteration\": 1077, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007324233651161194, \"iteration\": 1078, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009039470925927162, \"iteration\": 1079, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004334482364356518, \"iteration\": 1080, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0095036206766963, \"iteration\": 1081, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006942814216017723, \"iteration\": 1082, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015060270205140114, \"iteration\": 1083, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007081633899360895, \"iteration\": 1084, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00869729369878769, \"iteration\": 1085, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010396284982562065, \"iteration\": 1086, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009501338936388493, \"iteration\": 1087, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01085512526333332, \"iteration\": 1088, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007243293337523937, \"iteration\": 1089, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007768653333187103, \"iteration\": 1090, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009673265740275383, \"iteration\": 1091, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008378852158784866, \"iteration\": 1092, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008678937330842018, \"iteration\": 1093, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02281699702143669, \"iteration\": 1094, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017399925738573074, \"iteration\": 1095, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0071715181693434715, \"iteration\": 1096, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03249751403927803, \"iteration\": 1097, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005980723071843386, \"iteration\": 1098, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009481366723775864, \"iteration\": 1099, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0241403691470623, \"iteration\": 1100, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005516252480447292, \"iteration\": 1101, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008106514811515808, \"iteration\": 1102, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008960859850049019, \"iteration\": 1103, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006903365720063448, \"iteration\": 1104, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.024868961423635483, \"iteration\": 1105, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015075511299073696, \"iteration\": 1106, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0051006143912673, \"iteration\": 1107, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.027166467159986496, \"iteration\": 1108, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00873632077127695, \"iteration\": 1109, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014830762520432472, \"iteration\": 1110, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00967499054968357, \"iteration\": 1111, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03798498585820198, \"iteration\": 1112, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04931342229247093, \"iteration\": 1113, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012417647987604141, \"iteration\": 1114, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004245601128786802, \"iteration\": 1115, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008401542901992798, \"iteration\": 1116, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004887796938419342, \"iteration\": 1117, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005983215291053057, \"iteration\": 1118, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010275222361087799, \"iteration\": 1119, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006092008203268051, \"iteration\": 1120, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039007656276226044, \"iteration\": 1121, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014831611886620522, \"iteration\": 1122, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006278534419834614, \"iteration\": 1123, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006424547638744116, \"iteration\": 1124, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00846276618540287, \"iteration\": 1125, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014658695086836815, \"iteration\": 1126, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0067926389165222645, \"iteration\": 1127, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01355527713894844, \"iteration\": 1128, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013010108843445778, \"iteration\": 1129, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010116802528500557, \"iteration\": 1130, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0305036511272192, \"iteration\": 1131, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005842733196914196, \"iteration\": 1132, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011803937144577503, \"iteration\": 1133, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009361463598906994, \"iteration\": 1134, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012044684961438179, \"iteration\": 1135, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007005795836448669, \"iteration\": 1136, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01794111356139183, \"iteration\": 1137, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01578374020755291, \"iteration\": 1138, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023384638130664825, \"iteration\": 1139, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008761834353208542, \"iteration\": 1140, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006752814166247845, \"iteration\": 1141, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010642229579389095, \"iteration\": 1142, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010690581053495407, \"iteration\": 1143, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011593589559197426, \"iteration\": 1144, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008716350421309471, \"iteration\": 1145, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006017048377543688, \"iteration\": 1146, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017304962500929832, \"iteration\": 1147, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031118273735046387, \"iteration\": 1148, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008243970572948456, \"iteration\": 1149, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04063602536916733, \"iteration\": 1150, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025531305000185966, \"iteration\": 1151, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02265847474336624, \"iteration\": 1152, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012235952541232109, \"iteration\": 1153, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011033866554498672, \"iteration\": 1154, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023169826716184616, \"iteration\": 1155, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031080666929483414, \"iteration\": 1156, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0198526494204998, \"iteration\": 1157, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004114391747862101, \"iteration\": 1158, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011075178161263466, \"iteration\": 1159, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012742394581437111, \"iteration\": 1160, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005372823681682348, \"iteration\": 1161, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011714967899024487, \"iteration\": 1162, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00883658416569233, \"iteration\": 1163, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05052850767970085, \"iteration\": 1164, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011555951088666916, \"iteration\": 1165, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009390187449753284, \"iteration\": 1166, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006215566769242287, \"iteration\": 1167, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0031849294900894165, \"iteration\": 1168, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0038743354380130768, \"iteration\": 1169, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013521122746169567, \"iteration\": 1170, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012867605313658714, \"iteration\": 1171, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012114510871469975, \"iteration\": 1172, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012652682140469551, \"iteration\": 1173, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016560563817620277, \"iteration\": 1174, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05377580597996712, \"iteration\": 1175, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006347688380628824, \"iteration\": 1176, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01089075393974781, \"iteration\": 1177, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018413269892334938, \"iteration\": 1178, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010874059051275253, \"iteration\": 1179, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023594027385115623, \"iteration\": 1180, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011565142311155796, \"iteration\": 1181, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012274665758013725, \"iteration\": 1182, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009774211794137955, \"iteration\": 1183, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007178082130849361, \"iteration\": 1184, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0062565794214606285, \"iteration\": 1185, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014276508241891861, \"iteration\": 1186, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0039031081832945347, \"iteration\": 1187, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014442387968301773, \"iteration\": 1188, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006986889056861401, \"iteration\": 1189, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006701007019728422, \"iteration\": 1190, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010951107367873192, \"iteration\": 1191, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00936021190136671, \"iteration\": 1192, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01155809871852398, \"iteration\": 1193, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011798620223999023, \"iteration\": 1194, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013004172593355179, \"iteration\": 1195, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014967303723096848, \"iteration\": 1196, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.035673197358846664, \"iteration\": 1197, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0028113210573792458, \"iteration\": 1198, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.057376615703105927, \"iteration\": 1199, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01553738210350275, \"iteration\": 1200, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005240794271230698, \"iteration\": 1201, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008303974755108356, \"iteration\": 1202, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005492255557328463, \"iteration\": 1203, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00642326008528471, \"iteration\": 1204, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.003804930718615651, \"iteration\": 1205, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021419957280158997, \"iteration\": 1206, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005876078270375729, \"iteration\": 1207, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014403504319489002, \"iteration\": 1208, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013898702338337898, \"iteration\": 1209, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.002322782063856721, \"iteration\": 1210, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011088555678725243, \"iteration\": 1211, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0030955930706113577, \"iteration\": 1212, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.060010552406311035, \"iteration\": 1213, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00675946706905961, \"iteration\": 1214, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.003146409522742033, \"iteration\": 1215, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004331106785684824, \"iteration\": 1216, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008481690660119057, \"iteration\": 1217, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015212807804346085, \"iteration\": 1218, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006143126171082258, \"iteration\": 1219, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009938438422977924, \"iteration\": 1220, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016641145572066307, \"iteration\": 1221, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009366123005747795, \"iteration\": 1222, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04968111217021942, \"iteration\": 1223, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00389218726195395, \"iteration\": 1224, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00844227522611618, \"iteration\": 1225, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009692803025245667, \"iteration\": 1226, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007779423147439957, \"iteration\": 1227, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007249661721289158, \"iteration\": 1228, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0030834749341011047, \"iteration\": 1229, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02429754100739956, \"iteration\": 1230, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03727206960320473, \"iteration\": 1231, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011441011913120747, \"iteration\": 1232, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03498208522796631, \"iteration\": 1233, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015120238065719604, \"iteration\": 1234, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014635640196502209, \"iteration\": 1235, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020692989230155945, \"iteration\": 1236, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007699616253376007, \"iteration\": 1237, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015952324494719505, \"iteration\": 1238, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008190919645130634, \"iteration\": 1239, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012428653426468372, \"iteration\": 1240, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023186080157756805, \"iteration\": 1241, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017975332215428352, \"iteration\": 1242, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.055425141006708145, \"iteration\": 1243, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007240569684654474, \"iteration\": 1244, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009604710154235363, \"iteration\": 1245, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007383996620774269, \"iteration\": 1246, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008029165677726269, \"iteration\": 1247, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017900053411722183, \"iteration\": 1248, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007488533854484558, \"iteration\": 1249, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018613314256072044, \"iteration\": 1250, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010431153699755669, \"iteration\": 1251, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03379940986633301, \"iteration\": 1252, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06479839980602264, \"iteration\": 1253, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.28121712803840637, \"iteration\": 1254, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0037794385571032763, \"iteration\": 1255, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012490223161876202, \"iteration\": 1256, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0188906267285347, \"iteration\": 1257, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039508312940597534, \"iteration\": 1258, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04367288574576378, \"iteration\": 1259, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05984462797641754, \"iteration\": 1260, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009359552524983883, \"iteration\": 1261, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.017534876242280006, \"iteration\": 1262, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0024077431298792362, \"iteration\": 1263, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007310125976800919, \"iteration\": 1264, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009181304834783077, \"iteration\": 1265, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01634540967643261, \"iteration\": 1266, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0441272109746933, \"iteration\": 1267, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014412532560527325, \"iteration\": 1268, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01808938756585121, \"iteration\": 1269, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006942932028323412, \"iteration\": 1270, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008530110120773315, \"iteration\": 1271, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007901618257164955, \"iteration\": 1272, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002819524146616459, \"iteration\": 1273, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012666343711316586, \"iteration\": 1274, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0060910191386938095, \"iteration\": 1275, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011209833435714245, \"iteration\": 1276, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004766476806253195, \"iteration\": 1277, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029175829142332077, \"iteration\": 1278, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007374488282948732, \"iteration\": 1279, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00681816041469574, \"iteration\": 1280, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003211869392544031, \"iteration\": 1281, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023471813648939133, \"iteration\": 1282, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0029007948469370604, \"iteration\": 1283, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.019563334062695503, \"iteration\": 1284, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013706330209970474, \"iteration\": 1285, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007575611118227243, \"iteration\": 1286, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004846753552556038, \"iteration\": 1287, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036370086017996073, \"iteration\": 1288, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008608265779912472, \"iteration\": 1289, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005700059235095978, \"iteration\": 1290, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006914355792105198, \"iteration\": 1291, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013477349653840065, \"iteration\": 1292, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023671879898756742, \"iteration\": 1293, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010662212036550045, \"iteration\": 1294, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004408655688166618, \"iteration\": 1295, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008204762823879719, \"iteration\": 1296, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008476540446281433, \"iteration\": 1297, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008471661247313023, \"iteration\": 1298, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0029984412249177694, \"iteration\": 1299, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004995083902031183, \"iteration\": 1300, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006862159818410873, \"iteration\": 1301, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013071415945887566, \"iteration\": 1302, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002639634069055319, \"iteration\": 1303, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0040773674845695496, \"iteration\": 1304, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004586975090205669, \"iteration\": 1305, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004434395581483841, \"iteration\": 1306, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026558561250567436, \"iteration\": 1307, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00385458255186677, \"iteration\": 1308, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011703742668032646, \"iteration\": 1309, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0070077660493552685, \"iteration\": 1310, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003975429106503725, \"iteration\": 1311, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0040617999620735645, \"iteration\": 1312, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0049953339621424675, \"iteration\": 1313, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009252417832612991, \"iteration\": 1314, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0054367920383811, \"iteration\": 1315, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013116002082824707, \"iteration\": 1316, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007949450984597206, \"iteration\": 1317, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008679828606545925, \"iteration\": 1318, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008650371804833412, \"iteration\": 1319, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032746270298957825, \"iteration\": 1320, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004266662057489157, \"iteration\": 1321, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017504075076431036, \"iteration\": 1322, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022123183589428663, \"iteration\": 1323, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018908125348389149, \"iteration\": 1324, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017324096988886595, \"iteration\": 1325, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007622215431183577, \"iteration\": 1326, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005412198603153229, \"iteration\": 1327, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004957508761435747, \"iteration\": 1328, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0047576893121004105, \"iteration\": 1329, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002645551459863782, \"iteration\": 1330, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028181583620607853, \"iteration\": 1331, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019103368977084756, \"iteration\": 1332, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019496864406391978, \"iteration\": 1333, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005381367169320583, \"iteration\": 1334, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003941836766898632, \"iteration\": 1335, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004406388849020004, \"iteration\": 1336, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007409974467009306, \"iteration\": 1337, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012656491249799728, \"iteration\": 1338, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011433329433202744, \"iteration\": 1339, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004782914649695158, \"iteration\": 1340, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006880761589854956, \"iteration\": 1341, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0026230779476463795, \"iteration\": 1342, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.014559822157025337, \"iteration\": 1343, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0033192939590662718, \"iteration\": 1344, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017166666220873594, \"iteration\": 1345, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001477010315284133, \"iteration\": 1346, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0041716755367815495, \"iteration\": 1347, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003571108216419816, \"iteration\": 1348, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003783373162150383, \"iteration\": 1349, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03482167422771454, \"iteration\": 1350, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006024626549333334, \"iteration\": 1351, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009444059804081917, \"iteration\": 1352, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036296432372182608, \"iteration\": 1353, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007643367163836956, \"iteration\": 1354, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023295977152884007, \"iteration\": 1355, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004941883496940136, \"iteration\": 1356, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.015477444045245647, \"iteration\": 1357, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004572431556880474, \"iteration\": 1358, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005783725995570421, \"iteration\": 1359, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006899841129779816, \"iteration\": 1360, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006093039643019438, \"iteration\": 1361, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004091973882168531, \"iteration\": 1362, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014581568539142609, \"iteration\": 1363, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0026258269790560007, \"iteration\": 1364, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0060158525593578815, \"iteration\": 1365, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004239468835294247, \"iteration\": 1366, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005068857688456774, \"iteration\": 1367, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002054491313174367, \"iteration\": 1368, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009689319878816605, \"iteration\": 1369, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011463585309684277, \"iteration\": 1370, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0029792296700179577, \"iteration\": 1371, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009440225549042225, \"iteration\": 1372, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002301636151969433, \"iteration\": 1373, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038146537262946367, \"iteration\": 1374, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011430573649704456, \"iteration\": 1375, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015024836175143719, \"iteration\": 1376, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005342356860637665, \"iteration\": 1377, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003430877812206745, \"iteration\": 1378, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035860412754118443, \"iteration\": 1379, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035976669751107693, \"iteration\": 1380, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004818036686629057, \"iteration\": 1381, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002322269370779395, \"iteration\": 1382, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0024906559847295284, \"iteration\": 1383, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0011177343549206853, \"iteration\": 1384, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004267107229679823, \"iteration\": 1385, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035647270269691944, \"iteration\": 1386, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025444994680583477, \"iteration\": 1387, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004680110141634941, \"iteration\": 1388, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020951766055077314, \"iteration\": 1389, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001721999142318964, \"iteration\": 1390, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002543558133766055, \"iteration\": 1391, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015349899185821414, \"iteration\": 1392, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005851976107805967, \"iteration\": 1393, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006286806892603636, \"iteration\": 1394, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003414086764678359, \"iteration\": 1395, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0008443176047876477, \"iteration\": 1396, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00363383861258626, \"iteration\": 1397, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003036623355001211, \"iteration\": 1398, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002960741054266691, \"iteration\": 1399, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0008435691706836224, \"iteration\": 1400, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020177457481622696, \"iteration\": 1401, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005879399250261486, \"iteration\": 1402, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004619029350578785, \"iteration\": 1403, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003658292582258582, \"iteration\": 1404, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002281391294673085, \"iteration\": 1405, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036978055723011494, \"iteration\": 1406, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036390505265444517, \"iteration\": 1407, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0024283980019390583, \"iteration\": 1408, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031511050183326006, \"iteration\": 1409, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0042306710965931416, \"iteration\": 1410, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004130617715418339, \"iteration\": 1411, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00303214811719954, \"iteration\": 1412, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00984233058989048, \"iteration\": 1413, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004526303615421057, \"iteration\": 1414, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005214024800807238, \"iteration\": 1415, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031232019886374474, \"iteration\": 1416, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005581525154411793, \"iteration\": 1417, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003907719627022743, \"iteration\": 1418, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031687128357589245, \"iteration\": 1419, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017267446964979172, \"iteration\": 1420, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00527679268270731, \"iteration\": 1421, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037410215009003878, \"iteration\": 1422, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006086510606110096, \"iteration\": 1423, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006869436241686344, \"iteration\": 1424, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023054704070091248, \"iteration\": 1425, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0047255526296794415, \"iteration\": 1426, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0029634684324264526, \"iteration\": 1427, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002163024852052331, \"iteration\": 1428, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014422490494325757, \"iteration\": 1429, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025328805204480886, \"iteration\": 1430, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0049719917587935925, \"iteration\": 1431, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009506946429610252, \"iteration\": 1432, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005553059745579958, \"iteration\": 1433, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003535059979185462, \"iteration\": 1434, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0011432424653321505, \"iteration\": 1435, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003588081104680896, \"iteration\": 1436, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007102088537067175, \"iteration\": 1437, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007405636366456747, \"iteration\": 1438, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023539664689451456, \"iteration\": 1439, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001367545104585588, \"iteration\": 1440, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001913448330014944, \"iteration\": 1441, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010748104192316532, \"iteration\": 1442, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003920445218682289, \"iteration\": 1443, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003790932008996606, \"iteration\": 1444, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002601612126454711, \"iteration\": 1445, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035707575734704733, \"iteration\": 1446, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029553696513175964, \"iteration\": 1447, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005708504468202591, \"iteration\": 1448, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025881824549287558, \"iteration\": 1449, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018471285002306104, \"iteration\": 1450, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0021864583250135183, \"iteration\": 1451, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006591856013983488, \"iteration\": 1452, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0021067357156425714, \"iteration\": 1453, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005345233250409365, \"iteration\": 1454, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002910420298576355, \"iteration\": 1455, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015884095337241888, \"iteration\": 1456, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015212972648441792, \"iteration\": 1457, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002102989237755537, \"iteration\": 1458, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015121223405003548, \"iteration\": 1459, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009462816640734673, \"iteration\": 1460, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004820268601179123, \"iteration\": 1461, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014720764011144638, \"iteration\": 1462, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00037241127574816346, \"iteration\": 1463, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007709754863753915, \"iteration\": 1464, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011680108727887273, \"iteration\": 1465, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014884542906656861, \"iteration\": 1466, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009221734944730997, \"iteration\": 1467, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009059336152859032, \"iteration\": 1468, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0037419248837977648, \"iteration\": 1469, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015004435554146767, \"iteration\": 1470, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023124569561332464, \"iteration\": 1471, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.022457271814346313, \"iteration\": 1472, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000879027065820992, \"iteration\": 1473, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009399276459589601, \"iteration\": 1474, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007811242248862982, \"iteration\": 1475, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006580668268725276, \"iteration\": 1476, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006785226287320256, \"iteration\": 1477, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001088134478777647, \"iteration\": 1478, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0032076637726277113, \"iteration\": 1479, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008558582048863173, \"iteration\": 1480, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000993545982055366, \"iteration\": 1481, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012848227052018046, \"iteration\": 1482, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008129006018862128, \"iteration\": 1483, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005016300128772855, \"iteration\": 1484, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006696867058053613, \"iteration\": 1485, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011551602510735393, \"iteration\": 1486, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014000304508954287, \"iteration\": 1487, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006760357646271586, \"iteration\": 1488, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018250078428536654, \"iteration\": 1489, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009585403022356331, \"iteration\": 1490, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000826505827717483, \"iteration\": 1491, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014503113925457, \"iteration\": 1492, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006652476731687784, \"iteration\": 1493, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009197356994263828, \"iteration\": 1494, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008391137816943228, \"iteration\": 1495, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018340256065130234, \"iteration\": 1496, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011312924325466156, \"iteration\": 1497, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021775360219180584, \"iteration\": 1498, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006699304794892669, \"iteration\": 1499, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001046772114932537, \"iteration\": 1500, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009227974223904312, \"iteration\": 1501, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007200284744612873, \"iteration\": 1502, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009782983688637614, \"iteration\": 1503, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007315650000236928, \"iteration\": 1504, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005355597822926939, \"iteration\": 1505, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008464148850180209, \"iteration\": 1506, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021828729659318924, \"iteration\": 1507, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000857266946695745, \"iteration\": 1508, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005279235192574561, \"iteration\": 1509, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001261074678041041, \"iteration\": 1510, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017083745915442705, \"iteration\": 1511, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010280825663357973, \"iteration\": 1512, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005330222775228322, \"iteration\": 1513, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015054994728416204, \"iteration\": 1514, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005173322279006243, \"iteration\": 1515, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007273341761901975, \"iteration\": 1516, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005789865972474217, \"iteration\": 1517, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006929759401828051, \"iteration\": 1518, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008905016002245247, \"iteration\": 1519, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009181491332128644, \"iteration\": 1520, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03194291889667511, \"iteration\": 1521, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007329749641939998, \"iteration\": 1522, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007617026567459106, \"iteration\": 1523, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008363138767890632, \"iteration\": 1524, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007977416971698403, \"iteration\": 1525, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008388886926695704, \"iteration\": 1526, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004929290735162795, \"iteration\": 1527, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010520725045353174, \"iteration\": 1528, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006106158834882081, \"iteration\": 1529, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00048002999392338097, \"iteration\": 1530, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021022582426667213, \"iteration\": 1531, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005897069931961596, \"iteration\": 1532, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010677747195586562, \"iteration\": 1533, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00069961859844625, \"iteration\": 1534, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017473624320700765, \"iteration\": 1535, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011602988233789802, \"iteration\": 1536, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002589012496173382, \"iteration\": 1537, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005386749980971217, \"iteration\": 1538, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000450934749096632, \"iteration\": 1539, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005456250510178506, \"iteration\": 1540, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004021998029202223, \"iteration\": 1541, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010703816078603268, \"iteration\": 1542, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008661785395815969, \"iteration\": 1543, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004434659786056727, \"iteration\": 1544, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000635131262242794, \"iteration\": 1545, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009220068459399045, \"iteration\": 1546, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.049082592129707336, \"iteration\": 1547, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001403475645929575, \"iteration\": 1548, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007220589322969317, \"iteration\": 1549, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00078226113691926, \"iteration\": 1550, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025507956743240356, \"iteration\": 1551, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000384227663744241, \"iteration\": 1552, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010222411947324872, \"iteration\": 1553, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010441378690302372, \"iteration\": 1554, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017115359660238028, \"iteration\": 1555, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001468112925067544, \"iteration\": 1556, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008775151218287647, \"iteration\": 1557, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012736601056531072, \"iteration\": 1558, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015781756956130266, \"iteration\": 1559, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010178997181355953, \"iteration\": 1560, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002887001493945718, \"iteration\": 1561, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009533269912935793, \"iteration\": 1562, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005822879611514509, \"iteration\": 1563, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010057841427624226, \"iteration\": 1564, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007750537479296327, \"iteration\": 1565, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011993047082796693, \"iteration\": 1566, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009306964348070323, \"iteration\": 1567, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006849953206256032, \"iteration\": 1568, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005528958281502128, \"iteration\": 1569, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006054242257960141, \"iteration\": 1570, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009081303724087775, \"iteration\": 1571, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044181033968925476, \"iteration\": 1572, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005418846849352121, \"iteration\": 1573, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009628006373532116, \"iteration\": 1574, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028345119208097458, \"iteration\": 1575, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012278001522645354, \"iteration\": 1576, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011731787817552686, \"iteration\": 1577, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01798374392092228, \"iteration\": 1578, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007557080243714154, \"iteration\": 1579, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007919780910015106, \"iteration\": 1580, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.009940480813384056, \"iteration\": 1581, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011524842120707035, \"iteration\": 1582, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005781389772891998, \"iteration\": 1583, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00037483093910850585, \"iteration\": 1584, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011962337885051966, \"iteration\": 1585, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000886611407622695, \"iteration\": 1586, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012398837134242058, \"iteration\": 1587, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008291314588859677, \"iteration\": 1588, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006265426054596901, \"iteration\": 1589, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007423027418553829, \"iteration\": 1590, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00032713086693547666, \"iteration\": 1591, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00478268601000309, \"iteration\": 1592, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00067732366733253, \"iteration\": 1593, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000704817590303719, \"iteration\": 1594, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008873777696862817, \"iteration\": 1595, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002387354616075754, \"iteration\": 1596, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006799119291827083, \"iteration\": 1597, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005175881087779999, \"iteration\": 1598, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008083729189820588, \"iteration\": 1599, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00047023920342326164, \"iteration\": 1600, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006307492149062455, \"iteration\": 1601, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012771814363077283, \"iteration\": 1602, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018695323960855603, \"iteration\": 1603, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011119196424260736, \"iteration\": 1604, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006360646802932024, \"iteration\": 1605, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006117699667811394, \"iteration\": 1606, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.013390249572694302, \"iteration\": 1607, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009020866127684712, \"iteration\": 1608, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002843511290848255, \"iteration\": 1609, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003866978222504258, \"iteration\": 1610, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007841556798666716, \"iteration\": 1611, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011594219831749797, \"iteration\": 1612, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009239605278708041, \"iteration\": 1613, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005525542655959725, \"iteration\": 1614, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008466262370347977, \"iteration\": 1615, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00105898582842201, \"iteration\": 1616, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001505867694504559, \"iteration\": 1617, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004260013811290264, \"iteration\": 1618, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001978611573576927, \"iteration\": 1619, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007231803028844297, \"iteration\": 1620, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005118173430673778, \"iteration\": 1621, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006451067165471613, \"iteration\": 1622, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006128082750365138, \"iteration\": 1623, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009561780607327819, \"iteration\": 1624, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001606255304068327, \"iteration\": 1625, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005110413767397404, \"iteration\": 1626, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006037699640728533, \"iteration\": 1627, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010390901006758213, \"iteration\": 1628, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007135864580050111, \"iteration\": 1629, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00028146940167061985, \"iteration\": 1630, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004821981128770858, \"iteration\": 1631, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013523908564820886, \"iteration\": 1632, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0026557915844023228, \"iteration\": 1633, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012869633734226227, \"iteration\": 1634, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002097031334415078, \"iteration\": 1635, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006186842452734709, \"iteration\": 1636, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021977736614644527, \"iteration\": 1637, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00075634935637936, \"iteration\": 1638, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005849918816238642, \"iteration\": 1639, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000857293140143156, \"iteration\": 1640, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009435618412680924, \"iteration\": 1641, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006654245080426335, \"iteration\": 1642, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004685432941187173, \"iteration\": 1643, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011514381039887667, \"iteration\": 1644, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000818913453258574, \"iteration\": 1645, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003904497134499252, \"iteration\": 1646, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010485522216185927, \"iteration\": 1647, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005172256496734917, \"iteration\": 1648, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011133289663121104, \"iteration\": 1649, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009085745550692081, \"iteration\": 1650, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00032201147405430675, \"iteration\": 1651, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.009722013026475906, \"iteration\": 1652, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000720893032848835, \"iteration\": 1653, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019590372685343027, \"iteration\": 1654, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007244799635373056, \"iteration\": 1655, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006091681425459683, \"iteration\": 1656, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009627626277506351, \"iteration\": 1657, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007009137189015746, \"iteration\": 1658, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007528210990130901, \"iteration\": 1659, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009880037978291512, \"iteration\": 1660, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000898380356375128, \"iteration\": 1661, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0034060226753354073, \"iteration\": 1662, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020435082260519266, \"iteration\": 1663, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005456345970742404, \"iteration\": 1664, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016122263623401523, \"iteration\": 1665, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005422983085736632, \"iteration\": 1666, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005991916987113655, \"iteration\": 1667, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007377468864433467, \"iteration\": 1668, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005734142614528537, \"iteration\": 1669, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000780453672632575, \"iteration\": 1670, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018556242575868964, \"iteration\": 1671, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009764556889422238, \"iteration\": 1672, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00039354164618998766, \"iteration\": 1673, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00044172530760988593, \"iteration\": 1674, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005070370971225202, \"iteration\": 1675, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01672176644206047, \"iteration\": 1676, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009057307033799589, \"iteration\": 1677, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007714967941865325, \"iteration\": 1678, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00040845826151780784, \"iteration\": 1679, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006810055929236114, \"iteration\": 1680, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003904837358277291, \"iteration\": 1681, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002570690121501684, \"iteration\": 1682, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003947960212826729, \"iteration\": 1683, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041982647962868214, \"iteration\": 1684, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023465424601454288, \"iteration\": 1685, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004629770410247147, \"iteration\": 1686, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00044613791396841407, \"iteration\": 1687, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003722143010236323, \"iteration\": 1688, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00022586662089452147, \"iteration\": 1689, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005095727974548936, \"iteration\": 1690, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035755321732722223, \"iteration\": 1691, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037587384576909244, \"iteration\": 1692, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000690390937961638, \"iteration\": 1693, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000537969172000885, \"iteration\": 1694, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043723059934563935, \"iteration\": 1695, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045646633952856064, \"iteration\": 1696, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003649163991212845, \"iteration\": 1697, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035513279726728797, \"iteration\": 1698, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003945370845030993, \"iteration\": 1699, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003374548105057329, \"iteration\": 1700, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045567238703370094, \"iteration\": 1701, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011745183728635311, \"iteration\": 1702, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002680779143702239, \"iteration\": 1703, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003309750172775239, \"iteration\": 1704, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003564610087778419, \"iteration\": 1705, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031401548767462373, \"iteration\": 1706, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000278695544693619, \"iteration\": 1707, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003326750884298235, \"iteration\": 1708, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036115458351559937, \"iteration\": 1709, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00038222805596888065, \"iteration\": 1710, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026024726685136557, \"iteration\": 1711, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00576030882075429, \"iteration\": 1712, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004934715107083321, \"iteration\": 1713, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003366106888279319, \"iteration\": 1714, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003326450823806226, \"iteration\": 1715, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00030887676985003054, \"iteration\": 1716, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000278054823866114, \"iteration\": 1717, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024069273786153644, \"iteration\": 1718, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023477045760955662, \"iteration\": 1719, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037143606459721923, \"iteration\": 1720, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005338757764548063, \"iteration\": 1721, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003271130262874067, \"iteration\": 1722, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034827186027541757, \"iteration\": 1723, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002084070350974798, \"iteration\": 1724, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019491590501274914, \"iteration\": 1725, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000756286084651947, \"iteration\": 1726, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003739072708413005, \"iteration\": 1727, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003711947938427329, \"iteration\": 1728, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008477976662106812, \"iteration\": 1729, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031849998049438, \"iteration\": 1730, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000270765827735886, \"iteration\": 1731, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005352423759177327, \"iteration\": 1732, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028088537510484457, \"iteration\": 1733, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011505747679620981, \"iteration\": 1734, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00030960069852881134, \"iteration\": 1735, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004965309635736048, \"iteration\": 1736, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003572450368665159, \"iteration\": 1737, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005273078568279743, \"iteration\": 1738, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03628632053732872, \"iteration\": 1739, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019303231965750456, \"iteration\": 1740, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005722037749364972, \"iteration\": 1741, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005302692879922688, \"iteration\": 1742, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002835519262589514, \"iteration\": 1743, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026674181572161615, \"iteration\": 1744, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004298411076888442, \"iteration\": 1745, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019633611664175987, \"iteration\": 1746, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003763777785934508, \"iteration\": 1747, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003172054421156645, \"iteration\": 1748, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000396743300370872, \"iteration\": 1749, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002746959216892719, \"iteration\": 1750, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004978298675268888, \"iteration\": 1751, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004241002316121012, \"iteration\": 1752, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023899321968201548, \"iteration\": 1753, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007747335475869477, \"iteration\": 1754, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004966795677319169, \"iteration\": 1755, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000347241380950436, \"iteration\": 1756, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002648602530825883, \"iteration\": 1757, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00047442890354432166, \"iteration\": 1758, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00027678615879267454, \"iteration\": 1759, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034655959461815655, \"iteration\": 1760, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00044919969514012337, \"iteration\": 1761, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003812711511272937, \"iteration\": 1762, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028472006670199335, \"iteration\": 1763, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031113310251384974, \"iteration\": 1764, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024645900703035295, \"iteration\": 1765, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004004477523267269, \"iteration\": 1766, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026191191864199936, \"iteration\": 1767, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00042295618914067745, \"iteration\": 1768, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028105833916924894, \"iteration\": 1769, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021204256336204708, \"iteration\": 1770, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000327563495375216, \"iteration\": 1771, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0001968832511920482, \"iteration\": 1772, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000253172853263095, \"iteration\": 1773, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004250679921824485, \"iteration\": 1774, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002500541741028428, \"iteration\": 1775, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000357471319148317, \"iteration\": 1776, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034608671558089554, \"iteration\": 1777, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002671964466571808, \"iteration\": 1778, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002556376566644758, \"iteration\": 1779, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023881200468167663, \"iteration\": 1780, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019486712699290365, \"iteration\": 1781, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004184669815003872, \"iteration\": 1782, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023916226928122342, \"iteration\": 1783, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006815001834183931, \"iteration\": 1784, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002513369545340538, \"iteration\": 1785, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002813255996443331, \"iteration\": 1786, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034120140480808914, \"iteration\": 1787, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026774650905281305, \"iteration\": 1788, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00042325747199356556, \"iteration\": 1789, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043215701589360833, \"iteration\": 1790, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005303054349496961, \"iteration\": 1791, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004018657491542399, \"iteration\": 1792, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043937627924606204, \"iteration\": 1793, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002849409938789904, \"iteration\": 1794, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002254327991977334, \"iteration\": 1795, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003239985089749098, \"iteration\": 1796, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003129433316644281, \"iteration\": 1797, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037498524761758745, \"iteration\": 1798, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021438903058879077, \"iteration\": 1799, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005424221162684262, \"iteration\": 1800, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000564353889785707, \"iteration\": 1801, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045601429883390665, \"iteration\": 1802, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021589345124084502, \"iteration\": 1803, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002394644689047709, \"iteration\": 1804, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000510445621330291, \"iteration\": 1805, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002619432343635708, \"iteration\": 1806, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0001594250206835568, \"iteration\": 1807, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003085642238147557, \"iteration\": 1808, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028446686337701976, \"iteration\": 1809, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004589031159412116, \"iteration\": 1810, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00020303284691181034, \"iteration\": 1811, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.007628313731402159, \"iteration\": 1812, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004254568775650114, \"iteration\": 1813, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005429281736724079, \"iteration\": 1814, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033796741627156734, \"iteration\": 1815, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006115883006714284, \"iteration\": 1816, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00016983914247248322, \"iteration\": 1817, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002813322644215077, \"iteration\": 1818, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002225240459665656, \"iteration\": 1819, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00017284994828514755, \"iteration\": 1820, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003003855817951262, \"iteration\": 1821, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019013015844393522, \"iteration\": 1822, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003580214106477797, \"iteration\": 1823, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029777371673844755, \"iteration\": 1824, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006665755645371974, \"iteration\": 1825, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033454428194090724, \"iteration\": 1826, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00025718723190948367, \"iteration\": 1827, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024063765886239707, \"iteration\": 1828, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002614990808069706, \"iteration\": 1829, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00038454154855571687, \"iteration\": 1830, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002659926249179989, \"iteration\": 1831, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035747577203437686, \"iteration\": 1832, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003035587724298239, \"iteration\": 1833, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006583840004168451, \"iteration\": 1834, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00013349790242500603, \"iteration\": 1835, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002346018300158903, \"iteration\": 1836, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00018311841995455325, \"iteration\": 1837, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000348519446561113, \"iteration\": 1838, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002888300805352628, \"iteration\": 1839, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001056085922755301, \"iteration\": 1840, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00027153120026923716, \"iteration\": 1841, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00030120680457912385, \"iteration\": 1842, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003735353529918939, \"iteration\": 1843, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015135008143261075, \"iteration\": 1844, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00032821588683873415, \"iteration\": 1845, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002778702473733574, \"iteration\": 1846, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003639117639977485, \"iteration\": 1847, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023446463455911726, \"iteration\": 1848, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002361123450100422, \"iteration\": 1849, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021959042351227254, \"iteration\": 1850, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002324795932509005, \"iteration\": 1851, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036718702176585793, \"iteration\": 1852, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034918857272714376, \"iteration\": 1853, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003190930001437664, \"iteration\": 1854, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003605937527026981, \"iteration\": 1855, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002649836824275553, \"iteration\": 1856, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00022089731646701694, \"iteration\": 1857, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002015528443735093, \"iteration\": 1858, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00032471053418703377, \"iteration\": 1859, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003135066363029182, \"iteration\": 1860, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002877170918509364, \"iteration\": 1861, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00014518716488964856, \"iteration\": 1862, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002897586382459849, \"iteration\": 1863, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00020229922665748745, \"iteration\": 1864, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002570166252553463, \"iteration\": 1865, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00014760118210688233, \"iteration\": 1866, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029531549080275, \"iteration\": 1867, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029705764609389007, \"iteration\": 1868, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031653812038712204, \"iteration\": 1869, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008632733952254057, \"iteration\": 1870, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003283327096141875, \"iteration\": 1871, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00018130439275410026, \"iteration\": 1872, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003197191981598735, \"iteration\": 1873, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003587578539736569, \"iteration\": 1874, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029902864480391145, \"iteration\": 1875, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005944854929111898, \"iteration\": 1876, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028952377033419907, \"iteration\": 1877, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009538729209452868, \"iteration\": 1878, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00020474188204389066, \"iteration\": 1879, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036697962787002325, \"iteration\": 1880, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.727316501084715e-05, \"iteration\": 1881, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00011004111729562283, \"iteration\": 1882, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001780543359927833, \"iteration\": 1883, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002027929003816098, \"iteration\": 1884, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019188504666090012, \"iteration\": 1885, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014605780597776175, \"iteration\": 1886, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022100323985796422, \"iteration\": 1887, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031748463516123593, \"iteration\": 1888, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015537464059889317, \"iteration\": 1889, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021137742442078888, \"iteration\": 1890, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029689961229451, \"iteration\": 1891, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00034411740489304066, \"iteration\": 1892, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022092522704042494, \"iteration\": 1893, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000284616049611941, \"iteration\": 1894, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026293224073015153, \"iteration\": 1895, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014492226182483137, \"iteration\": 1896, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005924556753598154, \"iteration\": 1897, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021050054056104273, \"iteration\": 1898, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001976928033400327, \"iteration\": 1899, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013972926535643637, \"iteration\": 1900, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004161926917731762, \"iteration\": 1901, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019651057664304972, \"iteration\": 1902, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019494877778925002, \"iteration\": 1903, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000224569535930641, \"iteration\": 1904, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002473126514814794, \"iteration\": 1905, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014061294496059418, \"iteration\": 1906, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013700526324100792, \"iteration\": 1907, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019283393339719623, \"iteration\": 1908, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014679088781122118, \"iteration\": 1909, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002088793262373656, \"iteration\": 1910, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001919502392411232, \"iteration\": 1911, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018668072880245745, \"iteration\": 1912, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001411492412444204, \"iteration\": 1913, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030525773763656616, \"iteration\": 1914, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021037989063188434, \"iteration\": 1915, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017785263480618596, \"iteration\": 1916, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019425524806138128, \"iteration\": 1917, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001339519367320463, \"iteration\": 1918, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018267030827701092, \"iteration\": 1919, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0019598565995693207, \"iteration\": 1920, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027836806839331985, \"iteration\": 1921, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018998619634658098, \"iteration\": 1922, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013906607637181878, \"iteration\": 1923, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0034763088915497065, \"iteration\": 1924, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012518855510279536, \"iteration\": 1925, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000192759427591227, \"iteration\": 1926, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017992756329476833, \"iteration\": 1927, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023640532162971795, \"iteration\": 1928, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002691946574486792, \"iteration\": 1929, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006946999346837401, \"iteration\": 1930, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018473519594408572, \"iteration\": 1931, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002167663915315643, \"iteration\": 1932, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019353309471625835, \"iteration\": 1933, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001058337657013908, \"iteration\": 1934, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015621466445736587, \"iteration\": 1935, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00035634025698527694, \"iteration\": 1936, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000308079703245312, \"iteration\": 1937, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001208887915709056, \"iteration\": 1938, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002507138065993786, \"iteration\": 1939, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002252666890854016, \"iteration\": 1940, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028136353939771652, \"iteration\": 1941, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001521312806289643, \"iteration\": 1942, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017849895812105387, \"iteration\": 1943, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021453200315590948, \"iteration\": 1944, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015446495672222227, \"iteration\": 1945, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002183673350373283, \"iteration\": 1946, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00010760685836430639, \"iteration\": 1947, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012486076448112726, \"iteration\": 1948, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012023429735563695, \"iteration\": 1949, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024680187925696373, \"iteration\": 1950, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000280367792584002, \"iteration\": 1951, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022954876476433128, \"iteration\": 1952, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002763569063972682, \"iteration\": 1953, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020105723524466157, \"iteration\": 1954, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001367771183140576, \"iteration\": 1955, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001512433955213055, \"iteration\": 1956, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00034585926914587617, \"iteration\": 1957, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020187301561236382, \"iteration\": 1958, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017302051128353924, \"iteration\": 1959, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002116017567459494, \"iteration\": 1960, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014482410915661603, \"iteration\": 1961, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024983397452160716, \"iteration\": 1962, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014630367513746023, \"iteration\": 1963, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003086722572334111, \"iteration\": 1964, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016649630561005324, \"iteration\": 1965, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003347495221532881, \"iteration\": 1966, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019012167467735708, \"iteration\": 1967, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015437472029589117, \"iteration\": 1968, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019615775090642273, \"iteration\": 1969, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016243370191659778, \"iteration\": 1970, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015377035015262663, \"iteration\": 1971, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.64065475272946e-05, \"iteration\": 1972, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017276724975090474, \"iteration\": 1973, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014068061136640608, \"iteration\": 1974, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016681969282217324, \"iteration\": 1975, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000600360450334847, \"iteration\": 1976, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00036485245800577104, \"iteration\": 1977, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014233295223675668, \"iteration\": 1978, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020519588724710047, \"iteration\": 1979, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013159713125787675, \"iteration\": 1980, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020264452905394137, \"iteration\": 1981, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023333875287789851, \"iteration\": 1982, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015969060768838972, \"iteration\": 1983, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014855063636787236, \"iteration\": 1984, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024155784922186285, \"iteration\": 1985, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014174166426528245, \"iteration\": 1986, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016544766549486667, \"iteration\": 1987, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014059682143852115, \"iteration\": 1988, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003470932715572417, \"iteration\": 1989, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017815848696045578, \"iteration\": 1990, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017145962920039892, \"iteration\": 1991, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014589786587748677, \"iteration\": 1992, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002174077817471698, \"iteration\": 1993, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017493015911895782, \"iteration\": 1994, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002322618820471689, \"iteration\": 1995, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011102911958005279, \"iteration\": 1996, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001813777635106817, \"iteration\": 1997, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018268906569574028, \"iteration\": 1998, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004310071817599237, \"iteration\": 1999, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001283337187487632, \"iteration\": 2000, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015429539780598134, \"iteration\": 2001, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013981052325107157, \"iteration\": 2002, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021807316807098687, \"iteration\": 2003, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016048180987127125, \"iteration\": 2004, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020038479124195874, \"iteration\": 2005, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002799408102873713, \"iteration\": 2006, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.972160139819607e-05, \"iteration\": 2007, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017382956866640598, \"iteration\": 2008, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001225676533067599, \"iteration\": 2009, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019356193661224097, \"iteration\": 2010, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02483179420232773, \"iteration\": 2011, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001179457176476717, \"iteration\": 2012, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002505170996300876, \"iteration\": 2013, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005164992762729526, \"iteration\": 2014, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017207888595294207, \"iteration\": 2015, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001532130263512954, \"iteration\": 2016, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001398692256771028, \"iteration\": 2017, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023185080499388278, \"iteration\": 2018, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011595473915804178, \"iteration\": 2019, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021493923850357533, \"iteration\": 2020, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017378908523824066, \"iteration\": 2021, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003409647033549845, \"iteration\": 2022, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012864267046097666, \"iteration\": 2023, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015497162530664355, \"iteration\": 2024, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002381903468631208, \"iteration\": 2025, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019288461771793664, \"iteration\": 2026, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024311027664225549, \"iteration\": 2027, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017338783072773367, \"iteration\": 2028, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020728744857478887, \"iteration\": 2029, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020709179807454348, \"iteration\": 2030, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016889255493879318, \"iteration\": 2031, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018350839673075825, \"iteration\": 2032, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014658630243502557, \"iteration\": 2033, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002075610391329974, \"iteration\": 2034, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026452353224158287, \"iteration\": 2035, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001757487771101296, \"iteration\": 2036, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009148993412964046, \"iteration\": 2037, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014457933139055967, \"iteration\": 2038, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001601564435986802, \"iteration\": 2039, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001041859621182084, \"iteration\": 2040, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011874092160724103, \"iteration\": 2041, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002627344219945371, \"iteration\": 2042, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001794866839190945, \"iteration\": 2043, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019290206546429545, \"iteration\": 2044, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02267264388501644, \"iteration\": 2045, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002873713383451104, \"iteration\": 2046, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002081451384583488, \"iteration\": 2047, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003054944099858403, \"iteration\": 2048, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019925041124224663, \"iteration\": 2049, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004812955448869616, \"iteration\": 2050, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.422959556104615e-05, \"iteration\": 2051, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015420916315633804, \"iteration\": 2052, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016028819663915783, \"iteration\": 2053, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017988307808991522, \"iteration\": 2054, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013370212400332093, \"iteration\": 2055, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020573240180965513, \"iteration\": 2056, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006509863305836916, \"iteration\": 2057, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017509279132355005, \"iteration\": 2058, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00010981157538481057, \"iteration\": 2059, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000744272256270051, \"iteration\": 2060, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001183373315143399, \"iteration\": 2061, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026129637262783945, \"iteration\": 2062, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018659172928892076, \"iteration\": 2063, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019457565213087946, \"iteration\": 2064, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02360525168478489, \"iteration\": 2065, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002448542509227991, \"iteration\": 2066, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014029309386387467, \"iteration\": 2067, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00045699201291427016, \"iteration\": 2068, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001464078959543258, \"iteration\": 2069, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000250037235673517, \"iteration\": 2070, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006056674756109715, \"iteration\": 2071, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015471980441361666, \"iteration\": 2072, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018140011525247246, \"iteration\": 2073, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00010129029396921396, \"iteration\": 2074, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013246659364085644, \"iteration\": 2075, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003045497869607061, \"iteration\": 2076, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019667894230224192, \"iteration\": 2077, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00039748201379552484, \"iteration\": 2078, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003219316713511944, \"iteration\": 2079, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015289097791537642, \"iteration\": 2080, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000159234186867252, \"iteration\": 2081, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00010903594375122339, \"iteration\": 2082, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002791625156532973, \"iteration\": 2083, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024401368864346296, \"iteration\": 2084, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013979410869069397, \"iteration\": 2085, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016767650959081948, \"iteration\": 2086, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002189027436543256, \"iteration\": 2087, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.007628775201737881, \"iteration\": 2088, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014771164569538087, \"iteration\": 2089, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001061268339981325, \"iteration\": 2090, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# POC\n",
    "print(\"Prepare data...\")\n",
    "train_data_nn = encode_data(train_raw, tfidf_encoder)\n",
    "test_data_nn = encode_data(test_raw, tfidf_encoder)\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models/gb')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    "    \n",
    ")\n",
    "\n",
    "dataloader = DataLoader(train_data_nn, batch_size=128, shuffle=True)\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(tfidf_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "if (models_dir / 'model_nn.pt').exists() and USE_CACHE:\n",
    "    model_nn = load_model(model_nn, models_dir, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn, models_dir, \"model_nn\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # X_test = torch.stack([dta[0] for dta in test])\n",
    "    X_test = torch.stack([test[0] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_test = torch.stack([test[1] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_pred = model_nn.predict(X_test)\n",
    "\n",
    "\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='binary'))\n",
    "print(\"AUC\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 44.74batch/s, batch_accuracy=1, loss=0.259]    \n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 46.15batch/s, batch_accuracy=0.857, loss=0.224]\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.29batch/s, batch_accuracy=1, loss=0.156]     \n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.85batch/s, batch_accuracy=1, loss=0.442]     \n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 44.90batch/s, batch_accuracy=0.857, loss=0.309] \n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 43.80batch/s, batch_accuracy=1, loss=0.000741]  \n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.52batch/s, batch_accuracy=1, loss=0.000174]  \n",
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 46.16batch/s, batch_accuracy=1, loss=0.0255]    \n",
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.34batch/s, batch_accuracy=1, loss=3.27e-5]   \n",
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.90batch/s, batch_accuracy=1, loss=4.23e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7226652945716491, 0.7589840583626047, 0.7403795466526094, None)\n",
      "AUC 0.695218524907798\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-35fb0dc84e184c26a9e88f3e04c35419.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-35fb0dc84e184c26a9e88f3e04c35419.vega-embed details,\n",
       "  #altair-viz-35fb0dc84e184c26a9e88f3e04c35419.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-35fb0dc84e184c26a9e88f3e04c35419\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-35fb0dc84e184c26a9e88f3e04c35419\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-35fb0dc84e184c26a9e88f3e04c35419\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-6f7b914d55cc10ec2a2f5d154a020679\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-6f7b914d55cc10ec2a2f5d154a020679\": [{\"training_acc\": 0.578125, \"training_loss\": 0.6923887729644775, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6918081045150757, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6906307339668274, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6876694560050964, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6869733929634094, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 0.6923384070396423, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.690186619758606, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6823326945304871, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6834338307380676, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6743682622909546, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6757763028144836, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6694672107696533, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6732174754142761, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.661378800868988, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6775014400482178, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.515625, \"training_loss\": 0.6938682794570923, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6610860824584961, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.484375, \"training_loss\": 0.7076752185821533, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 0.7118377685546875, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6826286315917969, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6582725048065186, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.670867383480072, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6612330079078674, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 0.6961631774902344, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.688134491443634, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6690741777420044, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6521781086921692, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 0.6885555982589722, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6653655767440796, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6681665182113647, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6533540487289429, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6680343151092529, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 0.6859362721443176, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6407076716423035, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.4921875, \"training_loss\": 0.6874412298202515, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6536192297935486, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6639785766601562, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6648322939872742, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.662065327167511, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6464459300041199, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6350640058517456, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6456736922264099, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6730915904045105, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6483786702156067, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6670374274253845, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6354543566703796, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6676325798034668, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6773353219032288, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.635379433631897, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.6348624229431152, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.6229503154754639, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.621653139591217, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.611208438873291, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.6115902662277222, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6347943544387817, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.6219542026519775, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6014502644538879, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6570279002189636, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.6084660887718201, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.582269549369812, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5949937701225281, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.6138876676559448, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6165611743927002, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5858478546142578, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5503432154655457, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5903685688972473, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5598716139793396, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5442255735397339, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5508798956871033, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5619486570358276, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5867957472801208, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5778874754905701, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6147251725196838, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.6447964906692505, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5549261569976807, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5158447027206421, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5923943519592285, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5343689918518066, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5589202046394348, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5396547317504883, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5402830839157104, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.512822151184082, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4855712950229645, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5897951722145081, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5735079646110535, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5727715492248535, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5592740774154663, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5374603867530823, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.507577657699585, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5260552763938904, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5980650782585144, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5601244568824768, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5128251910209656, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5451897978782654, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4986780881881714, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5248579382896423, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5290843844413757, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5340381860733032, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5105305910110474, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.511772632598877, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5670266151428223, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.49606624245643616, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.465124249458313, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5272328853607178, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5262971520423889, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.46284252405166626, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5506987571716309, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4748563766479492, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.49871596693992615, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5026082992553711, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4432922303676605, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4806378185749054, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5068082809448242, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.47427642345428467, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.44685113430023193, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5207847356796265, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.49254727363586426, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5488864183425903, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4314441680908203, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.47071418166160583, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4824157655239105, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4435824453830719, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.518198549747467, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5610344409942627, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5015175342559814, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.484647274017334, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.4940689206123352, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5390467047691345, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.48277798295021057, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4585457146167755, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.532485842704773, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4448689818382263, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4639095366001129, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.48258450627326965, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5390339493751526, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4922638535499573, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.49836617708206177, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.43788400292396545, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5383306741714478, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.44544360041618347, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5586891174316406, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.42379745841026306, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5920029282569885, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5102249979972839, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.45163875818252563, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5481765866279602, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.46305525302886963, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.401894211769104, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.507215678691864, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.427114337682724, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4134462773799896, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.49871325492858887, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.44759035110473633, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5073177814483643, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4173247218132019, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4374963045120239, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4811812937259674, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4337875247001648, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5584404468536377, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5030316710472107, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4260812997817993, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5055534839630127, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5012648701667786, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4393549859523773, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.41680634021759033, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4051905572414398, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.43782275915145874, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.49033114314079285, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5536473989486694, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4802488684654236, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5426450371742249, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5483596324920654, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.890625, \"training_loss\": 0.3527895212173462, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4855319857597351, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4903485178947449, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.527760922908783, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.3880629539489746, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.512018084526062, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4894922971725464, \"iteration\": 179, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4244261384010315, \"iteration\": 180, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4295929968357086, \"iteration\": 181, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.41338610649108887, \"iteration\": 182, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.469269722700119, \"iteration\": 183, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.44482243061065674, \"iteration\": 184, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4845564663410187, \"iteration\": 185, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4451131820678711, \"iteration\": 186, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4953673183917999, \"iteration\": 187, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.4499783515930176, \"iteration\": 188, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4740189015865326, \"iteration\": 189, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.46172791719436646, \"iteration\": 190, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5275318622589111, \"iteration\": 191, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4900880455970764, \"iteration\": 192, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.40980827808380127, \"iteration\": 193, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.515474796295166, \"iteration\": 194, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.49970951676368713, \"iteration\": 195, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4669681787490845, \"iteration\": 196, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5156705379486084, \"iteration\": 197, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4416220486164093, \"iteration\": 198, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.46826615929603577, \"iteration\": 199, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4999590814113617, \"iteration\": 200, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.438430517911911, \"iteration\": 201, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4824925661087036, \"iteration\": 202, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4217991828918457, \"iteration\": 203, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.47988539934158325, \"iteration\": 204, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.44010019302368164, \"iteration\": 205, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.47976720333099365, \"iteration\": 206, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5402576923370361, \"iteration\": 207, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4939941167831421, \"iteration\": 208, \"epoch\": 1}, {\"training_acc\": 1.0, \"training_loss\": 0.2587355375289917, \"iteration\": 209, \"epoch\": 1}, {\"training_acc\": 0.90625, \"training_loss\": 0.2714990973472595, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2856869101524353, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3030731678009033, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.29122552275657654, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3411577641963959, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3265557289123535, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.26665839552879333, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21547381579875946, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.27737170457839966, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28020328283309937, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.271592378616333, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.29507187008857727, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2763020396232605, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2674710750579834, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.25085750222206116, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2842336595058441, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2868417203426361, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3280717730522156, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.288409024477005, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2635417878627777, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25687146186828613, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24852553009986877, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27102723717689514, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.34759974479675293, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2869758903980255, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.23538005352020264, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2023964375257492, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2451113760471344, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29831942915916443, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2932182550430298, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3007792532444, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2599834203720093, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2690993845462799, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2701241970062256, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2776678204536438, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.34206393361091614, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.31838080286979675, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.4121292233467102, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2957834303379059, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2828199565410614, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2788495719432831, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.32788747549057007, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30959242582321167, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.394035279750824, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23046524822711945, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.29009830951690674, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2808364927768707, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23033961653709412, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3291068971157074, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2850368022918701, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2818106710910797, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.34286975860595703, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3369787335395813, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30931082367897034, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3164517283439636, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3251187205314636, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2376929521560669, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24455447494983673, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3574366271495819, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2968704104423523, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3181701600551605, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3346133530139923, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.4059195816516876, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30270978808403015, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3089940845966339, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28729432821273804, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2748672068119049, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2375112771987915, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.31445953249931335, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3610999286174774, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3554290533065796, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27593258023262024, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.28443771600723267, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.38440611958503723, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.38858506083488464, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33966201543807983, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3765854239463806, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2700704038143158, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3164249658584595, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23640961945056915, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2657882273197174, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.26167136430740356, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2651897966861725, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.27507707476615906, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.42756515741348267, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3510081171989441, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24160444736480713, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3233017325401306, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.1984974443912506, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33926713466644287, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.21657344698905945, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3226573169231415, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.30892014503479004, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3478563725948334, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3353329002857208, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30414557456970215, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3784116506576538, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3551355302333832, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2767060697078705, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.34235918521881104, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.36400631070137024, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3807099163532257, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.36251014471054077, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3051950931549072, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.36370140314102173, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.37297436594963074, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27126064896583557, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3372228741645813, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.318414568901062, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.257344514131546, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.30148011445999146, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3083496391773224, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3061584234237671, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24571412801742554, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.39247381687164307, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23719699680805206, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.28917402029037476, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26607152819633484, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.29601746797561646, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29249459505081177, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.27326861023902893, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32850247621536255, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3050161600112915, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.331574946641922, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3080165684223175, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3515787422657013, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3262835443019867, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.279443621635437, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.36963698267936707, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.30027204751968384, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3222537636756897, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3335056006908417, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3125217854976654, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2685120403766632, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3942570984363556, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.44789621233940125, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3110150098800659, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2811563014984131, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.298761248588562, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3156142830848694, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21723580360412598, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.36650407314300537, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3498355448246002, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2902784049510956, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.29788732528686523, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2937852442264557, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.23442506790161133, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3690201938152313, \"iteration\": 357, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.42902374267578125, \"iteration\": 358, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.34207427501678467, \"iteration\": 359, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.22104495763778687, \"iteration\": 360, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2734578251838684, \"iteration\": 361, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32129380106925964, \"iteration\": 362, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3087959289550781, \"iteration\": 363, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3072909712791443, \"iteration\": 364, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.330969899892807, \"iteration\": 365, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3000503480434418, \"iteration\": 366, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3289891481399536, \"iteration\": 367, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3390238881111145, \"iteration\": 368, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.278719961643219, \"iteration\": 369, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19958528876304626, \"iteration\": 370, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3049369156360626, \"iteration\": 371, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3234744369983673, \"iteration\": 372, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.2971789836883545, \"iteration\": 373, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3480643033981323, \"iteration\": 374, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.34835898876190186, \"iteration\": 375, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.343464195728302, \"iteration\": 376, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30715256929397583, \"iteration\": 377, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.23923517763614655, \"iteration\": 378, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32325515151023865, \"iteration\": 379, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3015969395637512, \"iteration\": 380, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3131122589111328, \"iteration\": 381, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32932382822036743, \"iteration\": 382, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2505590319633484, \"iteration\": 383, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3273264169692993, \"iteration\": 384, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3373040556907654, \"iteration\": 385, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3098571300506592, \"iteration\": 386, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3336518108844757, \"iteration\": 387, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.36268699169158936, \"iteration\": 388, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3327949047088623, \"iteration\": 389, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24066635966300964, \"iteration\": 390, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3551272749900818, \"iteration\": 391, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.24868643283843994, \"iteration\": 392, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.39678940176963806, \"iteration\": 393, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.30797719955444336, \"iteration\": 394, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.39709872007369995, \"iteration\": 395, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34306320548057556, \"iteration\": 396, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3381797969341278, \"iteration\": 397, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3242224454879761, \"iteration\": 398, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3763301372528076, \"iteration\": 399, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.45399346947669983, \"iteration\": 400, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31026017665863037, \"iteration\": 401, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3463525176048279, \"iteration\": 402, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.39602336287498474, \"iteration\": 403, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4119807481765747, \"iteration\": 404, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.32369309663772583, \"iteration\": 405, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3680592179298401, \"iteration\": 406, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.389469712972641, \"iteration\": 407, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2474723756313324, \"iteration\": 408, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33741068840026855, \"iteration\": 409, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4572663903236389, \"iteration\": 410, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3868609666824341, \"iteration\": 411, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.29186028242111206, \"iteration\": 412, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.38071849942207336, \"iteration\": 413, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.37786632776260376, \"iteration\": 414, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.25956058502197266, \"iteration\": 415, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3351479470729828, \"iteration\": 416, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31142276525497437, \"iteration\": 417, \"epoch\": 2}, {\"training_acc\": 0.8571428571428571, \"training_loss\": 0.22356200218200684, \"iteration\": 418, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16671282052993774, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1531381607055664, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1962530016899109, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17533214390277863, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.15673059225082397, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1940799057483673, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.17052410542964935, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14483442902565002, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17038191854953766, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17147724330425262, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18049493432044983, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1627255380153656, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1808907836675644, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18973954021930695, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2433832883834839, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18255136907100677, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.17350620031356812, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.15745212137699127, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14600861072540283, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.17618940770626068, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15700632333755493, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10495330393314362, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1972537785768509, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.188658207654953, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2007993906736374, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17524650692939758, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16441917419433594, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14028891921043396, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1590234339237213, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1674819439649582, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23536044359207153, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1595669984817505, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16600215435028076, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1518535017967224, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15921680629253387, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18372361361980438, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1701090931892395, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21213316917419434, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1653425097465515, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13672806322574615, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15447434782981873, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.17155377566814423, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10697442293167114, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14064337313175201, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.11329783499240875, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15203961730003357, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10089857131242752, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12178943306207657, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17703823745250702, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1650579869747162, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21131081879138947, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10470803081989288, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10052873194217682, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12184010446071625, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.20314884185791016, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.14268293976783752, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.11621060967445374, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1400136947631836, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.27461978793144226, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.21566355228424072, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22041398286819458, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14495450258255005, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11885157227516174, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.12407554686069489, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12757538259029388, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18396079540252686, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.14754074811935425, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11584644019603729, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24704836308956146, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.17749124765396118, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1665881872177124, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1591482162475586, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1572171300649643, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18029089272022247, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.173270121216774, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12217361479997635, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.13366791605949402, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1806228905916214, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2552300691604614, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.1128128319978714, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2133505791425705, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.15901575982570648, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16529513895511627, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.14843912422657013, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14043350517749786, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.1987021416425705, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.177830308675766, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1374576985836029, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24133184552192688, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23952309787273407, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.20136038959026337, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.13893355429172516, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1327131688594818, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1613052636384964, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17878174781799316, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18198047578334808, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23737287521362305, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1618022918701172, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15126389265060425, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1700688600540161, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1306302547454834, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15321943163871765, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.09788373857736588, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20793163776397705, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2024705708026886, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.18800249695777893, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16524052619934082, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1660596877336502, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11941768229007721, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17266350984573364, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20155903697013855, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.20336097478866577, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2359423041343689, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2082979530096054, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24226361513137817, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.21658918261528015, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19147074222564697, \"iteration\": 535, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1919529289007187, \"iteration\": 536, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15648195147514343, \"iteration\": 537, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22939591109752655, \"iteration\": 538, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15724410116672516, \"iteration\": 539, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18881452083587646, \"iteration\": 540, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1938469409942627, \"iteration\": 541, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12663765251636505, \"iteration\": 542, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.17804011702537537, \"iteration\": 543, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.15273581445217133, \"iteration\": 544, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.16250649094581604, \"iteration\": 545, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21966639161109924, \"iteration\": 546, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18279039859771729, \"iteration\": 547, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.21079331636428833, \"iteration\": 548, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1653694063425064, \"iteration\": 549, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23271387815475464, \"iteration\": 550, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.254035621881485, \"iteration\": 551, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.19111289083957672, \"iteration\": 552, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.20950868725776672, \"iteration\": 553, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.1349605768918991, \"iteration\": 554, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1262277066707611, \"iteration\": 555, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.175026535987854, \"iteration\": 556, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16316178441047668, \"iteration\": 557, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.23260456323623657, \"iteration\": 558, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2024090439081192, \"iteration\": 559, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2118135541677475, \"iteration\": 560, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1989905834197998, \"iteration\": 561, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.20672380924224854, \"iteration\": 562, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13749468326568604, \"iteration\": 563, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.14275957643985748, \"iteration\": 564, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10348466038703918, \"iteration\": 565, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15632963180541992, \"iteration\": 566, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2558860182762146, \"iteration\": 567, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.23832151293754578, \"iteration\": 568, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.179607555270195, \"iteration\": 569, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.19514742493629456, \"iteration\": 570, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.23783659934997559, \"iteration\": 571, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.15683428943157196, \"iteration\": 572, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2512168884277344, \"iteration\": 573, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21750612556934357, \"iteration\": 574, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2305881381034851, \"iteration\": 575, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11617542058229446, \"iteration\": 576, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2354430854320526, \"iteration\": 577, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.22130624949932098, \"iteration\": 578, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20468001067638397, \"iteration\": 579, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.19227904081344604, \"iteration\": 580, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1826653778553009, \"iteration\": 581, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18117155134677887, \"iteration\": 582, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1536668837070465, \"iteration\": 583, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18340419232845306, \"iteration\": 584, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13284999132156372, \"iteration\": 585, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18335682153701782, \"iteration\": 586, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18386021256446838, \"iteration\": 587, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18456509709358215, \"iteration\": 588, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.23096327483654022, \"iteration\": 589, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2737588882446289, \"iteration\": 590, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30051273107528687, \"iteration\": 591, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1413896679878235, \"iteration\": 592, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3488967716693878, \"iteration\": 593, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.17574450373649597, \"iteration\": 594, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2039724737405777, \"iteration\": 595, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1895182877779007, \"iteration\": 596, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23369881510734558, \"iteration\": 597, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16120657324790955, \"iteration\": 598, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2116701900959015, \"iteration\": 599, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11529050767421722, \"iteration\": 600, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2304251492023468, \"iteration\": 601, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.264036625623703, \"iteration\": 602, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.295289009809494, \"iteration\": 603, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21569114923477173, \"iteration\": 604, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16322079300880432, \"iteration\": 605, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.24763353168964386, \"iteration\": 606, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21063554286956787, \"iteration\": 607, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18859237432479858, \"iteration\": 608, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2763759195804596, \"iteration\": 609, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1927889585494995, \"iteration\": 610, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31795692443847656, \"iteration\": 611, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24173475801944733, \"iteration\": 612, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23068906366825104, \"iteration\": 613, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.15725375711917877, \"iteration\": 614, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2433742880821228, \"iteration\": 615, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17962002754211426, \"iteration\": 616, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.3048933744430542, \"iteration\": 617, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24627315998077393, \"iteration\": 618, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14895173907279968, \"iteration\": 619, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1602051705121994, \"iteration\": 620, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24515363574028015, \"iteration\": 621, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23597532510757446, \"iteration\": 622, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.23594443500041962, \"iteration\": 623, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24107803404331207, \"iteration\": 624, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.27881842851638794, \"iteration\": 625, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2864903211593628, \"iteration\": 626, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.1555001437664032, \"iteration\": 627, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10033917427062988, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10715530067682266, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0778808444738388, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.125450998544693, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08144911378622055, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1358419954776764, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10069692134857178, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05731553956866264, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10438167303800583, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07866053283214569, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0930500328540802, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19765251874923706, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1269102841615677, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08814407885074615, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08158894628286362, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11129409819841385, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07905614376068115, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08572451770305634, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08649594336748123, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15483690798282623, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.059287264943122864, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07366962730884552, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05932486057281494, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1263786256313324, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08918368816375732, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0866614356637001, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10735836625099182, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06924021989107132, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08076576143503189, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08738324791193008, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12025478482246399, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08076794445514679, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06463922560214996, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1524857133626938, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07403410226106644, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09129542112350464, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07321257889270782, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14857791364192963, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06794805079698563, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08108402788639069, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09142524003982544, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05337296798825264, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08215716481208801, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09380413591861725, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0943884402513504, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07487601041793823, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10943659394979477, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12570929527282715, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10932400822639465, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08071275055408478, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.043497998267412186, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12674404680728912, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.03586656600236893, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09668932855129242, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06396638602018356, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.09446079283952713, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08961521089076996, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.09214244037866592, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12918347120285034, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.0924382358789444, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046485841274261475, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13542288541793823, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07317283749580383, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07897628843784332, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07240171730518341, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.06397630274295807, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07004977017641068, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.04186304286122322, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13385936617851257, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1359485387802124, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04707638919353485, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06792453676462173, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11519838124513626, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12483049929141998, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0720147117972374, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14079007506370544, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06751257926225662, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08369769155979156, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10541758686304092, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08898100256919861, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14289090037345886, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06933199614286423, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04823741316795349, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1497192680835724, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06636184453964233, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09654759615659714, \"iteration\": 713, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06443067640066147, \"iteration\": 714, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.07134664058685303, \"iteration\": 715, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07286399602890015, \"iteration\": 716, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.12400954961776733, \"iteration\": 717, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06966140866279602, \"iteration\": 718, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07346943765878677, \"iteration\": 719, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10940510034561157, \"iteration\": 720, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10574594885110855, \"iteration\": 721, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06416317075490952, \"iteration\": 722, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15605604648590088, \"iteration\": 723, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1644534170627594, \"iteration\": 724, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.05588282272219658, \"iteration\": 725, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06262142956256866, \"iteration\": 726, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.058689359575510025, \"iteration\": 727, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14582432806491852, \"iteration\": 728, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11986333131790161, \"iteration\": 729, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07022244483232498, \"iteration\": 730, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10609865188598633, \"iteration\": 731, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11181513220071793, \"iteration\": 732, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08796975016593933, \"iteration\": 733, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07979383319616318, \"iteration\": 734, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09361842274665833, \"iteration\": 735, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06562235951423645, \"iteration\": 736, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12650363147258759, \"iteration\": 737, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07363753020763397, \"iteration\": 738, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1427249312400818, \"iteration\": 739, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06185902655124664, \"iteration\": 740, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09307784587144852, \"iteration\": 741, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07997646927833557, \"iteration\": 742, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09972718358039856, \"iteration\": 743, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.051974426954984665, \"iteration\": 744, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.12110287696123123, \"iteration\": 745, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11465582996606827, \"iteration\": 746, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0548037551343441, \"iteration\": 747, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.18241193890571594, \"iteration\": 748, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05114265903830528, \"iteration\": 749, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06512938439846039, \"iteration\": 750, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15525749325752258, \"iteration\": 751, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.18822011351585388, \"iteration\": 752, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08652424812316895, \"iteration\": 753, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07605992257595062, \"iteration\": 754, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07181806117296219, \"iteration\": 755, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06695286929607391, \"iteration\": 756, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07759644836187363, \"iteration\": 757, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1581188142299652, \"iteration\": 758, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14077454805374146, \"iteration\": 759, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.21171513199806213, \"iteration\": 760, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14539462327957153, \"iteration\": 761, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07105763256549835, \"iteration\": 762, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13927717506885529, \"iteration\": 763, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.055546835064888, \"iteration\": 764, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12599362432956696, \"iteration\": 765, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0975884199142456, \"iteration\": 766, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12892618775367737, \"iteration\": 767, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.09906654804944992, \"iteration\": 768, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1289411038160324, \"iteration\": 769, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15855401754379272, \"iteration\": 770, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14981570839881897, \"iteration\": 771, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10025335848331451, \"iteration\": 772, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0829247534275055, \"iteration\": 773, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.14333854615688324, \"iteration\": 774, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09386640042066574, \"iteration\": 775, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11044485867023468, \"iteration\": 776, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06435434520244598, \"iteration\": 777, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1270298808813095, \"iteration\": 778, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14800222218036652, \"iteration\": 779, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.09604065120220184, \"iteration\": 780, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15574045479297638, \"iteration\": 781, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07419519126415253, \"iteration\": 782, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09231453388929367, \"iteration\": 783, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0732337087392807, \"iteration\": 784, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.19259926676750183, \"iteration\": 785, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09548439085483551, \"iteration\": 786, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09947032481431961, \"iteration\": 787, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14500917494297028, \"iteration\": 788, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17183473706245422, \"iteration\": 789, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.18320177495479584, \"iteration\": 790, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12912064790725708, \"iteration\": 791, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.15513361990451813, \"iteration\": 792, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18859368562698364, \"iteration\": 793, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14078323543071747, \"iteration\": 794, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10843582451343536, \"iteration\": 795, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15774917602539062, \"iteration\": 796, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1381632387638092, \"iteration\": 797, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0680646002292633, \"iteration\": 798, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11091434955596924, \"iteration\": 799, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16988587379455566, \"iteration\": 800, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0772641971707344, \"iteration\": 801, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07479779422283173, \"iteration\": 802, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10313671082258224, \"iteration\": 803, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07012636214494705, \"iteration\": 804, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18795469403266907, \"iteration\": 805, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09418845921754837, \"iteration\": 806, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1039266437292099, \"iteration\": 807, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09696032106876373, \"iteration\": 808, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0796566754579544, \"iteration\": 809, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08806389570236206, \"iteration\": 810, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.07861640304327011, \"iteration\": 811, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10011773556470871, \"iteration\": 812, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05161735415458679, \"iteration\": 813, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10566996783018112, \"iteration\": 814, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.2108275145292282, \"iteration\": 815, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07745388895273209, \"iteration\": 816, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.059161920100450516, \"iteration\": 817, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09061498194932938, \"iteration\": 818, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13134169578552246, \"iteration\": 819, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1105489730834961, \"iteration\": 820, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.16819941997528076, \"iteration\": 821, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12036675214767456, \"iteration\": 822, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.12809552252292633, \"iteration\": 823, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14704425632953644, \"iteration\": 824, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14292895793914795, \"iteration\": 825, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11551348865032196, \"iteration\": 826, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1673772633075714, \"iteration\": 827, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06686186045408249, \"iteration\": 828, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.14981979131698608, \"iteration\": 829, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1716388314962387, \"iteration\": 830, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0941798985004425, \"iteration\": 831, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10299596190452576, \"iteration\": 832, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09901240468025208, \"iteration\": 833, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1571504771709442, \"iteration\": 834, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13745737075805664, \"iteration\": 835, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.44155386090278625, \"iteration\": 836, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.05316653475165367, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01307602971792221, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01689721643924713, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.024902578443288803, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.04488975554704666, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.040165115147829056, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03139812499284744, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09561149775981903, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06917116791009903, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01819775253534317, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06481768935918808, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030558286234736443, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06699424237012863, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03267780691385269, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05830201879143715, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05069428309798241, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.033500075340270996, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.036803051829338074, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03340799733996391, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08143345266580582, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.029986590147018433, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.037993788719177246, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044171638786792755, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.042568616569042206, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05275437608361244, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02973191998898983, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0773058757185936, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02899589203298092, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05241873487830162, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07616513967514038, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.053522735834121704, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0427202433347702, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10146103799343109, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054329611361026764, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0573197603225708, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0646820068359375, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07409930229187012, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046153049916028976, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.053564611822366714, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04587638005614281, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04047616571187973, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.033118605613708496, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.058930184692144394, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.024293556809425354, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05646265670657158, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04652683809399605, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.060256727039813995, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06812895089387894, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.045099761337041855, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03024754300713539, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032179154455661774, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046087633818387985, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07559834420681, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040846724063158035, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030007213354110718, \"iteration\": 891, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05224579572677612, \"iteration\": 892, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01968349702656269, \"iteration\": 893, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0396389439702034, \"iteration\": 894, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.061995979398489, \"iteration\": 895, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06735558807849884, \"iteration\": 896, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1156669557094574, \"iteration\": 897, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04462670534849167, \"iteration\": 898, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.035039015114307404, \"iteration\": 899, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07835761457681656, \"iteration\": 900, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07346190512180328, \"iteration\": 901, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0397338792681694, \"iteration\": 902, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05457794666290283, \"iteration\": 903, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.057452477514743805, \"iteration\": 904, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0470392182469368, \"iteration\": 905, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03342098742723465, \"iteration\": 906, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.019534535706043243, \"iteration\": 907, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.051051605492830276, \"iteration\": 908, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02217981219291687, \"iteration\": 909, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021792493760585785, \"iteration\": 910, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04457314684987068, \"iteration\": 911, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05470294505357742, \"iteration\": 912, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.031415779143571854, \"iteration\": 913, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025868890807032585, \"iteration\": 914, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03774921968579292, \"iteration\": 915, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03127967566251755, \"iteration\": 916, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.053707294166088104, \"iteration\": 917, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07298024743795395, \"iteration\": 918, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.03185388073325157, \"iteration\": 919, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.065367192029953, \"iteration\": 920, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06227656453847885, \"iteration\": 921, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.058742012828588486, \"iteration\": 922, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04023916274309158, \"iteration\": 923, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.056536704301834106, \"iteration\": 924, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.043284401297569275, \"iteration\": 925, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05125061795115471, \"iteration\": 926, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04213062673807144, \"iteration\": 927, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02154967002570629, \"iteration\": 928, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.035109132528305054, \"iteration\": 929, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.017962802201509476, \"iteration\": 930, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.039492085576057434, \"iteration\": 931, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.019604753702878952, \"iteration\": 932, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06913484632968903, \"iteration\": 933, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02652478963136673, \"iteration\": 934, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03248682618141174, \"iteration\": 935, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09105145931243896, \"iteration\": 936, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07869581878185272, \"iteration\": 937, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.024039601907134056, \"iteration\": 938, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02678525261580944, \"iteration\": 939, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027224751189351082, \"iteration\": 940, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10762069374322891, \"iteration\": 941, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046428173780441284, \"iteration\": 942, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02294769510626793, \"iteration\": 943, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07741810381412506, \"iteration\": 944, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01606621965765953, \"iteration\": 945, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.019009007140994072, \"iteration\": 946, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.05968569591641426, \"iteration\": 947, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0160503089427948, \"iteration\": 948, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0400133915245533, \"iteration\": 949, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024854058399796486, \"iteration\": 950, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.058694422245025635, \"iteration\": 951, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06341559439897537, \"iteration\": 952, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.037704892456531525, \"iteration\": 953, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07148461043834686, \"iteration\": 954, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05201410874724388, \"iteration\": 955, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.055130429565906525, \"iteration\": 956, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08657333999872208, \"iteration\": 957, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08902633190155029, \"iteration\": 958, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025645721703767776, \"iteration\": 959, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04333409294486046, \"iteration\": 960, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06872904300689697, \"iteration\": 961, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.053494952619075775, \"iteration\": 962, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04358875751495361, \"iteration\": 963, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08196194469928741, \"iteration\": 964, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021735163405537605, \"iteration\": 965, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025868695229291916, \"iteration\": 966, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05661672353744507, \"iteration\": 967, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0416654571890831, \"iteration\": 968, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.018246203660964966, \"iteration\": 969, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02620818093419075, \"iteration\": 970, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0833505168557167, \"iteration\": 971, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.043667271733284, \"iteration\": 972, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.059144265949726105, \"iteration\": 973, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04661193862557411, \"iteration\": 974, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.061598747968673706, \"iteration\": 975, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.041627153754234314, \"iteration\": 976, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06332886219024658, \"iteration\": 977, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02153327874839306, \"iteration\": 978, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05850685387849808, \"iteration\": 979, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04085926711559296, \"iteration\": 980, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02429886721074581, \"iteration\": 981, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.044509317725896835, \"iteration\": 982, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08604244887828827, \"iteration\": 983, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07413481920957565, \"iteration\": 984, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04215554520487785, \"iteration\": 985, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021340562030673027, \"iteration\": 986, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.046003684401512146, \"iteration\": 987, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03224886581301689, \"iteration\": 988, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02502051554620266, \"iteration\": 989, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0386921688914299, \"iteration\": 990, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.032150786370038986, \"iteration\": 991, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0226481631398201, \"iteration\": 992, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05769965797662735, \"iteration\": 993, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.033013708889484406, \"iteration\": 994, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044150520116090775, \"iteration\": 995, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03139904886484146, \"iteration\": 996, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.022046836093068123, \"iteration\": 997, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031485795974731445, \"iteration\": 998, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06394025683403015, \"iteration\": 999, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.017917001619935036, \"iteration\": 1000, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04184615612030029, \"iteration\": 1001, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02609650045633316, \"iteration\": 1002, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05126285180449486, \"iteration\": 1003, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.014346151612699032, \"iteration\": 1004, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03875117376446724, \"iteration\": 1005, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03824649751186371, \"iteration\": 1006, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06452417373657227, \"iteration\": 1007, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1126096323132515, \"iteration\": 1008, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10675515979528427, \"iteration\": 1009, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11929351836442947, \"iteration\": 1010, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09082506597042084, \"iteration\": 1011, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028733985498547554, \"iteration\": 1012, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09043621271848679, \"iteration\": 1013, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0792306512594223, \"iteration\": 1014, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025087367743253708, \"iteration\": 1015, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0397099144756794, \"iteration\": 1016, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07965444028377533, \"iteration\": 1017, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.052715759724378586, \"iteration\": 1018, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03644857555627823, \"iteration\": 1019, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05723812058568001, \"iteration\": 1020, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03546728938817978, \"iteration\": 1021, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.048250552266836166, \"iteration\": 1022, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0367903858423233, \"iteration\": 1023, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02342280000448227, \"iteration\": 1024, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028083784505724907, \"iteration\": 1025, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03550341725349426, \"iteration\": 1026, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03345580771565437, \"iteration\": 1027, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.018729332834482193, \"iteration\": 1028, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03967016190290451, \"iteration\": 1029, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.029542051255702972, \"iteration\": 1030, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1124642938375473, \"iteration\": 1031, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.026408646255731583, \"iteration\": 1032, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02474052645266056, \"iteration\": 1033, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07201084494590759, \"iteration\": 1034, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05724220350384712, \"iteration\": 1035, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0765007734298706, \"iteration\": 1036, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08046070486307144, \"iteration\": 1037, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.041437506675720215, \"iteration\": 1038, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.033322397619485855, \"iteration\": 1039, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0409562923014164, \"iteration\": 1040, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.053154800087213516, \"iteration\": 1041, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.05283867567777634, \"iteration\": 1042, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.020297978073358536, \"iteration\": 1043, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.061091162264347076, \"iteration\": 1044, \"epoch\": 5}, {\"training_acc\": 0.8571428571428571, \"training_loss\": 0.3092140853404999, \"iteration\": 1045, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01932605355978012, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008289219811558723, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013004128821194172, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019795021042227745, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010627076029777527, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009388737380504608, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012094768695533276, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006338905543088913, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006601997651159763, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008402918465435505, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017973626032471657, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010149105452001095, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007200615480542183, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009908046573400497, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04408220946788788, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008770491927862167, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013054506853222847, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009623696096241474, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013046102598309517, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.014888396486639977, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04565829783678055, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023983517661690712, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004631361458450556, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02711760811507702, \"iteration\": 1069, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007963884621858597, \"iteration\": 1070, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011538486927747726, \"iteration\": 1071, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022644037380814552, \"iteration\": 1072, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0264348816126585, \"iteration\": 1073, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.05485593155026436, \"iteration\": 1074, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.034289129078388214, \"iteration\": 1075, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022319011390209198, \"iteration\": 1076, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025409134104847908, \"iteration\": 1077, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03518950566649437, \"iteration\": 1078, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006152610294520855, \"iteration\": 1079, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0065549518913030624, \"iteration\": 1080, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03290651738643646, \"iteration\": 1081, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014851558953523636, \"iteration\": 1082, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00877659022808075, \"iteration\": 1083, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02480948716402054, \"iteration\": 1084, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011559262871742249, \"iteration\": 1085, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006506552454084158, \"iteration\": 1086, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011380726471543312, \"iteration\": 1087, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009364099241793156, \"iteration\": 1088, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010290257632732391, \"iteration\": 1089, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.027193399146199226, \"iteration\": 1090, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019987627863883972, \"iteration\": 1091, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0036231903359293938, \"iteration\": 1092, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029103122651576996, \"iteration\": 1093, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06794198602437973, \"iteration\": 1094, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013379762880504131, \"iteration\": 1095, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009723463095724583, \"iteration\": 1096, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01052872370928526, \"iteration\": 1097, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010150428861379623, \"iteration\": 1098, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018826831132173538, \"iteration\": 1099, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006875460036098957, \"iteration\": 1100, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03782115876674652, \"iteration\": 1101, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016989801079034805, \"iteration\": 1102, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00688870158046484, \"iteration\": 1103, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008195036090910435, \"iteration\": 1104, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00903020054101944, \"iteration\": 1105, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009177001193165779, \"iteration\": 1106, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011237381026148796, \"iteration\": 1107, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00507403165102005, \"iteration\": 1108, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008711768314242363, \"iteration\": 1109, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006859671324491501, \"iteration\": 1110, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.011539480648934841, \"iteration\": 1111, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013229792937636375, \"iteration\": 1112, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03122725896537304, \"iteration\": 1113, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022563312202692032, \"iteration\": 1114, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02940603531897068, \"iteration\": 1115, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0067651779390871525, \"iteration\": 1116, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006898034829646349, \"iteration\": 1117, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00664876913651824, \"iteration\": 1118, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007527519017457962, \"iteration\": 1119, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011317293159663677, \"iteration\": 1120, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.085248202085495, \"iteration\": 1121, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.024702340364456177, \"iteration\": 1122, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01843421906232834, \"iteration\": 1123, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025951622053980827, \"iteration\": 1124, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006077941507101059, \"iteration\": 1125, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0095117362216115, \"iteration\": 1126, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007349337916821241, \"iteration\": 1127, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005643367767333984, \"iteration\": 1128, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010905859991908073, \"iteration\": 1129, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009694659151136875, \"iteration\": 1130, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019267316907644272, \"iteration\": 1131, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012786433100700378, \"iteration\": 1132, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010187814012169838, \"iteration\": 1133, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01959907077252865, \"iteration\": 1134, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026858801022171974, \"iteration\": 1135, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006761735305190086, \"iteration\": 1136, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039386600255966187, \"iteration\": 1137, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020175430923700333, \"iteration\": 1138, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006812100764364004, \"iteration\": 1139, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009497882798314095, \"iteration\": 1140, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009263705462217331, \"iteration\": 1141, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009070644155144691, \"iteration\": 1142, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016105251386761665, \"iteration\": 1143, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01703386753797531, \"iteration\": 1144, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011910250410437584, \"iteration\": 1145, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03537052869796753, \"iteration\": 1146, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00691826269030571, \"iteration\": 1147, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015718581154942513, \"iteration\": 1148, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0047914814203977585, \"iteration\": 1149, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012882104143500328, \"iteration\": 1150, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004518345929682255, \"iteration\": 1151, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020668603479862213, \"iteration\": 1152, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013810141943395138, \"iteration\": 1153, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004339854698628187, \"iteration\": 1154, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007383476942777634, \"iteration\": 1155, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004687542095780373, \"iteration\": 1156, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005076289642602205, \"iteration\": 1157, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.003691324731335044, \"iteration\": 1158, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04515130817890167, \"iteration\": 1159, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020705487579107285, \"iteration\": 1160, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0033418822567909956, \"iteration\": 1161, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007148156873881817, \"iteration\": 1162, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016668004915118217, \"iteration\": 1163, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010000061243772507, \"iteration\": 1164, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007260225713253021, \"iteration\": 1165, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04577590897679329, \"iteration\": 1166, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023102818056941032, \"iteration\": 1167, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010028078220784664, \"iteration\": 1168, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011610143817961216, \"iteration\": 1169, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010532115586102009, \"iteration\": 1170, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012435434386134148, \"iteration\": 1171, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.003869911888614297, \"iteration\": 1172, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01121902372688055, \"iteration\": 1173, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006356614176183939, \"iteration\": 1174, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007338156457990408, \"iteration\": 1175, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010710334405303001, \"iteration\": 1176, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005612894427031279, \"iteration\": 1177, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030415726825594902, \"iteration\": 1178, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015639228746294975, \"iteration\": 1179, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006900602951645851, \"iteration\": 1180, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0070711649022996426, \"iteration\": 1181, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044634368270635605, \"iteration\": 1182, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00522569939494133, \"iteration\": 1183, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005863534286618233, \"iteration\": 1184, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004891046788543463, \"iteration\": 1185, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0034196972846984863, \"iteration\": 1186, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014715483412146568, \"iteration\": 1187, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014737721532583237, \"iteration\": 1188, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005685656797140837, \"iteration\": 1189, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009525409899652004, \"iteration\": 1190, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016488445922732353, \"iteration\": 1191, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006529493723064661, \"iteration\": 1192, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01167057640850544, \"iteration\": 1193, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007841028273105621, \"iteration\": 1194, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005476420279592276, \"iteration\": 1195, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.043471094220876694, \"iteration\": 1196, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007469076197594404, \"iteration\": 1197, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030174341052770615, \"iteration\": 1198, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004591001197695732, \"iteration\": 1199, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02112687937915325, \"iteration\": 1200, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0048776837065815926, \"iteration\": 1201, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.015780562534928322, \"iteration\": 1202, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.014346150681376457, \"iteration\": 1203, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026147346943616867, \"iteration\": 1204, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02386396750807762, \"iteration\": 1205, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015231329947710037, \"iteration\": 1206, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044202279299497604, \"iteration\": 1207, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010263215750455856, \"iteration\": 1208, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006897651124745607, \"iteration\": 1209, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004622200038284063, \"iteration\": 1210, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011345120146870613, \"iteration\": 1211, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009496037848293781, \"iteration\": 1212, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024604149162769318, \"iteration\": 1213, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005905585829168558, \"iteration\": 1214, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.048862747848033905, \"iteration\": 1215, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.021870791912078857, \"iteration\": 1216, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014895482920110226, \"iteration\": 1217, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008970928378403187, \"iteration\": 1218, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016621368005871773, \"iteration\": 1219, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010050131008028984, \"iteration\": 1220, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006415597628802061, \"iteration\": 1221, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03314339369535446, \"iteration\": 1222, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013361796736717224, \"iteration\": 1223, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016289206221699715, \"iteration\": 1224, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01422918401658535, \"iteration\": 1225, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014438922517001629, \"iteration\": 1226, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005267349071800709, \"iteration\": 1227, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007556930650025606, \"iteration\": 1228, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016517184674739838, \"iteration\": 1229, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004033269360661507, \"iteration\": 1230, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009245344437658787, \"iteration\": 1231, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.05954398214817047, \"iteration\": 1232, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006625575013458729, \"iteration\": 1233, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01564207673072815, \"iteration\": 1234, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006458771415054798, \"iteration\": 1235, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009853978641331196, \"iteration\": 1236, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009184927679598331, \"iteration\": 1237, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010440820828080177, \"iteration\": 1238, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005073947831988335, \"iteration\": 1239, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012461473233997822, \"iteration\": 1240, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026155008003115654, \"iteration\": 1241, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00936594046652317, \"iteration\": 1242, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0070389942266047, \"iteration\": 1243, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014331920072436333, \"iteration\": 1244, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031037457287311554, \"iteration\": 1245, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014792175963521004, \"iteration\": 1246, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007321461103856564, \"iteration\": 1247, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013883329927921295, \"iteration\": 1248, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01484471932053566, \"iteration\": 1249, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009920543991029263, \"iteration\": 1250, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02808000147342682, \"iteration\": 1251, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011543484404683113, \"iteration\": 1252, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0069919005036354065, \"iteration\": 1253, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007409619283862412, \"iteration\": 1254, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.003492333460599184, \"iteration\": 1255, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002594886813312769, \"iteration\": 1256, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001785938162356615, \"iteration\": 1257, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003925420809537172, \"iteration\": 1258, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00253561744466424, \"iteration\": 1259, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0033860255498439074, \"iteration\": 1260, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0021294113248586655, \"iteration\": 1261, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003971779253333807, \"iteration\": 1262, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017858436331152916, \"iteration\": 1263, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001888686092570424, \"iteration\": 1264, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002626613946631551, \"iteration\": 1265, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028667941223829985, \"iteration\": 1266, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006427730433642864, \"iteration\": 1267, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017318681348115206, \"iteration\": 1268, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002307875081896782, \"iteration\": 1269, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002586613642051816, \"iteration\": 1270, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022644619457423687, \"iteration\": 1271, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034415957052260637, \"iteration\": 1272, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005726086441427469, \"iteration\": 1273, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022227163426578045, \"iteration\": 1274, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00271804491057992, \"iteration\": 1275, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034497997257858515, \"iteration\": 1276, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0076498715206980705, \"iteration\": 1277, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025660807732492685, \"iteration\": 1278, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004520505201071501, \"iteration\": 1279, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003237111959606409, \"iteration\": 1280, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00166131102014333, \"iteration\": 1281, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035613873042166233, \"iteration\": 1282, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003687609452754259, \"iteration\": 1283, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017495700158178806, \"iteration\": 1284, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0021248827688395977, \"iteration\": 1285, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012030606158077717, \"iteration\": 1286, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001231459085829556, \"iteration\": 1287, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018266825936734676, \"iteration\": 1288, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016225487925112247, \"iteration\": 1289, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025463365018367767, \"iteration\": 1290, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020567558240145445, \"iteration\": 1291, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030687272548675537, \"iteration\": 1292, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001799037796445191, \"iteration\": 1293, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001000189338810742, \"iteration\": 1294, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001328439568169415, \"iteration\": 1295, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016683617141097784, \"iteration\": 1296, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015136610018089414, \"iteration\": 1297, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001718164305202663, \"iteration\": 1298, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001907559810206294, \"iteration\": 1299, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.012823098339140415, \"iteration\": 1300, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015023240121081471, \"iteration\": 1301, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013888012617826462, \"iteration\": 1302, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004263955634087324, \"iteration\": 1303, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001144452253356576, \"iteration\": 1304, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002319814870133996, \"iteration\": 1305, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006705303676426411, \"iteration\": 1306, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025222916156053543, \"iteration\": 1307, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015202292706817389, \"iteration\": 1308, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016313395462930202, \"iteration\": 1309, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018437809776514769, \"iteration\": 1310, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027360471431165934, \"iteration\": 1311, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07060626149177551, \"iteration\": 1312, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015715791378170252, \"iteration\": 1313, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014244450721889734, \"iteration\": 1314, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0041513643227517605, \"iteration\": 1315, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012939395383000374, \"iteration\": 1316, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017240586457774043, \"iteration\": 1317, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0021583393681794405, \"iteration\": 1318, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001382625661790371, \"iteration\": 1319, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002690627472475171, \"iteration\": 1320, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001434157369658351, \"iteration\": 1321, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002169162966310978, \"iteration\": 1322, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016428889939561486, \"iteration\": 1323, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015252049779519439, \"iteration\": 1324, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019280659034848213, \"iteration\": 1325, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03112422116100788, \"iteration\": 1326, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002777406480163336, \"iteration\": 1327, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002330314600840211, \"iteration\": 1328, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001441675703972578, \"iteration\": 1329, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006147376261651516, \"iteration\": 1330, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004573723766952753, \"iteration\": 1331, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003424736438319087, \"iteration\": 1332, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019496764289215207, \"iteration\": 1333, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017652468523010612, \"iteration\": 1334, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020758777391165495, \"iteration\": 1335, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013755313120782375, \"iteration\": 1336, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022444548085331917, \"iteration\": 1337, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005457656923681498, \"iteration\": 1338, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012073125690221786, \"iteration\": 1339, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017474193591624498, \"iteration\": 1340, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020272431429475546, \"iteration\": 1341, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016531678847968578, \"iteration\": 1342, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00152528565376997, \"iteration\": 1343, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015219885390251875, \"iteration\": 1344, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012531208340078592, \"iteration\": 1345, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001186893554404378, \"iteration\": 1346, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034913094714283943, \"iteration\": 1347, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003323070704936981, \"iteration\": 1348, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00542532280087471, \"iteration\": 1349, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025507204700261354, \"iteration\": 1350, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001701006549410522, \"iteration\": 1351, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031281616538763046, \"iteration\": 1352, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002278550062328577, \"iteration\": 1353, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012777376687154174, \"iteration\": 1354, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.060249730944633484, \"iteration\": 1355, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003189590759575367, \"iteration\": 1356, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034101749770343304, \"iteration\": 1357, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014230855740606785, \"iteration\": 1358, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006205111276358366, \"iteration\": 1359, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0021799583919346333, \"iteration\": 1360, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001363309333100915, \"iteration\": 1361, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018494417890906334, \"iteration\": 1362, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001922024879604578, \"iteration\": 1363, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014062966220080853, \"iteration\": 1364, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017158100381493568, \"iteration\": 1365, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001757725840434432, \"iteration\": 1366, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014370634453371167, \"iteration\": 1367, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038870670832693577, \"iteration\": 1368, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023605728056281805, \"iteration\": 1369, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00257877423427999, \"iteration\": 1370, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0010857144370675087, \"iteration\": 1371, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015012096846476197, \"iteration\": 1372, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006934806704521179, \"iteration\": 1373, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014373844023793936, \"iteration\": 1374, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00385834788903594, \"iteration\": 1375, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016110909637063742, \"iteration\": 1376, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002148645929992199, \"iteration\": 1377, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031243744306266308, \"iteration\": 1378, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0033141535241156816, \"iteration\": 1379, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013401989126577973, \"iteration\": 1380, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017335847951471806, \"iteration\": 1381, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016485241940245032, \"iteration\": 1382, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018848286708816886, \"iteration\": 1383, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019726185128092766, \"iteration\": 1384, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001495035015977919, \"iteration\": 1385, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0021925405599176884, \"iteration\": 1386, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0010122423991560936, \"iteration\": 1387, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0030456988606601954, \"iteration\": 1388, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012677708873525262, \"iteration\": 1389, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022668628953397274, \"iteration\": 1390, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0008940288098528981, \"iteration\": 1391, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013470983831211925, \"iteration\": 1392, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002167673083022237, \"iteration\": 1393, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002883767709136009, \"iteration\": 1394, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003270127344876528, \"iteration\": 1395, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015234751626849174, \"iteration\": 1396, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012101841857656837, \"iteration\": 1397, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0030123754404485226, \"iteration\": 1398, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023332093842327595, \"iteration\": 1399, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0008190643857233226, \"iteration\": 1400, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013207708252593875, \"iteration\": 1401, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001635684515349567, \"iteration\": 1402, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013727250043302774, \"iteration\": 1403, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014437803765758872, \"iteration\": 1404, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.011936094611883163, \"iteration\": 1405, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0010870096739381552, \"iteration\": 1406, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0029005310498178005, \"iteration\": 1407, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016217520460486412, \"iteration\": 1408, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005873166490346193, \"iteration\": 1409, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012928354553878307, \"iteration\": 1410, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001384840114042163, \"iteration\": 1411, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001684651360847056, \"iteration\": 1412, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025656239595264196, \"iteration\": 1413, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00445268489420414, \"iteration\": 1414, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012592339189723134, \"iteration\": 1415, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0011184369213879108, \"iteration\": 1416, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034587462432682514, \"iteration\": 1417, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014791961293667555, \"iteration\": 1418, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014062162954360247, \"iteration\": 1419, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013891428243368864, \"iteration\": 1420, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017750663682818413, \"iteration\": 1421, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00215932191349566, \"iteration\": 1422, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015587996458634734, \"iteration\": 1423, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018568008672446012, \"iteration\": 1424, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0006137648597359657, \"iteration\": 1425, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003283741883933544, \"iteration\": 1426, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001133642392233014, \"iteration\": 1427, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0011909226886928082, \"iteration\": 1428, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04949759319424629, \"iteration\": 1429, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0008987594046629965, \"iteration\": 1430, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015735692577436566, \"iteration\": 1431, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00108176504727453, \"iteration\": 1432, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007970855804160237, \"iteration\": 1433, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0006848240154795349, \"iteration\": 1434, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019724920857697725, \"iteration\": 1435, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016467203386127949, \"iteration\": 1436, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007232881034724414, \"iteration\": 1437, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001030527986586094, \"iteration\": 1438, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0010810710955411196, \"iteration\": 1439, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0009599555050954223, \"iteration\": 1440, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0017608822090551257, \"iteration\": 1441, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028813518583774567, \"iteration\": 1442, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0009389747865498066, \"iteration\": 1443, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0011087489547207952, \"iteration\": 1444, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002052539261057973, \"iteration\": 1445, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028656193986535072, \"iteration\": 1446, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.012476579286158085, \"iteration\": 1447, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020736234728246927, \"iteration\": 1448, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0029472969472408295, \"iteration\": 1449, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015222493093460798, \"iteration\": 1450, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002003571018576622, \"iteration\": 1451, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0010062785586342216, \"iteration\": 1452, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020365663804113865, \"iteration\": 1453, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002765415236353874, \"iteration\": 1454, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007459817570634186, \"iteration\": 1455, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010015863925218582, \"iteration\": 1456, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013894394505769014, \"iteration\": 1457, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013779036235064268, \"iteration\": 1458, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013785370392724872, \"iteration\": 1459, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0012389584444463253, \"iteration\": 1460, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0013815686106681824, \"iteration\": 1461, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022492026910185814, \"iteration\": 1462, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00017445418052375317, \"iteration\": 1463, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015092343091964722, \"iteration\": 1464, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00126017932780087, \"iteration\": 1465, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013290143106132746, \"iteration\": 1466, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009811229538172483, \"iteration\": 1467, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005536346579901874, \"iteration\": 1468, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007125462871044874, \"iteration\": 1469, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009742111433297396, \"iteration\": 1470, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010954085737466812, \"iteration\": 1471, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005679418100044131, \"iteration\": 1472, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00043548946268856525, \"iteration\": 1473, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004683755978476256, \"iteration\": 1474, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006480423617176712, \"iteration\": 1475, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007204134599305689, \"iteration\": 1476, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007178213563747704, \"iteration\": 1477, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001232592505402863, \"iteration\": 1478, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007575037889182568, \"iteration\": 1479, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005189568619243801, \"iteration\": 1480, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007410276448354125, \"iteration\": 1481, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007533879252150655, \"iteration\": 1482, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007250271737575531, \"iteration\": 1483, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005567998741753399, \"iteration\": 1484, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007985172560438514, \"iteration\": 1485, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004230084887240082, \"iteration\": 1486, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005178869469091296, \"iteration\": 1487, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006925634806975722, \"iteration\": 1488, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006380121922120452, \"iteration\": 1489, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007355265552178025, \"iteration\": 1490, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005501474370248616, \"iteration\": 1491, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008628340438008308, \"iteration\": 1492, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003526137734297663, \"iteration\": 1493, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006057698628865182, \"iteration\": 1494, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001899356604553759, \"iteration\": 1495, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004591572214849293, \"iteration\": 1496, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000809553312137723, \"iteration\": 1497, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007522609666921198, \"iteration\": 1498, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007068899576552212, \"iteration\": 1499, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005768894334323704, \"iteration\": 1500, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004687845357693732, \"iteration\": 1501, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009655625326558948, \"iteration\": 1502, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004050335846841335, \"iteration\": 1503, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07284990698099136, \"iteration\": 1504, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009211878292262554, \"iteration\": 1505, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007474140729755163, \"iteration\": 1506, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003986415104009211, \"iteration\": 1507, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008125315071083605, \"iteration\": 1508, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007980597438290715, \"iteration\": 1509, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009679965442046523, \"iteration\": 1510, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000580037827603519, \"iteration\": 1511, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005065361619926989, \"iteration\": 1512, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007540956721641123, \"iteration\": 1513, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006622071960009634, \"iteration\": 1514, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00038334677810780704, \"iteration\": 1515, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009785884758457541, \"iteration\": 1516, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003917363937944174, \"iteration\": 1517, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006111572147347033, \"iteration\": 1518, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006018361309543252, \"iteration\": 1519, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005707431701011956, \"iteration\": 1520, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010136510245501995, \"iteration\": 1521, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006390167982317507, \"iteration\": 1522, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014436764176934958, \"iteration\": 1523, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000765570905059576, \"iteration\": 1524, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00034833356039598584, \"iteration\": 1525, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00039892352651804686, \"iteration\": 1526, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00047926936531439424, \"iteration\": 1527, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006608862895518541, \"iteration\": 1528, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005342484218999743, \"iteration\": 1529, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00043230215669609606, \"iteration\": 1530, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007705744355916977, \"iteration\": 1531, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007073460728861392, \"iteration\": 1532, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003100487811025232, \"iteration\": 1533, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00102414155844599, \"iteration\": 1534, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05095374956727028, \"iteration\": 1535, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00034355666139163077, \"iteration\": 1536, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005594298709183931, \"iteration\": 1537, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002748370752669871, \"iteration\": 1538, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005041966796852648, \"iteration\": 1539, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00042583863250911236, \"iteration\": 1540, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005201745079830289, \"iteration\": 1541, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003932365798391402, \"iteration\": 1542, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005008630105294287, \"iteration\": 1543, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000529330805875361, \"iteration\": 1544, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006622600485570729, \"iteration\": 1545, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006670638103969395, \"iteration\": 1546, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008348535047844052, \"iteration\": 1547, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000723121571354568, \"iteration\": 1548, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005312067805789411, \"iteration\": 1549, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006638395134359598, \"iteration\": 1550, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004435968294274062, \"iteration\": 1551, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005022328696213663, \"iteration\": 1552, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006870183860883117, \"iteration\": 1553, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00035031893639825284, \"iteration\": 1554, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002795836189761758, \"iteration\": 1555, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005529226618818939, \"iteration\": 1556, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00031498525640927255, \"iteration\": 1557, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004407844040542841, \"iteration\": 1558, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004915836616419256, \"iteration\": 1559, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004772277607116848, \"iteration\": 1560, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006372573552653193, \"iteration\": 1561, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002661669277586043, \"iteration\": 1562, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00047886246466077864, \"iteration\": 1563, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006303694099187851, \"iteration\": 1564, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00045771547593176365, \"iteration\": 1565, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003216807381249964, \"iteration\": 1566, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00045889519969932735, \"iteration\": 1567, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005320488126017153, \"iteration\": 1568, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002893406490329653, \"iteration\": 1569, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007319418364204466, \"iteration\": 1570, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000480636372230947, \"iteration\": 1571, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00041695148684084415, \"iteration\": 1572, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003993641585111618, \"iteration\": 1573, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00042615109123289585, \"iteration\": 1574, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007747763302177191, \"iteration\": 1575, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005006133578717709, \"iteration\": 1576, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000712455774191767, \"iteration\": 1577, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010334796970710158, \"iteration\": 1578, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00034828888601623476, \"iteration\": 1579, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00040734029607847333, \"iteration\": 1580, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003102657210547477, \"iteration\": 1581, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003846854669973254, \"iteration\": 1582, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005234886193647981, \"iteration\": 1583, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006800227565690875, \"iteration\": 1584, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006260175723582506, \"iteration\": 1585, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002327522379346192, \"iteration\": 1586, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005011279718019068, \"iteration\": 1587, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00036327747511677444, \"iteration\": 1588, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003281485696788877, \"iteration\": 1589, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010058821178972721, \"iteration\": 1590, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00037537317257374525, \"iteration\": 1591, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00035644322633743286, \"iteration\": 1592, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00040950821130536497, \"iteration\": 1593, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00033646111842244864, \"iteration\": 1594, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004489622951950878, \"iteration\": 1595, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00025862272013910115, \"iteration\": 1596, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000819995766505599, \"iteration\": 1597, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000394304224755615, \"iteration\": 1598, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004735536640509963, \"iteration\": 1599, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00023064938432071358, \"iteration\": 1600, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001041653798893094, \"iteration\": 1601, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006026638438925147, \"iteration\": 1602, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003270571178290993, \"iteration\": 1603, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00042502133874222636, \"iteration\": 1604, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00030963635072112083, \"iteration\": 1605, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00043218318023718894, \"iteration\": 1606, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004943714011460543, \"iteration\": 1607, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006660679937340319, \"iteration\": 1608, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008809567661955953, \"iteration\": 1609, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00031030218815431, \"iteration\": 1610, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005132128135301173, \"iteration\": 1611, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00047907725092954934, \"iteration\": 1612, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00042129744542762637, \"iteration\": 1613, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008291763952001929, \"iteration\": 1614, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004883257672190666, \"iteration\": 1615, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00031499803299084306, \"iteration\": 1616, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011204745387658477, \"iteration\": 1617, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000352267874404788, \"iteration\": 1618, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002787906560115516, \"iteration\": 1619, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004905113601125777, \"iteration\": 1620, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002500531554687768, \"iteration\": 1621, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006022161687724292, \"iteration\": 1622, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00040121341589838266, \"iteration\": 1623, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000431627529906109, \"iteration\": 1624, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00028953951550647616, \"iteration\": 1625, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04196459800004959, \"iteration\": 1626, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00048645155038684607, \"iteration\": 1627, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005503547145053744, \"iteration\": 1628, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005843626568093896, \"iteration\": 1629, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00036022200947627425, \"iteration\": 1630, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003248907160013914, \"iteration\": 1631, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003318295057397336, \"iteration\": 1632, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00036768728750757873, \"iteration\": 1633, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002881074324250221, \"iteration\": 1634, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004822149930987507, \"iteration\": 1635, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014461958780884743, \"iteration\": 1636, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003944974741898477, \"iteration\": 1637, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004614900972228497, \"iteration\": 1638, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005049321916885674, \"iteration\": 1639, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.045859165489673615, \"iteration\": 1640, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00031728565227240324, \"iteration\": 1641, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011343914084136486, \"iteration\": 1642, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005207073991186917, \"iteration\": 1643, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003332836495246738, \"iteration\": 1644, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010410802206024528, \"iteration\": 1645, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006163861835375428, \"iteration\": 1646, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006133537390269339, \"iteration\": 1647, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005069039762020111, \"iteration\": 1648, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002893081691581756, \"iteration\": 1649, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004723106394521892, \"iteration\": 1650, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003360050613991916, \"iteration\": 1651, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00044480993528850377, \"iteration\": 1652, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00029535600333474576, \"iteration\": 1653, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00030844961293041706, \"iteration\": 1654, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003038149094209075, \"iteration\": 1655, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015241829678416252, \"iteration\": 1656, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00036214804276824, \"iteration\": 1657, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00046139396727085114, \"iteration\": 1658, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00048776116454973817, \"iteration\": 1659, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00032664171885699034, \"iteration\": 1660, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00022476328012999147, \"iteration\": 1661, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010667800670489669, \"iteration\": 1662, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005447235889732838, \"iteration\": 1663, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004894083249382675, \"iteration\": 1664, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005403702380135655, \"iteration\": 1665, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00030037344549782574, \"iteration\": 1666, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00036143040051683784, \"iteration\": 1667, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003964936186093837, \"iteration\": 1668, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004883325891569257, \"iteration\": 1669, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00028455775463953614, \"iteration\": 1670, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002776162582449615, \"iteration\": 1671, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.02545529417693615, \"iteration\": 1672, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003384024603292346, \"iteration\": 1673, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019054519361816347, \"iteration\": 1674, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002955690142698586, \"iteration\": 1675, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003706570714712143, \"iteration\": 1676, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006063415203243494, \"iteration\": 1677, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005415864870883524, \"iteration\": 1678, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006922299508005381, \"iteration\": 1679, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00092978251632303, \"iteration\": 1680, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001149949966929853, \"iteration\": 1681, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010611392790451646, \"iteration\": 1682, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007647370803169906, \"iteration\": 1683, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006442744634114206, \"iteration\": 1684, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005955242086201906, \"iteration\": 1685, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009741443791426718, \"iteration\": 1686, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008650675881654024, \"iteration\": 1687, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013874091673642397, \"iteration\": 1688, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002272530400659889, \"iteration\": 1689, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006641490035690367, \"iteration\": 1690, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026064427220262587, \"iteration\": 1691, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006607613759115338, \"iteration\": 1692, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036130298394709826, \"iteration\": 1693, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00027221644995734096, \"iteration\": 1694, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003070549573749304, \"iteration\": 1695, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037314591463655233, \"iteration\": 1696, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041013615555129945, \"iteration\": 1697, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003009278152603656, \"iteration\": 1698, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004339493345469236, \"iteration\": 1699, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034875169512815773, \"iteration\": 1700, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003531572292558849, \"iteration\": 1701, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028437035507522523, \"iteration\": 1702, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002569795760791749, \"iteration\": 1703, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003408228512853384, \"iteration\": 1704, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003152125864289701, \"iteration\": 1705, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.037296101450920105, \"iteration\": 1706, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009697725181467831, \"iteration\": 1707, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005133252707310021, \"iteration\": 1708, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004845317453145981, \"iteration\": 1709, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003818408295046538, \"iteration\": 1710, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005220519960857928, \"iteration\": 1711, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029764993814751506, \"iteration\": 1712, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003879835712723434, \"iteration\": 1713, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004885682719759643, \"iteration\": 1714, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035113634658046067, \"iteration\": 1715, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031839311122894287, \"iteration\": 1716, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00032730537350289524, \"iteration\": 1717, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002787691482808441, \"iteration\": 1718, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005415861960500479, \"iteration\": 1719, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034276838414371014, \"iteration\": 1720, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000263001536950469, \"iteration\": 1721, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00030099230934865773, \"iteration\": 1722, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043988070683553815, \"iteration\": 1723, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003737959486898035, \"iteration\": 1724, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033457644167356193, \"iteration\": 1725, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003131275880150497, \"iteration\": 1726, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00018503019236959517, \"iteration\": 1727, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002599213330540806, \"iteration\": 1728, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002626683854032308, \"iteration\": 1729, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034061784390360117, \"iteration\": 1730, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00025945313973352313, \"iteration\": 1731, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00041565432911738753, \"iteration\": 1732, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00038325926288962364, \"iteration\": 1733, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003306080470792949, \"iteration\": 1734, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002452951739542186, \"iteration\": 1735, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029166482272557914, \"iteration\": 1736, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0001996973587665707, \"iteration\": 1737, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031907655647955835, \"iteration\": 1738, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033223643549717963, \"iteration\": 1739, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003430363140068948, \"iteration\": 1740, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011334391310811043, \"iteration\": 1741, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019792011880781502, \"iteration\": 1742, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002807999844662845, \"iteration\": 1743, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002136774710379541, \"iteration\": 1744, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00020073774794582278, \"iteration\": 1745, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023729141685180366, \"iteration\": 1746, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019028890877962112, \"iteration\": 1747, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00025641845422796905, \"iteration\": 1748, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00025916300364769995, \"iteration\": 1749, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007128879660740495, \"iteration\": 1750, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029082619585096836, \"iteration\": 1751, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0001849424879765138, \"iteration\": 1752, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024019589181989431, \"iteration\": 1753, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023891801538411528, \"iteration\": 1754, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033739113132469356, \"iteration\": 1755, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002922494022641331, \"iteration\": 1756, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008482775301672518, \"iteration\": 1757, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002611904055811465, \"iteration\": 1758, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034550749114714563, \"iteration\": 1759, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005835855845361948, \"iteration\": 1760, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005895375506952405, \"iteration\": 1761, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035005342215299606, \"iteration\": 1762, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000675670278724283, \"iteration\": 1763, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005374203319661319, \"iteration\": 1764, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005295649752952158, \"iteration\": 1765, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003758517268579453, \"iteration\": 1766, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023706025967840105, \"iteration\": 1767, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003529217792674899, \"iteration\": 1768, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003632503212429583, \"iteration\": 1769, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002494669461157173, \"iteration\": 1770, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035626336466521025, \"iteration\": 1771, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007182641420513391, \"iteration\": 1772, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019338411220815033, \"iteration\": 1773, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00022411654936149716, \"iteration\": 1774, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002803723909892142, \"iteration\": 1775, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00042374670738354325, \"iteration\": 1776, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.715341730043292e-05, \"iteration\": 1777, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006687566637992859, \"iteration\": 1778, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002606353082228452, \"iteration\": 1779, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023855455219745636, \"iteration\": 1780, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005914725479669869, \"iteration\": 1781, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026606349274516106, \"iteration\": 1782, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010222845012322068, \"iteration\": 1783, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00017634505638852715, \"iteration\": 1784, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000745969417039305, \"iteration\": 1785, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007564102998003364, \"iteration\": 1786, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000185274489922449, \"iteration\": 1787, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035403488436713815, \"iteration\": 1788, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0001657884567975998, \"iteration\": 1789, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029276940040290356, \"iteration\": 1790, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003225280379410833, \"iteration\": 1791, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00020607071928679943, \"iteration\": 1792, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004455024318303913, \"iteration\": 1793, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027275023981928825, \"iteration\": 1794, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023711974790785462, \"iteration\": 1795, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003670999431051314, \"iteration\": 1796, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06410609185695648, \"iteration\": 1797, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004540668160188943, \"iteration\": 1798, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037625906406901777, \"iteration\": 1799, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003376484091859311, \"iteration\": 1800, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009761298424564302, \"iteration\": 1801, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0001842692872742191, \"iteration\": 1802, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004048385890200734, \"iteration\": 1803, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029969000024721026, \"iteration\": 1804, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008262916235253215, \"iteration\": 1805, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031664728885516524, \"iteration\": 1806, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002806474221870303, \"iteration\": 1807, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004333882592618465, \"iteration\": 1808, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00044088304275646806, \"iteration\": 1809, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003464589826762676, \"iteration\": 1810, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019652686023619026, \"iteration\": 1811, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004134186601731926, \"iteration\": 1812, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001000567339360714, \"iteration\": 1813, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002329715498490259, \"iteration\": 1814, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006757598603144288, \"iteration\": 1815, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019916592282243073, \"iteration\": 1816, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003818131808657199, \"iteration\": 1817, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.009224229492247105, \"iteration\": 1818, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00020445424888748676, \"iteration\": 1819, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002957373799290508, \"iteration\": 1820, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00016572739696130157, \"iteration\": 1821, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003396388201508671, \"iteration\": 1822, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031698515522293746, \"iteration\": 1823, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004909060662612319, \"iteration\": 1824, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00018063346215058118, \"iteration\": 1825, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002945431915577501, \"iteration\": 1826, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000322782841976732, \"iteration\": 1827, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002798515488393605, \"iteration\": 1828, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023415366013068706, \"iteration\": 1829, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036290157004259527, \"iteration\": 1830, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028591748559847474, \"iteration\": 1831, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00034710715408436954, \"iteration\": 1832, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008713965653441846, \"iteration\": 1833, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021361332619562745, \"iteration\": 1834, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00017379519704263657, \"iteration\": 1835, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003129513352178037, \"iteration\": 1836, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00029165908927097917, \"iteration\": 1837, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002743092773016542, \"iteration\": 1838, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021072574600111693, \"iteration\": 1839, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003453877870924771, \"iteration\": 1840, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00017633585957810283, \"iteration\": 1841, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0069057694636285305, \"iteration\": 1842, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024989937082864344, \"iteration\": 1843, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002227673539891839, \"iteration\": 1844, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005433461046777666, \"iteration\": 1845, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019686110317707062, \"iteration\": 1846, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002134008245775476, \"iteration\": 1847, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043203093810006976, \"iteration\": 1848, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019014813005924225, \"iteration\": 1849, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023649100330658257, \"iteration\": 1850, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00013128729187883437, \"iteration\": 1851, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004029014671687037, \"iteration\": 1852, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003215467440895736, \"iteration\": 1853, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00017553704674355686, \"iteration\": 1854, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019346713088452816, \"iteration\": 1855, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00022743191220797598, \"iteration\": 1856, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003373764338903129, \"iteration\": 1857, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00022543768864125013, \"iteration\": 1858, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002746210666373372, \"iteration\": 1859, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003098374290857464, \"iteration\": 1860, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002485444420017302, \"iteration\": 1861, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002215701388195157, \"iteration\": 1862, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002312005526619032, \"iteration\": 1863, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00022382911993190646, \"iteration\": 1864, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016563914716243744, \"iteration\": 1865, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019052698917221278, \"iteration\": 1866, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002436271868646145, \"iteration\": 1867, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00022416972205974162, \"iteration\": 1868, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002922207931987941, \"iteration\": 1869, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028130755526944995, \"iteration\": 1870, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00017832263256423175, \"iteration\": 1871, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003079810703638941, \"iteration\": 1872, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002048335300059989, \"iteration\": 1873, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010184186976402998, \"iteration\": 1874, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023652658273931593, \"iteration\": 1875, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028793394449166954, \"iteration\": 1876, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003014731337316334, \"iteration\": 1877, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004281961009837687, \"iteration\": 1878, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002087407629005611, \"iteration\": 1879, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008203125325962901, \"iteration\": 1880, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.2711377571104094e-05, \"iteration\": 1881, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024933251552283764, \"iteration\": 1882, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001275020622415468, \"iteration\": 1883, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001370747631881386, \"iteration\": 1884, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001791666727513075, \"iteration\": 1885, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017544117872603238, \"iteration\": 1886, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027028899057768285, \"iteration\": 1887, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019802908354904503, \"iteration\": 1888, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021737015049438924, \"iteration\": 1889, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020424617105163634, \"iteration\": 1890, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021984461636748165, \"iteration\": 1891, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022124691167846322, \"iteration\": 1892, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05319835990667343, \"iteration\": 1893, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023795297602191567, \"iteration\": 1894, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023093710478860885, \"iteration\": 1895, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00035060543450526893, \"iteration\": 1896, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013012031558901072, \"iteration\": 1897, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001414500002283603, \"iteration\": 1898, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0038461354561150074, \"iteration\": 1899, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017492001643404365, \"iteration\": 1900, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002385674451943487, \"iteration\": 1901, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002950038469862193, \"iteration\": 1902, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002927510649897158, \"iteration\": 1903, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001409056130796671, \"iteration\": 1904, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013825148926116526, \"iteration\": 1905, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015637966862414032, \"iteration\": 1906, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021005475718993694, \"iteration\": 1907, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019245660223532468, \"iteration\": 1908, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026183598674833775, \"iteration\": 1909, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02899441309273243, \"iteration\": 1910, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001989751326618716, \"iteration\": 1911, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018071953672915697, \"iteration\": 1912, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017476266657467932, \"iteration\": 1913, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023756128211971372, \"iteration\": 1914, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024338773800991476, \"iteration\": 1915, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024738055071793497, \"iteration\": 1916, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014278969028964639, \"iteration\": 1917, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002033113269135356, \"iteration\": 1918, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027869187761098146, \"iteration\": 1919, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003191940486431122, \"iteration\": 1920, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016265678277704865, \"iteration\": 1921, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012145938671892509, \"iteration\": 1922, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014134698722045869, \"iteration\": 1923, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023451856395695359, \"iteration\": 1924, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017276585276704282, \"iteration\": 1925, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016620296810287982, \"iteration\": 1926, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002365086693316698, \"iteration\": 1927, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003056329442188144, \"iteration\": 1928, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017627590568736196, \"iteration\": 1929, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005428151343949139, \"iteration\": 1930, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021538144210353494, \"iteration\": 1931, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00035794227733276784, \"iteration\": 1932, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002336574107175693, \"iteration\": 1933, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002704818616621196, \"iteration\": 1934, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002157829876523465, \"iteration\": 1935, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001941909285960719, \"iteration\": 1936, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019319370039738715, \"iteration\": 1937, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019149536092299968, \"iteration\": 1938, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002592030796222389, \"iteration\": 1939, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002288995892740786, \"iteration\": 1940, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002379033248871565, \"iteration\": 1941, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021713602473028004, \"iteration\": 1942, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022065297525841743, \"iteration\": 1943, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021506738266907632, \"iteration\": 1944, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012816698290407658, \"iteration\": 1945, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014618068234995008, \"iteration\": 1946, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016499916091561317, \"iteration\": 1947, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005456603830680251, \"iteration\": 1948, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000272703095106408, \"iteration\": 1949, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001766018249327317, \"iteration\": 1950, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001883137592813, \"iteration\": 1951, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001693919039098546, \"iteration\": 1952, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001606948208063841, \"iteration\": 1953, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019177800277248025, \"iteration\": 1954, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016655685612931848, \"iteration\": 1955, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014697869482915848, \"iteration\": 1956, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022961369541008025, \"iteration\": 1957, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012985902139917016, \"iteration\": 1958, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018465494213160127, \"iteration\": 1959, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012197883188491687, \"iteration\": 1960, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022870759130455554, \"iteration\": 1961, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.528621790697798e-05, \"iteration\": 1962, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004131928435526788, \"iteration\": 1963, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001281650474993512, \"iteration\": 1964, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017647251661401242, \"iteration\": 1965, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015412172069773078, \"iteration\": 1966, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00010541012306930497, \"iteration\": 1967, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013942057557869703, \"iteration\": 1968, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012849093764089048, \"iteration\": 1969, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008903106208890676, \"iteration\": 1970, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001411002012901008, \"iteration\": 1971, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03693670406937599, \"iteration\": 1972, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016063389193732291, \"iteration\": 1973, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013211097393650562, \"iteration\": 1974, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018164535867981613, \"iteration\": 1975, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029704420012421906, \"iteration\": 1976, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012718951620627195, \"iteration\": 1977, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018931446538772434, \"iteration\": 1978, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004947721026837826, \"iteration\": 1979, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015313301992136985, \"iteration\": 1980, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.52219997998327e-05, \"iteration\": 1981, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011216019629500806, \"iteration\": 1982, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000295501813525334, \"iteration\": 1983, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.014846025966107845, \"iteration\": 1984, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027637690072879195, \"iteration\": 1985, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017733601271174848, \"iteration\": 1986, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00042691119597293437, \"iteration\": 1987, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004914790391921997, \"iteration\": 1988, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000240100416704081, \"iteration\": 1989, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012106488429708406, \"iteration\": 1990, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021479761926457286, \"iteration\": 1991, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006618630141019821, \"iteration\": 1992, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009718055953271687, \"iteration\": 1993, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002014931378653273, \"iteration\": 1994, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002498528338037431, \"iteration\": 1995, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014418344653677195, \"iteration\": 1996, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003593002329580486, \"iteration\": 1997, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003566755913197994, \"iteration\": 1998, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017260901222471148, \"iteration\": 1999, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018579501193016768, \"iteration\": 2000, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001081117516150698, \"iteration\": 2001, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029995711520314217, \"iteration\": 2002, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012140079343225807, \"iteration\": 2003, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023444383987225592, \"iteration\": 2004, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001479509228374809, \"iteration\": 2005, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016539718490093946, \"iteration\": 2006, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022358409478329122, \"iteration\": 2007, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.467498603044078e-05, \"iteration\": 2008, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003732422483153641, \"iteration\": 2009, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026173461810685694, \"iteration\": 2010, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013957935152575374, \"iteration\": 2011, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018628794350661337, \"iteration\": 2012, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008130865171551704, \"iteration\": 2013, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014490871399175376, \"iteration\": 2014, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022645540593657643, \"iteration\": 2015, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002952245995402336, \"iteration\": 2016, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.091918036574498e-05, \"iteration\": 2017, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014048129378352314, \"iteration\": 2018, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016211655747611076, \"iteration\": 2019, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.230260184267536e-05, \"iteration\": 2020, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011658939183689654, \"iteration\": 2021, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013452974963001907, \"iteration\": 2022, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020504597341641784, \"iteration\": 2023, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001140690001193434, \"iteration\": 2024, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020529571338556707, \"iteration\": 2025, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019911098934244365, \"iteration\": 2026, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011190785153303295, \"iteration\": 2027, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001996248320210725, \"iteration\": 2028, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012327393051236868, \"iteration\": 2029, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015785136201884598, \"iteration\": 2030, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000152100546984002, \"iteration\": 2031, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015619047917425632, \"iteration\": 2032, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001911678846227005, \"iteration\": 2033, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005026024300605059, \"iteration\": 2034, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004297302511986345, \"iteration\": 2035, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.569276153342798e-05, \"iteration\": 2036, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002532393264118582, \"iteration\": 2037, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002020226529566571, \"iteration\": 2038, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013425380166154355, \"iteration\": 2039, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000224011717364192, \"iteration\": 2040, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002099508565152064, \"iteration\": 2041, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013506303366739303, \"iteration\": 2042, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.376539674121886e-05, \"iteration\": 2043, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012123385386075824, \"iteration\": 2044, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017831928562372923, \"iteration\": 2045, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014115615340415388, \"iteration\": 2046, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002756429894361645, \"iteration\": 2047, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.049490523058921e-05, \"iteration\": 2048, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016334511747118086, \"iteration\": 2049, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020838421187363565, \"iteration\": 2050, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019643158884719014, \"iteration\": 2051, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002276355808135122, \"iteration\": 2052, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.908082286827266e-05, \"iteration\": 2053, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013742453302256763, \"iteration\": 2054, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032345770159736276, \"iteration\": 2055, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017696485156193376, \"iteration\": 2056, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00010179536184296012, \"iteration\": 2057, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012938192230649292, \"iteration\": 2058, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022168543364387006, \"iteration\": 2059, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001584756391821429, \"iteration\": 2060, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021219874906819314, \"iteration\": 2061, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021161208860576153, \"iteration\": 2062, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012388092000037432, \"iteration\": 2063, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023897277424111962, \"iteration\": 2064, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000209073958103545, \"iteration\": 2065, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001116432249546051, \"iteration\": 2066, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012340486864559352, \"iteration\": 2067, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022523908410221338, \"iteration\": 2068, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0019924533553421497, \"iteration\": 2069, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015552702825516462, \"iteration\": 2070, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000153514658450149, \"iteration\": 2071, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016099645290523767, \"iteration\": 2072, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023943408450577408, \"iteration\": 2073, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014170425129123032, \"iteration\": 2074, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014093969366513193, \"iteration\": 2075, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.463591413805261e-05, \"iteration\": 2076, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018731222371570766, \"iteration\": 2077, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022291070490609854, \"iteration\": 2078, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024305244733113796, \"iteration\": 2079, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004140596720390022, \"iteration\": 2080, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00010892756108660251, \"iteration\": 2081, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022456706210505217, \"iteration\": 2082, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011370731226634234, \"iteration\": 2083, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001464213419239968, \"iteration\": 2084, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015462264127563685, \"iteration\": 2085, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001454593730159104, \"iteration\": 2086, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.353801629506052e-05, \"iteration\": 2087, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018543032638262957, \"iteration\": 2088, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.727861859370023e-05, \"iteration\": 2089, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.2313445192121435e-06, \"iteration\": 2090, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters finding\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models/gb')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    "    optimizer_params= {\"lr\": 0.0001, \"weight_decay\": 0.001, }\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(train_data_nn, batch_size=128, shuffle=True)\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(tfidf_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "if (models_dir / 'model_nn.pt').exists() and USE_CACHE:\n",
    "    model_nn = load_model(model_nn, models_dir, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn, models_dir, \"model_nn\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # X_test = torch.stack([dta[0] for dta in test])\n",
    "    X_test = torch.stack([test[0] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_test = torch.stack([test[1] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_pred = model_nn.predict(X_test)\n",
    "\n",
    "\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='binary'))\n",
    "print(\"AUC\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:05<00:00, 41.70batch/s, batch_accuracy=0.714, loss=0.424]\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 46.36batch/s, batch_accuracy=1, loss=0.123]    \n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.63batch/s, batch_accuracy=0.857, loss=0.685]\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.54batch/s, batch_accuracy=1, loss=0.0587]    \n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.10batch/s, batch_accuracy=1, loss=0.00202]   \n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.45batch/s, batch_accuracy=1, loss=0.00921]   \n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.36batch/s, batch_accuracy=1, loss=8.01e-5]   \n",
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.52batch/s, batch_accuracy=1, loss=0.00048]  \n",
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.43batch/s, batch_accuracy=1, loss=0.000123]  \n",
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 44.88batch/s, batch_accuracy=1, loss=0.0189]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7170138888888888, 0.7811402323696298, 0.7477046424414846, None)\n",
      "AUC 0.6955273811420799\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-c9ca38b61a104176b8288c37eebbdcac.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-c9ca38b61a104176b8288c37eebbdcac.vega-embed details,\n",
       "  #altair-viz-c9ca38b61a104176b8288c37eebbdcac.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-c9ca38b61a104176b8288c37eebbdcac\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-c9ca38b61a104176b8288c37eebbdcac\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-c9ca38b61a104176b8288c37eebbdcac\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-4239c3033e861322e6395b6051f687df\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-4239c3033e861322e6395b6051f687df\": [{\"training_acc\": 0.4453125, \"training_loss\": 0.6996070146560669, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.4609375, \"training_loss\": 0.6973796486854553, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.4375, \"training_loss\": 0.6984745264053345, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.453125, \"training_loss\": 0.6965832710266113, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.4453125, \"training_loss\": 0.6957418322563171, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.484375, \"training_loss\": 0.6937721967697144, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6933110356330872, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6945821642875671, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6912545561790466, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6909065842628479, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.4921875, \"training_loss\": 0.6915910243988037, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6881608963012695, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 0.6893864274024963, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.687563955783844, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6854714155197144, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 0.6889857053756714, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6817271113395691, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6837180256843567, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6781880259513855, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 0.6962884068489075, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.46875, \"training_loss\": 0.6954493522644043, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6782951354980469, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.5078125, \"training_loss\": 0.6881133913993835, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.677049994468689, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6731741428375244, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6739206314086914, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.676883339881897, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6823127865791321, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6714334487915039, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6561683416366577, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6626551747322083, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6713370680809021, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6705657839775085, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6664447784423828, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6573405265808105, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6398134231567383, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6556485891342163, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6641379594802856, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6392057538032532, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.651229977607727, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6280027627944946, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6436291933059692, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6360248327255249, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6549018621444702, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.6250879168510437, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.6100376844406128, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.6194480657577515, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.6235089302062988, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.6018767952919006, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.6272839307785034, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6417108178138733, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6196538805961609, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6380345821380615, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5722730755805969, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.6029286980628967, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5790308117866516, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5891786217689514, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6210665106773376, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6304913759231567, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5548788905143738, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5832865238189697, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5233617424964905, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5529929399490356, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5513771772384644, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5430980920791626, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5400822758674622, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5491291880607605, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6707416772842407, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5571920871734619, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.563859224319458, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5416481494903564, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.532904326915741, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5721122026443481, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5546389818191528, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5515696406364441, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5204923748970032, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5226161479949951, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5024476647377014, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5277513861656189, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.47905993461608887, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4698144793510437, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.4974641799926758, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.47465693950653076, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.48378491401672363, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4804205894470215, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5520665645599365, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.49910250306129456, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.46033233404159546, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5321557521820068, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5847347974777222, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5281680822372437, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.47601643204689026, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.657171905040741, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5211498737335205, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.49544835090637207, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.460437148809433, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.42605841159820557, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.47331324219703674, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5993279218673706, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5059134364128113, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4775657057762146, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5302706956863403, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.46167290210723877, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5003044605255127, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4378548860549927, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4858022928237915, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5208001136779785, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5368958711624146, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.524213969707489, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4915107786655426, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4421367943286896, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4982846677303314, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5827634930610657, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.46598687767982483, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5419684052467346, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.40926462411880493, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5039368867874146, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.46166670322418213, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5248308181762695, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4847806394100189, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3908628225326538, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4421347379684448, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.41878265142440796, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4433116316795349, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4499830901622772, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5278910994529724, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4751278758049011, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.48261258006095886, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.43578675389289856, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5082213878631592, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4756326675415039, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.45282822847366333, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4533041715621948, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4951276481151581, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.45282357931137085, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5041033029556274, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5251119136810303, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5132116079330444, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.494903028011322, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.45963963866233826, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4985312819480896, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4618058204650879, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.449896901845932, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4369449317455292, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.44414326548576355, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5064532160758972, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.45200735330581665, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4544624984264374, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.43898820877075195, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4728609323501587, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4570924639701843, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.49164116382598877, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4620039165019989, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.48177871108055115, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.46104609966278076, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.47812992334365845, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.45217064023017883, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.484541118144989, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.39826852083206177, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4676828384399414, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4833393692970276, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4278876781463623, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.41328340768814087, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.3298914134502411, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5281137228012085, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5221056938171387, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5163301825523376, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4510950744152069, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4238072335720062, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5110867619514465, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4876634180545807, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5813706517219543, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.43766096234321594, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4960062503814697, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4686284363269806, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.45345866680145264, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5059390664100647, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4374130368232727, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.39815130829811096, \"iteration\": 179, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5748147368431091, \"iteration\": 180, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4580262303352356, \"iteration\": 181, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.47894981503486633, \"iteration\": 182, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.49194225668907166, \"iteration\": 183, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.42773061990737915, \"iteration\": 184, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.43319016695022583, \"iteration\": 185, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4588569402694702, \"iteration\": 186, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5068730711936951, \"iteration\": 187, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.542109489440918, \"iteration\": 188, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5221673846244812, \"iteration\": 189, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5245441198348999, \"iteration\": 190, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.49818265438079834, \"iteration\": 191, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.44413191080093384, \"iteration\": 192, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4955602288246155, \"iteration\": 193, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4427465498447418, \"iteration\": 194, \"epoch\": 1}, {\"training_acc\": 0.8828125, \"training_loss\": 0.37560415267944336, \"iteration\": 195, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4200195372104645, \"iteration\": 196, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4544578492641449, \"iteration\": 197, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.466909795999527, \"iteration\": 198, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.432816743850708, \"iteration\": 199, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4919695556163788, \"iteration\": 200, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5729056596755981, \"iteration\": 201, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.49832987785339355, \"iteration\": 202, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.48453620076179504, \"iteration\": 203, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5522307753562927, \"iteration\": 204, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.43475744128227234, \"iteration\": 205, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4052038788795471, \"iteration\": 206, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4833908975124359, \"iteration\": 207, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4436955749988556, \"iteration\": 208, \"epoch\": 1}, {\"training_acc\": 0.7142857142857143, \"training_loss\": 0.42427220940589905, \"iteration\": 209, \"epoch\": 1}, {\"training_acc\": 0.875, \"training_loss\": 0.43606650829315186, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.31153273582458496, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.34370654821395874, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3093937635421753, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.30505895614624023, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3264203667640686, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2725466191768646, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.33795198798179626, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3036230504512787, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2854782044887543, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2591768205165863, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3186832666397095, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2511977255344391, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2909409999847412, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2503645122051239, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28775036334991455, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25620153546333313, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.34634044766426086, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.28731581568717957, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.29987797141075134, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3362943232059479, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21666541695594788, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2693278193473816, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.289268434047699, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.315196692943573, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.325264573097229, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.27447596192359924, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28905007243156433, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.2632126808166504, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3617483079433441, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.23230811953544617, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2600792944431305, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31821173429489136, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.272561639547348, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3035805821418762, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2682405412197113, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3492964804172516, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27057603001594543, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2669222950935364, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.30802345275878906, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24874916672706604, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24952025711536407, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3025183379650116, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2932790517807007, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2686573266983032, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2535388469696045, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.22143152356147766, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23471075296401978, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2559397518634796, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.33792147040367126, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3069702088832855, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3444649577140808, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.36790987849235535, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28430622816085815, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.2015109360218048, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.37568026781082153, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22813032567501068, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3321540057659149, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.39951419830322266, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3047984838485718, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25343358516693115, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.30797865986824036, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.21540606021881104, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33346232771873474, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3887181580066681, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.30405208468437195, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.40961119532585144, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21108484268188477, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2346363663673401, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.21633978188037872, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.3154710829257965, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3071070909500122, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2795889973640442, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.30381301045417786, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3600611090660095, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3673924207687378, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.34154099225997925, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17671066522598267, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21859285235404968, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30912232398986816, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26273977756500244, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2025100290775299, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28015008568763733, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27135881781578064, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3686942756175995, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.31530871987342834, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.28443554043769836, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4471334218978882, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.30988651514053345, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3178660571575165, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2592485845088959, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2990589141845703, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3275001049041748, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3861974775791168, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.24861088395118713, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.29542556405067444, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34804850816726685, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28148335218429565, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3485223650932312, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3353019654750824, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2393801063299179, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3760961592197418, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33591604232788086, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.358310729265213, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28906211256980896, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32938632369041443, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.41910889744758606, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.37826475501060486, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30542588233947754, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.31314918398857117, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24160800874233246, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3146047592163086, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.35366111993789673, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3540419340133667, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3071903884410858, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.30624091625213623, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.26289257407188416, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3039267361164093, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.43130552768707275, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28525203466415405, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.35648277401924133, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3677560091018677, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3994702398777008, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32240885496139526, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.38793841004371643, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.317680299282074, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2857111394405365, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3094720244407654, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.282782644033432, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3173089027404785, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24466249346733093, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3286815285682678, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30838829278945923, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24259525537490845, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3380735516548157, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28734657168388367, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2446412742137909, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.23431473970413208, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.25010576844215393, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.33932775259017944, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30596625804901123, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2507985830307007, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3307885229587555, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3778560757637024, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2922102212905884, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.25891879200935364, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2998950183391571, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32764098048210144, \"iteration\": 357, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3295624554157257, \"iteration\": 358, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.2929113209247589, \"iteration\": 359, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32465705275535583, \"iteration\": 360, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2940980792045593, \"iteration\": 361, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2594835162162781, \"iteration\": 362, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3582690358161926, \"iteration\": 363, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.44162964820861816, \"iteration\": 364, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.31541043519973755, \"iteration\": 365, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.39991843700408936, \"iteration\": 366, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3469609022140503, \"iteration\": 367, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31549331545829773, \"iteration\": 368, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3892879784107208, \"iteration\": 369, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2834119200706482, \"iteration\": 370, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3393087685108185, \"iteration\": 371, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21168610453605652, \"iteration\": 372, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3507218360900879, \"iteration\": 373, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3843242824077606, \"iteration\": 374, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.37761390209198, \"iteration\": 375, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.31639564037323, \"iteration\": 376, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.26679378747940063, \"iteration\": 377, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2815810739994049, \"iteration\": 378, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29277846217155457, \"iteration\": 379, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.35125046968460083, \"iteration\": 380, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3773665726184845, \"iteration\": 381, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.29513758420944214, \"iteration\": 382, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.325745552778244, \"iteration\": 383, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28982648253440857, \"iteration\": 384, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3129085898399353, \"iteration\": 385, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.27618056535720825, \"iteration\": 386, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3149331212043762, \"iteration\": 387, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26207467913627625, \"iteration\": 388, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2582719326019287, \"iteration\": 389, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3130573034286499, \"iteration\": 390, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23095794022083282, \"iteration\": 391, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3468029499053955, \"iteration\": 392, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3643234968185425, \"iteration\": 393, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.28593459725379944, \"iteration\": 394, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3427787721157074, \"iteration\": 395, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32065531611442566, \"iteration\": 396, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.254036009311676, \"iteration\": 397, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2537854313850403, \"iteration\": 398, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.30676501989364624, \"iteration\": 399, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3254960775375366, \"iteration\": 400, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.305271178483963, \"iteration\": 401, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4063161015510559, \"iteration\": 402, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.40499812364578247, \"iteration\": 403, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.34712493419647217, \"iteration\": 404, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.36637333035469055, \"iteration\": 405, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.35814934968948364, \"iteration\": 406, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2997839152812958, \"iteration\": 407, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.28002893924713135, \"iteration\": 408, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.40280377864837646, \"iteration\": 409, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2999516725540161, \"iteration\": 410, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.29420268535614014, \"iteration\": 411, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2826906144618988, \"iteration\": 412, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3566507399082184, \"iteration\": 413, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3979918956756592, \"iteration\": 414, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.25505703687667847, \"iteration\": 415, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24349895119667053, \"iteration\": 416, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4058050811290741, \"iteration\": 417, \"epoch\": 2}, {\"training_acc\": 1.0, \"training_loss\": 0.12255425751209259, \"iteration\": 418, \"epoch\": 2}, {\"training_acc\": 0.96875, \"training_loss\": 0.42476439476013184, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.2014622837305069, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.15388867259025574, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18362197279930115, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.19265525043010712, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1957344263792038, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17513704299926758, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13708524405956268, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17030787467956543, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18896935880184174, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2069745659828186, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.21379083395004272, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.12873704731464386, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19777782261371613, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13410232961177826, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2143222987651825, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1729143261909485, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.19921571016311646, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1258329153060913, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18232758343219757, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.1383836418390274, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.22352004051208496, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1338346004486084, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13977354764938354, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1423727124929428, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17966777086257935, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09970571100711823, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10677008330821991, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.17986585199832916, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13642655313014984, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13075381517410278, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1303931623697281, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17326416075229645, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11582423001527786, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15630804002285004, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18689808249473572, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15273994207382202, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20544308423995972, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1270771622657776, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12195425480604172, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13251090049743652, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.23276983201503754, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15798179805278778, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11267990618944168, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13493475317955017, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.15932722389698029, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2073565274477005, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1631775200366974, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1288074553012848, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1536838710308075, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.22484582662582397, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14659076929092407, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18495148420333862, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12398190796375275, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1352328062057495, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1921827346086502, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13593187928199768, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.153653085231781, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.19733434915542603, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.22151854634284973, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13882312178611755, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16351313889026642, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.19030417501926422, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.14822804927825928, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18339906632900238, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16843146085739136, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11577590554952621, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1776878833770752, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.19001083076000214, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16123582422733307, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13456356525421143, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21473649144172668, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17024457454681396, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1823628842830658, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.16079458594322205, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2079838365316391, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.16421633958816528, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1443234533071518, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.23465776443481445, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12942150235176086, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1176961213350296, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18763777613639832, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1452798694372177, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1694355010986328, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1946464627981186, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.20714476704597473, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1231616884469986, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.13908275961875916, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22357670962810516, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.24729828536510468, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2311137616634369, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.26451921463012695, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2839714586734772, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.19065740704536438, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.23018182814121246, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10875219851732254, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.12797975540161133, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15472647547721863, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16089144349098206, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18282689154148102, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20429272949695587, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13942179083824158, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1337878555059433, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1866241693496704, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.16091981530189514, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2252950221300125, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20094481110572815, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1645440012216568, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1416027843952179, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18335440754890442, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1581702083349228, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2097494751214981, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16380426287651062, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13024428486824036, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16970966756343842, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.148149773478508, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.16123570501804352, \"iteration\": 535, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18820659816265106, \"iteration\": 536, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17213980853557587, \"iteration\": 537, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1574651002883911, \"iteration\": 538, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18976566195487976, \"iteration\": 539, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.16538117825984955, \"iteration\": 540, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3268778622150421, \"iteration\": 541, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20046177506446838, \"iteration\": 542, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1890960931777954, \"iteration\": 543, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2649121582508087, \"iteration\": 544, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2429569512605667, \"iteration\": 545, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16374018788337708, \"iteration\": 546, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1484040766954422, \"iteration\": 547, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17064061760902405, \"iteration\": 548, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12628313899040222, \"iteration\": 549, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1681579351425171, \"iteration\": 550, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.19245633482933044, \"iteration\": 551, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21417593955993652, \"iteration\": 552, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.18271669745445251, \"iteration\": 553, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.19391688704490662, \"iteration\": 554, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1899174600839615, \"iteration\": 555, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.20663973689079285, \"iteration\": 556, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1657889187335968, \"iteration\": 557, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.27743101119995117, \"iteration\": 558, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.131031796336174, \"iteration\": 559, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.19384214282035828, \"iteration\": 560, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1947304606437683, \"iteration\": 561, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2959303855895996, \"iteration\": 562, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3140355944633484, \"iteration\": 563, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24594563245773315, \"iteration\": 564, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.20686736702919006, \"iteration\": 565, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1686350703239441, \"iteration\": 566, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16882959008216858, \"iteration\": 567, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.18049445748329163, \"iteration\": 568, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.18355223536491394, \"iteration\": 569, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.32351621985435486, \"iteration\": 570, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1604662388563156, \"iteration\": 571, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2428445965051651, \"iteration\": 572, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1905621439218521, \"iteration\": 573, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18417105078697205, \"iteration\": 574, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22242338955402374, \"iteration\": 575, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3255479335784912, \"iteration\": 576, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13632211089134216, \"iteration\": 577, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.2174353301525116, \"iteration\": 578, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.300713449716568, \"iteration\": 579, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17770417034626007, \"iteration\": 580, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2573363482952118, \"iteration\": 581, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.11382442712783813, \"iteration\": 582, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19812069833278656, \"iteration\": 583, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.16917039453983307, \"iteration\": 584, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.1791985183954239, \"iteration\": 585, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1729317009449005, \"iteration\": 586, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21439726650714874, \"iteration\": 587, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.21354570984840393, \"iteration\": 588, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23743942379951477, \"iteration\": 589, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.1901552826166153, \"iteration\": 590, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17253723740577698, \"iteration\": 591, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18941965699195862, \"iteration\": 592, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.33530545234680176, \"iteration\": 593, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19590280950069427, \"iteration\": 594, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.13713835179805756, \"iteration\": 595, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23685084283351898, \"iteration\": 596, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20035064220428467, \"iteration\": 597, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.18888765573501587, \"iteration\": 598, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12052816897630692, \"iteration\": 599, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.20497457683086395, \"iteration\": 600, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19787612557411194, \"iteration\": 601, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.16660523414611816, \"iteration\": 602, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2356930524110794, \"iteration\": 603, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2018946260213852, \"iteration\": 604, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.21584631502628326, \"iteration\": 605, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26173919439315796, \"iteration\": 606, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23442870378494263, \"iteration\": 607, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20183664560317993, \"iteration\": 608, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2540135979652405, \"iteration\": 609, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20340071618556976, \"iteration\": 610, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2650466859340668, \"iteration\": 611, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.22470299899578094, \"iteration\": 612, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21925190091133118, \"iteration\": 613, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.17490699887275696, \"iteration\": 614, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20797942578792572, \"iteration\": 615, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31601452827453613, \"iteration\": 616, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3399142324924469, \"iteration\": 617, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1985337734222412, \"iteration\": 618, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.25758278369903564, \"iteration\": 619, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2332088202238083, \"iteration\": 620, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18416638672351837, \"iteration\": 621, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2379942238330841, \"iteration\": 622, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1673508584499359, \"iteration\": 623, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21574121713638306, \"iteration\": 624, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.31155237555503845, \"iteration\": 625, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.195950448513031, \"iteration\": 626, \"epoch\": 3}, {\"training_acc\": 0.8571428571428571, \"training_loss\": 0.6849087476730347, \"iteration\": 627, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.6252702474594116, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11587625741958618, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1186845600605011, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08612114191055298, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07892604172229767, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12679441273212433, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07132990658283234, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.13884638249874115, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07744823396205902, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07433544099330902, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06975030153989792, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08165574073791504, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09243381768465042, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08178220689296722, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.09834282845258713, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0863410234451294, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08244704455137253, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10817999392747879, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.11428399384021759, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11329853534698486, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10104252398014069, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.06008084863424301, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.055319879204034805, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1237780749797821, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07120153307914734, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0697363018989563, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15477830171585083, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10393409430980682, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13392451405525208, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12308267503976822, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10690167546272278, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09975114464759827, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04958799108862877, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08208715915679932, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13038454949855804, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09513035416603088, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.043390437960624695, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.12045453488826752, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11891531199216843, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13580143451690674, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06356896460056305, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09798786789178848, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.10520733147859573, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07694239169359207, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1298035830259323, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11984631419181824, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1133236289024353, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.061481159180402756, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07138994336128235, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.11189913004636765, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08338844776153564, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.070020891726017, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06751324236392975, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.03885869309306145, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08171027898788452, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07245749235153198, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.06638098508119583, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1006324291229248, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09415967762470245, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.10386110097169876, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.05556527525186539, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13194489479064941, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09274397045373917, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08355458825826645, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06654874980449677, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.15545661747455597, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09262361377477646, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07303798198699951, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09388565272092819, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10934848338365555, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.06618407368659973, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09426163136959076, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07293287664651871, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0691758245229721, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0710170790553093, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05839503929018974, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06179257482290268, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09477640688419342, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06117483600974083, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.09992166608572006, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0712459608912468, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09519112855195999, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08643101900815964, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06647010147571564, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0835006982088089, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08623579144477844, \"iteration\": 713, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.132358580827713, \"iteration\": 714, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08810068666934967, \"iteration\": 715, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08361275494098663, \"iteration\": 716, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13735578954219818, \"iteration\": 717, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1026477962732315, \"iteration\": 718, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1133057028055191, \"iteration\": 719, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11875604838132858, \"iteration\": 720, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0719601958990097, \"iteration\": 721, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10378366708755493, \"iteration\": 722, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1481841504573822, \"iteration\": 723, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0707046389579773, \"iteration\": 724, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10494468361139297, \"iteration\": 725, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10628720372915268, \"iteration\": 726, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13730058073997498, \"iteration\": 727, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11949007213115692, \"iteration\": 728, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05617832764983177, \"iteration\": 729, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11165526509284973, \"iteration\": 730, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06994237750768661, \"iteration\": 731, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08644265681505203, \"iteration\": 732, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.053777363151311874, \"iteration\": 733, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09744395315647125, \"iteration\": 734, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15335063636302948, \"iteration\": 735, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15105777978897095, \"iteration\": 736, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1158471554517746, \"iteration\": 737, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11238687485456467, \"iteration\": 738, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10077593475580215, \"iteration\": 739, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07966138422489166, \"iteration\": 740, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09029977023601532, \"iteration\": 741, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06520934402942657, \"iteration\": 742, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1112779825925827, \"iteration\": 743, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09395143389701843, \"iteration\": 744, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05976700782775879, \"iteration\": 745, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08939362317323685, \"iteration\": 746, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10711635649204254, \"iteration\": 747, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07757832109928131, \"iteration\": 748, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.11480897665023804, \"iteration\": 749, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09712421149015427, \"iteration\": 750, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07098068296909332, \"iteration\": 751, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08589351922273636, \"iteration\": 752, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11067742109298706, \"iteration\": 753, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.03592190891504288, \"iteration\": 754, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10847827792167664, \"iteration\": 755, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08225547522306442, \"iteration\": 756, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.060246534645557404, \"iteration\": 757, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09232733398675919, \"iteration\": 758, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06575033068656921, \"iteration\": 759, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09801983088254929, \"iteration\": 760, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0461859330534935, \"iteration\": 761, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06510033458471298, \"iteration\": 762, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13737598061561584, \"iteration\": 763, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0837310403585434, \"iteration\": 764, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07378003746271133, \"iteration\": 765, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14514122903347015, \"iteration\": 766, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18336649239063263, \"iteration\": 767, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12320461869239807, \"iteration\": 768, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13620221614837646, \"iteration\": 769, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1023457944393158, \"iteration\": 770, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09700791537761688, \"iteration\": 771, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.09489136189222336, \"iteration\": 772, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07405296713113785, \"iteration\": 773, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.12004928290843964, \"iteration\": 774, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07440736889839172, \"iteration\": 775, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10897185653448105, \"iteration\": 776, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13652454316616058, \"iteration\": 777, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.18181496858596802, \"iteration\": 778, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0763268992304802, \"iteration\": 779, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09860167652368546, \"iteration\": 780, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.04099275544285774, \"iteration\": 781, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1018514484167099, \"iteration\": 782, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.13570326566696167, \"iteration\": 783, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11404650658369064, \"iteration\": 784, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.0817042887210846, \"iteration\": 785, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12367051839828491, \"iteration\": 786, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0682118833065033, \"iteration\": 787, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11377109587192535, \"iteration\": 788, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.11308352649211884, \"iteration\": 789, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08388826251029968, \"iteration\": 790, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05913111940026283, \"iteration\": 791, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1457361876964569, \"iteration\": 792, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09429022669792175, \"iteration\": 793, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.15934719145298004, \"iteration\": 794, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07056320458650589, \"iteration\": 795, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13345009088516235, \"iteration\": 796, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07336629182100296, \"iteration\": 797, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.12467767298221588, \"iteration\": 798, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11715500801801682, \"iteration\": 799, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07433964312076569, \"iteration\": 800, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.14341560006141663, \"iteration\": 801, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07534585893154144, \"iteration\": 802, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.16969242691993713, \"iteration\": 803, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08224837481975555, \"iteration\": 804, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19104063510894775, \"iteration\": 805, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1967959851026535, \"iteration\": 806, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12621448934078217, \"iteration\": 807, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1149211898446083, \"iteration\": 808, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10860925912857056, \"iteration\": 809, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13348904252052307, \"iteration\": 810, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.09539883583784103, \"iteration\": 811, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12161493301391602, \"iteration\": 812, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11753050982952118, \"iteration\": 813, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18814153969287872, \"iteration\": 814, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.13628220558166504, \"iteration\": 815, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12511755526065826, \"iteration\": 816, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12723423540592194, \"iteration\": 817, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.10536554455757141, \"iteration\": 818, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13557910919189453, \"iteration\": 819, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.16007208824157715, \"iteration\": 820, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.12507648766040802, \"iteration\": 821, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18213069438934326, \"iteration\": 822, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11440282315015793, \"iteration\": 823, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.13401292264461517, \"iteration\": 824, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.1105518639087677, \"iteration\": 825, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10121425241231918, \"iteration\": 826, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.1271655261516571, \"iteration\": 827, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.11031681299209595, \"iteration\": 828, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11547355353832245, \"iteration\": 829, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07253406196832657, \"iteration\": 830, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.07820781320333481, \"iteration\": 831, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.17914989590644836, \"iteration\": 832, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12784253060817719, \"iteration\": 833, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.08423268795013428, \"iteration\": 834, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10351850837469101, \"iteration\": 835, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.05865542218089104, \"iteration\": 836, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.503644585609436, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.05842083692550659, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05433037504553795, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03729464113712311, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.024754047393798828, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.037329647690057755, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.037100981920957565, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04133915156126022, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03682684153318405, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07700546085834503, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028026415035128593, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.044922105967998505, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05671416223049164, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06234961748123169, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.042066194117069244, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025533780455589294, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0434577651321888, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05781308934092522, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025579001754522324, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04259113967418671, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07948852330446243, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.017376594245433807, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.035699959844350815, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06678102910518646, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03161036595702171, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08629397302865982, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.013640254735946655, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025296006351709366, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08173874020576477, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07359375059604645, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.045376814901828766, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.0777001604437828, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0856637954711914, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040339015424251556, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03444027528166771, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03620325028896332, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.015290568582713604, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1535760760307312, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030486563220620155, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0642431452870369, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07417222857475281, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04094718396663666, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05024659261107445, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.029872532933950424, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029280366376042366, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05098283290863037, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06164243072271347, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039002642035484314, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03619828820228577, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04310586303472519, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05411115661263466, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.048295002430677414, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04946022480726242, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08537190407514572, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028139332309365273, \"iteration\": 891, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.060371994972229004, \"iteration\": 892, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.022703781723976135, \"iteration\": 893, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05103066563606262, \"iteration\": 894, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.030072035267949104, \"iteration\": 895, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.022651484236121178, \"iteration\": 896, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03962955251336098, \"iteration\": 897, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.026791902258992195, \"iteration\": 898, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.031460173428058624, \"iteration\": 899, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.060899242758750916, \"iteration\": 900, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.019724352285265923, \"iteration\": 901, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027723120525479317, \"iteration\": 902, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04936574399471283, \"iteration\": 903, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10418020188808441, \"iteration\": 904, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.039835937321186066, \"iteration\": 905, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06593696027994156, \"iteration\": 906, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01924985833466053, \"iteration\": 907, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04605215787887573, \"iteration\": 908, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03617791086435318, \"iteration\": 909, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03162626549601555, \"iteration\": 910, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05760107561945915, \"iteration\": 911, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.052389174699783325, \"iteration\": 912, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07501718401908875, \"iteration\": 913, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.058504585176706314, \"iteration\": 914, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01893780753016472, \"iteration\": 915, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02151772379875183, \"iteration\": 916, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0762566402554512, \"iteration\": 917, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.027751073241233826, \"iteration\": 918, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03886450082063675, \"iteration\": 919, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.042337071150541306, \"iteration\": 920, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.023992646485567093, \"iteration\": 921, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.026285652071237564, \"iteration\": 922, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03209936246275902, \"iteration\": 923, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0751463919878006, \"iteration\": 924, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.028519660234451294, \"iteration\": 925, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03874102234840393, \"iteration\": 926, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.012399382889270782, \"iteration\": 927, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05333061143755913, \"iteration\": 928, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10302595794200897, \"iteration\": 929, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0686723068356514, \"iteration\": 930, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.017615830525755882, \"iteration\": 931, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05430060252547264, \"iteration\": 932, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.035985615104436874, \"iteration\": 933, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01980460062623024, \"iteration\": 934, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.026015957817435265, \"iteration\": 935, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0640607550740242, \"iteration\": 936, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.013178087770938873, \"iteration\": 937, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06510031223297119, \"iteration\": 938, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06195151060819626, \"iteration\": 939, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02991432696580887, \"iteration\": 940, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0686776340007782, \"iteration\": 941, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06913870573043823, \"iteration\": 942, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05145265907049179, \"iteration\": 943, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.022706609219312668, \"iteration\": 944, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.018698401749134064, \"iteration\": 945, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04830358549952507, \"iteration\": 946, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.01792753115296364, \"iteration\": 947, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.05117852985858917, \"iteration\": 948, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04097120836377144, \"iteration\": 949, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.042310040444135666, \"iteration\": 950, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06676480919122696, \"iteration\": 951, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.04925483092665672, \"iteration\": 952, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06345752626657486, \"iteration\": 953, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07099317014217377, \"iteration\": 954, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05078759789466858, \"iteration\": 955, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05794902145862579, \"iteration\": 956, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.024526547640562057, \"iteration\": 957, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.051874272525310516, \"iteration\": 958, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03253258019685745, \"iteration\": 959, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04138680920004845, \"iteration\": 960, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.040583934634923935, \"iteration\": 961, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.019272493198513985, \"iteration\": 962, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.05865788459777832, \"iteration\": 963, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06052127107977867, \"iteration\": 964, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04879864677786827, \"iteration\": 965, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07440564036369324, \"iteration\": 966, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040695421397686005, \"iteration\": 967, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05154493451118469, \"iteration\": 968, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08837393671274185, \"iteration\": 969, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0517951138317585, \"iteration\": 970, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.058936309069395065, \"iteration\": 971, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.10497652739286423, \"iteration\": 972, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03392530232667923, \"iteration\": 973, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.032805316150188446, \"iteration\": 974, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029812663793563843, \"iteration\": 975, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05012368783354759, \"iteration\": 976, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.058013904839754105, \"iteration\": 977, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0714394673705101, \"iteration\": 978, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03694969043135643, \"iteration\": 979, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06255726516246796, \"iteration\": 980, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.025804437696933746, \"iteration\": 981, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03117477335035801, \"iteration\": 982, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05285247787833214, \"iteration\": 983, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.057932350784540176, \"iteration\": 984, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04775935411453247, \"iteration\": 985, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07918050140142441, \"iteration\": 986, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02389848418533802, \"iteration\": 987, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03560897335410118, \"iteration\": 988, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05194227024912834, \"iteration\": 989, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.037080489099025726, \"iteration\": 990, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06750349700450897, \"iteration\": 991, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046874530613422394, \"iteration\": 992, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.037341147661209106, \"iteration\": 993, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.040247343480587006, \"iteration\": 994, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09126508980989456, \"iteration\": 995, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03885822370648384, \"iteration\": 996, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.032684218138456345, \"iteration\": 997, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09644775092601776, \"iteration\": 998, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02966688759624958, \"iteration\": 999, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0927828922867775, \"iteration\": 1000, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04021601751446724, \"iteration\": 1001, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.037060145288705826, \"iteration\": 1002, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.043604712933301926, \"iteration\": 1003, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15281182527542114, \"iteration\": 1004, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.05304381996393204, \"iteration\": 1005, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07973942905664444, \"iteration\": 1006, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.02802928164601326, \"iteration\": 1007, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08809082210063934, \"iteration\": 1008, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04225800931453705, \"iteration\": 1009, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03836517781019211, \"iteration\": 1010, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.034539930522441864, \"iteration\": 1011, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04116439446806908, \"iteration\": 1012, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03996976092457771, \"iteration\": 1013, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05445568636059761, \"iteration\": 1014, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.06505225598812103, \"iteration\": 1015, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03838126361370087, \"iteration\": 1016, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03629859909415245, \"iteration\": 1017, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04432283341884613, \"iteration\": 1018, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04688864201307297, \"iteration\": 1019, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.029705852270126343, \"iteration\": 1020, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.049626465886831284, \"iteration\": 1021, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04350847005844116, \"iteration\": 1022, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04077734425663948, \"iteration\": 1023, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.021478354930877686, \"iteration\": 1024, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04143133386969566, \"iteration\": 1025, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0572492778301239, \"iteration\": 1026, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07690214365720749, \"iteration\": 1027, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.039762355387210846, \"iteration\": 1028, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04860346019268036, \"iteration\": 1029, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03868056461215019, \"iteration\": 1030, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0291887316852808, \"iteration\": 1031, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.03892521932721138, \"iteration\": 1032, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05053746700286865, \"iteration\": 1033, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08890952169895172, \"iteration\": 1034, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.10170313715934753, \"iteration\": 1035, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03771236538887024, \"iteration\": 1036, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0580553263425827, \"iteration\": 1037, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.04083922877907753, \"iteration\": 1038, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.03608899191021919, \"iteration\": 1039, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04706568270921707, \"iteration\": 1040, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08024530112743378, \"iteration\": 1041, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03333150967955589, \"iteration\": 1042, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06897450238466263, \"iteration\": 1043, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08717284351587296, \"iteration\": 1044, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002019158098846674, \"iteration\": 1045, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.6173391342163086, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05225663259625435, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007165104150772095, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011082423850893974, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008800323121249676, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03565770387649536, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009747193194925785, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011687682010233402, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00799882784485817, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011870549991726875, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013055171817541122, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00955820083618164, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015182988718152046, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04383902624249458, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018530873581767082, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016202881932258606, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013948259875178337, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010976769961416721, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008840671740472317, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0410628505051136, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009385033510625362, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020228605717420578, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.022834738716483116, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009344147518277168, \"iteration\": 1069, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011431758292019367, \"iteration\": 1070, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007421090267598629, \"iteration\": 1071, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018687311559915543, \"iteration\": 1072, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.025051608681678772, \"iteration\": 1073, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02294071763753891, \"iteration\": 1074, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031221341341733932, \"iteration\": 1075, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016691245138645172, \"iteration\": 1076, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019495785236358643, \"iteration\": 1077, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010228638537228107, \"iteration\": 1078, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010446816682815552, \"iteration\": 1079, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01228559110313654, \"iteration\": 1080, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010156892240047455, \"iteration\": 1081, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009257696568965912, \"iteration\": 1082, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014069363474845886, \"iteration\": 1083, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012480846606194973, \"iteration\": 1084, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010514372028410435, \"iteration\": 1085, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012808863073587418, \"iteration\": 1086, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01009640283882618, \"iteration\": 1087, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0076309265568852425, \"iteration\": 1088, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01037214882671833, \"iteration\": 1089, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018254203721880913, \"iteration\": 1090, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016423890367150307, \"iteration\": 1091, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025959355756640434, \"iteration\": 1092, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013988491147756577, \"iteration\": 1093, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016500163823366165, \"iteration\": 1094, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0067567829973995686, \"iteration\": 1095, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017202068120241165, \"iteration\": 1096, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010807388462126255, \"iteration\": 1097, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.025054791942238808, \"iteration\": 1098, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02223176136612892, \"iteration\": 1099, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007705566473305225, \"iteration\": 1100, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.022792715579271317, \"iteration\": 1101, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009576799347996712, \"iteration\": 1102, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006375799421221018, \"iteration\": 1103, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010042172856628895, \"iteration\": 1104, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00712310615926981, \"iteration\": 1105, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015741946175694466, \"iteration\": 1106, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030315052717924118, \"iteration\": 1107, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008905097842216492, \"iteration\": 1108, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021579578518867493, \"iteration\": 1109, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011402064934372902, \"iteration\": 1110, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.026953477412462234, \"iteration\": 1111, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006353924050927162, \"iteration\": 1112, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016595998778939247, \"iteration\": 1113, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019300760701298714, \"iteration\": 1114, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009510870091617107, \"iteration\": 1115, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01489809900522232, \"iteration\": 1116, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016686346381902695, \"iteration\": 1117, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01756163313984871, \"iteration\": 1118, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007809422444552183, \"iteration\": 1119, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014249710366129875, \"iteration\": 1120, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012114014476537704, \"iteration\": 1121, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029747670516371727, \"iteration\": 1122, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020581930875778198, \"iteration\": 1123, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.03451152518391609, \"iteration\": 1124, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02044636569917202, \"iteration\": 1125, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016030561178922653, \"iteration\": 1126, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014305132441222668, \"iteration\": 1127, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.004267258103936911, \"iteration\": 1128, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07658692449331284, \"iteration\": 1129, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01432681456208229, \"iteration\": 1130, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011516069062054157, \"iteration\": 1131, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010622036643326283, \"iteration\": 1132, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012201990000903606, \"iteration\": 1133, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04496738314628601, \"iteration\": 1134, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009619664400815964, \"iteration\": 1135, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010561039671301842, \"iteration\": 1136, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015494891442358494, \"iteration\": 1137, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010781675577163696, \"iteration\": 1138, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030021166428923607, \"iteration\": 1139, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01371156144887209, \"iteration\": 1140, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011900922283530235, \"iteration\": 1141, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007514637894928455, \"iteration\": 1142, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.029079264029860497, \"iteration\": 1143, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03268444165587425, \"iteration\": 1144, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.017599040642380714, \"iteration\": 1145, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.021507905796170235, \"iteration\": 1146, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005754407029598951, \"iteration\": 1147, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00950601790100336, \"iteration\": 1148, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005908987484872341, \"iteration\": 1149, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11026544868946075, \"iteration\": 1150, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005433268379420042, \"iteration\": 1151, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046011410653591156, \"iteration\": 1152, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.037901364266872406, \"iteration\": 1153, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01286553405225277, \"iteration\": 1154, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03870973363518715, \"iteration\": 1155, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020285695791244507, \"iteration\": 1156, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.04532593861222267, \"iteration\": 1157, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022948479279875755, \"iteration\": 1158, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005091180093586445, \"iteration\": 1159, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019733961671590805, \"iteration\": 1160, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007818439044058323, \"iteration\": 1161, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010679101571440697, \"iteration\": 1162, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012654024176299572, \"iteration\": 1163, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011732183396816254, \"iteration\": 1164, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013321762904524803, \"iteration\": 1165, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03188064694404602, \"iteration\": 1166, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008644119836390018, \"iteration\": 1167, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015103496611118317, \"iteration\": 1168, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.027327297255396843, \"iteration\": 1169, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06044328957796097, \"iteration\": 1170, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012023184448480606, \"iteration\": 1171, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04284152761101723, \"iteration\": 1172, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.025758158415555954, \"iteration\": 1173, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006530700251460075, \"iteration\": 1174, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012131390161812305, \"iteration\": 1175, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014108225703239441, \"iteration\": 1176, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.014869351871311665, \"iteration\": 1177, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010049518197774887, \"iteration\": 1178, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06235567852854729, \"iteration\": 1179, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016175445169210434, \"iteration\": 1180, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010264248587191105, \"iteration\": 1181, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009221854619681835, \"iteration\": 1182, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005485848989337683, \"iteration\": 1183, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01620236411690712, \"iteration\": 1184, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015050051733851433, \"iteration\": 1185, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013505448587238789, \"iteration\": 1186, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009566457942128181, \"iteration\": 1187, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.04412161186337471, \"iteration\": 1188, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010418674908578396, \"iteration\": 1189, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01217709295451641, \"iteration\": 1190, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008656632155179977, \"iteration\": 1191, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06960047781467438, \"iteration\": 1192, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020353207364678383, \"iteration\": 1193, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013310030102729797, \"iteration\": 1194, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02281508967280388, \"iteration\": 1195, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007893403060734272, \"iteration\": 1196, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006328498013317585, \"iteration\": 1197, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02223540097475052, \"iteration\": 1198, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018601641058921814, \"iteration\": 1199, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012187757529318333, \"iteration\": 1200, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0235997773706913, \"iteration\": 1201, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.037922609597444534, \"iteration\": 1202, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.005508050788193941, \"iteration\": 1203, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04475734382867813, \"iteration\": 1204, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016823705285787582, \"iteration\": 1205, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006131432019174099, \"iteration\": 1206, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009447399526834488, \"iteration\": 1207, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.035764534026384354, \"iteration\": 1208, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0209052711725235, \"iteration\": 1209, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006490691564977169, \"iteration\": 1210, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008427120745182037, \"iteration\": 1211, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011340172961354256, \"iteration\": 1212, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010754680261015892, \"iteration\": 1213, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016861606389284134, \"iteration\": 1214, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022798782214522362, \"iteration\": 1215, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0076434859074652195, \"iteration\": 1216, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022495467215776443, \"iteration\": 1217, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009319692850112915, \"iteration\": 1218, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02067774534225464, \"iteration\": 1219, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01311713457107544, \"iteration\": 1220, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008884623646736145, \"iteration\": 1221, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03595792502164841, \"iteration\": 1222, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009818090125918388, \"iteration\": 1223, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009527897462248802, \"iteration\": 1224, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007971517741680145, \"iteration\": 1225, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007377891335636377, \"iteration\": 1226, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024767903611063957, \"iteration\": 1227, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.030188459903001785, \"iteration\": 1228, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01707668974995613, \"iteration\": 1229, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01729411631822586, \"iteration\": 1230, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015450099483132362, \"iteration\": 1231, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02635129913687706, \"iteration\": 1232, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016566505655646324, \"iteration\": 1233, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.010318285785615444, \"iteration\": 1234, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00745377317070961, \"iteration\": 1235, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007130591664463282, \"iteration\": 1236, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.018799813464283943, \"iteration\": 1237, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013018774800002575, \"iteration\": 1238, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007673680782318115, \"iteration\": 1239, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00708526186645031, \"iteration\": 1240, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007138202898204327, \"iteration\": 1241, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0407850444316864, \"iteration\": 1242, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01462471578270197, \"iteration\": 1243, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008865823037922382, \"iteration\": 1244, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007131144404411316, \"iteration\": 1245, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.006454821210354567, \"iteration\": 1246, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01693015731871128, \"iteration\": 1247, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020175546407699585, \"iteration\": 1248, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012288925237953663, \"iteration\": 1249, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.016155285760760307, \"iteration\": 1250, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011739836074411869, \"iteration\": 1251, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.012737192213535309, \"iteration\": 1252, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.008396944962441921, \"iteration\": 1253, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.009212176315486431, \"iteration\": 1254, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.814785361289978, \"iteration\": 1255, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006139055825769901, \"iteration\": 1256, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01623186282813549, \"iteration\": 1257, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.025381144136190414, \"iteration\": 1258, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01749964989721775, \"iteration\": 1259, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012623804621398449, \"iteration\": 1260, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014140557497739792, \"iteration\": 1261, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0050878203473985195, \"iteration\": 1262, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008111221715807915, \"iteration\": 1263, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004049379378557205, \"iteration\": 1264, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027231436222791672, \"iteration\": 1265, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0063608624041080475, \"iteration\": 1266, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007747170515358448, \"iteration\": 1267, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005315566435456276, \"iteration\": 1268, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007791842333972454, \"iteration\": 1269, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021702302619814873, \"iteration\": 1270, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007606389466673136, \"iteration\": 1271, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012930137105286121, \"iteration\": 1272, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009042787365615368, \"iteration\": 1273, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0058237845078110695, \"iteration\": 1274, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0030306559056043625, \"iteration\": 1275, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00802529975771904, \"iteration\": 1276, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007759805303066969, \"iteration\": 1277, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023542025592178106, \"iteration\": 1278, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002473510568961501, \"iteration\": 1279, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.017691360786557198, \"iteration\": 1280, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02164629101753235, \"iteration\": 1281, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006273795384913683, \"iteration\": 1282, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004848540294915438, \"iteration\": 1283, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01027431059628725, \"iteration\": 1284, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005562378093600273, \"iteration\": 1285, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006128023378551006, \"iteration\": 1286, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011050946079194546, \"iteration\": 1287, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006754853297024965, \"iteration\": 1288, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003389174584299326, \"iteration\": 1289, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01513752993196249, \"iteration\": 1290, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008873668499290943, \"iteration\": 1291, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006048521492630243, \"iteration\": 1292, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004431159235537052, \"iteration\": 1293, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028645722195506096, \"iteration\": 1294, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007942598313093185, \"iteration\": 1295, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005491314921528101, \"iteration\": 1296, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007994676940143108, \"iteration\": 1297, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010513553395867348, \"iteration\": 1298, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00681003974750638, \"iteration\": 1299, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003954785410314798, \"iteration\": 1300, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003442330751568079, \"iteration\": 1301, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003872200381010771, \"iteration\": 1302, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007304789032787085, \"iteration\": 1303, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008610758930444717, \"iteration\": 1304, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006704295985400677, \"iteration\": 1305, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006218678317964077, \"iteration\": 1306, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007292201276868582, \"iteration\": 1307, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004545581992715597, \"iteration\": 1308, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005432077217847109, \"iteration\": 1309, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002983660437166691, \"iteration\": 1310, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004867862444370985, \"iteration\": 1311, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003705062670633197, \"iteration\": 1312, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003589001717045903, \"iteration\": 1313, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0024527953937649727, \"iteration\": 1314, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01316608302295208, \"iteration\": 1315, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007738810032606125, \"iteration\": 1316, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035049552097916603, \"iteration\": 1317, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004023767542093992, \"iteration\": 1318, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003262158250436187, \"iteration\": 1319, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009329568594694138, \"iteration\": 1320, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003918059635907412, \"iteration\": 1321, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004846670664846897, \"iteration\": 1322, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0066755833104252815, \"iteration\": 1323, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006924087181687355, \"iteration\": 1324, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002428038977086544, \"iteration\": 1325, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009670460596680641, \"iteration\": 1326, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0033904039300978184, \"iteration\": 1327, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0068452004343271255, \"iteration\": 1328, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00865027867257595, \"iteration\": 1329, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00668594054877758, \"iteration\": 1330, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004294481128454208, \"iteration\": 1331, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03690722584724426, \"iteration\": 1332, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031418846920132637, \"iteration\": 1333, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030203254893422127, \"iteration\": 1334, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034978536423295736, \"iteration\": 1335, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00607891334220767, \"iteration\": 1336, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010463934391736984, \"iteration\": 1337, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022195542696863413, \"iteration\": 1338, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003558835946023464, \"iteration\": 1339, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010799997486174107, \"iteration\": 1340, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004073929041624069, \"iteration\": 1341, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014959984458982944, \"iteration\": 1342, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004899071995168924, \"iteration\": 1343, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009698323905467987, \"iteration\": 1344, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003233264898881316, \"iteration\": 1345, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006410841830074787, \"iteration\": 1346, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004286841955035925, \"iteration\": 1347, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006163684651255608, \"iteration\": 1348, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022887869272381067, \"iteration\": 1349, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028457215521484613, \"iteration\": 1350, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006038743071258068, \"iteration\": 1351, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025834874249994755, \"iteration\": 1352, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006234490778297186, \"iteration\": 1353, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003351437160745263, \"iteration\": 1354, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019490931183099747, \"iteration\": 1355, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00985964946448803, \"iteration\": 1356, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009198490530252457, \"iteration\": 1357, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0043547498062253, \"iteration\": 1358, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004479098599404097, \"iteration\": 1359, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005102618131786585, \"iteration\": 1360, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004722935613244772, \"iteration\": 1361, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004533010069280863, \"iteration\": 1362, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0020696488209068775, \"iteration\": 1363, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0026841070502996445, \"iteration\": 1364, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036210014950484037, \"iteration\": 1365, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0032161592971533537, \"iteration\": 1366, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0040032644756138325, \"iteration\": 1367, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004660549573600292, \"iteration\": 1368, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006362696178257465, \"iteration\": 1369, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037546781823039055, \"iteration\": 1370, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0011782438959926367, \"iteration\": 1371, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014846858102828264, \"iteration\": 1372, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0030804453417658806, \"iteration\": 1373, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028921328485012054, \"iteration\": 1374, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002478326903656125, \"iteration\": 1375, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00524536706507206, \"iteration\": 1376, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002346874913200736, \"iteration\": 1377, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0021707015112042427, \"iteration\": 1378, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0015780436806380749, \"iteration\": 1379, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004849244840443134, \"iteration\": 1380, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018691435689106584, \"iteration\": 1381, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003774350043386221, \"iteration\": 1382, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031799129210412502, \"iteration\": 1383, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014654225669801235, \"iteration\": 1384, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006216759793460369, \"iteration\": 1385, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0325479693710804, \"iteration\": 1386, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022998591884970665, \"iteration\": 1387, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007722623646259308, \"iteration\": 1388, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005337696522474289, \"iteration\": 1389, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023674650583416224, \"iteration\": 1390, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004082005936652422, \"iteration\": 1391, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015887415036559105, \"iteration\": 1392, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014702117070555687, \"iteration\": 1393, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031459564343094826, \"iteration\": 1394, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002602055436000228, \"iteration\": 1395, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016051302663981915, \"iteration\": 1396, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018874735105782747, \"iteration\": 1397, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005756146740168333, \"iteration\": 1398, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004210399929434061, \"iteration\": 1399, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010139083489775658, \"iteration\": 1400, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02284325286746025, \"iteration\": 1401, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0028094793669879436, \"iteration\": 1402, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0063958726823329926, \"iteration\": 1403, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009383383207023144, \"iteration\": 1404, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003388534765690565, \"iteration\": 1405, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01668604463338852, \"iteration\": 1406, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007894598878920078, \"iteration\": 1407, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004228188656270504, \"iteration\": 1408, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006818970665335655, \"iteration\": 1409, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005446005612611771, \"iteration\": 1410, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002623455598950386, \"iteration\": 1411, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027336152270436287, \"iteration\": 1412, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005122077185660601, \"iteration\": 1413, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004869803786277771, \"iteration\": 1414, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005797966383397579, \"iteration\": 1415, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007985162548720837, \"iteration\": 1416, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00659607071429491, \"iteration\": 1417, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006409316323697567, \"iteration\": 1418, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006998045835644007, \"iteration\": 1419, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015566893853247166, \"iteration\": 1420, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0031866696663200855, \"iteration\": 1421, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0019733612425625324, \"iteration\": 1422, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004771833773702383, \"iteration\": 1423, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004785877652466297, \"iteration\": 1424, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002882421249523759, \"iteration\": 1425, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003988997545093298, \"iteration\": 1426, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008148375898599625, \"iteration\": 1427, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006270573474466801, \"iteration\": 1428, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003797597950324416, \"iteration\": 1429, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003559700446203351, \"iteration\": 1430, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010357193648815155, \"iteration\": 1431, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0046691205352544785, \"iteration\": 1432, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0033461987040936947, \"iteration\": 1433, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010006716474890709, \"iteration\": 1434, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025603342801332474, \"iteration\": 1435, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001968878321349621, \"iteration\": 1436, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007323859259486198, \"iteration\": 1437, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027828484307974577, \"iteration\": 1438, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005445306189358234, \"iteration\": 1439, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005188740789890289, \"iteration\": 1440, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002790167462080717, \"iteration\": 1441, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004588073585182428, \"iteration\": 1442, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005327311344444752, \"iteration\": 1443, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001691675977781415, \"iteration\": 1444, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0022076014429330826, \"iteration\": 1445, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001825865125283599, \"iteration\": 1446, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0036215661093592644, \"iteration\": 1447, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010182792320847511, \"iteration\": 1448, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0033204001374542713, \"iteration\": 1449, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012754424475133419, \"iteration\": 1450, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002558134961873293, \"iteration\": 1451, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003155247773975134, \"iteration\": 1452, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003802094142884016, \"iteration\": 1453, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003397595137357712, \"iteration\": 1454, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037493566051125526, \"iteration\": 1455, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.002027505077421665, \"iteration\": 1456, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015963148325681686, \"iteration\": 1457, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003528292989358306, \"iteration\": 1458, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003489936701953411, \"iteration\": 1459, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00535593694075942, \"iteration\": 1460, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0034030447714030743, \"iteration\": 1461, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0024842433631420135, \"iteration\": 1462, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.008588338270783e-05, \"iteration\": 1463, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.47517070174217224, \"iteration\": 1464, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008769490523263812, \"iteration\": 1465, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003370479680597782, \"iteration\": 1466, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016267409548163414, \"iteration\": 1467, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.033922385424375534, \"iteration\": 1468, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.026316985487937927, \"iteration\": 1469, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010768811218440533, \"iteration\": 1470, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009467488154768944, \"iteration\": 1471, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0044371564872562885, \"iteration\": 1472, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022158350329846144, \"iteration\": 1473, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007622302509844303, \"iteration\": 1474, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0037961057387292385, \"iteration\": 1475, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016550006112083793, \"iteration\": 1476, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004116817843168974, \"iteration\": 1477, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005029785446822643, \"iteration\": 1478, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006648353300988674, \"iteration\": 1479, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002903604181483388, \"iteration\": 1480, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.026263514533638954, \"iteration\": 1481, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0036315922625362873, \"iteration\": 1482, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003357101231813431, \"iteration\": 1483, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021926399786025286, \"iteration\": 1484, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002136797644197941, \"iteration\": 1485, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018007589969784021, \"iteration\": 1486, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0030637194868177176, \"iteration\": 1487, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012674554018303752, \"iteration\": 1488, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018359433161094785, \"iteration\": 1489, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023058955557644367, \"iteration\": 1490, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002484328346326947, \"iteration\": 1491, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003514073323458433, \"iteration\": 1492, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0038968997541815042, \"iteration\": 1493, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021171411499381065, \"iteration\": 1494, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0025814392138272524, \"iteration\": 1495, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0025413697585463524, \"iteration\": 1496, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0032437187619507313, \"iteration\": 1497, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006332674529403448, \"iteration\": 1498, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001482167630456388, \"iteration\": 1499, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016099499771371484, \"iteration\": 1500, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011146105825901031, \"iteration\": 1501, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002198172267526388, \"iteration\": 1502, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007967820391058922, \"iteration\": 1503, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015892332885414362, \"iteration\": 1504, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021765201818197966, \"iteration\": 1505, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005102337803691626, \"iteration\": 1506, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001851582434028387, \"iteration\": 1507, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017721618060022593, \"iteration\": 1508, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015510852681472898, \"iteration\": 1509, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019564274698495865, \"iteration\": 1510, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004473299253731966, \"iteration\": 1511, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007321791257709265, \"iteration\": 1512, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002491583349183202, \"iteration\": 1513, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0042778016068041325, \"iteration\": 1514, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012021608417853713, \"iteration\": 1515, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006381705868989229, \"iteration\": 1516, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0024096104316413403, \"iteration\": 1517, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021123308688402176, \"iteration\": 1518, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008702109567821026, \"iteration\": 1519, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005751568824052811, \"iteration\": 1520, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001372382277622819, \"iteration\": 1521, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0028768733609467745, \"iteration\": 1522, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004278176464140415, \"iteration\": 1523, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017184991156682372, \"iteration\": 1524, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017089033499360085, \"iteration\": 1525, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003966403193771839, \"iteration\": 1526, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003178597893565893, \"iteration\": 1527, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002454818692058325, \"iteration\": 1528, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0032916879281401634, \"iteration\": 1529, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019897138699889183, \"iteration\": 1530, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0026969872415065765, \"iteration\": 1531, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004579606000334024, \"iteration\": 1532, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003916829824447632, \"iteration\": 1533, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0031209448352456093, \"iteration\": 1534, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00416084798052907, \"iteration\": 1535, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014117956161499023, \"iteration\": 1536, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0025771488435566425, \"iteration\": 1537, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020476949866861105, \"iteration\": 1538, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04157212749123573, \"iteration\": 1539, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023070231545716524, \"iteration\": 1540, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023554451763629913, \"iteration\": 1541, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0024024159647524357, \"iteration\": 1542, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013134856708347797, \"iteration\": 1543, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014269290259107947, \"iteration\": 1544, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0026643997989594936, \"iteration\": 1545, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0024836568627506495, \"iteration\": 1546, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014031881000846624, \"iteration\": 1547, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019240503897890449, \"iteration\": 1548, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007872236310504377, \"iteration\": 1549, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001974418992176652, \"iteration\": 1550, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002627088688313961, \"iteration\": 1551, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002351687755435705, \"iteration\": 1552, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001893149921670556, \"iteration\": 1553, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001718706451356411, \"iteration\": 1554, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023589066695421934, \"iteration\": 1555, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002252888400107622, \"iteration\": 1556, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005250904243439436, \"iteration\": 1557, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003207275876775384, \"iteration\": 1558, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008505808655172586, \"iteration\": 1559, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002403602935373783, \"iteration\": 1560, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001032570144161582, \"iteration\": 1561, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003893343498930335, \"iteration\": 1562, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010250468039885163, \"iteration\": 1563, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013119992800056934, \"iteration\": 1564, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009135952568612993, \"iteration\": 1565, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002776315901428461, \"iteration\": 1566, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013370682718232274, \"iteration\": 1567, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001623918884433806, \"iteration\": 1568, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016596283530816436, \"iteration\": 1569, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004468976054340601, \"iteration\": 1570, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0032360004261136055, \"iteration\": 1571, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004259842913597822, \"iteration\": 1572, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001817298587411642, \"iteration\": 1573, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001133725163526833, \"iteration\": 1574, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014434762997552752, \"iteration\": 1575, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001210207468830049, \"iteration\": 1576, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004514540079981089, \"iteration\": 1577, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016896581510081887, \"iteration\": 1578, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003651698585599661, \"iteration\": 1579, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003250895068049431, \"iteration\": 1580, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009447355754673481, \"iteration\": 1581, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012138074962422252, \"iteration\": 1582, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015959005104377866, \"iteration\": 1583, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0026250367518514395, \"iteration\": 1584, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009880716679617763, \"iteration\": 1585, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013667972758412361, \"iteration\": 1586, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0024725901894271374, \"iteration\": 1587, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015526276547461748, \"iteration\": 1588, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002678307704627514, \"iteration\": 1589, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019758623093366623, \"iteration\": 1590, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012094095582142472, \"iteration\": 1591, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0025821845047175884, \"iteration\": 1592, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014740746701136231, \"iteration\": 1593, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015371298650279641, \"iteration\": 1594, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001063983654603362, \"iteration\": 1595, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010761784389615059, \"iteration\": 1596, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001281896373257041, \"iteration\": 1597, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002543994691222906, \"iteration\": 1598, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002600819570943713, \"iteration\": 1599, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0027641826309263706, \"iteration\": 1600, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014598395209759474, \"iteration\": 1601, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017946442821994424, \"iteration\": 1602, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011052540503442287, \"iteration\": 1603, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0032776237931102514, \"iteration\": 1604, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019403963815420866, \"iteration\": 1605, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00047579879174008965, \"iteration\": 1606, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018675633473321795, \"iteration\": 1607, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017187942285090685, \"iteration\": 1608, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001551043358631432, \"iteration\": 1609, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001665662508457899, \"iteration\": 1610, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018603276694193482, \"iteration\": 1611, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010202606208622456, \"iteration\": 1612, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006565611809492111, \"iteration\": 1613, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00117272709030658, \"iteration\": 1614, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016084517119452357, \"iteration\": 1615, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014571177307516336, \"iteration\": 1616, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017817061161622405, \"iteration\": 1617, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001148889889009297, \"iteration\": 1618, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005422132555395365, \"iteration\": 1619, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013815246056765318, \"iteration\": 1620, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00630562799051404, \"iteration\": 1621, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00113115762360394, \"iteration\": 1622, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00295439874753356, \"iteration\": 1623, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010949362767860293, \"iteration\": 1624, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016911939019337296, \"iteration\": 1625, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004182715900242329, \"iteration\": 1626, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015052934177219868, \"iteration\": 1627, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001047964091412723, \"iteration\": 1628, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013425243087112904, \"iteration\": 1629, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019340614089742303, \"iteration\": 1630, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022883261553943157, \"iteration\": 1631, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0055051641538739204, \"iteration\": 1632, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011763123329728842, \"iteration\": 1633, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00276869535446167, \"iteration\": 1634, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002598527353256941, \"iteration\": 1635, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002030178438872099, \"iteration\": 1636, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013643016573041677, \"iteration\": 1637, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012358957901597023, \"iteration\": 1638, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004786951467394829, \"iteration\": 1639, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008064927533268929, \"iteration\": 1640, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010623082052916288, \"iteration\": 1641, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009671961888670921, \"iteration\": 1642, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001724803471006453, \"iteration\": 1643, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002316560596227646, \"iteration\": 1644, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007241846062242985, \"iteration\": 1645, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019549436401575804, \"iteration\": 1646, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0027620079927146435, \"iteration\": 1647, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00036674304283224046, \"iteration\": 1648, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001673117047175765, \"iteration\": 1649, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015209151897579432, \"iteration\": 1650, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002260618144646287, \"iteration\": 1651, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001389733050018549, \"iteration\": 1652, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020676031708717346, \"iteration\": 1653, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00120202312245965, \"iteration\": 1654, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018555237911641598, \"iteration\": 1655, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.024478698149323463, \"iteration\": 1656, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013295607641339302, \"iteration\": 1657, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0030579082667827606, \"iteration\": 1658, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001639832742512226, \"iteration\": 1659, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008900648099370301, \"iteration\": 1660, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022057155147194862, \"iteration\": 1661, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004358613397926092, \"iteration\": 1662, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007393306586891413, \"iteration\": 1663, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010950262658298016, \"iteration\": 1664, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001521412399597466, \"iteration\": 1665, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005527575267478824, \"iteration\": 1666, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002824573079124093, \"iteration\": 1667, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0025064304936677217, \"iteration\": 1668, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021568008232861757, \"iteration\": 1669, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009850016795098782, \"iteration\": 1670, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011067587183788419, \"iteration\": 1671, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004796893917955458, \"iteration\": 1672, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.7694904804229736, \"iteration\": 1673, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013688455801457167, \"iteration\": 1674, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.010848729871213436, \"iteration\": 1675, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.04466038569808006, \"iteration\": 1676, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.029852144420146942, \"iteration\": 1677, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.06027833744883537, \"iteration\": 1678, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006890403106808662, \"iteration\": 1679, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008138190023601055, \"iteration\": 1680, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000727008911781013, \"iteration\": 1681, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012794702779501677, \"iteration\": 1682, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006218348629772663, \"iteration\": 1683, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.01745772548019886, \"iteration\": 1684, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.07396435737609863, \"iteration\": 1685, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004802080802619457, \"iteration\": 1686, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0027402378618717194, \"iteration\": 1687, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002453702036291361, \"iteration\": 1688, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018344651907682419, \"iteration\": 1689, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013435884611681104, \"iteration\": 1690, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0036069315392524004, \"iteration\": 1691, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003818802535533905, \"iteration\": 1692, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002803076757118106, \"iteration\": 1693, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.009496401064097881, \"iteration\": 1694, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006590667646378279, \"iteration\": 1695, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002632842632010579, \"iteration\": 1696, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029075853526592255, \"iteration\": 1697, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003454149467870593, \"iteration\": 1698, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0028351731598377228, \"iteration\": 1699, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.010432206094264984, \"iteration\": 1700, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0027295229956507683, \"iteration\": 1701, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002254125429317355, \"iteration\": 1702, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012432904914021492, \"iteration\": 1703, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015631449641659856, \"iteration\": 1704, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002580905333161354, \"iteration\": 1705, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029340581968426704, \"iteration\": 1706, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0060398573987185955, \"iteration\": 1707, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029784408397972584, \"iteration\": 1708, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008828138001263142, \"iteration\": 1709, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029528532177209854, \"iteration\": 1710, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.009737711399793625, \"iteration\": 1711, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017179017886519432, \"iteration\": 1712, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014982660068199039, \"iteration\": 1713, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009560994803905487, \"iteration\": 1714, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0038360189646482468, \"iteration\": 1715, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00260360911488533, \"iteration\": 1716, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002690486377105117, \"iteration\": 1717, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0036999809090048075, \"iteration\": 1718, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013557407073676586, \"iteration\": 1719, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020225243642926216, \"iteration\": 1720, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001806301181204617, \"iteration\": 1721, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019017667509615421, \"iteration\": 1722, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008812104351818562, \"iteration\": 1723, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002183884847909212, \"iteration\": 1724, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0026150206103920937, \"iteration\": 1725, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004002188798040152, \"iteration\": 1726, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0023048552684485912, \"iteration\": 1727, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002647426910698414, \"iteration\": 1728, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006681726314127445, \"iteration\": 1729, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0027094236575067043, \"iteration\": 1730, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011372787412256002, \"iteration\": 1731, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00113121815957129, \"iteration\": 1732, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010377290891483426, \"iteration\": 1733, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002011904725804925, \"iteration\": 1734, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016212740447372198, \"iteration\": 1735, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00479111447930336, \"iteration\": 1736, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005813750438392162, \"iteration\": 1737, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017683205660432577, \"iteration\": 1738, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0024110879749059677, \"iteration\": 1739, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0038491161540150642, \"iteration\": 1740, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0031330010388046503, \"iteration\": 1741, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006650619907304645, \"iteration\": 1742, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004099796060472727, \"iteration\": 1743, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016356201376765966, \"iteration\": 1744, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001993586076423526, \"iteration\": 1745, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002279783133417368, \"iteration\": 1746, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016640479443594813, \"iteration\": 1747, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020763317588716745, \"iteration\": 1748, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007190594915300608, \"iteration\": 1749, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003407893469557166, \"iteration\": 1750, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003284994512796402, \"iteration\": 1751, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013347137719392776, \"iteration\": 1752, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011025614803656936, \"iteration\": 1753, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0031233991030603647, \"iteration\": 1754, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012348202290013433, \"iteration\": 1755, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030657244846224785, \"iteration\": 1756, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015518319560214877, \"iteration\": 1757, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003152174409478903, \"iteration\": 1758, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002835493301972747, \"iteration\": 1759, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016798003343865275, \"iteration\": 1760, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003080837894231081, \"iteration\": 1761, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005234021809883416, \"iteration\": 1762, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009918470168486238, \"iteration\": 1763, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0036075860261917114, \"iteration\": 1764, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021353065967559814, \"iteration\": 1765, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001050067599862814, \"iteration\": 1766, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012913676910102367, \"iteration\": 1767, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025048204697668552, \"iteration\": 1768, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005053414031863213, \"iteration\": 1769, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001576098962686956, \"iteration\": 1770, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008230357780121267, \"iteration\": 1771, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00365609978325665, \"iteration\": 1772, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009345810394734144, \"iteration\": 1773, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008435375057160854, \"iteration\": 1774, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009628752013668418, \"iteration\": 1775, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029197572730481625, \"iteration\": 1776, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007479899795725942, \"iteration\": 1777, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011463852133601904, \"iteration\": 1778, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013829133240506053, \"iteration\": 1779, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.059712305665016174, \"iteration\": 1780, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0026131002232432365, \"iteration\": 1781, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018401624402031302, \"iteration\": 1782, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005815112381242216, \"iteration\": 1783, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001605281955562532, \"iteration\": 1784, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017477297224104404, \"iteration\": 1785, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013290229253470898, \"iteration\": 1786, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0037365525495260954, \"iteration\": 1787, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014766583917662501, \"iteration\": 1788, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0024049696512520313, \"iteration\": 1789, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002337757498025894, \"iteration\": 1790, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00044929012074135244, \"iteration\": 1791, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018126624636352062, \"iteration\": 1792, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004260432906448841, \"iteration\": 1793, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013125197729095817, \"iteration\": 1794, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029310432728379965, \"iteration\": 1795, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0027509843930602074, \"iteration\": 1796, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001283682999201119, \"iteration\": 1797, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017803988885134459, \"iteration\": 1798, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00363868847489357, \"iteration\": 1799, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016604568809270859, \"iteration\": 1800, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010814090492203832, \"iteration\": 1801, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019139285432174802, \"iteration\": 1802, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011357746552675962, \"iteration\": 1803, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013775068800896406, \"iteration\": 1804, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010472272988408804, \"iteration\": 1805, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001989553915336728, \"iteration\": 1806, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014263576595112681, \"iteration\": 1807, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021618560422211885, \"iteration\": 1808, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014679261948913336, \"iteration\": 1809, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0032569949980825186, \"iteration\": 1810, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010055259335786104, \"iteration\": 1811, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029284600168466568, \"iteration\": 1812, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021844475995749235, \"iteration\": 1813, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002151759108528495, \"iteration\": 1814, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014438295038416982, \"iteration\": 1815, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021897517144680023, \"iteration\": 1816, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001206902670674026, \"iteration\": 1817, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005282878410071135, \"iteration\": 1818, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001610135193914175, \"iteration\": 1819, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002652908908203244, \"iteration\": 1820, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009232437005266547, \"iteration\": 1821, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012815829832106829, \"iteration\": 1822, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002537146210670471, \"iteration\": 1823, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008608895004726946, \"iteration\": 1824, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015212675789371133, \"iteration\": 1825, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014178319834172726, \"iteration\": 1826, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001259613549336791, \"iteration\": 1827, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005308556719683111, \"iteration\": 1828, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00100202695466578, \"iteration\": 1829, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001139688421972096, \"iteration\": 1830, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029871514067053795, \"iteration\": 1831, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016080557834357023, \"iteration\": 1832, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009578523458912969, \"iteration\": 1833, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001330032479017973, \"iteration\": 1834, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016195086063817143, \"iteration\": 1835, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013953467132523656, \"iteration\": 1836, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002345558488741517, \"iteration\": 1837, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001019848044961691, \"iteration\": 1838, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0037326712626963854, \"iteration\": 1839, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007662635762244463, \"iteration\": 1840, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007360827876254916, \"iteration\": 1841, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001762325526215136, \"iteration\": 1842, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01726173795759678, \"iteration\": 1843, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016003921627998352, \"iteration\": 1844, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010036883177235723, \"iteration\": 1845, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001639331690967083, \"iteration\": 1846, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002365737222135067, \"iteration\": 1847, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006681543309241533, \"iteration\": 1848, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001905101933516562, \"iteration\": 1849, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0022866956423968077, \"iteration\": 1850, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015001015271991491, \"iteration\": 1851, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006534373969770968, \"iteration\": 1852, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001577650778926909, \"iteration\": 1853, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013348632492125034, \"iteration\": 1854, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013361949240788817, \"iteration\": 1855, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009712330065667629, \"iteration\": 1856, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011889082379639149, \"iteration\": 1857, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005432565696537495, \"iteration\": 1858, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0028909111861139536, \"iteration\": 1859, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011808720882982016, \"iteration\": 1860, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002380971796810627, \"iteration\": 1861, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015236122999340296, \"iteration\": 1862, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001123002264648676, \"iteration\": 1863, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0038916426710784435, \"iteration\": 1864, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005189395509660244, \"iteration\": 1865, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009501928579993546, \"iteration\": 1866, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006951370742172003, \"iteration\": 1867, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001240184879861772, \"iteration\": 1868, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004547010757960379, \"iteration\": 1869, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002192746615037322, \"iteration\": 1870, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015781153924763203, \"iteration\": 1871, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016709488118067384, \"iteration\": 1872, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014135233359411359, \"iteration\": 1873, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001242870930582285, \"iteration\": 1874, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015818106476217508, \"iteration\": 1875, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0022237072698771954, \"iteration\": 1876, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015327159781008959, \"iteration\": 1877, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010712783550843596, \"iteration\": 1878, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003126715775579214, \"iteration\": 1879, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008709547109901905, \"iteration\": 1880, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00012320645328145474, \"iteration\": 1881, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.6938989162445068, \"iteration\": 1882, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007055207970552146, \"iteration\": 1883, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009339055977761745, \"iteration\": 1884, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012971129035577178, \"iteration\": 1885, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04096889868378639, \"iteration\": 1886, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0046586208045482635, \"iteration\": 1887, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.009084345772862434, \"iteration\": 1888, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.006960459053516388, \"iteration\": 1889, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005354019347578287, \"iteration\": 1890, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016720411367714405, \"iteration\": 1891, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005941308103501797, \"iteration\": 1892, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015780833782628179, \"iteration\": 1893, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0019228097517043352, \"iteration\": 1894, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006463826866820455, \"iteration\": 1895, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0060368487611413, \"iteration\": 1896, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0019846174400299788, \"iteration\": 1897, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018779177917167544, \"iteration\": 1898, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002299383981153369, \"iteration\": 1899, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017937887459993362, \"iteration\": 1900, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010914577869698405, \"iteration\": 1901, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0019025903893634677, \"iteration\": 1902, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009122147457674146, \"iteration\": 1903, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012213322333991528, \"iteration\": 1904, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009113743435591459, \"iteration\": 1905, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010548301506787539, \"iteration\": 1906, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021351759787648916, \"iteration\": 1907, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0038708688225597143, \"iteration\": 1908, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032393988221883774, \"iteration\": 1909, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013148380676284432, \"iteration\": 1910, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002183208242058754, \"iteration\": 1911, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.008931290358304977, \"iteration\": 1912, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013276587706059217, \"iteration\": 1913, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015223650261759758, \"iteration\": 1914, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001176237827166915, \"iteration\": 1915, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002899231854826212, \"iteration\": 1916, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0019866367802023888, \"iteration\": 1917, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008968397742137313, \"iteration\": 1918, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015369793400168419, \"iteration\": 1919, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016377846477553248, \"iteration\": 1920, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002438385970890522, \"iteration\": 1921, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.03258056938648224, \"iteration\": 1922, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017184014432132244, \"iteration\": 1923, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005477017257362604, \"iteration\": 1924, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015373260248452425, \"iteration\": 1925, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009990135440602899, \"iteration\": 1926, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016899966867640615, \"iteration\": 1927, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.006592487916350365, \"iteration\": 1928, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0060775321908295155, \"iteration\": 1929, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009979597525671124, \"iteration\": 1930, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000959675177000463, \"iteration\": 1931, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012310456950217485, \"iteration\": 1932, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006617470644414425, \"iteration\": 1933, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016815849812701344, \"iteration\": 1934, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0028405459597706795, \"iteration\": 1935, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0024036250542849302, \"iteration\": 1936, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013630345929414034, \"iteration\": 1937, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0024789804592728615, \"iteration\": 1938, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003832755144685507, \"iteration\": 1939, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0023699302691966295, \"iteration\": 1940, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0045809452421963215, \"iteration\": 1941, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012354778591543436, \"iteration\": 1942, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009199104970321059, \"iteration\": 1943, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006806050660088658, \"iteration\": 1944, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015995807480067015, \"iteration\": 1945, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011915036011487246, \"iteration\": 1946, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012565312208607793, \"iteration\": 1947, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013551644515246153, \"iteration\": 1948, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001014328794553876, \"iteration\": 1949, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001625510398298502, \"iteration\": 1950, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000836953753605485, \"iteration\": 1951, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009859380079433322, \"iteration\": 1952, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001167671987786889, \"iteration\": 1953, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014921327820047736, \"iteration\": 1954, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008074629586189985, \"iteration\": 1955, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013651603367179632, \"iteration\": 1956, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007468953263014555, \"iteration\": 1957, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009283705148845911, \"iteration\": 1958, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009341865661554039, \"iteration\": 1959, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007816784782335162, \"iteration\": 1960, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021010292693972588, \"iteration\": 1961, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007482664659619331, \"iteration\": 1962, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012458465062081814, \"iteration\": 1963, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001068353303708136, \"iteration\": 1964, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009984261123463511, \"iteration\": 1965, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009193882578983903, \"iteration\": 1966, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005484125576913357, \"iteration\": 1967, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014795558527112007, \"iteration\": 1968, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002183780074119568, \"iteration\": 1969, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004588324576616287, \"iteration\": 1970, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011035626521334052, \"iteration\": 1971, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001243129256181419, \"iteration\": 1972, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012356723891571164, \"iteration\": 1973, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00119496020488441, \"iteration\": 1974, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008784091915003955, \"iteration\": 1975, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014474793570116162, \"iteration\": 1976, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0037329341284930706, \"iteration\": 1977, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001775486976839602, \"iteration\": 1978, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017916106153279543, \"iteration\": 1979, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005501606501638889, \"iteration\": 1980, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002053620992228389, \"iteration\": 1981, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02222426049411297, \"iteration\": 1982, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005091120838187635, \"iteration\": 1983, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014050072059035301, \"iteration\": 1984, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008457132498733699, \"iteration\": 1985, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011216964339837432, \"iteration\": 1986, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013424016069620848, \"iteration\": 1987, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017838224302977324, \"iteration\": 1988, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011462914990261197, \"iteration\": 1989, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003584094112738967, \"iteration\": 1990, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018285748083144426, \"iteration\": 1991, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016843456542119384, \"iteration\": 1992, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0076078688725829124, \"iteration\": 1993, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001104100956581533, \"iteration\": 1994, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010345301125198603, \"iteration\": 1995, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012797273229807615, \"iteration\": 1996, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.007909081876277924, \"iteration\": 1997, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008264203788712621, \"iteration\": 1998, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005826007109135389, \"iteration\": 1999, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014420408988371491, \"iteration\": 2000, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003899879055097699, \"iteration\": 2001, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001961911329999566, \"iteration\": 2002, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00046780111733824015, \"iteration\": 2003, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016678229440003633, \"iteration\": 2004, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016015840228646994, \"iteration\": 2005, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019957302138209343, \"iteration\": 2006, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013571369927376509, \"iteration\": 2007, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021038509439677, \"iteration\": 2008, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012816260568797588, \"iteration\": 2009, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023692961782217026, \"iteration\": 2010, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016353495884686708, \"iteration\": 2011, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006802842253819108, \"iteration\": 2012, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007001578342169523, \"iteration\": 2013, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009298385703004897, \"iteration\": 2014, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0025716086383908987, \"iteration\": 2015, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014878478832542896, \"iteration\": 2016, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001245679333806038, \"iteration\": 2017, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008121221326291561, \"iteration\": 2018, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011093507055193186, \"iteration\": 2019, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000741666997782886, \"iteration\": 2020, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010996632045134902, \"iteration\": 2021, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014238472795113921, \"iteration\": 2022, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0035034180618822575, \"iteration\": 2023, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012054643593728542, \"iteration\": 2024, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014688036171719432, \"iteration\": 2025, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004438306204974651, \"iteration\": 2026, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000923430547118187, \"iteration\": 2027, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003001320408657193, \"iteration\": 2028, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009167471434921026, \"iteration\": 2029, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002395723480731249, \"iteration\": 2030, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007771467790007591, \"iteration\": 2031, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011141669237986207, \"iteration\": 2032, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0023812763392925262, \"iteration\": 2033, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.007024574093520641, \"iteration\": 2034, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005098860245198011, \"iteration\": 2035, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004970922018401325, \"iteration\": 2036, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0027683191001415253, \"iteration\": 2037, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008269542013294995, \"iteration\": 2038, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014518483076244593, \"iteration\": 2039, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004248737241141498, \"iteration\": 2040, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0029946700669825077, \"iteration\": 2041, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001145674497820437, \"iteration\": 2042, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008210976957343519, \"iteration\": 2043, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010553353931754827, \"iteration\": 2044, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014350672718137503, \"iteration\": 2045, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008121982682496309, \"iteration\": 2046, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00068161531817168, \"iteration\": 2047, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00043618050403892994, \"iteration\": 2048, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007888671243563294, \"iteration\": 2049, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.007908504456281662, \"iteration\": 2050, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003332791617140174, \"iteration\": 2051, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001100317109376192, \"iteration\": 2052, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00041837827302515507, \"iteration\": 2053, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004155893810093403, \"iteration\": 2054, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013226560549810529, \"iteration\": 2055, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001431808341294527, \"iteration\": 2056, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0023634859826415777, \"iteration\": 2057, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012887201737612486, \"iteration\": 2058, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006301486864686012, \"iteration\": 2059, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013907111715525389, \"iteration\": 2060, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000670991837978363, \"iteration\": 2061, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009016820113174617, \"iteration\": 2062, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002964579500257969, \"iteration\": 2063, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0027130923699587584, \"iteration\": 2064, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006957458099350333, \"iteration\": 2065, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006318734958767891, \"iteration\": 2066, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003865696198772639, \"iteration\": 2067, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00044393661664798856, \"iteration\": 2068, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006952983676455915, \"iteration\": 2069, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0047885095700621605, \"iteration\": 2070, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007796790450811386, \"iteration\": 2071, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012966706417500973, \"iteration\": 2072, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000959641532972455, \"iteration\": 2073, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011165020987391472, \"iteration\": 2074, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018132824916392565, \"iteration\": 2075, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012913401005789638, \"iteration\": 2076, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008245678618550301, \"iteration\": 2077, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013836515136063099, \"iteration\": 2078, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.007855783216655254, \"iteration\": 2079, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005160753498785198, \"iteration\": 2080, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001184495398774743, \"iteration\": 2081, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00043755944352597, \"iteration\": 2082, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005760234780609608, \"iteration\": 2083, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018407069146633148, \"iteration\": 2084, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002409970387816429, \"iteration\": 2085, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016424598870798945, \"iteration\": 2086, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003533459093887359, \"iteration\": 2087, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012286340352147818, \"iteration\": 2088, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009234566823579371, \"iteration\": 2089, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.018896957859396935, \"iteration\": 2090, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop out\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models/gb')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    "    optimizer_params= {\"lr\": 0.001, \"weight_decay\": 0.01, }\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(train_data_nn, batch_size=128, shuffle=True)\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(tfidf_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    dropout=0.5,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "if (models_dir / 'model_nn.pt').exists() and USE_CACHE:\n",
    "    model_nn = load_model(model_nn, models_dir, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn, models_dir, \"model_nn\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # X_test = torch.stack([dta[0] for dta in test])\n",
    "    X_test = torch.stack([test[0] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_test = torch.stack([test[1] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_pred = model_nn.predict(X_test)\n",
    "\n",
    "\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='binary'))\n",
    "print(\"AUC\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other classifiers\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "\"Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC, SVM\n",
    "Effective in high dimensional spaces.\n",
    "\n",
    "Still effective in cases where number of dimensions is greater than the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC with TfIdf did good on balanced English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoanghapham/.pyenv/versions/3.11.5/envs/power-identification/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.749000999000999, 0.8103215347203458, 0.7784555483452303, None)\n",
      "AUC: 0.7333658955653011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# LinearSVC, tfidf\n",
    "X_train = tfidf_encoder.transform(train_raw.texts)\n",
    "print(\"Fit model\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_train, train_raw.labels)\n",
    "\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(tfidf_encoder.transform(test_raw.texts))\n",
    "\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_LinearSVC_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier\n",
    "SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "\n",
    "SGD is sensitive to feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7422609493235497, 0.8746284787895163, 0.803026544281816, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7451774872580061"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_train, train_raw.labels)\n",
    "\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(tfidf_encoder.transform(test_raw.texts))\n",
    "\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Overall bad performance, not worth pursuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.620243232640251, 0.427181842745204, 0.50592, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5481208359025165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model_GaussianNB_tfidf = GaussianNB()\n",
    "model_GaussianNB_tfidf.fit(X_train.toarray(), train_raw.labels)\n",
    "\n",
    "pred_GaussianNB_tfidf = model_GaussianNB_tfidf.predict(tfidf_encoder.transform(test_raw.texts).toarray())\n",
    "\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_GaussianNB_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_GaussianNB_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- Neural network is still a good option\n",
    "- sklearn's SGD is also good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard count vectors & scale\n",
    "Not good on both LinearSVC and SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoanghapham/.pyenv/versions/3.11.5/envs/power-identification/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/hoanghapham/.pyenv/versions/3.11.5/envs/power-identification/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.689257969461559, 0.6952175087814104, 0.6922249125638956, None)\n",
      "AUC: 0.6493181561001069\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "encoding_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('scaler', StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "encoding_pipeline.fit(train_raw.texts)\n",
    "\n",
    "X_train = encoding_pipeline.transform(train_raw.texts)\n",
    "\n",
    "\n",
    "print(\"Fit model\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_train, train_raw.labels)\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(encoding_pipeline.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_LinearSVC_tfidf))\n",
    "\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_train, train_raw.labels)\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(encoding_pipeline.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-level TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoanghapham/.pyenv/versions/3.11.5/envs/power-identification/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.753175591531756, 0.8170764658200487, 0.7838258164852255, None)\n",
      "AUC: 0.7391365235083149\n",
      "SGDClassifier\n",
      "(0.7359676695105523, 0.8857065657930289, 0.8039239730226855, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7418276418708734"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tfidf = TfidfVectorizer(sublinear_tf=True, analyzer=\"word\", ngram_range=(3,5), max_features=10000)\n",
    "\n",
    "X_train = word_tfidf.fit_transform(train_raw.texts)\n",
    "\n",
    "\n",
    "print(\"LinearSVC\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_train, train_raw.labels)\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(word_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_LinearSVC_tfidf))\n",
    "\n",
    "print(\"SGDClassifier\")\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_train, train_raw.labels)\n",
    "\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(word_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use more tfidf word (50000) features improve 1%, but takes much more time to transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoanghapham/.pyenv/versions/3.11.5/envs/power-identification/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7683168316831683, 0.8386922453390976, 0.801963570598114, None)\n",
      "AUC: 0.7593461226695487\n",
      "SGDClassifier\n",
      "(0.7429515418502203, 0.9113753039718995, 0.8185899769445456, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7562004724987703"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tfidf = TfidfVectorizer(sublinear_tf=True, analyzer=\"word\", ngram_range=(3,7), max_features=50000)\n",
    "\n",
    "X_train = word_tfidf.fit_transform(train_raw.texts)\n",
    "\n",
    "import scipy\n",
    "scipy.sparse.save_npz(\"models/tfidf/ngram_word_3to7_50000.npz\", X_train)\n",
    "\n",
    "print(\"LinearSVC\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_train, train_raw.labels)\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(word_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_LinearSVC_tfidf))\n",
    "\n",
    "print(\"SGDClassifier\")\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_train, train_raw.labels)\n",
    "\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(word_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Char ngram is slower and offers the same performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoanghapham/.pyenv/versions/3.11.5/envs/power-identification/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7789526686807654, 0.8359902728992165, 0.8064642252052652, None)\n",
      "AUC: 0.7679096663641382\n",
      "SGDClassifier\n",
      "(0.7625231910946196, 0.88840853823291, 0.8206664170722576, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7691615340737199"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_tfidf = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(3,7), max_features=50000)\n",
    "\n",
    "X_train = char_tfidf.fit_transform(train_raw.texts)\n",
    "\n",
    "import scipy\n",
    "scipy.sparse.save_npz(\"models/tfidf/ngram_char_3to7_50000.npz\", X_train)\n",
    "\n",
    "print(\"LinearSVC\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_train, train_raw.labels)\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(char_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_LinearSVC_tfidf))\n",
    "\n",
    "print(\"SGDClassifier\")\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_train, train_raw.labels)\n",
    "\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(char_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 45.44batch/s, batch_accuracy=1, loss=0.22]     \n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:03<00:00, 58.35batch/s, batch_accuracy=1, loss=0.205]    \n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:03<00:00, 57.01batch/s, batch_accuracy=1, loss=0.112]    \n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:03<00:00, 53.92batch/s, batch_accuracy=1, loss=0.428]    \n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:03<00:00, 54.05batch/s, batch_accuracy=1, loss=0.0821]   \n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:03<00:00, 54.59batch/s, batch_accuracy=1, loss=0.135]     \n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:03<00:00, 53.61batch/s, batch_accuracy=1, loss=0.0163]    \n",
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:03<00:00, 56.02batch/s, batch_accuracy=1, loss=0.0147]    \n",
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 49.90batch/s, batch_accuracy=1, loss=0.000198]   \n",
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:04<00:00, 51.04batch/s, batch_accuracy=0.857, loss=0.711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7721052631578947, 0.7927587138611186, 0.782295693907479, None)\n",
      "AUC 0.7483451688963714\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-0e169e31f4cc4f75bfd751bd8f9ef49f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-0e169e31f4cc4f75bfd751bd8f9ef49f.vega-embed details,\n",
       "  #altair-viz-0e169e31f4cc4f75bfd751bd8f9ef49f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-0e169e31f4cc4f75bfd751bd8f9ef49f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-0e169e31f4cc4f75bfd751bd8f9ef49f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-0e169e31f4cc4f75bfd751bd8f9ef49f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-48cce803979d0cff68ce3b73e1aee9e3\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-48cce803979d0cff68ce3b73e1aee9e3\": [{\"training_acc\": 0.546875, \"training_loss\": 0.6923115253448486, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.6904150247573853, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6896675825119019, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.453125, \"training_loss\": 0.699777364730835, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.6845544576644897, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6854587197303772, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6703388690948486, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6777333617210388, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6697731018066406, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6589611768722534, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6830880641937256, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6544348001480103, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6780118942260742, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 0.6858096122741699, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.6815674304962158, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.453125, \"training_loss\": 0.7183542847633362, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6364020109176636, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6318628191947937, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.662925124168396, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.6745350956916809, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.656960666179657, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6537585854530334, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6621615886688232, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6571002006530762, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6306527853012085, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6253247857093811, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6354222893714905, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.6033501029014587, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6279420852661133, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6107553839683533, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6277210712432861, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6150563955307007, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.6160429120063782, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6343495845794678, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.605819046497345, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.58774733543396, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5909695029258728, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5628331303596497, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5578855276107788, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5849493741989136, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5590649843215942, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.6041550040245056, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.6037363409996033, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5687967538833618, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5637754201889038, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5691377520561218, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5686430931091309, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5245521068572998, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5615459084510803, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5788320302963257, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5400304794311523, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5515148639678955, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5861181616783142, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4766910672187805, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.549045979976654, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.48998212814331055, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5396103262901306, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5104104280471802, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.45515626668930054, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5716965198516846, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.44598525762557983, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4816209077835083, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5007185339927673, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.48573508858680725, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.4904968738555908, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4740294814109802, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3433286249637604, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.45616698265075684, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5457935333251953, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.45837199687957764, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.4842178225517273, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5263607501983643, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4644155204296112, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.517432451248169, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.48446181416511536, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4435577690601349, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5354033708572388, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5146763324737549, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.44150301814079285, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5636827945709229, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.48301541805267334, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4779773950576782, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.47401055693626404, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.875, \"training_loss\": 0.35968342423439026, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5777714848518372, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5364689826965332, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4773808419704437, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.456296443939209, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.4917684495449066, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6227158308029175, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.47623005509376526, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5065587162971497, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.38746553659439087, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5358699560165405, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.45850348472595215, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.454773485660553, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4810747802257538, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.46296781301498413, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4083634912967682, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.44593822956085205, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4619210660457611, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.43730953335762024, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.43378686904907227, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5013609528541565, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5914939641952515, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5101168751716614, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.46970683336257935, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4412747919559479, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.489864706993103, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4876372218132019, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.49021095037460327, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4636729061603546, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5285229682922363, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.38985323905944824, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.44406604766845703, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.46846187114715576, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5063080787658691, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3890867233276367, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.41663601994514465, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4753095507621765, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.48077914118766785, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.40848374366760254, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5735717415809631, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5121099948883057, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.48065975308418274, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.48548081517219543, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5358828902244568, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.48472902178764343, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.43510180711746216, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.48267343640327454, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4417455792427063, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.46540385484695435, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.45279526710510254, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4812180697917938, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4490984082221985, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.46468764543533325, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4800299406051636, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.46002262830734253, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.42713525891304016, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4723969101905823, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4129742980003357, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.43569162487983704, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.42583051323890686, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.49476468563079834, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.47428733110427856, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4897860586643219, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.41840115189552307, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.39714744687080383, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.35773003101348877, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.523654580116272, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3734886050224304, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.42080894112586975, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4353860020637512, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5016718506813049, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.44453561305999756, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.40920376777648926, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.33729326725006104, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.43123364448547363, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.48095595836639404, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.501530647277832, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.4010005593299866, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4342727065086365, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.47557005286216736, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.3853606581687927, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.4728032350540161, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.48641809821128845, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5419497489929199, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5243536233901978, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.382057249546051, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4404760003089905, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.46142008900642395, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3857674300670624, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.46885475516319275, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4917764961719513, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4988456070423126, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.45179057121276855, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4169277846813202, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.41030579805374146, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.42036575078964233, \"iteration\": 179, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4645712375640869, \"iteration\": 180, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5165600776672363, \"iteration\": 181, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4895780086517334, \"iteration\": 182, \"epoch\": 1}, {\"training_acc\": 0.90625, \"training_loss\": 0.28958240151405334, \"iteration\": 183, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5324050188064575, \"iteration\": 184, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4495077431201935, \"iteration\": 185, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.42904001474380493, \"iteration\": 186, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4165591895580292, \"iteration\": 187, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4668046832084656, \"iteration\": 188, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.44795888662338257, \"iteration\": 189, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5278165936470032, \"iteration\": 190, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.4931858777999878, \"iteration\": 191, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4840395152568817, \"iteration\": 192, \"epoch\": 1}, {\"training_acc\": 0.875, \"training_loss\": 0.3653992712497711, \"iteration\": 193, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5442978739738464, \"iteration\": 194, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3764769732952118, \"iteration\": 195, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3513355553150177, \"iteration\": 196, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4177892506122589, \"iteration\": 197, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.44436022639274597, \"iteration\": 198, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.41813987493515015, \"iteration\": 199, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.43255674839019775, \"iteration\": 200, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4131125807762146, \"iteration\": 201, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.445557564496994, \"iteration\": 202, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.3966512084007263, \"iteration\": 203, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.42831456661224365, \"iteration\": 204, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4713452160358429, \"iteration\": 205, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5539007782936096, \"iteration\": 206, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.44386357069015503, \"iteration\": 207, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3990621268749237, \"iteration\": 208, \"epoch\": 1}, {\"training_acc\": 1.0, \"training_loss\": 0.22038887441158295, \"iteration\": 209, \"epoch\": 1}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3676157295703888, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3482864797115326, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3704211711883545, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.46340394020080566, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3916749358177185, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.39688047766685486, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.26476767659187317, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32218849658966064, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.35501986742019653, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3468211591243744, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4455108046531677, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3273974359035492, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.31907787919044495, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4242057800292969, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.375537633895874, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.28382378816604614, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.31190261244773865, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.35775405168533325, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.41915690898895264, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3955349922180176, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2957634925842285, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.37994515895843506, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34842199087142944, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.34733065962791443, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3691028952598572, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3165469169616699, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.36110419034957886, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.38516294956207275, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3516915440559387, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30260196328163147, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3709692060947418, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4208255112171173, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.37308040261268616, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2709369659423828, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4762938618659973, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.47351282835006714, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3794485926628113, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3782901167869568, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.39279159903526306, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.36766570806503296, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 0.45522862672805786, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.33814147114753723, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.40958371758461, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3665020763874054, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4122437536716461, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.361704021692276, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.4472208321094513, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.35604047775268555, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2803308069705963, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3944370448589325, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.39917322993278503, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.34279489517211914, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3091259300708771, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4065667390823364, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.421457439661026, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.34648722410202026, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.37597689032554626, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3903753161430359, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.45025399327278137, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.4440804719924927, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3620589077472687, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.3791346549987793, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.37979552149772644, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.34713977575302124, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4349367022514343, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4237543046474457, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3582300841808319, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.35673442482948303, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.45808136463165283, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3928476870059967, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.291140079498291, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32647091150283813, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.46549054980278015, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.36349764466285706, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.3663487434387207, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.41915270686149597, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3481101989746094, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.3896940052509308, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3729695975780487, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3310616612434387, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4020141363143921, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3631588816642761, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.38608288764953613, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.32887002825737, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.38999947905540466, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.38756704330444336, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.36690622568130493, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3662935495376587, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3633168637752533, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.39702513813972473, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.25393202900886536, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.419476181268692, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.39532145857810974, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3428693413734436, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.38246119022369385, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4173775017261505, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33661696314811707, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 0.4862958788871765, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3880852162837982, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3355027139186859, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.44356709718704224, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.40267622470855713, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3978689908981323, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.36757057905197144, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40738627314567566, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.36833763122558594, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3660252094268799, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.3702923059463501, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32927021384239197, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.41171860694885254, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.38530951738357544, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4001609981060028, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.48299920558929443, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.3985355496406555, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.44925686717033386, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4217977523803711, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3183371126651764, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3707912564277649, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3398548662662506, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2815318703651428, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33002999424934387, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3662239611148834, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4966997504234314, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3324638307094574, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3492066562175751, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4348345398902893, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2656903862953186, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3433375358581543, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.314538836479187, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3587598502635956, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3461952805519104, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.38871675729751587, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.33630654215812683, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.44789960980415344, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.382890909910202, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2724367678165436, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31687915325164795, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.34035617113113403, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.41789600253105164, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4337952136993408, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.42528849840164185, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3844697177410126, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.402351051568985, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3651714324951172, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4185456931591034, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4289943277835846, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2445504367351532, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3469231128692627, \"iteration\": 357, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.42385542392730713, \"iteration\": 358, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3949460983276367, \"iteration\": 359, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.42497074604034424, \"iteration\": 360, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3634242117404938, \"iteration\": 361, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.30313360691070557, \"iteration\": 362, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4148702025413513, \"iteration\": 363, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3894456923007965, \"iteration\": 364, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4412250816822052, \"iteration\": 365, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.39761418104171753, \"iteration\": 366, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.419219434261322, \"iteration\": 367, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4036218225955963, \"iteration\": 368, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.4932399094104767, \"iteration\": 369, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31753087043762207, \"iteration\": 370, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.376676470041275, \"iteration\": 371, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.37105047702789307, \"iteration\": 372, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.417470246553421, \"iteration\": 373, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.38410744071006775, \"iteration\": 374, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3471737504005432, \"iteration\": 375, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3413105309009552, \"iteration\": 376, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.28198254108428955, \"iteration\": 377, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4368433654308319, \"iteration\": 378, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.3871934413909912, \"iteration\": 379, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.44696441292762756, \"iteration\": 380, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.34424394369125366, \"iteration\": 381, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.38147181272506714, \"iteration\": 382, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3876235783100128, \"iteration\": 383, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.45096758008003235, \"iteration\": 384, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3490973711013794, \"iteration\": 385, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.38133957982063293, \"iteration\": 386, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.3774965703487396, \"iteration\": 387, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.37038546800613403, \"iteration\": 388, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.38527753949165344, \"iteration\": 389, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3653317391872406, \"iteration\": 390, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.44566941261291504, \"iteration\": 391, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.29090213775634766, \"iteration\": 392, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2886146605014801, \"iteration\": 393, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.37397828698158264, \"iteration\": 394, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3907652199268341, \"iteration\": 395, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.36267489194869995, \"iteration\": 396, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4737503230571747, \"iteration\": 397, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.32762816548347473, \"iteration\": 398, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5345592498779297, \"iteration\": 399, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.3763854205608368, \"iteration\": 400, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4034540355205536, \"iteration\": 401, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.476152241230011, \"iteration\": 402, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3912198543548584, \"iteration\": 403, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.31852543354034424, \"iteration\": 404, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3173673748970032, \"iteration\": 405, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.40162426233291626, \"iteration\": 406, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.40876898169517517, \"iteration\": 407, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.33208054304122925, \"iteration\": 408, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.43408486247062683, \"iteration\": 409, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.36920878291130066, \"iteration\": 410, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3269099295139313, \"iteration\": 411, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.40907785296440125, \"iteration\": 412, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.37557920813560486, \"iteration\": 413, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.33834049105644226, \"iteration\": 414, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.39027708768844604, \"iteration\": 415, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3872480094432831, \"iteration\": 416, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3490399420261383, \"iteration\": 417, \"epoch\": 2}, {\"training_acc\": 1.0, \"training_loss\": 0.20545850694179535, \"iteration\": 418, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2971424460411072, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.40207338333129883, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.31176838278770447, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3362114131450653, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.334133505821228, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3171977996826172, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.30718740820884705, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2877022922039032, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3028547763824463, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3530225157737732, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.21971163153648376, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2491060495376587, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.30226364731788635, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3284764289855957, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3486257493495941, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2740461528301239, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3467796742916107, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3286561965942383, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.34573978185653687, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.24365736544132233, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.2841237187385559, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.38673660159111023, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.29669055342674255, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.22906000912189484, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.326712429523468, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.2870432138442993, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.2927035689353943, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.35083433985710144, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3049842119216919, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2780086100101471, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.31890323758125305, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3365578055381775, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.33214348554611206, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3897438645362854, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.36247217655181885, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30469560623168945, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.28377318382263184, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33486059308052063, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.23909404873847961, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23694628477096558, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2220742106437683, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31505081057548523, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2593245506286621, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.32535916566848755, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.31359055638313293, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20789405703544617, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18589052557945251, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3062543570995331, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2963608205318451, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3981533646583557, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2723791003227234, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2706674635410309, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.28195542097091675, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22111530601978302, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.270379900932312, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2751155197620392, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2928411364555359, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.31636545062065125, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33124199509620667, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22920602560043335, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2639806866645813, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3188525140285492, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.26709914207458496, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.27891865372657776, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3088870644569397, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.29651913046836853, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.40467238426208496, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3255843222141266, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34137266874313354, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.382233589887619, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.2530496120452881, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.282196581363678, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24796822667121887, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.26474544405937195, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27393707633018494, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.29608154296875, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29859933257102966, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3376460075378418, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.35298827290534973, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.31325915455818176, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18664370477199554, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.34985440969467163, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.34022268652915955, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24462640285491943, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3064272999763489, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.41567495465278625, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.43269285559654236, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2736879587173462, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.298254132270813, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3518590033054352, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.36884376406669617, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.35033169388771057, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.35414981842041016, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3792092800140381, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3121297359466553, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4002232253551483, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.28665703535079956, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3720061779022217, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33843016624450684, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4251248836517334, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.26806044578552246, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3004571199417114, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3901771306991577, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3377753794193268, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3604952394962311, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.34635114669799805, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3654925525188446, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4186665117740631, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.31080642342567444, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.32767441868782043, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.32385486364364624, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.326820969581604, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33008310198783875, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.380299836397171, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3713909387588501, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28134244680404663, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.36109912395477295, \"iteration\": 535, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.29008370637893677, \"iteration\": 536, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.38861456513404846, \"iteration\": 537, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2948800325393677, \"iteration\": 538, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.318450927734375, \"iteration\": 539, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.351471871137619, \"iteration\": 540, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3434344232082367, \"iteration\": 541, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.34920477867126465, \"iteration\": 542, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.33292490243911743, \"iteration\": 543, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2568616271018982, \"iteration\": 544, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3128545880317688, \"iteration\": 545, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3016092777252197, \"iteration\": 546, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2367573231458664, \"iteration\": 547, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3388221263885498, \"iteration\": 548, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3549237847328186, \"iteration\": 549, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.27241456508636475, \"iteration\": 550, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.31641289591789246, \"iteration\": 551, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3121583163738251, \"iteration\": 552, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 0.43352752923965454, \"iteration\": 553, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.29873934388160706, \"iteration\": 554, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3323720097541809, \"iteration\": 555, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4746326208114624, \"iteration\": 556, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.35683515667915344, \"iteration\": 557, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33744657039642334, \"iteration\": 558, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2381371110677719, \"iteration\": 559, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.35187551379203796, \"iteration\": 560, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.29936832189559937, \"iteration\": 561, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 0.46927228569984436, \"iteration\": 562, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.250143826007843, \"iteration\": 563, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.322980135679245, \"iteration\": 564, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.26770296692848206, \"iteration\": 565, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3024129569530487, \"iteration\": 566, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.33852139115333557, \"iteration\": 567, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.37001657485961914, \"iteration\": 568, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 0.462385892868042, \"iteration\": 569, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.31657707691192627, \"iteration\": 570, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.29634082317352295, \"iteration\": 571, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.30474886298179626, \"iteration\": 572, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2958724796772003, \"iteration\": 573, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30699849128723145, \"iteration\": 574, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3200248181819916, \"iteration\": 575, \"epoch\": 3}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5149544477462769, \"iteration\": 576, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.37161457538604736, \"iteration\": 577, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4365977346897125, \"iteration\": 578, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.34406185150146484, \"iteration\": 579, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.34977293014526367, \"iteration\": 580, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3077336251735687, \"iteration\": 581, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.25515609979629517, \"iteration\": 582, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3447771668434143, \"iteration\": 583, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.33897972106933594, \"iteration\": 584, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1595497727394104, \"iteration\": 585, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.35729193687438965, \"iteration\": 586, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.406818687915802, \"iteration\": 587, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.4950277507305145, \"iteration\": 588, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3393886685371399, \"iteration\": 589, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2520428001880646, \"iteration\": 590, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.42292940616607666, \"iteration\": 591, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.4125593900680542, \"iteration\": 592, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3647546172142029, \"iteration\": 593, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4115155339241028, \"iteration\": 594, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.35562899708747864, \"iteration\": 595, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.452675998210907, \"iteration\": 596, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.35784783959388733, \"iteration\": 597, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.26596423983573914, \"iteration\": 598, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3014300465583801, \"iteration\": 599, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40495410561561584, \"iteration\": 600, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3274976909160614, \"iteration\": 601, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2902771830558777, \"iteration\": 602, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40134963393211365, \"iteration\": 603, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.4241807162761688, \"iteration\": 604, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3677217960357666, \"iteration\": 605, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3541790843009949, \"iteration\": 606, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.31934690475463867, \"iteration\": 607, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3587929606437683, \"iteration\": 608, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.33706867694854736, \"iteration\": 609, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3479243516921997, \"iteration\": 610, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.272836834192276, \"iteration\": 611, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.39999130368232727, \"iteration\": 612, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3096107840538025, \"iteration\": 613, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.4049418568611145, \"iteration\": 614, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.29881829023361206, \"iteration\": 615, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3091133236885071, \"iteration\": 616, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 0.4131346344947815, \"iteration\": 617, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.27206116914749146, \"iteration\": 618, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.2851139008998871, \"iteration\": 619, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.30203914642333984, \"iteration\": 620, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2936112582683563, \"iteration\": 621, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.305093377828598, \"iteration\": 622, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3283643424510956, \"iteration\": 623, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.38224366307258606, \"iteration\": 624, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3685261309146881, \"iteration\": 625, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3811838626861572, \"iteration\": 626, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.11240565031766891, \"iteration\": 627, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1863967776298523, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.23963068425655365, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.2175549566745758, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2319936752319336, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2512189447879791, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30672580003738403, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.20758570730686188, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24461424350738525, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2577865421772003, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3052354156970978, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.28311142325401306, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21847179532051086, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2439327836036682, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.18606039881706238, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2805679440498352, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.30429813265800476, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.21359339356422424, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1864469349384308, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2138034701347351, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2367338389158249, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2110065519809723, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.20982934534549713, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2491537630558014, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22738638520240784, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.23753155767917633, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2947433888912201, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.31872421503067017, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.22517094016075134, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.26414158940315247, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.21992170810699463, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20015452802181244, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17531245946884155, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.18718941509723663, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24120323359966278, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.21026945114135742, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24757522344589233, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1563797891139984, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2949850857257843, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.22927147150039673, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.3007971942424774, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1837044060230255, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1898268461227417, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.23727963864803314, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3255479037761688, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26689520478248596, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24235282838344574, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23971915245056152, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.23831170797348022, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.2614455819129944, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31104564666748047, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21074527502059937, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2829384505748749, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2587495446205139, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3022034466266632, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2435554563999176, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.22807429730892181, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.25387269258499146, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.22676095366477966, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.28476232290267944, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33239227533340454, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.24900951981544495, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2524964511394501, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28973257541656494, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.335792601108551, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29395389556884766, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3479827046394348, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3042305111885071, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.27614259719848633, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2999287545681, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.2804834544658661, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.28845202922821045, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.20982526242733002, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3329988121986389, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.31168320775032043, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2898285686969757, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.257396399974823, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.25266391038894653, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.26943519711494446, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28897199034690857, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2905083894729614, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.284757137298584, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.3149644732475281, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2401873767375946, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24543879926204681, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3441232144832611, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23537373542785645, \"iteration\": 713, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2207147628068924, \"iteration\": 714, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2671111226081848, \"iteration\": 715, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.33341139554977417, \"iteration\": 716, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2846739590167999, \"iteration\": 717, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.24155494570732117, \"iteration\": 718, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31724774837493896, \"iteration\": 719, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22327053546905518, \"iteration\": 720, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.2830675542354584, \"iteration\": 721, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22433653473854065, \"iteration\": 722, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.26287806034088135, \"iteration\": 723, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1854298859834671, \"iteration\": 724, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.19643200933933258, \"iteration\": 725, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3484501838684082, \"iteration\": 726, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2745494246482849, \"iteration\": 727, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.36102619767189026, \"iteration\": 728, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.26629194617271423, \"iteration\": 729, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2676823139190674, \"iteration\": 730, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.3801265358924866, \"iteration\": 731, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.1976184844970703, \"iteration\": 732, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.3420942723751068, \"iteration\": 733, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.29393792152404785, \"iteration\": 734, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.30742505192756653, \"iteration\": 735, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2845016121864319, \"iteration\": 736, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.291920930147171, \"iteration\": 737, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.29900750517845154, \"iteration\": 738, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32283568382263184, \"iteration\": 739, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32450222969055176, \"iteration\": 740, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.36278054118156433, \"iteration\": 741, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.25629884004592896, \"iteration\": 742, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.26694396138191223, \"iteration\": 743, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33557531237602234, \"iteration\": 744, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.280682235956192, \"iteration\": 745, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3477630317211151, \"iteration\": 746, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22158244252204895, \"iteration\": 747, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3906612694263458, \"iteration\": 748, \"epoch\": 4}, {\"training_acc\": 0.8125, \"training_loss\": 0.36011213064193726, \"iteration\": 749, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.20726782083511353, \"iteration\": 750, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2668062150478363, \"iteration\": 751, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.36514702439308167, \"iteration\": 752, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2903384268283844, \"iteration\": 753, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.22716642916202545, \"iteration\": 754, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2670035660266876, \"iteration\": 755, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.19582299888134003, \"iteration\": 756, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27550187706947327, \"iteration\": 757, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.3316600024700165, \"iteration\": 758, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2348576784133911, \"iteration\": 759, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.20485040545463562, \"iteration\": 760, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.34494489431381226, \"iteration\": 761, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.1956843137741089, \"iteration\": 762, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3399657607078552, \"iteration\": 763, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.25264397263526917, \"iteration\": 764, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.3028120994567871, \"iteration\": 765, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.30752068758010864, \"iteration\": 766, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.32043927907943726, \"iteration\": 767, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2371014952659607, \"iteration\": 768, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.27333882451057434, \"iteration\": 769, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3094460666179657, \"iteration\": 770, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.34017661213874817, \"iteration\": 771, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.30059927701950073, \"iteration\": 772, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2341596782207489, \"iteration\": 773, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.34114983677864075, \"iteration\": 774, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25821545720100403, \"iteration\": 775, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2675592005252838, \"iteration\": 776, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2547454535961151, \"iteration\": 777, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.35160839557647705, \"iteration\": 778, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.3628571629524231, \"iteration\": 779, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.25454577803611755, \"iteration\": 780, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22685247659683228, \"iteration\": 781, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27952051162719727, \"iteration\": 782, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.30146729946136475, \"iteration\": 783, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23813197016716003, \"iteration\": 784, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2404240071773529, \"iteration\": 785, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.28051677346229553, \"iteration\": 786, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27745088934898376, \"iteration\": 787, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28384923934936523, \"iteration\": 788, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 0.36166366934776306, \"iteration\": 789, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27913135290145874, \"iteration\": 790, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30754321813583374, \"iteration\": 791, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2996082901954651, \"iteration\": 792, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2939631938934326, \"iteration\": 793, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29398173093795776, \"iteration\": 794, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.3104756772518158, \"iteration\": 795, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2910727560520172, \"iteration\": 796, \"epoch\": 4}, {\"training_acc\": 0.8125, \"training_loss\": 0.45040327310562134, \"iteration\": 797, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2953305244445801, \"iteration\": 798, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.22077949345111847, \"iteration\": 799, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.23294688761234283, \"iteration\": 800, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29341864585876465, \"iteration\": 801, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.29838827252388, \"iteration\": 802, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3779843747615814, \"iteration\": 803, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.3103122115135193, \"iteration\": 804, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.2998526096343994, \"iteration\": 805, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.3295954763889313, \"iteration\": 806, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.2881726622581482, \"iteration\": 807, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.25950169563293457, \"iteration\": 808, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2760716378688812, \"iteration\": 809, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.3169112205505371, \"iteration\": 810, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.35893166065216064, \"iteration\": 811, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27480435371398926, \"iteration\": 812, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.293485552072525, \"iteration\": 813, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.2831401526927948, \"iteration\": 814, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.255955308675766, \"iteration\": 815, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2741968631744385, \"iteration\": 816, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.26437902450561523, \"iteration\": 817, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25488826632499695, \"iteration\": 818, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3754735589027405, \"iteration\": 819, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23288817703723907, \"iteration\": 820, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3489837646484375, \"iteration\": 821, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3237958550453186, \"iteration\": 822, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 0.33834561705589294, \"iteration\": 823, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.29370734095573425, \"iteration\": 824, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 0.30726295709609985, \"iteration\": 825, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2115442305803299, \"iteration\": 826, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.2928383946418762, \"iteration\": 827, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2883101999759674, \"iteration\": 828, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.24391326308250427, \"iteration\": 829, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21156443655490875, \"iteration\": 830, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22885701060295105, \"iteration\": 831, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2547943890094757, \"iteration\": 832, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.24362188577651978, \"iteration\": 833, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3266303241252899, \"iteration\": 834, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2798146903514862, \"iteration\": 835, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.4278692305088043, \"iteration\": 836, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.17874230444431305, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.24824583530426025, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.19826152920722961, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19404557347297668, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13918331265449524, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.1477496325969696, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.207490935921669, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18752826750278473, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21616750955581665, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15101322531700134, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1581287384033203, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.21616657078266144, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.24494850635528564, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.20285376906394958, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.1842404156923294, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.17318633198738098, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2014205902814865, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12864115834236145, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17811115086078644, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19806447625160217, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15824656188488007, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.25571563839912415, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18982301652431488, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18714550137519836, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.21622434258460999, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2066134661436081, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14568166434764862, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14084941148757935, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.17594371736049652, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18150590360164642, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.18686527013778687, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.20366770029067993, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19140152633190155, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2179928421974182, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20238308608531952, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.1770104467868805, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.2123977541923523, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.2330063283443451, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08895352482795715, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.118466317653656, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.2241676151752472, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15276318788528442, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.22248372435569763, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.121136873960495, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21081654727458954, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.15790703892707825, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.19741806387901306, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2751631736755371, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11359796673059464, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.20335990190505981, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17092815041542053, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2891145944595337, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.15462103486061096, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.23080673813819885, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2568022608757019, \"iteration\": 891, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.20016227662563324, \"iteration\": 892, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1844327598810196, \"iteration\": 893, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.2109454721212387, \"iteration\": 894, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 0.24684207141399384, \"iteration\": 895, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22747573256492615, \"iteration\": 896, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14477398991584778, \"iteration\": 897, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 0.19655205309391022, \"iteration\": 898, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.20223411917686462, \"iteration\": 899, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21678046882152557, \"iteration\": 900, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14158093929290771, \"iteration\": 901, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1866598278284073, \"iteration\": 902, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.14116814732551575, \"iteration\": 903, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.19653786718845367, \"iteration\": 904, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.25547128915786743, \"iteration\": 905, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1400924026966095, \"iteration\": 906, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.26662424206733704, \"iteration\": 907, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.15851077437400818, \"iteration\": 908, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.18873032927513123, \"iteration\": 909, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24039165675640106, \"iteration\": 910, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.20029374957084656, \"iteration\": 911, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.11024769395589828, \"iteration\": 912, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33945298194885254, \"iteration\": 913, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14982452988624573, \"iteration\": 914, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18895351886749268, \"iteration\": 915, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23165710270404816, \"iteration\": 916, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.1671597957611084, \"iteration\": 917, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.17533616721630096, \"iteration\": 918, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.26158401370048523, \"iteration\": 919, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2588767409324646, \"iteration\": 920, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1711873561143875, \"iteration\": 921, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 0.24788925051689148, \"iteration\": 922, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2249365597963333, \"iteration\": 923, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17818811535835266, \"iteration\": 924, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.3039695620536804, \"iteration\": 925, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.19471503794193268, \"iteration\": 926, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1818256378173828, \"iteration\": 927, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18916849792003632, \"iteration\": 928, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.21584750711917877, \"iteration\": 929, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18646752834320068, \"iteration\": 930, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.159504696726799, \"iteration\": 931, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.141005739569664, \"iteration\": 932, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.20364585518836975, \"iteration\": 933, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 0.37870195508003235, \"iteration\": 934, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.20107319951057434, \"iteration\": 935, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.22999393939971924, \"iteration\": 936, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.22233380377292633, \"iteration\": 937, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1837766170501709, \"iteration\": 938, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1800919473171234, \"iteration\": 939, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18953731656074524, \"iteration\": 940, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16600316762924194, \"iteration\": 941, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2365148812532425, \"iteration\": 942, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.2166772186756134, \"iteration\": 943, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.20029717683792114, \"iteration\": 944, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2719062268733978, \"iteration\": 945, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.1765829175710678, \"iteration\": 946, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24945150315761566, \"iteration\": 947, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1757189780473709, \"iteration\": 948, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17624711990356445, \"iteration\": 949, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 0.25583457946777344, \"iteration\": 950, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17224830389022827, \"iteration\": 951, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.16923198103904724, \"iteration\": 952, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24284061789512634, \"iteration\": 953, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.18149757385253906, \"iteration\": 954, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.29872503876686096, \"iteration\": 955, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.20920170843601227, \"iteration\": 956, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.14989987015724182, \"iteration\": 957, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2560274302959442, \"iteration\": 958, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13743075728416443, \"iteration\": 959, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2474970668554306, \"iteration\": 960, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1940963864326477, \"iteration\": 961, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.20643892884254456, \"iteration\": 962, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1591697782278061, \"iteration\": 963, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.22238124907016754, \"iteration\": 964, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2348591387271881, \"iteration\": 965, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.2783659100532532, \"iteration\": 966, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2576213479042053, \"iteration\": 967, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.13941258192062378, \"iteration\": 968, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21221452951431274, \"iteration\": 969, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23475410044193268, \"iteration\": 970, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.20992404222488403, \"iteration\": 971, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 0.30406612157821655, \"iteration\": 972, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.1734662503004074, \"iteration\": 973, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 0.34371864795684814, \"iteration\": 974, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23796474933624268, \"iteration\": 975, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.25854045152664185, \"iteration\": 976, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2236909717321396, \"iteration\": 977, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2855425179004669, \"iteration\": 978, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18911908566951752, \"iteration\": 979, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18731439113616943, \"iteration\": 980, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.18827326595783234, \"iteration\": 981, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21411849558353424, \"iteration\": 982, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.20581470429897308, \"iteration\": 983, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2019505351781845, \"iteration\": 984, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.18898522853851318, \"iteration\": 985, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.28483855724334717, \"iteration\": 986, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21618804335594177, \"iteration\": 987, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.23315086960792542, \"iteration\": 988, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1547727733850479, \"iteration\": 989, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22369304299354553, \"iteration\": 990, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.2012249380350113, \"iteration\": 991, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 0.263162225484848, \"iteration\": 992, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21250633895397186, \"iteration\": 993, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1387854516506195, \"iteration\": 994, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2315506637096405, \"iteration\": 995, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2505981922149658, \"iteration\": 996, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21122847497463226, \"iteration\": 997, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.18894976377487183, \"iteration\": 998, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.22085729241371155, \"iteration\": 999, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2357410043478012, \"iteration\": 1000, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17877764999866486, \"iteration\": 1001, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2301352620124817, \"iteration\": 1002, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13807007670402527, \"iteration\": 1003, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 0.274819940328598, \"iteration\": 1004, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.2657616138458252, \"iteration\": 1005, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.21379560232162476, \"iteration\": 1006, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2438548505306244, \"iteration\": 1007, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14929479360580444, \"iteration\": 1008, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1703222692012787, \"iteration\": 1009, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.1930903196334839, \"iteration\": 1010, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.24618352949619293, \"iteration\": 1011, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.2660079598426819, \"iteration\": 1012, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.15912531316280365, \"iteration\": 1013, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.16938979923725128, \"iteration\": 1014, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.174716517329216, \"iteration\": 1015, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.19317004084587097, \"iteration\": 1016, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.15346944332122803, \"iteration\": 1017, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.18335513770580292, \"iteration\": 1018, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2951713502407074, \"iteration\": 1019, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24361318349838257, \"iteration\": 1020, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16346965730190277, \"iteration\": 1021, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.2598641514778137, \"iteration\": 1022, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 0.2147781103849411, \"iteration\": 1023, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1939525604248047, \"iteration\": 1024, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.22094129025936127, \"iteration\": 1025, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.11930490285158157, \"iteration\": 1026, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.25078824162483215, \"iteration\": 1027, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28543615341186523, \"iteration\": 1028, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18712377548217773, \"iteration\": 1029, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15136705338954926, \"iteration\": 1030, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.24020853638648987, \"iteration\": 1031, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18307125568389893, \"iteration\": 1032, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.21789711713790894, \"iteration\": 1033, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.17829158902168274, \"iteration\": 1034, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.21055004000663757, \"iteration\": 1035, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23734703660011292, \"iteration\": 1036, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.16822747886180878, \"iteration\": 1037, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.22029326856136322, \"iteration\": 1038, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1449824869632721, \"iteration\": 1039, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16594836115837097, \"iteration\": 1040, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.2658514976501465, \"iteration\": 1041, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18010419607162476, \"iteration\": 1042, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 0.20943081378936768, \"iteration\": 1043, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26480650901794434, \"iteration\": 1044, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.08208731561899185, \"iteration\": 1045, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.08670354634523392, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.10581520199775696, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08715210109949112, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09550650417804718, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11868603527545929, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.14790214598178864, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.16974742710590363, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.14028280973434448, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12409724295139313, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1245741918683052, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.14029547572135925, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08686371892690659, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.13718757033348083, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09392757713794708, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09904944151639938, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.13457371294498444, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11811866611242294, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09670975804328918, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.10974448919296265, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.13652931153774261, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07121456414461136, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08903835713863373, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.0820813849568367, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09355693310499191, \"iteration\": 1069, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10978014767169952, \"iteration\": 1070, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.10600215196609497, \"iteration\": 1071, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07749998569488525, \"iteration\": 1072, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.10718663781881332, \"iteration\": 1073, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08949165791273117, \"iteration\": 1074, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11988654732704163, \"iteration\": 1075, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1281878799200058, \"iteration\": 1076, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10439088940620422, \"iteration\": 1077, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09293895214796066, \"iteration\": 1078, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.08092833310365677, \"iteration\": 1079, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1323215514421463, \"iteration\": 1080, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13652849197387695, \"iteration\": 1081, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0998762995004654, \"iteration\": 1082, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.08534453809261322, \"iteration\": 1083, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11193257570266724, \"iteration\": 1084, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06240767985582352, \"iteration\": 1085, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08319251239299774, \"iteration\": 1086, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11584633588790894, \"iteration\": 1087, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.15355384349822998, \"iteration\": 1088, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09965428709983826, \"iteration\": 1089, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1514367163181305, \"iteration\": 1090, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.1049182116985321, \"iteration\": 1091, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0952109545469284, \"iteration\": 1092, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13380764424800873, \"iteration\": 1093, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.060995154082775116, \"iteration\": 1094, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.10020434111356735, \"iteration\": 1095, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11793413013219833, \"iteration\": 1096, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10333973169326782, \"iteration\": 1097, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07557711005210876, \"iteration\": 1098, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08830849081277847, \"iteration\": 1099, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07926305383443832, \"iteration\": 1100, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11671654880046844, \"iteration\": 1101, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.15904518961906433, \"iteration\": 1102, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.08630773425102234, \"iteration\": 1103, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11804431676864624, \"iteration\": 1104, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11115143448114395, \"iteration\": 1105, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07479259371757507, \"iteration\": 1106, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09346283972263336, \"iteration\": 1107, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07620088011026382, \"iteration\": 1108, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11631550639867783, \"iteration\": 1109, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.09171801805496216, \"iteration\": 1110, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12427530437707901, \"iteration\": 1111, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.11703205108642578, \"iteration\": 1112, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12958811223506927, \"iteration\": 1113, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.12015588581562042, \"iteration\": 1114, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11000432074069977, \"iteration\": 1115, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1144837737083435, \"iteration\": 1116, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.05843006819486618, \"iteration\": 1117, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08145789802074432, \"iteration\": 1118, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10107769817113876, \"iteration\": 1119, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07987833023071289, \"iteration\": 1120, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09451515227556229, \"iteration\": 1121, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0753311961889267, \"iteration\": 1122, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06572658568620682, \"iteration\": 1123, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14675740897655487, \"iteration\": 1124, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08390834927558899, \"iteration\": 1125, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08538497984409332, \"iteration\": 1126, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12316256016492844, \"iteration\": 1127, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10324323922395706, \"iteration\": 1128, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12017425149679184, \"iteration\": 1129, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.13558262586593628, \"iteration\": 1130, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17505896091461182, \"iteration\": 1131, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12984542548656464, \"iteration\": 1132, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09928726404905319, \"iteration\": 1133, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11907455325126648, \"iteration\": 1134, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06988959014415741, \"iteration\": 1135, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07306698709726334, \"iteration\": 1136, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.057557426393032074, \"iteration\": 1137, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 0.18451423943042755, \"iteration\": 1138, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08626819401979446, \"iteration\": 1139, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05943308770656586, \"iteration\": 1140, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16992253065109253, \"iteration\": 1141, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.059166114777326584, \"iteration\": 1142, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12251542508602142, \"iteration\": 1143, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09241414070129395, \"iteration\": 1144, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09367474168539047, \"iteration\": 1145, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07605491578578949, \"iteration\": 1146, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05545192211866379, \"iteration\": 1147, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09589041769504547, \"iteration\": 1148, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12221730500459671, \"iteration\": 1149, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.10790663957595825, \"iteration\": 1150, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09937678277492523, \"iteration\": 1151, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11804424226284027, \"iteration\": 1152, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06394299864768982, \"iteration\": 1153, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.19181577861309052, \"iteration\": 1154, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10386958718299866, \"iteration\": 1155, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07097488641738892, \"iteration\": 1156, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.054374221712350845, \"iteration\": 1157, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08334121108055115, \"iteration\": 1158, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.126018226146698, \"iteration\": 1159, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.0965031236410141, \"iteration\": 1160, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.15191315114498138, \"iteration\": 1161, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.061374835669994354, \"iteration\": 1162, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.12204328924417496, \"iteration\": 1163, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.12773962318897247, \"iteration\": 1164, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.15986107289791107, \"iteration\": 1165, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.11884365230798721, \"iteration\": 1166, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11078974604606628, \"iteration\": 1167, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10884125530719757, \"iteration\": 1168, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.2010045200586319, \"iteration\": 1169, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1266874372959137, \"iteration\": 1170, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0759778618812561, \"iteration\": 1171, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09351842105388641, \"iteration\": 1172, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11047019064426422, \"iteration\": 1173, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.14490175247192383, \"iteration\": 1174, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1582428365945816, \"iteration\": 1175, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15348035097122192, \"iteration\": 1176, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12774653732776642, \"iteration\": 1177, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07635204493999481, \"iteration\": 1178, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09158706665039062, \"iteration\": 1179, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08408595621585846, \"iteration\": 1180, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.16972997784614563, \"iteration\": 1181, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.10288161039352417, \"iteration\": 1182, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11749640852212906, \"iteration\": 1183, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.08016397058963776, \"iteration\": 1184, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0721164345741272, \"iteration\": 1185, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.05587984621524811, \"iteration\": 1186, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11448739469051361, \"iteration\": 1187, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08215244114398956, \"iteration\": 1188, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.1211385577917099, \"iteration\": 1189, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.1838892102241516, \"iteration\": 1190, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1185169368982315, \"iteration\": 1191, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.11336133629083633, \"iteration\": 1192, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.1182384043931961, \"iteration\": 1193, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.08494716137647629, \"iteration\": 1194, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07185373455286026, \"iteration\": 1195, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1882697492837906, \"iteration\": 1196, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13261458277702332, \"iteration\": 1197, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06277033686637878, \"iteration\": 1198, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.13515231013298035, \"iteration\": 1199, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 0.18767933547496796, \"iteration\": 1200, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1196284219622612, \"iteration\": 1201, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.13419321179389954, \"iteration\": 1202, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12279213964939117, \"iteration\": 1203, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09961746633052826, \"iteration\": 1204, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11443747580051422, \"iteration\": 1205, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.10517445206642151, \"iteration\": 1206, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07373450696468353, \"iteration\": 1207, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1333128809928894, \"iteration\": 1208, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.13529378175735474, \"iteration\": 1209, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11358451843261719, \"iteration\": 1210, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17901922762393951, \"iteration\": 1211, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08993479609489441, \"iteration\": 1212, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14246876537799835, \"iteration\": 1213, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11478480696678162, \"iteration\": 1214, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11145415902137756, \"iteration\": 1215, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08614145964384079, \"iteration\": 1216, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 0.20996849238872528, \"iteration\": 1217, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.1821742057800293, \"iteration\": 1218, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.14848507940769196, \"iteration\": 1219, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15464410185813904, \"iteration\": 1220, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1494356393814087, \"iteration\": 1221, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1417960673570633, \"iteration\": 1222, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09513580054044724, \"iteration\": 1223, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.08100251853466034, \"iteration\": 1224, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 0.17828570306301117, \"iteration\": 1225, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09576760232448578, \"iteration\": 1226, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11379725486040115, \"iteration\": 1227, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09303498268127441, \"iteration\": 1228, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.12145200371742249, \"iteration\": 1229, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07663512229919434, \"iteration\": 1230, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.17404557764530182, \"iteration\": 1231, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.12547169625759125, \"iteration\": 1232, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06078837811946869, \"iteration\": 1233, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.17299486696720123, \"iteration\": 1234, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.10073089599609375, \"iteration\": 1235, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07953198999166489, \"iteration\": 1236, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.15171894431114197, \"iteration\": 1237, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.11089055985212326, \"iteration\": 1238, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08976338803768158, \"iteration\": 1239, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06919527798891068, \"iteration\": 1240, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.18583884835243225, \"iteration\": 1241, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.18317922949790955, \"iteration\": 1242, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.07987193018198013, \"iteration\": 1243, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.1374165564775467, \"iteration\": 1244, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 0.13829146325588226, \"iteration\": 1245, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.18542444705963135, \"iteration\": 1246, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.15642589330673218, \"iteration\": 1247, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.1542779952287674, \"iteration\": 1248, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15029381215572357, \"iteration\": 1249, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 0.19390538334846497, \"iteration\": 1250, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17520172894001007, \"iteration\": 1251, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 0.13925990462303162, \"iteration\": 1252, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12081611156463623, \"iteration\": 1253, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.13531751930713654, \"iteration\": 1254, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.06877652555704117, \"iteration\": 1255, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.05110044777393341, \"iteration\": 1256, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.044760942459106445, \"iteration\": 1257, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0910303145647049, \"iteration\": 1258, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06175677478313446, \"iteration\": 1259, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05606967583298683, \"iteration\": 1260, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04771222174167633, \"iteration\": 1261, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03783325105905533, \"iteration\": 1262, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02675800770521164, \"iteration\": 1263, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09426312893629074, \"iteration\": 1264, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0418163537979126, \"iteration\": 1265, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03372766822576523, \"iteration\": 1266, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03427821770310402, \"iteration\": 1267, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07917420566082001, \"iteration\": 1268, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.03215557709336281, \"iteration\": 1269, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.0433216355741024, \"iteration\": 1270, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.028187457472085953, \"iteration\": 1271, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.0577855184674263, \"iteration\": 1272, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.049220286309719086, \"iteration\": 1273, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04107087850570679, \"iteration\": 1274, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03648468852043152, \"iteration\": 1275, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022757338359951973, \"iteration\": 1276, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046198975294828415, \"iteration\": 1277, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02550213411450386, \"iteration\": 1278, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03949299827218056, \"iteration\": 1279, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02681741863489151, \"iteration\": 1280, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06061253324151039, \"iteration\": 1281, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02107616700232029, \"iteration\": 1282, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.027572298422455788, \"iteration\": 1283, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.034843236207962036, \"iteration\": 1284, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040517911314964294, \"iteration\": 1285, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024685490876436234, \"iteration\": 1286, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02399098500609398, \"iteration\": 1287, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.035595908761024475, \"iteration\": 1288, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04187634959816933, \"iteration\": 1289, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02862214297056198, \"iteration\": 1290, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02389856055378914, \"iteration\": 1291, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0729132741689682, \"iteration\": 1292, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02508651278913021, \"iteration\": 1293, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07289900630712509, \"iteration\": 1294, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.030253514647483826, \"iteration\": 1295, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09546004235744476, \"iteration\": 1296, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10217681527137756, \"iteration\": 1297, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04462222382426262, \"iteration\": 1298, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.059070222079753876, \"iteration\": 1299, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03159449249505997, \"iteration\": 1300, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02957417070865631, \"iteration\": 1301, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02914920635521412, \"iteration\": 1302, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.031894754618406296, \"iteration\": 1303, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06033884733915329, \"iteration\": 1304, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.048238545656204224, \"iteration\": 1305, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04409440979361534, \"iteration\": 1306, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03748777136206627, \"iteration\": 1307, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.06702850759029388, \"iteration\": 1308, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04008026421070099, \"iteration\": 1309, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.050389088690280914, \"iteration\": 1310, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.051359038800001144, \"iteration\": 1311, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04859442263841629, \"iteration\": 1312, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05826011672616005, \"iteration\": 1313, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02791461907327175, \"iteration\": 1314, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02414494939148426, \"iteration\": 1315, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07617592811584473, \"iteration\": 1316, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07069068402051926, \"iteration\": 1317, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0337623655796051, \"iteration\": 1318, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02373252995312214, \"iteration\": 1319, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04362335428595543, \"iteration\": 1320, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.036069560796022415, \"iteration\": 1321, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054948121309280396, \"iteration\": 1322, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07646495848894119, \"iteration\": 1323, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05489173159003258, \"iteration\": 1324, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.043145254254341125, \"iteration\": 1325, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.056083790957927704, \"iteration\": 1326, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02232719585299492, \"iteration\": 1327, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039274029433727264, \"iteration\": 1328, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02187519147992134, \"iteration\": 1329, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03545328229665756, \"iteration\": 1330, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01877167634665966, \"iteration\": 1331, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07434040307998657, \"iteration\": 1332, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.053442999720573425, \"iteration\": 1333, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0740065798163414, \"iteration\": 1334, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04532121494412422, \"iteration\": 1335, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0769457072019577, \"iteration\": 1336, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07129919528961182, \"iteration\": 1337, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.042131874710321426, \"iteration\": 1338, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.021316589787602425, \"iteration\": 1339, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.051866963505744934, \"iteration\": 1340, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05359653756022453, \"iteration\": 1341, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.033819977194070816, \"iteration\": 1342, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03491269797086716, \"iteration\": 1343, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.06632241606712341, \"iteration\": 1344, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.06275872141122818, \"iteration\": 1345, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02441910281777382, \"iteration\": 1346, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.023758992552757263, \"iteration\": 1347, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01827266998589039, \"iteration\": 1348, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05144421383738518, \"iteration\": 1349, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.042785391211509705, \"iteration\": 1350, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04292932152748108, \"iteration\": 1351, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03285042941570282, \"iteration\": 1352, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03645436093211174, \"iteration\": 1353, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.059025008231401443, \"iteration\": 1354, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0453866682946682, \"iteration\": 1355, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07104455679655075, \"iteration\": 1356, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039019957184791565, \"iteration\": 1357, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01395295187830925, \"iteration\": 1358, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02446751855313778, \"iteration\": 1359, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03628179058432579, \"iteration\": 1360, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03466864675283432, \"iteration\": 1361, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.05066400021314621, \"iteration\": 1362, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.06298716366291046, \"iteration\": 1363, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0496487095952034, \"iteration\": 1364, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05993691086769104, \"iteration\": 1365, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.035417571663856506, \"iteration\": 1366, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.06011594459414482, \"iteration\": 1367, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0968427062034607, \"iteration\": 1368, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.039517395198345184, \"iteration\": 1369, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.04734335094690323, \"iteration\": 1370, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05664948746562004, \"iteration\": 1371, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02158806473016739, \"iteration\": 1372, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0524471178650856, \"iteration\": 1373, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04339049011468887, \"iteration\": 1374, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024253947660326958, \"iteration\": 1375, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.026922598481178284, \"iteration\": 1376, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.047189369797706604, \"iteration\": 1377, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04385353624820709, \"iteration\": 1378, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04601118713617325, \"iteration\": 1379, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03162599727511406, \"iteration\": 1380, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.027528153732419014, \"iteration\": 1381, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0582607202231884, \"iteration\": 1382, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02904120273888111, \"iteration\": 1383, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.034384164959192276, \"iteration\": 1384, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.020689068362116814, \"iteration\": 1385, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.08449902385473251, \"iteration\": 1386, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.056177616119384766, \"iteration\": 1387, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06319062411785126, \"iteration\": 1388, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.053372450172901154, \"iteration\": 1389, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.021729376167058945, \"iteration\": 1390, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04963116720318794, \"iteration\": 1391, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02656499482691288, \"iteration\": 1392, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.027537643909454346, \"iteration\": 1393, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.039065103977918625, \"iteration\": 1394, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02723640576004982, \"iteration\": 1395, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024813231080770493, \"iteration\": 1396, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04873527213931084, \"iteration\": 1397, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07360782474279404, \"iteration\": 1398, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05334100127220154, \"iteration\": 1399, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.05206986889243126, \"iteration\": 1400, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.037146735936403275, \"iteration\": 1401, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04186420887708664, \"iteration\": 1402, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.038498856127262115, \"iteration\": 1403, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05483738332986832, \"iteration\": 1404, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.019782427698373795, \"iteration\": 1405, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04168034344911575, \"iteration\": 1406, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.060241829603910446, \"iteration\": 1407, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03259741887450218, \"iteration\": 1408, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03385499119758606, \"iteration\": 1409, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.038636595010757446, \"iteration\": 1410, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03236427903175354, \"iteration\": 1411, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.0564207099378109, \"iteration\": 1412, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04581921920180321, \"iteration\": 1413, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029242459684610367, \"iteration\": 1414, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029203996062278748, \"iteration\": 1415, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.023348726332187653, \"iteration\": 1416, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.029619157314300537, \"iteration\": 1417, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03927956894040108, \"iteration\": 1418, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04850877821445465, \"iteration\": 1419, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022259417921304703, \"iteration\": 1420, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02367817610502243, \"iteration\": 1421, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03936651349067688, \"iteration\": 1422, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.062309056520462036, \"iteration\": 1423, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.021325426176190376, \"iteration\": 1424, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03878575563430786, \"iteration\": 1425, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.057538799941539764, \"iteration\": 1426, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.043766383081674576, \"iteration\": 1427, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.059950508177280426, \"iteration\": 1428, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04041512683033943, \"iteration\": 1429, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05319037660956383, \"iteration\": 1430, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07274939119815826, \"iteration\": 1431, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.060645878314971924, \"iteration\": 1432, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.05785887688398361, \"iteration\": 1433, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.028692923486232758, \"iteration\": 1434, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06967776268720627, \"iteration\": 1435, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03666435927152634, \"iteration\": 1436, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07730863988399506, \"iteration\": 1437, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04869689419865608, \"iteration\": 1438, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.11553017795085907, \"iteration\": 1439, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01918594166636467, \"iteration\": 1440, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03602782264351845, \"iteration\": 1441, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.07981041818857193, \"iteration\": 1442, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.05624961480498314, \"iteration\": 1443, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02121431939303875, \"iteration\": 1444, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.026200182735919952, \"iteration\": 1445, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03428024798631668, \"iteration\": 1446, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04956187307834625, \"iteration\": 1447, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.025797123089432716, \"iteration\": 1448, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02936433255672455, \"iteration\": 1449, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04948960244655609, \"iteration\": 1450, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028083590790629387, \"iteration\": 1451, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.03728500381112099, \"iteration\": 1452, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06465107947587967, \"iteration\": 1453, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02767959237098694, \"iteration\": 1454, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01866033300757408, \"iteration\": 1455, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.026808835566043854, \"iteration\": 1456, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.041677460074424744, \"iteration\": 1457, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.021370302885770798, \"iteration\": 1458, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028551481664180756, \"iteration\": 1459, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.030671296641230583, \"iteration\": 1460, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.04600616544485092, \"iteration\": 1461, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02909521944820881, \"iteration\": 1462, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016345111653208733, \"iteration\": 1463, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009833093732595444, \"iteration\": 1464, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012110535055398941, \"iteration\": 1465, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012953972443938255, \"iteration\": 1466, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012292907573282719, \"iteration\": 1467, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02425161376595497, \"iteration\": 1468, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008046841248869896, \"iteration\": 1469, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 0.029531273990869522, \"iteration\": 1470, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.019189879298210144, \"iteration\": 1471, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.019591351971030235, \"iteration\": 1472, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01821650192141533, \"iteration\": 1473, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0249473936855793, \"iteration\": 1474, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.017946574836969376, \"iteration\": 1475, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01868104189634323, \"iteration\": 1476, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01799638383090496, \"iteration\": 1477, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016417328268289566, \"iteration\": 1478, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01310319360345602, \"iteration\": 1479, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009346434846520424, \"iteration\": 1480, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006446946412324905, \"iteration\": 1481, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004689573775976896, \"iteration\": 1482, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011400911957025528, \"iteration\": 1483, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013677037321031094, \"iteration\": 1484, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026310985907912254, \"iteration\": 1485, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009042995050549507, \"iteration\": 1486, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03441809117794037, \"iteration\": 1487, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012927084229886532, \"iteration\": 1488, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006976197473704815, \"iteration\": 1489, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0059911212883889675, \"iteration\": 1490, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011633835732936859, \"iteration\": 1491, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010548301041126251, \"iteration\": 1492, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007413725834339857, \"iteration\": 1493, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016302408650517464, \"iteration\": 1494, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009337074123322964, \"iteration\": 1495, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009301658719778061, \"iteration\": 1496, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.017901582643389702, \"iteration\": 1497, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014065004885196686, \"iteration\": 1498, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010285771451890469, \"iteration\": 1499, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009821797721087933, \"iteration\": 1500, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 0.03989589959383011, \"iteration\": 1501, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01226175669580698, \"iteration\": 1502, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014233492314815521, \"iteration\": 1503, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012235620059072971, \"iteration\": 1504, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006881938315927982, \"iteration\": 1505, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007749245036393404, \"iteration\": 1506, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012970066629350185, \"iteration\": 1507, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016460465267300606, \"iteration\": 1508, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011783759109675884, \"iteration\": 1509, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0069879391230642796, \"iteration\": 1510, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012718040496110916, \"iteration\": 1511, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010203578509390354, \"iteration\": 1512, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00417918898165226, \"iteration\": 1513, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023321853950619698, \"iteration\": 1514, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007682777475565672, \"iteration\": 1515, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013979755342006683, \"iteration\": 1516, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.034614305943250656, \"iteration\": 1517, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0097054373472929, \"iteration\": 1518, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01566356234252453, \"iteration\": 1519, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023140158504247665, \"iteration\": 1520, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009805859066545963, \"iteration\": 1521, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011404969729483128, \"iteration\": 1522, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012495896779000759, \"iteration\": 1523, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009090847335755825, \"iteration\": 1524, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02873660996556282, \"iteration\": 1525, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0068875877186656, \"iteration\": 1526, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007298481650650501, \"iteration\": 1527, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00862727127969265, \"iteration\": 1528, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011484692804515362, \"iteration\": 1529, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011455874890089035, \"iteration\": 1530, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013207366690039635, \"iteration\": 1531, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.015245223417878151, \"iteration\": 1532, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005702944938093424, \"iteration\": 1533, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009363927878439426, \"iteration\": 1534, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006469728425145149, \"iteration\": 1535, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009353257715702057, \"iteration\": 1536, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007982760667800903, \"iteration\": 1537, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009907161816954613, \"iteration\": 1538, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028923168778419495, \"iteration\": 1539, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008954940363764763, \"iteration\": 1540, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00929296389222145, \"iteration\": 1541, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009474038146436214, \"iteration\": 1542, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01782911643385887, \"iteration\": 1543, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006883698515594006, \"iteration\": 1544, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006008516065776348, \"iteration\": 1545, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007118647452443838, \"iteration\": 1546, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0065246811136603355, \"iteration\": 1547, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004805075936019421, \"iteration\": 1548, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005427081137895584, \"iteration\": 1549, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010385064408183098, \"iteration\": 1550, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014356765896081924, \"iteration\": 1551, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012352966703474522, \"iteration\": 1552, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016908833757042885, \"iteration\": 1553, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.015043213963508606, \"iteration\": 1554, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006167966406792402, \"iteration\": 1555, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004358758218586445, \"iteration\": 1556, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01443677581846714, \"iteration\": 1557, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014250670559704304, \"iteration\": 1558, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011142974719405174, \"iteration\": 1559, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011813376098871231, \"iteration\": 1560, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013346055522561073, \"iteration\": 1561, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013743860647082329, \"iteration\": 1562, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007836977019906044, \"iteration\": 1563, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007156242150813341, \"iteration\": 1564, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.015193154104053974, \"iteration\": 1565, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010890856385231018, \"iteration\": 1566, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014485204592347145, \"iteration\": 1567, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00931495800614357, \"iteration\": 1568, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005945001263171434, \"iteration\": 1569, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005513534881174564, \"iteration\": 1570, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029104266315698624, \"iteration\": 1571, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0062156543135643005, \"iteration\": 1572, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016866255551576614, \"iteration\": 1573, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008233041502535343, \"iteration\": 1574, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016616489738225937, \"iteration\": 1575, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006565839983522892, \"iteration\": 1576, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007814865559339523, \"iteration\": 1577, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006433381699025631, \"iteration\": 1578, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008967711590230465, \"iteration\": 1579, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011340709403157234, \"iteration\": 1580, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008297336287796497, \"iteration\": 1581, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03818710148334503, \"iteration\": 1582, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.041497815400362015, \"iteration\": 1583, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013031424023211002, \"iteration\": 1584, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016690218821167946, \"iteration\": 1585, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011423757299780846, \"iteration\": 1586, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009725486859679222, \"iteration\": 1587, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00811214093118906, \"iteration\": 1588, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009866400621831417, \"iteration\": 1589, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012594335712492466, \"iteration\": 1590, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.017902156338095665, \"iteration\": 1591, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012719692662358284, \"iteration\": 1592, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012409152463078499, \"iteration\": 1593, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.015965338796377182, \"iteration\": 1594, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012385630048811436, \"iteration\": 1595, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.03103933297097683, \"iteration\": 1596, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004783678334206343, \"iteration\": 1597, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007319105789065361, \"iteration\": 1598, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008145482279360294, \"iteration\": 1599, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01542041264474392, \"iteration\": 1600, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01019168458878994, \"iteration\": 1601, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005325079895555973, \"iteration\": 1602, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004737622570246458, \"iteration\": 1603, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04861527681350708, \"iteration\": 1604, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006543280556797981, \"iteration\": 1605, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.015774093568325043, \"iteration\": 1606, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00582221569493413, \"iteration\": 1607, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009338775649666786, \"iteration\": 1608, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03222621604800224, \"iteration\": 1609, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012533810921013355, \"iteration\": 1610, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016958724707365036, \"iteration\": 1611, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011252310127019882, \"iteration\": 1612, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010588109493255615, \"iteration\": 1613, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00759105896577239, \"iteration\": 1614, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007307733409106731, \"iteration\": 1615, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008169161155819893, \"iteration\": 1616, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0075884233228862286, \"iteration\": 1617, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009885166771709919, \"iteration\": 1618, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005685428623110056, \"iteration\": 1619, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007505607325583696, \"iteration\": 1620, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014460032805800438, \"iteration\": 1621, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006699577905237675, \"iteration\": 1622, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018950609490275383, \"iteration\": 1623, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008290035650134087, \"iteration\": 1624, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014066419564187527, \"iteration\": 1625, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00793365016579628, \"iteration\": 1626, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014214897528290749, \"iteration\": 1627, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008744053542613983, \"iteration\": 1628, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.017269162461161613, \"iteration\": 1629, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007768750656396151, \"iteration\": 1630, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0044601475819945335, \"iteration\": 1631, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004892242606729269, \"iteration\": 1632, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0071183484978973866, \"iteration\": 1633, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019353052601218224, \"iteration\": 1634, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01640816405415535, \"iteration\": 1635, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.010325415059924126, \"iteration\": 1636, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008746675215661526, \"iteration\": 1637, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0050562163814902306, \"iteration\": 1638, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021016592159867287, \"iteration\": 1639, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008140413090586662, \"iteration\": 1640, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014309782534837723, \"iteration\": 1641, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011998658999800682, \"iteration\": 1642, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005939312279224396, \"iteration\": 1643, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005733324680477381, \"iteration\": 1644, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004405127838253975, \"iteration\": 1645, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03724232688546181, \"iteration\": 1646, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01054692454636097, \"iteration\": 1647, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00882173515856266, \"iteration\": 1648, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008138544857501984, \"iteration\": 1649, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01271765399724245, \"iteration\": 1650, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0183493010699749, \"iteration\": 1651, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 0.02473331429064274, \"iteration\": 1652, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006848563905805349, \"iteration\": 1653, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012479947879910469, \"iteration\": 1654, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.014844957739114761, \"iteration\": 1655, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005297719966620207, \"iteration\": 1656, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.011950288899242878, \"iteration\": 1657, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.02426830865442753, \"iteration\": 1658, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.030682135373353958, \"iteration\": 1659, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01765255816280842, \"iteration\": 1660, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007547587156295776, \"iteration\": 1661, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00702747842296958, \"iteration\": 1662, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.036051761358976364, \"iteration\": 1663, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.02122608758509159, \"iteration\": 1664, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009175225161015987, \"iteration\": 1665, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012646391987800598, \"iteration\": 1666, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04121600091457367, \"iteration\": 1667, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.012372629716992378, \"iteration\": 1668, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01861400529742241, \"iteration\": 1669, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008160277269780636, \"iteration\": 1670, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007519540376961231, \"iteration\": 1671, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.014742947183549404, \"iteration\": 1672, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004511770326644182, \"iteration\": 1673, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005461086053401232, \"iteration\": 1674, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0039793807081878185, \"iteration\": 1675, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003388844896107912, \"iteration\": 1676, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0034759107511490583, \"iteration\": 1677, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04264025762677193, \"iteration\": 1678, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0032451804727315903, \"iteration\": 1679, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0038180011324584484, \"iteration\": 1680, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004032508470118046, \"iteration\": 1681, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003944891504943371, \"iteration\": 1682, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0030458588153123856, \"iteration\": 1683, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0030106238555163145, \"iteration\": 1684, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007991507649421692, \"iteration\": 1685, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004209623206406832, \"iteration\": 1686, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0039044120348989964, \"iteration\": 1687, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003695998340845108, \"iteration\": 1688, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003408950986340642, \"iteration\": 1689, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0031733037903904915, \"iteration\": 1690, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.010867608711123466, \"iteration\": 1691, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0028995489701628685, \"iteration\": 1692, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005238810088485479, \"iteration\": 1693, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029507747385650873, \"iteration\": 1694, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001879533869214356, \"iteration\": 1695, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0041083707474172115, \"iteration\": 1696, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00309292902238667, \"iteration\": 1697, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004071807488799095, \"iteration\": 1698, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002723119920119643, \"iteration\": 1699, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0046313246712088585, \"iteration\": 1700, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00374784367159009, \"iteration\": 1701, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002624496351927519, \"iteration\": 1702, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0033197938464581966, \"iteration\": 1703, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0038627488538622856, \"iteration\": 1704, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001936660846695304, \"iteration\": 1705, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0046932329423725605, \"iteration\": 1706, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0051039112731814384, \"iteration\": 1707, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004308376926928759, \"iteration\": 1708, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029809284023940563, \"iteration\": 1709, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020580568816512823, \"iteration\": 1710, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001944378949701786, \"iteration\": 1711, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00460317637771368, \"iteration\": 1712, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02597951702773571, \"iteration\": 1713, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004590910393744707, \"iteration\": 1714, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004186594393104315, \"iteration\": 1715, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04861999675631523, \"iteration\": 1716, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0035208379849791527, \"iteration\": 1717, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0031146828550845385, \"iteration\": 1718, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006388980429619551, \"iteration\": 1719, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0026748785749077797, \"iteration\": 1720, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003110615536570549, \"iteration\": 1721, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005036490503698587, \"iteration\": 1722, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007104702293872833, \"iteration\": 1723, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004837437067180872, \"iteration\": 1724, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003609765786677599, \"iteration\": 1725, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005321939941495657, \"iteration\": 1726, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007834733463823795, \"iteration\": 1727, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00341753289103508, \"iteration\": 1728, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006259669084101915, \"iteration\": 1729, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0036529419012367725, \"iteration\": 1730, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008973093703389168, \"iteration\": 1731, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0032063566613942385, \"iteration\": 1732, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021876185201108456, \"iteration\": 1733, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020315004512667656, \"iteration\": 1734, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017272088443860412, \"iteration\": 1735, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0030929907225072384, \"iteration\": 1736, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006583180278539658, \"iteration\": 1737, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00215194677002728, \"iteration\": 1738, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021372607443481684, \"iteration\": 1739, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019471824634820223, \"iteration\": 1740, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0031435778364539146, \"iteration\": 1741, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0036374309565871954, \"iteration\": 1742, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0023557620588690042, \"iteration\": 1743, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029021690133959055, \"iteration\": 1744, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0030395716894418, \"iteration\": 1745, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025279249530285597, \"iteration\": 1746, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014820153592154384, \"iteration\": 1747, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015294885961338878, \"iteration\": 1748, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029812052845954895, \"iteration\": 1749, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029427004046738148, \"iteration\": 1750, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0032068612053990364, \"iteration\": 1751, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004316229373216629, \"iteration\": 1752, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002856754232198, \"iteration\": 1753, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003710803808644414, \"iteration\": 1754, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002162580844014883, \"iteration\": 1755, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0043345848098397255, \"iteration\": 1756, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019496351014822721, \"iteration\": 1757, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015603381907567382, \"iteration\": 1758, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006749526597559452, \"iteration\": 1759, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0050740777514874935, \"iteration\": 1760, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.009683093056082726, \"iteration\": 1761, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017857407219707966, \"iteration\": 1762, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002602183725684881, \"iteration\": 1763, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004321501590311527, \"iteration\": 1764, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004609066992998123, \"iteration\": 1765, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016914092702791095, \"iteration\": 1766, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003825967665761709, \"iteration\": 1767, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025525877717882395, \"iteration\": 1768, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0038864975795149803, \"iteration\": 1769, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005637065041810274, \"iteration\": 1770, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025214862544089556, \"iteration\": 1771, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015639481134712696, \"iteration\": 1772, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004362394101917744, \"iteration\": 1773, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003416489576920867, \"iteration\": 1774, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003985562361776829, \"iteration\": 1775, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029824578668922186, \"iteration\": 1776, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021195760928094387, \"iteration\": 1777, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004209739621728659, \"iteration\": 1778, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018883703742176294, \"iteration\": 1779, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0042135282419621944, \"iteration\": 1780, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004141034558415413, \"iteration\": 1781, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0023165084421634674, \"iteration\": 1782, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021504778414964676, \"iteration\": 1783, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0033372030593454838, \"iteration\": 1784, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0027591255493462086, \"iteration\": 1785, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002261555753648281, \"iteration\": 1786, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002082409104332328, \"iteration\": 1787, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003332981839776039, \"iteration\": 1788, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001889218925498426, \"iteration\": 1789, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013621249236166477, \"iteration\": 1790, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003766973502933979, \"iteration\": 1791, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029166708700358868, \"iteration\": 1792, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003917547408491373, \"iteration\": 1793, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00367550365626812, \"iteration\": 1794, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015342974802479148, \"iteration\": 1795, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008207151666283607, \"iteration\": 1796, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001829091808758676, \"iteration\": 1797, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006377808749675751, \"iteration\": 1798, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020881064236164093, \"iteration\": 1799, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015345020219683647, \"iteration\": 1800, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025710437912493944, \"iteration\": 1801, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011712495470419526, \"iteration\": 1802, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0028963671065866947, \"iteration\": 1803, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0026320703327655792, \"iteration\": 1804, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0023813219740986824, \"iteration\": 1805, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001520740333944559, \"iteration\": 1806, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002504106843844056, \"iteration\": 1807, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001928867306560278, \"iteration\": 1808, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004465604666620493, \"iteration\": 1809, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0023451722227036953, \"iteration\": 1810, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002310320967808366, \"iteration\": 1811, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001967435237020254, \"iteration\": 1812, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021792759653180838, \"iteration\": 1813, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00279654236510396, \"iteration\": 1814, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002638820093125105, \"iteration\": 1815, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017286234069615602, \"iteration\": 1816, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01993647962808609, \"iteration\": 1817, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.009879011660814285, \"iteration\": 1818, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016765029868111014, \"iteration\": 1819, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019122770754620433, \"iteration\": 1820, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029438212513923645, \"iteration\": 1821, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0023967414163053036, \"iteration\": 1822, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010447794338688254, \"iteration\": 1823, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001768134767189622, \"iteration\": 1824, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0017106614541262388, \"iteration\": 1825, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003023706376552582, \"iteration\": 1826, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0022849920205771923, \"iteration\": 1827, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004390672314912081, \"iteration\": 1828, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001359781832434237, \"iteration\": 1829, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019886705558747053, \"iteration\": 1830, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0034505848307162523, \"iteration\": 1831, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006573494989424944, \"iteration\": 1832, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.007152937352657318, \"iteration\": 1833, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0046591851860284805, \"iteration\": 1834, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019959802739322186, \"iteration\": 1835, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001479198457673192, \"iteration\": 1836, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03593752905726433, \"iteration\": 1837, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020706213545054197, \"iteration\": 1838, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002642572857439518, \"iteration\": 1839, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0086622079834342, \"iteration\": 1840, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0026250730734318495, \"iteration\": 1841, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021295633632689714, \"iteration\": 1842, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018969390075653791, \"iteration\": 1843, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005565831903368235, \"iteration\": 1844, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015989909879863262, \"iteration\": 1845, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011949363397434354, \"iteration\": 1846, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003075886983424425, \"iteration\": 1847, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0024688486009836197, \"iteration\": 1848, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0035432628355920315, \"iteration\": 1849, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018501533195376396, \"iteration\": 1850, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0021063503809273243, \"iteration\": 1851, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002988894237205386, \"iteration\": 1852, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0035190186463296413, \"iteration\": 1853, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015131542459130287, \"iteration\": 1854, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011831459123641253, \"iteration\": 1855, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.006122257560491562, \"iteration\": 1856, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002574677811935544, \"iteration\": 1857, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0026498730294406414, \"iteration\": 1858, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005348695907741785, \"iteration\": 1859, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013040294870734215, \"iteration\": 1860, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020809401758015156, \"iteration\": 1861, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0030298291239887476, \"iteration\": 1862, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014085039729252458, \"iteration\": 1863, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003149505704641342, \"iteration\": 1864, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0033975651022046804, \"iteration\": 1865, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002165365032851696, \"iteration\": 1866, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0025828140787780285, \"iteration\": 1867, \"epoch\": 9}, {\"training_acc\": 0.984375, \"training_loss\": 0.050639454275369644, \"iteration\": 1868, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0020006131380796432, \"iteration\": 1869, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029429260175675154, \"iteration\": 1870, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005403141491115093, \"iteration\": 1871, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002177551854401827, \"iteration\": 1872, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002754536923021078, \"iteration\": 1873, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0029291126411408186, \"iteration\": 1874, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0033232246059924364, \"iteration\": 1875, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002343897707760334, \"iteration\": 1876, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0026064920239150524, \"iteration\": 1877, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018857662798836827, \"iteration\": 1878, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0022700238041579723, \"iteration\": 1879, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0018795173382386565, \"iteration\": 1880, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019806250929832458, \"iteration\": 1881, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0019192713079974055, \"iteration\": 1882, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018853074871003628, \"iteration\": 1883, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014741106424480677, \"iteration\": 1884, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0020129033364355564, \"iteration\": 1885, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002029039431363344, \"iteration\": 1886, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012624183436855674, \"iteration\": 1887, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013959072530269623, \"iteration\": 1888, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015467749908566475, \"iteration\": 1889, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001042586169205606, \"iteration\": 1890, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009062405442818999, \"iteration\": 1891, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012750515015795827, \"iteration\": 1892, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008051394252106547, \"iteration\": 1893, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011757311876863241, \"iteration\": 1894, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012132762931287289, \"iteration\": 1895, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001907839672639966, \"iteration\": 1896, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010554128093644977, \"iteration\": 1897, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011978487018495798, \"iteration\": 1898, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008861660026013851, \"iteration\": 1899, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009746277937665582, \"iteration\": 1900, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000857899896800518, \"iteration\": 1901, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000968976819422096, \"iteration\": 1902, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016020380426198244, \"iteration\": 1903, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012249444844201207, \"iteration\": 1904, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012943685287609696, \"iteration\": 1905, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015595346922054887, \"iteration\": 1906, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009760515531525016, \"iteration\": 1907, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014995357487350702, \"iteration\": 1908, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013127400306984782, \"iteration\": 1909, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007672632345929742, \"iteration\": 1910, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017700977623462677, \"iteration\": 1911, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010783732868731022, \"iteration\": 1912, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008596036350354552, \"iteration\": 1913, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010484688682481647, \"iteration\": 1914, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013337568379938602, \"iteration\": 1915, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001382301445119083, \"iteration\": 1916, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001012949738651514, \"iteration\": 1917, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0033956803381443024, \"iteration\": 1918, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010156307835131884, \"iteration\": 1919, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007031594286672771, \"iteration\": 1920, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009882613085210323, \"iteration\": 1921, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002374756382778287, \"iteration\": 1922, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009710567537695169, \"iteration\": 1923, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009277756907977164, \"iteration\": 1924, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007726791081950068, \"iteration\": 1925, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000881203799508512, \"iteration\": 1926, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011928756721317768, \"iteration\": 1927, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011664561461657286, \"iteration\": 1928, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001155573409050703, \"iteration\": 1929, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008013970218598843, \"iteration\": 1930, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007084216922521591, \"iteration\": 1931, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008634479017928243, \"iteration\": 1932, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008680402534082532, \"iteration\": 1933, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014831471489742398, \"iteration\": 1934, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010389805538579822, \"iteration\": 1935, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010348281357437372, \"iteration\": 1936, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001698304433375597, \"iteration\": 1937, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017028526635840535, \"iteration\": 1938, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008932203054428101, \"iteration\": 1939, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010269677732139826, \"iteration\": 1940, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011966442689299583, \"iteration\": 1941, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009500895394012332, \"iteration\": 1942, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044259946793317795, \"iteration\": 1943, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001350738457404077, \"iteration\": 1944, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006590814446099102, \"iteration\": 1945, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009900396689772606, \"iteration\": 1946, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010411553084850311, \"iteration\": 1947, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011128203477710485, \"iteration\": 1948, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012877975823357701, \"iteration\": 1949, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009183749789372087, \"iteration\": 1950, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014977867249399424, \"iteration\": 1951, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007176076178438962, \"iteration\": 1952, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012339736567810178, \"iteration\": 1953, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009763252455741167, \"iteration\": 1954, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016633595805615187, \"iteration\": 1955, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009052536333911121, \"iteration\": 1956, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012546752113848925, \"iteration\": 1957, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001058912486769259, \"iteration\": 1958, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008325602393597364, \"iteration\": 1959, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012821187265217304, \"iteration\": 1960, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013553828466683626, \"iteration\": 1961, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011592673836275935, \"iteration\": 1962, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009571705013513565, \"iteration\": 1963, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001213797484524548, \"iteration\": 1964, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013086581602692604, \"iteration\": 1965, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018635144224390388, \"iteration\": 1966, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023899445310235023, \"iteration\": 1967, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017423061653971672, \"iteration\": 1968, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009155155275948346, \"iteration\": 1969, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013072710717096925, \"iteration\": 1970, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009624855010770261, \"iteration\": 1971, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015945651102811098, \"iteration\": 1972, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012330282479524612, \"iteration\": 1973, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015345123829320073, \"iteration\": 1974, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013464648509398103, \"iteration\": 1975, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007243038853630424, \"iteration\": 1976, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.013717800378799438, \"iteration\": 1977, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008849897421896458, \"iteration\": 1978, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001002977485768497, \"iteration\": 1979, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0017155117820948362, \"iteration\": 1980, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012493632966652513, \"iteration\": 1981, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012461903970688581, \"iteration\": 1982, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013678934192284942, \"iteration\": 1983, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.007054248824715614, \"iteration\": 1984, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008947111200541258, \"iteration\": 1985, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003700978821143508, \"iteration\": 1986, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001353378058411181, \"iteration\": 1987, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001249366207048297, \"iteration\": 1988, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015970190288498998, \"iteration\": 1989, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015774276107549667, \"iteration\": 1990, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00290705356746912, \"iteration\": 1991, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010265447199344635, \"iteration\": 1992, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.006978771183639765, \"iteration\": 1993, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001450505224056542, \"iteration\": 1994, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001541447127237916, \"iteration\": 1995, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010150570888072252, \"iteration\": 1996, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00131393619813025, \"iteration\": 1997, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013865219661965966, \"iteration\": 1998, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013358754804357886, \"iteration\": 1999, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011082355631515384, \"iteration\": 2000, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008940392872318625, \"iteration\": 2001, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008885013521648943, \"iteration\": 2002, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009820699924603105, \"iteration\": 2003, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005865868180990219, \"iteration\": 2004, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0020832770969718695, \"iteration\": 2005, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013062749058008194, \"iteration\": 2006, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001650697784498334, \"iteration\": 2007, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010572831379249692, \"iteration\": 2008, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001324004027992487, \"iteration\": 2009, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008097109966911376, \"iteration\": 2010, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010116430930793285, \"iteration\": 2011, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006267008138820529, \"iteration\": 2012, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005946016754023731, \"iteration\": 2013, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007496827165596187, \"iteration\": 2014, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008117342949844897, \"iteration\": 2015, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012778446543961763, \"iteration\": 2016, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001069457270205021, \"iteration\": 2017, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013889926485717297, \"iteration\": 2018, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008246120996773243, \"iteration\": 2019, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004819764290004969, \"iteration\": 2020, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011482259724289179, \"iteration\": 2021, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008905163849703968, \"iteration\": 2022, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001355221844278276, \"iteration\": 2023, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012289986480027437, \"iteration\": 2024, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016539000207558274, \"iteration\": 2025, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018824131693691015, \"iteration\": 2026, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009446945041418076, \"iteration\": 2027, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011698262533172965, \"iteration\": 2028, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009810453047975898, \"iteration\": 2029, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001047800062224269, \"iteration\": 2030, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00137512874789536, \"iteration\": 2031, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007570765446871519, \"iteration\": 2032, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008330976124852896, \"iteration\": 2033, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009519411250948906, \"iteration\": 2034, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008593301172368228, \"iteration\": 2035, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006832334911450744, \"iteration\": 2036, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011583003215491772, \"iteration\": 2037, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013070732820779085, \"iteration\": 2038, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009294630726799369, \"iteration\": 2039, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007695374079048634, \"iteration\": 2040, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006333598284982145, \"iteration\": 2041, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009277394274249673, \"iteration\": 2042, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007755272090435028, \"iteration\": 2043, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001322261057794094, \"iteration\": 2044, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010832601692527533, \"iteration\": 2045, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008543411968275905, \"iteration\": 2046, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0012590050464496017, \"iteration\": 2047, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009573926799930632, \"iteration\": 2048, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011852143798023462, \"iteration\": 2049, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008774287416599691, \"iteration\": 2050, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010506322141736746, \"iteration\": 2051, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008993877563625574, \"iteration\": 2052, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011238557053729892, \"iteration\": 2053, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014544620644301176, \"iteration\": 2054, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011176317930221558, \"iteration\": 2055, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014661329332739115, \"iteration\": 2056, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009793376084417105, \"iteration\": 2057, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01095613744109869, \"iteration\": 2058, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008499395335093141, \"iteration\": 2059, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011079603573307395, \"iteration\": 2060, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007314164540730417, \"iteration\": 2061, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008948089089244604, \"iteration\": 2062, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007808257942087948, \"iteration\": 2063, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000959539960604161, \"iteration\": 2064, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009112310945056379, \"iteration\": 2065, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008383590611629188, \"iteration\": 2066, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011022386606782675, \"iteration\": 2067, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008280837791971862, \"iteration\": 2068, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005723217036575079, \"iteration\": 2069, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011372520821169019, \"iteration\": 2070, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008342255023308098, \"iteration\": 2071, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001074845902621746, \"iteration\": 2072, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005859498050995171, \"iteration\": 2073, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016195019707083702, \"iteration\": 2074, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005989149212837219, \"iteration\": 2075, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001087019219994545, \"iteration\": 2076, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013638141099363565, \"iteration\": 2077, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006891528610140085, \"iteration\": 2078, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008563892915844917, \"iteration\": 2079, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011021076934412122, \"iteration\": 2080, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0024258762132376432, \"iteration\": 2081, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009776240913197398, \"iteration\": 2082, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000978491036221385, \"iteration\": 2083, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006450662040151656, \"iteration\": 2084, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006548001547344029, \"iteration\": 2085, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010604305425658822, \"iteration\": 2086, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005116029060445726, \"iteration\": 2087, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010081601794809103, \"iteration\": 2088, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005005319253541529, \"iteration\": 2089, \"epoch\": 10}, {\"training_acc\": 0.8571428571428571, \"training_loss\": 0.7106228470802307, \"iteration\": 2090, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test char tfidf feature on NN\n",
    "train_data_nn = encode_data(train_raw, char_tfidf)\n",
    "test_data_nn = encode_data(test_raw, char_tfidf)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(train_data_nn, batch_size=128, shuffle=True)\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(char_tfidf.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "if (models_dir / 'model_nn.pt').exists() and USE_CACHE:\n",
    "    model_nn = load_model(model_nn, models_dir, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn, models_dir, \"model_nn\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # X_test = torch.stack([dta[0] for dta in test])\n",
    "    X_test = torch.stack([test[0] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_test = torch.stack([test[1] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_pred = model_nn.predict(X_test)\n",
    "\n",
    "\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='binary'))\n",
    "print(\"AUC\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features = tfidf_encoder.transform(train_raw.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare data for xgboost\n",
    "train_dmat = xgb.DMatrix(tfidf_encoder.transform(train_raw.texts).todense(), pd.array(train_raw.labels).astype('category'))\n",
    "test_dmat = xgb.DMatrix(tfidf_encoder.transform(test_raw.texts).todense(), pd.array(test_raw.labels).astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.62286\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"device\": \"cpu\",\n",
    "    \"objective\": \"binary:logistic\",  # there is also binary:hinge\n",
    "    \"tree_method\": \"auto\",  # default to hist\n",
    "\n",
    "    # Params for tree booster\n",
    "    \"eta\": 0.3,\n",
    "    \"gamma\": 0.0,  # Min loss achieved to split the tree\n",
    "    \"max_depth\": 6,\n",
    "    \"reg_alpha\": 0,\n",
    "    \"reg_lambda\": 1,\n",
    "\n",
    "}\n",
    "evals = [(train_dmat, \"train\")]\n",
    "iterations = 5000\n",
    "\n",
    "model_xgb = xgb.train(\n",
    "    params = params,\n",
    "    dtrain = train_dmat,\n",
    "    num_boost_round = iterations,\n",
    "    evals = evals,\n",
    "    verbose_eval = 250\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power-identification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
