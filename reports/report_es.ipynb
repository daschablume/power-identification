{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISVpuTqy1oZT",
        "outputId": "6f352caf-42f1-4c1a-b315-349678108a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Tesla T4\n",
            "Total: 15,835.66 MB\n",
            "Reserved: 0.00 MB\n",
            "Allocated: 0.00 MB\n",
            "Free in reserved: 0.00 MB\n"
          ]
        }
      ],
      "source": [
        "# Load packages\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from models import NeuralNetwork, RNNClassifier, TrainConfig, evaluate, save_model, load_model, plot_results\n",
        "from utils import load_data, split_data, encode_data, check_cuda_memory, PositionalEncoder\n",
        "from pathlib import Path\n",
        "import altair as alt\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Device: cuda\")\n",
        "    check_cuda_memory()\n",
        "else:\n",
        "    print(\"Device: cpu\")\n",
        "\n",
        "models_dir = Path('models/es')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC07BPSM1oZZ"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SphbhIFz1oZc",
        "outputId": "72449661-0c5b-4a0d-ff3a-9849446cbd82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Data size: 10707, % positive class: 67.38%\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "base_path = \"/content/drive/MyDrive/\"\n",
        "\n",
        "es_file_list = [\n",
        "    'power-es-ct-train.tsv',\n",
        "    'power-es-ga-train.tsv',\n",
        "    'power-es-pv-train.tsv',\n",
        "    'power-es-train.tsv',\n",
        "]\n",
        "data = load_data(folder_path=base_path + \"data/train/power/\", file_list=es_file_list,text_head='text')\n",
        "train_raw, test_raw = split_data(data, test_size=0.2, random_state=0)\n",
        "print(f\"Data size: {len(data)}, % positive class: {sum(data.labels) / len(data) * 100:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKwG6Qfj1oZd"
      },
      "source": [
        "# Encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "UxaCplKM1oZe",
        "outputId": "a2a9cbc3-50ac-4e75-fa4c-27b9d33cd490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare words_encoder...\n",
            "Prepare chars_encoder...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='char', max_features=50000, ngram_range=(3, 5),\n",
              "                sublinear_tf=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=50000, ngram_range=(3, 5),\n",
              "                sublinear_tf=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=50000, ngram_range=(3, 5),\n",
              "                sublinear_tf=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "print(\"Prepare words_encoder...\")\n",
        "words_encoder = TfidfVectorizer(max_features=50000)\n",
        "words_encoder.fit(train_raw.texts)\n",
        "\n",
        "print(\"Prepare chars_encoder...\")\n",
        "chars_encoder = TfidfVectorizer(max_features=50000, analyzer=\"char\", ngram_range=(3,5), use_idf=True, sublinear_tf=True)\n",
        "chars_encoder.fit(train_raw.texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISI4eVCj1oZf"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXvVzhZ21oZf"
      },
      "source": [
        "### Word feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "5YVJqp8e1oZg",
        "outputId": "3d1d90f0-8426-4f35-d5d9-e3221155b36c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare data...\n",
            "Train model\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 67/67 [00:02<00:00, 29.07batch/s, batch_accuracy=0.333, loss=0.858]\n",
            "Epoch 2: 100%|██████████| 67/67 [00:01<00:00, 42.94batch/s, batch_accuracy=1, loss=0.19]\n",
            "Epoch 3: 100%|██████████| 67/67 [00:01<00:00, 40.11batch/s, batch_accuracy=1, loss=0.04]\n",
            "Epoch 4: 100%|██████████| 67/67 [00:01<00:00, 43.57batch/s, batch_accuracy=1, loss=0.0301]\n",
            "Epoch 5: 100%|██████████| 67/67 [00:01<00:00, 45.91batch/s, batch_accuracy=1, loss=0.00108]\n",
            "Epoch 6: 100%|██████████| 67/67 [00:01<00:00, 44.51batch/s, batch_accuracy=1, loss=0.000615]\n",
            "Epoch 7: 100%|██████████| 67/67 [00:01<00:00, 46.30batch/s, batch_accuracy=1, loss=0.000905]\n",
            "Epoch 8: 100%|██████████| 67/67 [00:01<00:00, 48.66batch/s, batch_accuracy=1, loss=0.000343]\n",
            "Epoch 9: 100%|██████████| 67/67 [00:01<00:00, 47.49batch/s, batch_accuracy=1, loss=0.000199]\n",
            "Epoch 10: 100%|██████████| 67/67 [00:01<00:00, 45.23batch/s, batch_accuracy=1, loss=0.000235]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8162, Precision: 0.8436, Recall: 0.8945, F1: 0.8683, AUC: 0.8697\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "show() method requires the altair_viewer package. See http://github.com/altair-viz/altair_viewer",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/altair/vegalite/v4/api.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, embed_opt, open_browser)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0maltair_viewer\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'altair_viewer'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-deb515a8cdfb>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Plot training accuracy and loss side-by-side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_nn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mmodel_nn_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models.py\u001b[0m in \u001b[0;36mplot_results\u001b[0;34m(model, train_config, train_dataloader)\u001b[0m\n\u001b[1;32m    432\u001b[0m     (nn_training_accuracy_chart | nn_training_loss_chart).properties(\n\u001b[1;32m    433\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Base Neural Network with Tf-Idf vectors'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     ).show()\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/altair/vegalite/v4/api.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, embed_opt, open_browser)\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0maltair_viewer\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1792\u001b[0m                 \u001b[0;34m\"show() method requires the altair_viewer package. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 \u001b[0;34m\"See http://github.com/altair-viz/altair_viewer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: show() method requires the altair_viewer package. See http://github.com/altair-viz/altair_viewer"
          ]
        }
      ],
      "source": [
        "print(\"Prepare data...\")\n",
        "train_nn_words = encode_data(train_raw, words_encoder)\n",
        "test_nn_words = encode_data(test_raw, words_encoder)\n",
        "\n",
        "print(\"Train model\")\n",
        "\n",
        "if not models_dir.exists():\n",
        "    models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_config = TrainConfig(\n",
        "    num_epochs      = 10,\n",
        "    early_stop      = False,\n",
        "    violation_limit = 5,\n",
        "\n",
        ")\n",
        "\n",
        "dataloader = DataLoader(train_nn_words, batch_size=128, shuffle=True)\n",
        "\n",
        "USE_CACHE = True\n",
        "\n",
        "model_nn_words = NeuralNetwork(\n",
        "    input_size=len(words_encoder.vocabulary_),\n",
        "    hidden_size=128,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "if (models_dir / 'model_nn_words.pt').exists() and USE_CACHE:\n",
        "    model_nn_words = load_model(model_nn_words, models_dir, 'model_nn_words')\n",
        "else:\n",
        "    model_nn_words.fit(dataloader, train_config, disable_progress_bar=False)\n",
        "    save_model(model_nn_words, models_dir, \"model_nn_words\")\n",
        "\n",
        "\n",
        "# Evaluate\n",
        "with torch.no_grad():\n",
        "    X_test_nn = torch.stack([test[0] for test in test_nn_words]).cpu()\n",
        "    y_test_nn = torch.stack([test[1] for test in test_nn_words]).cpu()\n",
        "    y_pred_nn_words = model_nn_words.predict(X_test_nn)\n",
        "    logits_nn_words = model_nn_words.forward(X_test_nn)\n",
        "\n",
        "result_nn_words = evaluate(y_test_nn.cpu(), y_pred_nn_words.cpu(), logits_nn_words.cpu())\n",
        "\n",
        "# Plot training accuracy and loss side-by-side\n",
        "plot_results(model_nn_words, train_config, dataloader)\n",
        "\n",
        "model_nn_words.to('cpu')\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNeyNHSI1oZg"
      },
      "source": [
        "### Char features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "Do1MCG7m1oZh",
        "outputId": "f3908805-3568-46f3-b771-bec36344c412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare data...\n",
            "Train model\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 67/67 [00:01<00:00, 45.26batch/s, batch_accuracy=0.667, loss=0.903]\n",
            "Epoch 2: 100%|██████████| 67/67 [00:01<00:00, 48.40batch/s, batch_accuracy=1, loss=0.324]\n",
            "Epoch 3: 100%|██████████| 67/67 [00:01<00:00, 48.81batch/s, batch_accuracy=1, loss=0.337]\n",
            "Epoch 4: 100%|██████████| 67/67 [00:01<00:00, 43.10batch/s, batch_accuracy=1, loss=0.000424]\n",
            "Epoch 5: 100%|██████████| 67/67 [00:01<00:00, 42.80batch/s, batch_accuracy=1, loss=0.0073]\n",
            "Epoch 6: 100%|██████████| 67/67 [00:01<00:00, 38.30batch/s, batch_accuracy=1, loss=0.000797]\n",
            "Epoch 7: 100%|██████████| 67/67 [00:01<00:00, 38.26batch/s, batch_accuracy=1, loss=0.00563]\n",
            "Epoch 8: 100%|██████████| 67/67 [00:01<00:00, 40.83batch/s, batch_accuracy=1, loss=0.00113]\n",
            "Epoch 9: 100%|██████████| 67/67 [00:01<00:00, 42.43batch/s, batch_accuracy=1, loss=0.000204]\n",
            "Epoch 10: 100%|██████████| 67/67 [00:01<00:00, 49.73batch/s, batch_accuracy=1, loss=0.000129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8344, Precision: 0.8731, Recall: 0.8840, F1: 0.8785, AUC: 0.8853\n",
            "Displaying chart at http://localhost:33467/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1094f1bc33f1>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Plot training accuracy and loss side-by-side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_nn_chars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/models.py\u001b[0m in \u001b[0;36mplot_results\u001b[0;34m(model, train_config, train_dataloader)\u001b[0m\n\u001b[1;32m    432\u001b[0m     (nn_training_accuracy_chart | nn_training_loss_chart).properties(\n\u001b[1;32m    433\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Base Neural Network with Tf-Idf vectors'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     ).show()\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/altair/vegalite/v4/api.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, embed_opt, open_browser)\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 \u001b[0;34m\"See http://github.com/altair-viz/altair_viewer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             )\n\u001b[0;32m-> 1795\u001b[0;31m         \u001b[0maltair_viewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_browser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen_browser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResolve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/altair_viewer/_viewer.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, chart, embed_opt, open_browser)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_provider\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disconnect_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"Prepare data...\")\n",
        "test_nn_chars = encode_data(test_raw, chars_encoder)\n",
        "\n",
        "print(\"Train model\")\n",
        "\n",
        "if not models_dir.exists():\n",
        "    models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_config = TrainConfig(\n",
        "    num_epochs      = 10,\n",
        "    early_stop      = False,\n",
        "    violation_limit = 5,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "USE_CACHE = True\n",
        "\n",
        "model_nn_chars = NeuralNetwork(\n",
        "    input_size=len(chars_encoder.vocabulary_),\n",
        "    hidden_size=128,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "if (models_dir / 'model_nn_chars.pt').exists() and USE_CACHE:\n",
        "    model_nn_chars = load_model(model_nn_chars, models_dir, 'model_nn_chars')\n",
        "else:\n",
        "    train_nn_chars = encode_data(train_raw, chars_encoder)\n",
        "    dataloader = DataLoader(train_nn_chars, batch_size=128, shuffle=True)\n",
        "\n",
        "    model_nn_chars.fit(dataloader, train_config, disable_progress_bar=False)\n",
        "    save_model(model_nn_chars, models_dir, \"model_nn_chars\")\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    X_test = torch.stack([test[0] for test in test_nn_chars]).to(model_nn_chars.device)\n",
        "    y_test = torch.stack([test[1] for test in test_nn_chars]).to(model_nn_chars.device)\n",
        "    y_pred = model_nn_chars.predict(X_test)\n",
        "    logits = model_nn_chars.forward(X_test)\n",
        "\n",
        "result_nn_chars = evaluate(y_test.cpu(), y_pred.cpu(), logits.cpu())\n",
        "\n",
        "# Plot training accuracy and loss side-by-side\n",
        "plot_results(model_nn_chars, train_config, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDaXZeG61oZi"
      },
      "source": [
        "# RNN\n",
        "\n",
        "### Word feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpxGj6wz1oZj",
        "outputId": "86024752-8f8c-489d-cfcc-89cc976b1b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare data encoder...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:   0%|          | 0/67 [00:00<?, ?batch/s]/content/utils.py:94: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  tokens_sparse = torch.sparse_csr_tensor(crow, col, token_val, size=mat_size, dtype=torch.long)\n",
            "Epoch 1: 100%|██████████| 67/67 [01:13<00:00,  1.10s/batch, batch_accuracy=0.833, loss=8.96]\n",
            "Epoch 2: 100%|██████████| 67/67 [01:00<00:00,  1.10batch/s, batch_accuracy=0.833, loss=9.04]\n",
            "Epoch 3: 100%|██████████| 67/67 [00:59<00:00,  1.13batch/s, batch_accuracy=0.833, loss=8.95]\n",
            "Epoch 4: 100%|██████████| 67/67 [00:58<00:00,  1.14batch/s, batch_accuracy=0.833, loss=6.22]\n",
            "Epoch 5: 100%|██████████| 67/67 [01:00<00:00,  1.11batch/s, batch_accuracy=0.833, loss=3.59]\n",
            "Epoch 6: 100%|██████████| 67/67 [00:59<00:00,  1.12batch/s, batch_accuracy=1, loss=8.05]\n",
            "Epoch 7: 100%|██████████| 67/67 [00:59<00:00,  1.13batch/s, batch_accuracy=0.833, loss=3.66]\n",
            "Epoch 8: 100%|██████████| 67/67 [01:00<00:00,  1.10batch/s, batch_accuracy=1, loss=8.05]\n",
            "Epoch 9: 100%|██████████| 67/67 [01:00<00:00,  1.11batch/s, batch_accuracy=1, loss=5.56]\n",
            "Epoch 10: 100%|██████████| 67/67 [00:58<00:00,  1.14batch/s, batch_accuracy=1, loss=8.05]\n",
            "Predicting: 100%|██████████| 18/18 [00:37<00:00,  2.11s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6862, Precision: 0.7198, Recall: 0.8788, F1: 0.7914, AUC: 0.6587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Prepare data encoder...\")\n",
        "rnn_words_encoder = PositionalEncoder()\n",
        "rnn_words_encoder.fit(train_raw.texts)\n",
        "\n",
        "train_dataloader = DataLoader(train_raw, batch_size=128, shuffle=True)\n",
        "test_dataloader = DataLoader(test_raw, batch_size=128, shuffle=False)\n",
        "\n",
        "# Prepare baseline config\n",
        "train_config = TrainConfig(\n",
        "    optimizer_params = {'lr': 0.01},\n",
        "    num_epochs       = 10,\n",
        "    early_stop       = False,\n",
        "    violation_limit  = 5\n",
        ")\n",
        "\n",
        "# Train baseline model\n",
        "model_lstm_words = RNNClassifier(\n",
        "    rnn_network         = nn.LSTM,\n",
        "    word_embedding_dim  = 32,\n",
        "    hidden_dim          = 64,\n",
        "    bidirectional       = False,\n",
        "    dropout             = 0,\n",
        "    encoder             = rnn_words_encoder,\n",
        "    device              = 'cuda'\n",
        ")\n",
        "\n",
        "USE_CACHE = False\n",
        "\n",
        "if (models_dir / 'model_lstm_words.pt').exists() and USE_CACHE:\n",
        "    model_lstm_words = load_model(model_lstm_words, 'model_lstm_words')\n",
        "else:\n",
        "    model_lstm_words.fit(train_dataloader, train_config, no_progress_bar=False)\n",
        "    save_model(model_lstm_words, models_dir, \"model_lstm_words\")\n",
        "\n",
        "test_dataloader = DataLoader(test_raw, batch_size=128, shuffle=False)\n",
        "\n",
        "# Evaluate\n",
        "with torch.no_grad():\n",
        "    model_lstm_words.device = \"cpu\"\n",
        "    model_lstm_words.cpu()\n",
        "\n",
        "    pred_LSTM_words_lst = []\n",
        "    probs_LSTM_words_lst = []\n",
        "\n",
        "    for _, _, raw_inputs, raw_targets in tqdm(test_dataloader, unit=\"batch\", desc=\"Predicting\"):\n",
        "        batch_encoder = PositionalEncoder(vocabulary=rnn_words_encoder.vocabulary)\n",
        "        test_inputs = batch_encoder.fit_transform(raw_inputs).cpu()\n",
        "        test_targets = torch.as_tensor(raw_targets, dtype=torch.float).cpu()\n",
        "\n",
        "        pred_LSTM_words_lst.append(model_lstm_words.predict(test_inputs))\n",
        "        probs_LSTM_words_lst.append(model_lstm_words._sigmoid(model_lstm_words.forward(test_inputs)).squeeze())\n",
        "\n",
        "\n",
        "pred_LSTM_words = torch.cat(pred_LSTM_words_lst).long().numpy()\n",
        "probs_LSTM_words = torch.concat(probs_LSTM_words_lst).numpy()\n",
        "\n",
        "model_lstm_words_result = evaluate(test_raw.labels, pred_LSTM_words, probs_LSTM_words)\n",
        "\n",
        "np.save(models_dir / 'model_lstm_words_results.npy', model_lstm_words_result)\n",
        "\n",
        "model_lstm_words.cpu()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POcep24S1oZk"
      },
      "source": [
        "### Char features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "-W7KrdiY1oZl",
        "outputId": "bed35404-76c1-4e10-925c-355d8909ed99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare data encoder...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Length of token_val is incorrect: 6991069 != 6991059",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-064f49dda1a4>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_chars_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Prepare baseline config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mcol\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;34mf\"Length of token_val is incorrect: {len(token_val)} != {self.max_sentence_length_ * len(X)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Length of token_val is incorrect: 6991069 != 6991059"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Prepare data encoder...\")\n",
        "rnn_chars_encoder = PositionalEncoder(tokenizer=chars_encoder.build_tokenizer())\n",
        "rnn_chars_encoder.fit(train_raw.texts)\n",
        "\n",
        "train_dataloader = DataLoader(train_raw, batch_size=128, shuffle=True)\n",
        "test_dataloader = DataLoader(test_raw, batch_size=128, shuffle=False)\n",
        "\n",
        "test_inputs = rnn_chars_encoder.transform(test_raw.texts)\n",
        "\n",
        "# Prepare baseline config\n",
        "train_config = TrainConfig(\n",
        "    optimizer_params = {'lr': 0.01},\n",
        "    num_epochs       = 10,\n",
        "    early_stop       = False,\n",
        "    violation_limit  = 5\n",
        ")\n",
        "\n",
        "# Train baseline model\n",
        "model_lstm_chars = RNNClassifier(\n",
        "    rnn_network         = nn.LSTM,\n",
        "    word_embedding_dim  = 32,\n",
        "    hidden_dim          = 64,\n",
        "    bidirectional       = False,\n",
        "    dropout             = 0,\n",
        "    encoder             = rnn_chars_encoder,\n",
        "    device              = 'cuda'\n",
        ")\n",
        "\n",
        "USE_CACHE = False\n",
        "\n",
        "if (models_dir / 'model_lstm_chars.pt').exists() and USE_CACHE:\n",
        "    model_lstm_chars = load_model(model_lstm_chars, 'model_lstm_chars')\n",
        "else:\n",
        "    model_lstm_chars.fit(train_dataloader, train_config, no_progress_bar=False)\n",
        "    save_model(model_lstm_chars, models_dir, \"model_lstm_chars\")\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    model_lstm_chars.device = \"cpu\"\n",
        "    model_lstm_chars.cpu()\n",
        "\n",
        "    pred_LSTM_chars = []\n",
        "    logits_LSTM_chars = []\n",
        "\n",
        "    for _, _, raw_inputs, raw_targets in tqdm(test_dataloader, unit=\"batch\", desc=\"Predicting\"):\n",
        "        batch_encoder = PositionalEncoder(vocabulary=rnn_chars_encoder.vocabulary)\n",
        "        test_inputs = batch_encoder.fit_transform(raw_inputs).cpu()\n",
        "        test_targets = torch.as_tensor(raw_targets, dtype=torch.float).cpu()\n",
        "\n",
        "        pred_LSTM_chars.append(model_lstm_chars.predict(test_inputs))\n",
        "        logits_LSTM_chars.append(model_lstm_chars.forward(test_inputs))\n",
        "\n",
        "pred_LSTM_chars = torch.concat(pred_LSTM_chars).numpy()\n",
        "logits_LSTM_chars = torch.concat(logits_LSTM_chars).numpy()\n",
        "\n",
        "model_lstm_chars_result = evaluate(test_raw.labels, pred_LSTM_chars, logits_LSTM_chars)\n",
        "# print(model_lstm_chars_result)\n",
        "\n",
        "np.save(models_dir / 'model_lstm_chars_results.npy', model_lstm_chars_result)\n",
        "model_lstm_words.cpu()\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuVokA1u1oZm"
      },
      "source": [
        "# Other classifiers from sklearn\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
        "\n",
        "\"Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ryvpZOyP1oZm"
      },
      "outputs": [],
      "source": [
        "# Prepare train & test set\n",
        "X_train_skl_words = words_encoder.transform(train_raw.texts)\n",
        "X_test_skl_words = words_encoder.transform(test_raw.texts)\n",
        "\n",
        "X_train_skl_chars = chars_encoder.transform(train_raw.texts)\n",
        "X_test_skl_chars = chars_encoder.transform(test_raw.texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoNikV2C1oZn"
      },
      "source": [
        "## Linear SVC\n",
        "Effective in high dimensional spaces.\n",
        "\n",
        "Still effective in cases where number of dimensions is greater than the number of samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mx9pEH71oZn"
      },
      "source": [
        "LinearSVC with TfIdf did good on balanced English"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhnp_ZHo1oZo"
      },
      "source": [
        "### Word feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL8XfYNx1oZo",
        "outputId": "f577dc5a-3374-4f29-b9c1-dfeaaa892a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model\n",
            "Accuracy: 0.8256, Precision: 0.8461, Recall: 0.9076, F1: 0.8758, AUC: 0.8782\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# LinearSVC, word\n",
        "\n",
        "\n",
        "print(\"Fit model\")\n",
        "base_svc = LinearSVC()\n",
        "model_LinearSVC_words = CalibratedClassifierCV(estimator=base_svc, cv=5)\n",
        "model_LinearSVC_words.fit(X_train_skl_words, train_raw.labels)\n",
        "\n",
        "pred_LinearSVC_words = model_LinearSVC_words.predict(X_test_skl_words)\n",
        "logits_linearSVC_words = model_LinearSVC_words.predict_proba(X_test_skl_words)\n",
        "\n",
        "result_linearSVC_words =  evaluate(test_raw.labels, pred_LinearSVC_words, logits_linearSVC_words[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpYAim7s1oZp",
        "outputId": "8ccb1c67-46d3-4723-d787-75a58d7cfa16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model\n",
            "Accuracy: 0.8420, Precision: 0.8625, Recall: 0.9122, F1: 0.8866, AUC: 0.8918\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "print(\"Fit model\")\n",
        "base_svc = LinearSVC()\n",
        "model_LinearSVC_chars = CalibratedClassifierCV(estimator=base_svc, cv=5)\n",
        "model_LinearSVC_chars.fit(X_train_skl_chars, train_raw.labels)\n",
        "\n",
        "pred_LinearSVC_chars = model_LinearSVC_chars.predict(X_test_skl_chars)\n",
        "logits_linearSVC_chars = model_LinearSVC_chars.predict_proba(X_test_skl_chars)\n",
        "\n",
        "result_linearSVC_chars =  evaluate(test_raw.labels, pred_LinearSVC_chars, logits_linearSVC_chars[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fovG2Kgx1oZp"
      },
      "source": [
        "# Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxO58mQp1oZq",
        "outputId": "0211ab29-8edd-491a-9474-871590a4c4c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model\n",
            "Accuracy: 0.7967, Precision: 0.7908, Recall: 0.9515, F1: 0.8638, AUC: 0.8529\n"
          ]
        }
      ],
      "source": [
        "# Word features\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "print(\"Fit model\")\n",
        "model_logreg_words = LogisticRegression()\n",
        "model_logreg_words.fit(X_train_skl_words, train_raw.labels)\n",
        "\n",
        "pred_logreg_words = model_logreg_words.predict(X_test_skl_words)\n",
        "logits_logreg_words = model_logreg_words.predict_proba(X_test_skl_words)\n",
        "\n",
        "result_linearlogreg_words =  evaluate(test_raw.labels, pred_logreg_words, logits_logreg_words[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-wk0X7b1oZq",
        "outputId": "05875d4f-d164-4fec-bc99-e4dba32f1d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model\n",
            "Accuracy: 0.8176, Precision: 0.8141, Recall: 0.9469, F1: 0.8755, AUC: 0.8752\n"
          ]
        }
      ],
      "source": [
        "# char features\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "print(\"Fit model\")\n",
        "model_logreg_chars = LogisticRegression()\n",
        "model_logreg_chars.fit(X_train_skl_chars, train_raw.labels)\n",
        "\n",
        "pred_logreg_chars = model_logreg_chars.predict(X_test_skl_chars)\n",
        "logits_logreg_chars = model_logreg_chars.predict_proba(X_test_skl_chars)\n",
        "\n",
        "result_linearlogreg_chars =  evaluate(test_raw.labels, pred_logreg_chars, logits_logreg_chars[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTYf219Z1oZr"
      },
      "source": [
        "## SGDClassifier\n",
        "SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
        "\n",
        "SGD is sensitive to feature scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JSyFvMo1oZr",
        "outputId": "fd493474-12a5-432c-b2f7-41951156718c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model\n",
            "Accuracy: 0.7949, Precision: 0.7869, Recall: 0.9561, F1: 0.8633, AUC: 0.8540\n"
          ]
        }
      ],
      "source": [
        "# word features\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "print(\"Fit model\")\n",
        "model_sgd_words = SGDClassifier(loss='log_loss')\n",
        "model_sgd_words.fit(X_train_skl_words, train_raw.labels)\n",
        "\n",
        "pred_sgd_words = model_sgd_words.predict(X_test_skl_words)\n",
        "logits_sgd_words = model_sgd_words.predict_proba(X_test_skl_words)\n",
        "\n",
        "result_linearsgd_words =  evaluate(test_raw.labels, pred_sgd_words, logits_sgd_words[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUE9IgUT1oZs",
        "outputId": "1f0ef3bd-7d61-48c0-c5c1-1c79e8b862e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model\n",
            "Accuracy: 0.8278, Precision: 0.8266, Recall: 0.9436, F1: 0.8813, AUC: 0.8818\n"
          ]
        }
      ],
      "source": [
        "# chars features\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "print(\"Fit model\")\n",
        "model_sgd_chars = SGDClassifier(loss='log_loss')\n",
        "model_sgd_chars.fit(X_train_skl_chars, train_raw.labels)\n",
        "\n",
        "pred_sgd_chars = model_sgd_chars.predict(X_test_skl_chars)\n",
        "logits_sgd_chars = model_sgd_chars.predict_proba(X_test_skl_chars)\n",
        "\n",
        "result_linearsgd_chars =  evaluate(test_raw.labels, pred_sgd_chars, logits_sgd_chars[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPrJmSgd1oZt"
      },
      "source": [
        "## Naive Bayes\n",
        "\n",
        "Overall bad performance, not worth pursuing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78rm-lKr1oZt",
        "outputId": "b1794021-d5b5-402c-e2a5-4ca34fe5e2b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model\n",
            "Accuracy: 0.6431, Precision: 0.7096, Recall: 0.8008, F1: 0.7525, AUC: 0.5565\n"
          ]
        }
      ],
      "source": [
        "# words features\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "print(\"Fit model\")\n",
        "model_gnb_words = GaussianNB()\n",
        "model_gnb_words.fit(X_train_skl_words.toarray(), train_raw.labels)\n",
        "\n",
        "pred_gnb_words = model_gnb_words.predict(X_test_skl_words.toarray())\n",
        "logits_gnb_words = model_gnb_words.predict_proba(X_test_skl_words.toarray())\n",
        "\n",
        "result_lineargnb_words =  evaluate(test_raw.labels, pred_gnb_words, logits_gnb_words[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ALJ-x6p81oZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd555188-1e55-4caa-9143-51576aa763ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model\n",
            "Accuracy: 0.6161, Precision: 0.6938, Recall: 0.7752, F1: 0.7323, AUC: 0.5274\n"
          ]
        }
      ],
      "source": [
        "# chars features\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "print(\"Fit model\")\n",
        "model_gnb_chars = GaussianNB()\n",
        "model_gnb_chars.fit(X_train_skl_chars.toarray(), train_raw.labels)\n",
        "\n",
        "pred_gnb_chars = model_gnb_chars.predict(X_test_skl_chars.toarray())\n",
        "logits_gnb_chars = model_gnb_chars.predict_proba(X_test_skl_chars.toarray())\n",
        "\n",
        "result_lineargnb_chars =  evaluate(test_raw.labels, pred_gnb_chars, logits_gnb_chars[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6MF4gJc1oZu"
      },
      "source": [
        "# Xgboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v_xUqULl1oZu"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "\n",
        "# Prepare data for xgboost\n",
        "train_dmat_words = xgb.DMatrix(X_train_skl_words, pd.array(train_raw.labels).astype('category'))\n",
        "test_dmat_words = xgb.DMatrix(X_test_skl_words, pd.array(test_raw.labels).astype('category'))\n",
        "\n",
        "train_dmat_chars = xgb.DMatrix(X_train_skl_chars, pd.array(train_raw.labels).astype('category'))\n",
        "test_dmat_chars = xgb.DMatrix(X_test_skl_chars, pd.array(test_raw.labels).astype('category'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqwKRGxS1oZv"
      },
      "source": [
        "### Word features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vsDPOs6b1oZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "536a8b91-f5e4-4e59-aca6-38d2e0c32220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-logloss:0.57702\n",
            "[100]\ttrain-logloss:0.10264\n",
            "[200]\ttrain-logloss:0.03758\n",
            "[300]\ttrain-logloss:0.01687\n",
            "[400]\ttrain-logloss:0.00894\n",
            "[500]\ttrain-logloss:0.00569\n",
            "[600]\ttrain-logloss:0.00415\n",
            "[700]\ttrain-logloss:0.00316\n",
            "[800]\ttrain-logloss:0.00248\n",
            "[900]\ttrain-logloss:0.00202\n",
            "[1000]\ttrain-logloss:0.00167\n",
            "[1100]\ttrain-logloss:0.00143\n",
            "[1200]\ttrain-logloss:0.00126\n",
            "[1300]\ttrain-logloss:0.00114\n",
            "[1400]\ttrain-logloss:0.00105\n",
            "[1500]\ttrain-logloss:0.00098\n",
            "[1600]\ttrain-logloss:0.00092\n",
            "[1700]\ttrain-logloss:0.00087\n",
            "[1800]\ttrain-logloss:0.00083\n",
            "[1900]\ttrain-logloss:0.00080\n",
            "[1999]\ttrain-logloss:0.00077\n",
            "Accuracy: 0.8087, Precision: 0.8320, Recall: 0.8991, F1: 0.8643, AUC: 0.8691\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    \"booster\": \"gbtree\",\n",
        "    \"device\": \"cpu\",\n",
        "    \"objective\": \"binary:logistic\",  # there is also binary:hinge but hinge does not output probability\n",
        "    \"tree_method\": \"hist\",  # default to hist\n",
        "    \"device\": \"cuda\",\n",
        "\n",
        "    # Params for tree booster\n",
        "    \"eta\": 0.3,\n",
        "    \"gamma\": 0.0,  # Min loss achieved to split the tree\n",
        "    \"max_depth\": 6,\n",
        "    \"reg_alpha\": 0,\n",
        "    \"reg_lambda\": 1,\n",
        "\n",
        "}\n",
        "evals_words = [(train_dmat_words, \"train\")]\n",
        "iterations = 2000\n",
        "\n",
        "model_xgb_words = xgb.train(\n",
        "    params = params,\n",
        "    dtrain = train_dmat_words,\n",
        "    num_boost_round = iterations,\n",
        "    evals = evals_words,\n",
        "    verbose_eval = 100\n",
        ")\n",
        "\n",
        "pred_xgb_words_probs = model_xgb_words.predict(test_dmat_words)\n",
        "result_xgb_words = evaluate(test_raw.labels, pred_xgb_words_probs > 0.5, pred_xgb_words_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sra-UjUS1oZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae550f02-bb6f-4be3-d33e-8d2d5ef9ae57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-logloss:0.56536\n",
            "[100]\ttrain-logloss:0.02068\n",
            "[200]\ttrain-logloss:0.00411\n",
            "[300]\ttrain-logloss:0.00187\n",
            "[400]\ttrain-logloss:0.00122\n",
            "[500]\ttrain-logloss:0.00094\n",
            "[600]\ttrain-logloss:0.00079\n",
            "[700]\ttrain-logloss:0.00068\n",
            "[800]\ttrain-logloss:0.00061\n",
            "[900]\ttrain-logloss:0.00056\n",
            "[1000]\ttrain-logloss:0.00052\n",
            "[1100]\ttrain-logloss:0.00049\n",
            "[1200]\ttrain-logloss:0.00047\n",
            "[1300]\ttrain-logloss:0.00044\n",
            "[1400]\ttrain-logloss:0.00043\n",
            "[1500]\ttrain-logloss:0.00041\n",
            "[1600]\ttrain-logloss:0.00039\n",
            "[1700]\ttrain-logloss:0.00038\n",
            "[1800]\ttrain-logloss:0.00037\n",
            "[1900]\ttrain-logloss:0.00037\n",
            "[1999]\ttrain-logloss:0.00036\n",
            "Accuracy: 0.8078, Precision: 0.8232, Recall: 0.9122, F1: 0.8654, AUC: 0.8618\n"
          ]
        }
      ],
      "source": [
        "# Can use only half of the original max features\n",
        "xgb_chars_encoder = TfidfVectorizer(max_features=20000, analyzer=\"char\", ngram_range=(3,5), use_idf=True, sublinear_tf=True)\n",
        "xgb_chars_encoder.fit(train_raw.texts)\n",
        "\n",
        "# Prepare train & test set\n",
        "X_train_xgb_chars = xgb_chars_encoder.transform(train_raw.texts)\n",
        "X_test_xgb_chars = xgb_chars_encoder.transform(test_raw.texts)\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "train_dmat_chars = xgb.DMatrix(X_train_xgb_chars, pd.array(train_raw.labels).astype('category'))\n",
        "test_dmat_chars = xgb.DMatrix(X_test_xgb_chars, pd.array(test_raw.labels).astype('category'))\n",
        "\n",
        "params = {\n",
        "    \"booster\": \"gbtree\",\n",
        "    \"device\": \"cpu\",\n",
        "    \"objective\": \"binary:logistic\",  # there is also binary:hinge but hinge does not output probability\n",
        "    \"tree_method\": \"hist\",  # default to hist\n",
        "    \"device\": \"cuda\",\n",
        "\n",
        "    # Params for tree booster\n",
        "    \"eta\": 0.3,\n",
        "    \"gamma\": 0.0,  # Min loss achieved to split the tree\n",
        "    \"max_depth\": 6,\n",
        "    \"reg_alpha\": 0,\n",
        "    \"reg_lambda\": 1,\n",
        "\n",
        "}\n",
        "evals_chars = [(train_dmat_chars, \"train\")]\n",
        "iterations = 2000\n",
        "\n",
        "model_xgb_chars = xgb.train(\n",
        "    params = params,\n",
        "    dtrain = train_dmat_chars,\n",
        "    num_boost_round = iterations,\n",
        "    evals = evals_chars,\n",
        "    verbose_eval = 100\n",
        ")\n",
        "\n",
        "pred_xgb_chars_probs = model_xgb_chars.predict(test_dmat_chars)\n",
        "result_xgb_chars = evaluate(test_raw.labels, pred_xgb_chars_probs > 0.5, pred_xgb_chars_probs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HO3FmmBg2Ve8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}