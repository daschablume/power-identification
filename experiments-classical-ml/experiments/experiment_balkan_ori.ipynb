{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from models import NeuralNetwork, TrainConfig, evaluate_nn_model, save_model, load_model, plot_results\n",
    "from utils import load_data, split_data, encode_data, mapping_dict\n",
    "from pathlib import Path\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"Device: cuda\")\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"Device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "balkan_file_list = [\n",
    "    'power-ba-train.tsv',\n",
    "    'power-hr-train.tsv',\n",
    "    'power-rs-train.tsv'\n",
    "]\n",
    "data = load_data(folder_path=\"data/train/power/\", file_list=balkan_file_list,text_head='text')\n",
    "train_raw, test_raw = split_data(data, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data encoder...\n",
      "Prepare data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Prepare data encoder...\")\n",
    "tfidf_encoder = TfidfVectorizer(max_features=50000)\n",
    "tfidf_encoder.fit(train_raw.texts)\n",
    "\n",
    "print(\"Prepare data...\")\n",
    "train_data_nn = encode_data(train_raw, tfidf_encoder)\n",
    "test_data_nn = encode_data(test_raw, tfidf_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 178/178 [00:03<00:00, 45.86batch/s, batch_accuracy=0.841, loss=0.513]\n",
      "Epoch 2: 100%|██████████| 178/178 [00:03<00:00, 47.35batch/s, batch_accuracy=0.89, loss=0.322] \n",
      "Epoch 3: 100%|██████████| 178/178 [00:03<00:00, 45.71batch/s, batch_accuracy=1, loss=0.0346]    \n",
      "Epoch 4: 100%|██████████| 178/178 [00:03<00:00, 45.31batch/s, batch_accuracy=1, loss=0.0119]    \n",
      "Epoch 5: 100%|██████████| 178/178 [00:03<00:00, 44.52batch/s, batch_accuracy=1, loss=0.000489]   \n",
      "Epoch 6: 100%|██████████| 178/178 [00:03<00:00, 46.59batch/s, batch_accuracy=1, loss=0.000165]\n",
      "Epoch 7: 100%|██████████| 178/178 [00:04<00:00, 44.33batch/s, batch_accuracy=1, loss=0.000128]\n",
      "Epoch 8: 100%|██████████| 178/178 [00:03<00:00, 45.28batch/s, batch_accuracy=1, loss=6.22e-5] \n",
      "Epoch 9: 100%|██████████| 178/178 [00:03<00:00, 46.16batch/s, batch_accuracy=1, loss=7.74e-6]\n",
      "Epoch 10: 100%|██████████| 178/178 [00:03<00:00, 46.41batch/s, batch_accuracy=1, loss=5.11e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6982421875, 0.6296785557023338, 0.6621903218337578, None)\n",
      "AUC 0.7233379453074891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d029740166fa4d24874acf188ec7a737.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d029740166fa4d24874acf188ec7a737.vega-embed details,\n",
       "  #altair-viz-d029740166fa4d24874acf188ec7a737.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d029740166fa4d24874acf188ec7a737\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d029740166fa4d24874acf188ec7a737\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d029740166fa4d24874acf188ec7a737\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-72aad68c9a373c67850160175ec672df\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-72aad68c9a373c67850160175ec672df\": [{\"training_acc\": 0.28125, \"training_loss\": 0.6985058188438416, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.6946955919265747, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6931579113006592, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6911135911941528, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6889933943748474, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6885442733764648, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6864479780197144, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6872007846832275, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6788118481636047, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.6711724996566772, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6770716309547424, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6747614741325378, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6666491627693176, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6699414849281311, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.663806676864624, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6584294438362122, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 0.686999499797821, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6645075678825378, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6616065502166748, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6390367746353149, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6316894292831421, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6334187388420105, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6613845229148865, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.630843997001648, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6256076097488403, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6664812564849854, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6685179471969604, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6090742945671082, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6438391804695129, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6365252137184143, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6345893144607544, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6153505444526672, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6041802763938904, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6808130145072937, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6312235593795776, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5988481640815735, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.609456479549408, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6742223501205444, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6764218211174011, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6365420818328857, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.64745032787323, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6288554072380066, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5988646745681763, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6348327398300171, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6575445532798767, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6182115077972412, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6275877356529236, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.5900045037269592, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6081153154373169, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6550268530845642, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5832628011703491, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6387820243835449, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6424170136451721, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6183672547340393, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6158940196037292, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6352038979530334, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6101073622703552, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6183477640151978, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.650834321975708, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6180298924446106, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6159456372261047, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6072970628738403, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5635084509849548, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6376690864562988, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6376724243164062, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.619227409362793, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 0.6663025617599487, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6454563140869141, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5689472556114197, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.5994939804077148, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.618326723575592, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.5658432841300964, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6080526113510132, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.5622650384902954, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5433955192565918, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.5633392930030823, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.5704519748687744, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.5635048151016235, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.5603609085083008, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.5910266041755676, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.5353072881698608, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6257135272026062, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.5576145648956299, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5149329304695129, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.4904746413230896, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6064627170562744, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.5870252847671509, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.5732173919677734, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.5837703347206116, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.597540557384491, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6067726016044617, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.5693511366844177, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.5743565559387207, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.5762412548065186, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.627220869064331, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5399537682533264, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5701877474784851, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5761725306510925, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5656470060348511, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5442958474159241, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.585336446762085, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5426820516586304, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5910635590553284, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5070335865020752, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5369963645935059, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.48131564259529114, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5163188576698303, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5450984239578247, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6147844195365906, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.536560595035553, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.49524229764938354, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5218162536621094, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.605760931968689, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5257636308670044, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5349199175834656, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4753738045692444, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5590645670890808, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5189518332481384, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5161601901054382, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5396349430084229, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5421032905578613, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5514175295829773, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5534089803695679, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5270305871963501, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5371229648590088, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5264462232589722, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5084418654441833, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5030195116996765, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5124213099479675, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4877232015132904, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5144070386886597, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.45359599590301514, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5261437892913818, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4538452923297882, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5196757316589355, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5315819382667542, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.46804457902908325, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5701342821121216, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.4729512631893158, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.48232853412628174, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5093544721603394, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5125401616096497, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5416898727416992, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.49806684255599976, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.45938509702682495, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5199944376945496, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.47025415301322937, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.45543819665908813, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.47424009442329407, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5211456418037415, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.542373538017273, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5054245591163635, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4292338192462921, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5310221910476685, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5131276249885559, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.47664883732795715, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5087945461273193, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.501911461353302, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.515131413936615, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.8828125, \"training_loss\": 0.410111665725708, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4185324013233185, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4411408007144928, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4448261857032776, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4291287958621979, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.48593276739120483, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.46936675906181335, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.48240745067596436, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.47490715980529785, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5181881189346313, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.43264803290367126, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4741208851337433, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.42240476608276367, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.47425377368927, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4652201235294342, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4217480719089508, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.875, \"training_loss\": 0.3924385905265808, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.43272191286087036, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.8414634146341463, \"training_loss\": 0.5125077962875366, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.8984375, \"training_loss\": 0.33972933888435364, \"iteration\": 179, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2797205150127411, \"iteration\": 180, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.31228360533714294, \"iteration\": 181, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.27784937620162964, \"iteration\": 182, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.35413792729377747, \"iteration\": 183, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31455743312835693, \"iteration\": 184, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3264227509498596, \"iteration\": 185, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3054244816303253, \"iteration\": 186, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.314615398645401, \"iteration\": 187, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.29670780897140503, \"iteration\": 188, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.27834558486938477, \"iteration\": 189, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2835450768470764, \"iteration\": 190, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26384860277175903, \"iteration\": 191, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3105982840061188, \"iteration\": 192, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.28975167870521545, \"iteration\": 193, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32115933299064636, \"iteration\": 194, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.32658851146698, \"iteration\": 195, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2697386145591736, \"iteration\": 196, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.23738570511341095, \"iteration\": 197, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.34454280138015747, \"iteration\": 198, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2363521158695221, \"iteration\": 199, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2479119896888733, \"iteration\": 200, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.21180085837841034, \"iteration\": 201, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2984359860420227, \"iteration\": 202, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2805647552013397, \"iteration\": 203, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23474624752998352, \"iteration\": 204, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21331559121608734, \"iteration\": 205, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3862142860889435, \"iteration\": 206, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2466137707233429, \"iteration\": 207, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21436810493469238, \"iteration\": 208, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3313329815864563, \"iteration\": 209, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2543376088142395, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2708868384361267, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26323625445365906, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3148946166038513, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.22454820573329926, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3312886357307434, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.26263511180877686, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2430814504623413, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.26093626022338867, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.266801655292511, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.23403841257095337, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.23977132141590118, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2489292323589325, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2807822823524475, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2614824175834656, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30286961793899536, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33439886569976807, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25459370017051697, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.259867399930954, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19996501505374908, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.27122414112091064, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.262185662984848, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.26533347368240356, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.29728931188583374, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22502297163009644, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22580237686634064, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30316343903541565, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3105674088001251, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.32231372594833374, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.28062155842781067, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21033352613449097, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2467881590127945, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.381252646446228, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3652125597000122, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2027319371700287, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29875391721725464, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2529250979423523, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.18684285879135132, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.26445817947387695, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2929205596446991, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2918694317340851, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27433598041534424, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2642327845096588, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2390839159488678, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3672756254673004, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2750868499279022, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29512324929237366, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.96875, \"training_loss\": 0.2100246548652649, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3009364604949951, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3093549609184265, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24455320835113525, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23048296570777893, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25168487429618835, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24077224731445312, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28889378905296326, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24182163178920746, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2652399241924286, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2876206040382385, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31967130303382874, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3543490171432495, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.20938640832901, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2566758096218109, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24300995469093323, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2661948800086975, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.33259984850883484, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24616974592208862, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3458304703235626, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31968870759010315, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25886672735214233, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.23102793097496033, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.23391148447990417, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2612072825431824, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2550733685493469, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25673115253448486, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.2154885083436966, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2742260694503784, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26165005564689636, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.26694750785827637, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30505338311195374, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.33709216117858887, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2910841107368469, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2231653928756714, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.19298870861530304, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2594911754131317, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2357499897480011, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2603340744972229, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4162328839302063, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2187187820672989, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2842556834220886, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3682892322540283, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2970452904701233, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.22437025606632233, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2996825575828552, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.2352379411458969, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25481972098350525, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.27484387159347534, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.38554948568344116, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2529486119747162, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.25218868255615234, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2483462244272232, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.25365740060806274, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2944181263446808, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.33122771978378296, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2296840250492096, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18530939519405365, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.245626300573349, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3172276020050049, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3074341118335724, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.31482818722724915, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.31581515073776245, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23469284176826477, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2585570514202118, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2544938921928406, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3052188754081726, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28156259655952454, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2676027715206146, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.2927951514720917, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3245752453804016, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.9609375, \"training_loss\": 0.21921482682228088, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2712467908859253, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.24777249991893768, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2979296147823334, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3767421543598175, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4149045944213867, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29567068815231323, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24142789840698242, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.36769434809684753, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3643859326839447, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2532975673675537, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22715090215206146, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2460712492465973, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.32537856698036194, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24254180490970612, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32520592212677, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3354296088218689, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28228700160980225, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.25639936327934265, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3648665249347687, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.234042689204216, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28690680861473083, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2833805978298187, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25684475898742676, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.33077746629714966, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2645566761493683, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2867182195186615, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.22142353653907776, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.8902439024390244, \"training_loss\": 0.32173213362693787, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10610974580049515, \"iteration\": 357, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12181057035923004, \"iteration\": 358, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.07466797530651093, \"iteration\": 359, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09821493923664093, \"iteration\": 360, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.12592560052871704, \"iteration\": 361, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0965142473578453, \"iteration\": 362, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09151887893676758, \"iteration\": 363, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12040112912654877, \"iteration\": 364, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08981116116046906, \"iteration\": 365, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10665472596883774, \"iteration\": 366, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.058267585933208466, \"iteration\": 367, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09193484485149384, \"iteration\": 368, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08932854235172272, \"iteration\": 369, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.1007106602191925, \"iteration\": 370, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09854434430599213, \"iteration\": 371, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07117701321840286, \"iteration\": 372, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06901516765356064, \"iteration\": 373, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09650985896587372, \"iteration\": 374, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.0824560672044754, \"iteration\": 375, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10148927569389343, \"iteration\": 376, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06896108388900757, \"iteration\": 377, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08667680621147156, \"iteration\": 378, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07443469017744064, \"iteration\": 379, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06003361940383911, \"iteration\": 380, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07100604474544525, \"iteration\": 381, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08465413004159927, \"iteration\": 382, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0808870941400528, \"iteration\": 383, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05684895068407059, \"iteration\": 384, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08464524894952774, \"iteration\": 385, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06475964933633804, \"iteration\": 386, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10208773612976074, \"iteration\": 387, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07218171656131744, \"iteration\": 388, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09601660817861557, \"iteration\": 389, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1599934995174408, \"iteration\": 390, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14454858005046844, \"iteration\": 391, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1342266947031021, \"iteration\": 392, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03425931558012962, \"iteration\": 393, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09955542534589767, \"iteration\": 394, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03643112629652023, \"iteration\": 395, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07766296714544296, \"iteration\": 396, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07940351963043213, \"iteration\": 397, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.024316273629665375, \"iteration\": 398, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08391530811786652, \"iteration\": 399, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.09584241360425949, \"iteration\": 400, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07163654267787933, \"iteration\": 401, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04223071038722992, \"iteration\": 402, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04187095910310745, \"iteration\": 403, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1157664954662323, \"iteration\": 404, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06912408024072647, \"iteration\": 405, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07535412162542343, \"iteration\": 406, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039696138352155685, \"iteration\": 407, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12749285995960236, \"iteration\": 408, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0849413275718689, \"iteration\": 409, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04201137274503708, \"iteration\": 410, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.048138055950403214, \"iteration\": 411, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06047850847244263, \"iteration\": 412, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12382836639881134, \"iteration\": 413, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08491869270801544, \"iteration\": 414, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06873944401741028, \"iteration\": 415, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06393416225910187, \"iteration\": 416, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04010307416319847, \"iteration\": 417, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06884319335222244, \"iteration\": 418, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06844183802604675, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09312382340431213, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09615413844585419, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04949133098125458, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0888717770576477, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.053271181881427765, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07387522608041763, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07588232308626175, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07774119824171066, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.042744386941194534, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13139303028583527, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0831315815448761, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15819938480854034, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.026315174996852875, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08657893538475037, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.04721401259303093, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09584090113639832, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03415381535887718, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.061011552810668945, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.09802717715501785, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046289052814245224, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06998143345117569, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09750153869390488, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.058063991367816925, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17521093785762787, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.10933901369571686, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05015725642442703, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.107533298432827, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0588667206466198, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07964982092380524, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.04999591037631035, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12280850857496262, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.05782013759016991, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.060283586382865906, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06393633037805557, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.1044548749923706, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07541392743587494, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.15585413575172424, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10596245527267456, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1274051070213318, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08664577454328537, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06891385465860367, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05987470597028732, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.0356447733938694, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08229382336139679, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03686954453587532, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09200315177440643, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06745750457048416, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.07893508672714233, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04333443194627762, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05270299315452576, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12949377298355103, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08185109496116638, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03856612369418144, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06579924374818802, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04380982741713524, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06878991425037384, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03654184937477112, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05795499309897423, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12767553329467773, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14377638697624207, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09322629868984222, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.13510413467884064, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06572172045707703, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07362273335456848, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11478012800216675, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11073488742113113, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08312012255191803, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08357732743024826, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.07083694636821747, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09375359117984772, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08035692572593689, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05725890398025513, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07812966406345367, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07785564661026001, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06705022603273392, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05234562233090401, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04174946993589401, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05011359229683876, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09850876033306122, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08186137676239014, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12526896595954895, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10611534863710403, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06261801719665527, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07065263390541077, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04880118370056152, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11718030273914337, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06856188178062439, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05944430083036423, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08596669882535934, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12577839195728302, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08964360505342484, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06227995827794075, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08924621343612671, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03948477283120155, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10975278913974762, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09093189984560013, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11237767338752747, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12144870311021805, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0704825296998024, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04326873645186424, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10030219703912735, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07845062017440796, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10925154387950897, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.037869106978178024, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07738208025693893, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10647900402545929, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.041627187281847, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0977148488163948, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10282190144062042, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03670861944556236, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08671127259731293, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17385712265968323, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06139429658651352, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08657059073448181, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03457052260637283, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.014893331564962864, \"iteration\": 535, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014873943291604519, \"iteration\": 536, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.04269389435648918, \"iteration\": 537, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.017490945756435394, \"iteration\": 538, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02574978582561016, \"iteration\": 539, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01204898115247488, \"iteration\": 540, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.015832528471946716, \"iteration\": 541, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.016925012692809105, \"iteration\": 542, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014297151006758213, \"iteration\": 543, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.053516685962677, \"iteration\": 544, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.017596926540136337, \"iteration\": 545, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014065236784517765, \"iteration\": 546, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010563763789832592, \"iteration\": 547, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008063110522925854, \"iteration\": 548, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008357689715921879, \"iteration\": 549, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008570720441639423, \"iteration\": 550, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.013065937906503677, \"iteration\": 551, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007278971839696169, \"iteration\": 552, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028335068374872208, \"iteration\": 553, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006689330562949181, \"iteration\": 554, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014654899016022682, \"iteration\": 555, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014292421750724316, \"iteration\": 556, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010341381654143333, \"iteration\": 557, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02892104722559452, \"iteration\": 558, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008252151310443878, \"iteration\": 559, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012776706367731094, \"iteration\": 560, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01578792743384838, \"iteration\": 561, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01617327518761158, \"iteration\": 562, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007952975109219551, \"iteration\": 563, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.022823726758360863, \"iteration\": 564, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05264677107334137, \"iteration\": 565, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012670964002609253, \"iteration\": 566, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028030939400196075, \"iteration\": 567, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03308991342782974, \"iteration\": 568, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00904893223196268, \"iteration\": 569, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008609124459326267, \"iteration\": 570, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.015669530257582664, \"iteration\": 571, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.035707738250494, \"iteration\": 572, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008367829024791718, \"iteration\": 573, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030877895653247833, \"iteration\": 574, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.020514339208602905, \"iteration\": 575, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.017016621306538582, \"iteration\": 576, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.015790900215506554, \"iteration\": 577, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.022012267261743546, \"iteration\": 578, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00821802020072937, \"iteration\": 579, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030865179374814034, \"iteration\": 580, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006939947139471769, \"iteration\": 581, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010707070119678974, \"iteration\": 582, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00980395544320345, \"iteration\": 583, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009683887474238873, \"iteration\": 584, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012564019300043583, \"iteration\": 585, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010987453162670135, \"iteration\": 586, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0036496135871857405, \"iteration\": 587, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004788307938724756, \"iteration\": 588, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00512115191668272, \"iteration\": 589, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009792008437216282, \"iteration\": 590, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008245822042226791, \"iteration\": 591, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00983486883342266, \"iteration\": 592, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007865970954298973, \"iteration\": 593, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006238236092031002, \"iteration\": 594, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007865441963076591, \"iteration\": 595, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03232855722308159, \"iteration\": 596, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0067475661635398865, \"iteration\": 597, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.017825018614530563, \"iteration\": 598, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.015117734670639038, \"iteration\": 599, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006448881700634956, \"iteration\": 600, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007659459486603737, \"iteration\": 601, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008281459100544453, \"iteration\": 602, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0040656086057424545, \"iteration\": 603, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0129566490650177, \"iteration\": 604, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005355001427233219, \"iteration\": 605, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06287700682878494, \"iteration\": 606, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006658944301307201, \"iteration\": 607, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.024598484858870506, \"iteration\": 608, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006751493085175753, \"iteration\": 609, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02948695793747902, \"iteration\": 610, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010528409853577614, \"iteration\": 611, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0072382851503789425, \"iteration\": 612, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025757642462849617, \"iteration\": 613, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.020851045846939087, \"iteration\": 614, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025450587272644043, \"iteration\": 615, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027554979547858238, \"iteration\": 616, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04306335747241974, \"iteration\": 617, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019542671740055084, \"iteration\": 618, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01292324997484684, \"iteration\": 619, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007733514066785574, \"iteration\": 620, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008794109337031841, \"iteration\": 621, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.014997920021414757, \"iteration\": 622, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.048501718789339066, \"iteration\": 623, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009550519287586212, \"iteration\": 624, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01078115776181221, \"iteration\": 625, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.013235348276793957, \"iteration\": 626, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018879108130931854, \"iteration\": 627, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.012918753549456596, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004462049808353186, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005558080971240997, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05189219117164612, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011937099508941174, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.013377807103097439, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.036158107221126556, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032189175486564636, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.02314189448952675, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01344310026615858, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0045150029473006725, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01118244044482708, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0074601550586521626, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006702960468828678, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024345651268959045, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005219914484769106, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01377861201763153, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024941764771938324, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01170339435338974, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0032711420208215714, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010593187063932419, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008031057193875313, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01153519470244646, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007444568909704685, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00778536219149828, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.019923781976103783, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01383226364850998, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004923073574900627, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.014429554343223572, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011843372136354446, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01155354455113411, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006443467922508717, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01589948870241642, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004728875122964382, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016754694283008575, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0037032701075077057, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005438758060336113, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0049184635281562805, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0077858613803982735, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006118997000157833, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006640352308750153, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010096688754856586, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006210252642631531, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007220900151878595, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.015943758189678192, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004728972911834717, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00528708565980196, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010538696311414242, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.003494277596473694, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006706707179546356, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0035600929986685514, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0028892564587295055, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007496989332139492, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03204727917909622, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005106261465698481, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0038439002819359303, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.023160550743341446, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008851571008563042, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005568580236285925, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009413297288119793, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.012814553454518318, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.022655881941318512, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005202381871640682, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.003430380253121257, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0062904078513383865, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.06939465552568436, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011267097666859627, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0038131335750222206, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0044640894047915936, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019968703389167786, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00300543662160635, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02280905842781067, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004893484525382519, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019744638353586197, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0070783826522529125, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009993406943976879, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007890966720879078, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.003779718419536948, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010850629769265652, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0025240422692149878, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007743183523416519, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010964781977236271, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004425854422152042, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006592992693185806, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011917122639715672, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0030189508106559515, \"iteration\": 713, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.006822757888585329, \"iteration\": 714, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003126580500975251, \"iteration\": 715, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002730829641222954, \"iteration\": 716, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003968311473727226, \"iteration\": 717, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002422490855678916, \"iteration\": 718, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015695308102294803, \"iteration\": 719, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013159430818632245, \"iteration\": 720, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013800389133393764, \"iteration\": 721, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002479572780430317, \"iteration\": 722, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001016364200040698, \"iteration\": 723, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013139653019607067, \"iteration\": 724, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014847589191049337, \"iteration\": 725, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001614182721823454, \"iteration\": 726, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001575676491484046, \"iteration\": 727, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.004893281031399965, \"iteration\": 728, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0022141041699796915, \"iteration\": 729, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011246877256780863, \"iteration\": 730, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015765017597004771, \"iteration\": 731, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010487922700121999, \"iteration\": 732, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0027612217236310244, \"iteration\": 733, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0022220714017748833, \"iteration\": 734, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012445809552446008, \"iteration\": 735, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001107078162021935, \"iteration\": 736, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001331687206402421, \"iteration\": 737, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0018025444587692618, \"iteration\": 738, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0022329993080347776, \"iteration\": 739, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000659612356685102, \"iteration\": 740, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001148558221757412, \"iteration\": 741, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012487334897741675, \"iteration\": 742, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.006210689898580313, \"iteration\": 743, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010293644154444337, \"iteration\": 744, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010226013837382197, \"iteration\": 745, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0018175742588937283, \"iteration\": 746, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010590575402602553, \"iteration\": 747, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.013293800875544548, \"iteration\": 748, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001178954029455781, \"iteration\": 749, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013081884244456887, \"iteration\": 750, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011573093943297863, \"iteration\": 751, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011097401147708297, \"iteration\": 752, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012462910963222384, \"iteration\": 753, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011362001532688737, \"iteration\": 754, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009711794555187225, \"iteration\": 755, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014938927488401532, \"iteration\": 756, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.012237604707479477, \"iteration\": 757, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014456723583862185, \"iteration\": 758, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013022066559642553, \"iteration\": 759, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00124118581879884, \"iteration\": 760, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0020558666437864304, \"iteration\": 761, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00112954992800951, \"iteration\": 762, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011007252614945173, \"iteration\": 763, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006881169974803925, \"iteration\": 764, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001600311603397131, \"iteration\": 765, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010988934664055705, \"iteration\": 766, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0019866819493472576, \"iteration\": 767, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000747646379750222, \"iteration\": 768, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012179345358163118, \"iteration\": 769, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007816385477781296, \"iteration\": 770, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010100665967911482, \"iteration\": 771, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012480360455811024, \"iteration\": 772, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000810303958132863, \"iteration\": 773, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011386452242732048, \"iteration\": 774, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013174723135307431, \"iteration\": 775, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0060705034993588924, \"iteration\": 776, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000932306342292577, \"iteration\": 777, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012333567719906569, \"iteration\": 778, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008267048979178071, \"iteration\": 779, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014150277711451054, \"iteration\": 780, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017349288100376725, \"iteration\": 781, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001973764505237341, \"iteration\": 782, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007459067855961621, \"iteration\": 783, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007640367257408798, \"iteration\": 784, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017676695715636015, \"iteration\": 785, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001019576215185225, \"iteration\": 786, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013192029437050223, \"iteration\": 787, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001125291921198368, \"iteration\": 788, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017046965658664703, \"iteration\": 789, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009605803061276674, \"iteration\": 790, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007655413937754929, \"iteration\": 791, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008263863855972886, \"iteration\": 792, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014086130540817976, \"iteration\": 793, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008902667323127389, \"iteration\": 794, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008955033263191581, \"iteration\": 795, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007600050303153694, \"iteration\": 796, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.010548953898251057, \"iteration\": 797, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009439066052436829, \"iteration\": 798, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008417289354838431, \"iteration\": 799, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000811172416433692, \"iteration\": 800, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015809910837560892, \"iteration\": 801, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009559942409396172, \"iteration\": 802, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011890120804309845, \"iteration\": 803, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010373682016506791, \"iteration\": 804, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010913400910794735, \"iteration\": 805, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001000337884761393, \"iteration\": 806, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014162118313834071, \"iteration\": 807, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009498095605522394, \"iteration\": 808, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00258330418728292, \"iteration\": 809, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006266041891649365, \"iteration\": 810, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005323720979504287, \"iteration\": 811, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009976280853152275, \"iteration\": 812, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006078991573303938, \"iteration\": 813, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009627653053030372, \"iteration\": 814, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013506398536264896, \"iteration\": 815, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010529193095862865, \"iteration\": 816, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008732075220905244, \"iteration\": 817, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012986782239750028, \"iteration\": 818, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001279152580536902, \"iteration\": 819, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011241603642702103, \"iteration\": 820, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006062367465347052, \"iteration\": 821, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011914883507415652, \"iteration\": 822, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007153288461267948, \"iteration\": 823, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00168989400845021, \"iteration\": 824, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006038430728949606, \"iteration\": 825, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011355102760717273, \"iteration\": 826, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00040937899029813707, \"iteration\": 827, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014621634036302567, \"iteration\": 828, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006764455465599895, \"iteration\": 829, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001183218788355589, \"iteration\": 830, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008890004828572273, \"iteration\": 831, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0030612065456807613, \"iteration\": 832, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002459782175719738, \"iteration\": 833, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.006578367203474045, \"iteration\": 834, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005841519450768828, \"iteration\": 835, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000733318564016372, \"iteration\": 836, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007243449799716473, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008434919873252511, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009763637208379805, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0016209138557314873, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006594318547286093, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004229603800922632, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007446445524692535, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.00966049637645483, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007216499070636928, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008246568613685668, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005863088881596923, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.005464876536279917, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.011045088991522789, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000744267541449517, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015015823300927877, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008168913191184402, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010618024971336126, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001388971577398479, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009302761754952371, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017907284200191498, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008167148334905505, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0023988327011466026, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007237115642055869, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011201746528968215, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010743987513706088, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015984047204256058, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001948612742125988, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007579800439998507, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009460811270400882, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00040471990359947085, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008812180603854358, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000629210495389998, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007460227934643626, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005333703011274338, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008518417598679662, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009276352939195931, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010757301934063435, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007766293128952384, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003614067565649748, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006700732046738267, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001180908759124577, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005383690586313605, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006134045543149114, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005299291806295514, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00047184902359731495, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006302839028649032, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003327620681375265, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005534628289751709, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0018128692172467709, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005383018287830055, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006957079749554396, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002101846970617771, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005454907077364624, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004892940050922334, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005088516627438366, \"iteration\": 891, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00044605392031371593, \"iteration\": 892, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000388694170396775, \"iteration\": 893, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004943913663737476, \"iteration\": 894, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00044736836571246386, \"iteration\": 895, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00040200926014222205, \"iteration\": 896, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005304792430251837, \"iteration\": 897, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003051531675737351, \"iteration\": 898, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007779139559715986, \"iteration\": 899, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00031567696714773774, \"iteration\": 900, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00047561764949932694, \"iteration\": 901, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00035725097404792905, \"iteration\": 902, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004769745282828808, \"iteration\": 903, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00043167127296328545, \"iteration\": 904, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004189668979961425, \"iteration\": 905, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005500901606865227, \"iteration\": 906, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00030850517214275897, \"iteration\": 907, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005464869318529963, \"iteration\": 908, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00036064916639588773, \"iteration\": 909, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.001120535540394485, \"iteration\": 910, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0011496421648189425, \"iteration\": 911, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005103807779960334, \"iteration\": 912, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024407084856647998, \"iteration\": 913, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003164113441016525, \"iteration\": 914, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006701810634694993, \"iteration\": 915, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0016394242411479354, \"iteration\": 916, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000511237361934036, \"iteration\": 917, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004857729363720864, \"iteration\": 918, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009372658096253872, \"iteration\": 919, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003801803395617753, \"iteration\": 920, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00043235643533989787, \"iteration\": 921, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003382900031283498, \"iteration\": 922, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002453169727232307, \"iteration\": 923, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003027140337508172, \"iteration\": 924, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004234335501678288, \"iteration\": 925, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007136099739000201, \"iteration\": 926, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005351260188035667, \"iteration\": 927, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00037373925442807376, \"iteration\": 928, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006778629031032324, \"iteration\": 929, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00039817095967009664, \"iteration\": 930, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002934725780505687, \"iteration\": 931, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004299851425457746, \"iteration\": 932, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003974413557443768, \"iteration\": 933, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000571951677557081, \"iteration\": 934, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00027461667195893824, \"iteration\": 935, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007248190231621265, \"iteration\": 936, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002980593708343804, \"iteration\": 937, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00025735885719768703, \"iteration\": 938, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002544785675127059, \"iteration\": 939, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009889269713312387, \"iteration\": 940, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004990764427930117, \"iteration\": 941, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004792023100890219, \"iteration\": 942, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006978159653954208, \"iteration\": 943, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003154308069497347, \"iteration\": 944, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004584317503031343, \"iteration\": 945, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00435020262375474, \"iteration\": 946, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004958169884048402, \"iteration\": 947, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00037469278322532773, \"iteration\": 948, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002258222666569054, \"iteration\": 949, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003894596884492785, \"iteration\": 950, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005756550817750394, \"iteration\": 951, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003283788391854614, \"iteration\": 952, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00042610810487531126, \"iteration\": 953, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006537516601383686, \"iteration\": 954, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00038659488200210035, \"iteration\": 955, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00040414021350443363, \"iteration\": 956, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00033134050318039954, \"iteration\": 957, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0013687163591384888, \"iteration\": 958, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006828622426837683, \"iteration\": 959, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004874984733760357, \"iteration\": 960, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002905892615672201, \"iteration\": 961, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008072814671322703, \"iteration\": 962, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004603227716870606, \"iteration\": 963, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004047262482345104, \"iteration\": 964, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002787130943033844, \"iteration\": 965, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005979289999231696, \"iteration\": 966, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00048394009354524314, \"iteration\": 967, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002748869592323899, \"iteration\": 968, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002777955960482359, \"iteration\": 969, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000654025876428932, \"iteration\": 970, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005556096439249814, \"iteration\": 971, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002766982652246952, \"iteration\": 972, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00033903628354892135, \"iteration\": 973, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00037715089274570346, \"iteration\": 974, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005657162982970476, \"iteration\": 975, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000602371001150459, \"iteration\": 976, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003886753984261304, \"iteration\": 977, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002698432363104075, \"iteration\": 978, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002667130611371249, \"iteration\": 979, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000502260634675622, \"iteration\": 980, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00022328893828671426, \"iteration\": 981, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00034632367896847427, \"iteration\": 982, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00046198407653719187, \"iteration\": 983, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004771639942191541, \"iteration\": 984, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00018599609029479325, \"iteration\": 985, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000432364409789443, \"iteration\": 986, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009053301764652133, \"iteration\": 987, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003553218557499349, \"iteration\": 988, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00042244105134159327, \"iteration\": 989, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00023976534430403262, \"iteration\": 990, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00022972204897087067, \"iteration\": 991, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00027670690906234086, \"iteration\": 992, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003682017559185624, \"iteration\": 993, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00017193699022755027, \"iteration\": 994, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00026473935577087104, \"iteration\": 995, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003193381999153644, \"iteration\": 996, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00023846031399443746, \"iteration\": 997, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00028567510889843106, \"iteration\": 998, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00034388224594295025, \"iteration\": 999, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024872299400158226, \"iteration\": 1000, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003064032061956823, \"iteration\": 1001, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000293966120807454, \"iteration\": 1002, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00037705653812736273, \"iteration\": 1003, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002488367899786681, \"iteration\": 1004, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00046707273577339947, \"iteration\": 1005, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00038472830783575773, \"iteration\": 1006, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003296630457043648, \"iteration\": 1007, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00032793715945445, \"iteration\": 1008, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00047887986875139177, \"iteration\": 1009, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003921354073099792, \"iteration\": 1010, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024821102852001786, \"iteration\": 1011, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004696287796832621, \"iteration\": 1012, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024545384803786874, \"iteration\": 1013, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024791734176687896, \"iteration\": 1014, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00029257425921969116, \"iteration\": 1015, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002796406333800405, \"iteration\": 1016, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00029724155319854617, \"iteration\": 1017, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00017642944294493645, \"iteration\": 1018, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00021176224981900305, \"iteration\": 1019, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003046673082280904, \"iteration\": 1020, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000405333936214447, \"iteration\": 1021, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00019929678819607943, \"iteration\": 1022, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00023587244504597038, \"iteration\": 1023, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00020843319362029433, \"iteration\": 1024, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005130833014845848, \"iteration\": 1025, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00022733185323886573, \"iteration\": 1026, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00023378056357614696, \"iteration\": 1027, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002306554524693638, \"iteration\": 1028, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00019284497830085456, \"iteration\": 1029, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005869905580766499, \"iteration\": 1030, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0010003832867369056, \"iteration\": 1031, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003048843936994672, \"iteration\": 1032, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004786366771440953, \"iteration\": 1033, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00015762911061756313, \"iteration\": 1034, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00034684277488850057, \"iteration\": 1035, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001540543744340539, \"iteration\": 1036, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00027969502843916416, \"iteration\": 1037, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00021093417308293283, \"iteration\": 1038, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005906037404201925, \"iteration\": 1039, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005616276175715029, \"iteration\": 1040, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00019267058814875782, \"iteration\": 1041, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003767691960092634, \"iteration\": 1042, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00014750275295227766, \"iteration\": 1043, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00017418160859961063, \"iteration\": 1044, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00017478100198786706, \"iteration\": 1045, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00034579364000819623, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003564672661013901, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00021081640443298966, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004534267936833203, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00016101772780530155, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00033697401522658765, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003291055327281356, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003097979642916471, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00037792386137880385, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003292484034318477, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00019283872097730637, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005960133858025074, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005159107386134565, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00023609338677488267, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001745520276017487, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00018101651221513748, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024142107577063143, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001980175729840994, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00019101551151834428, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002077754761558026, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002645126369316131, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00022200332023203373, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001649123732931912, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024234154261648655, \"iteration\": 1069, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00022330175852403045, \"iteration\": 1070, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001582805998623371, \"iteration\": 1071, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00028244202258065343, \"iteration\": 1072, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00021853503130842, \"iteration\": 1073, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002936628588940948, \"iteration\": 1074, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001352135877823457, \"iteration\": 1075, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010548785940045491, \"iteration\": 1076, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000182188450708054, \"iteration\": 1077, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012281956151127815, \"iteration\": 1078, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002500060072634369, \"iteration\": 1079, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00022747699404135346, \"iteration\": 1080, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000218276385567151, \"iteration\": 1081, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016151616000570357, \"iteration\": 1082, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001666815223870799, \"iteration\": 1083, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002387283748248592, \"iteration\": 1084, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00014106083835940808, \"iteration\": 1085, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00015458384586963803, \"iteration\": 1086, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00019370017980691046, \"iteration\": 1087, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00024162983754649758, \"iteration\": 1088, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00014441413804888725, \"iteration\": 1089, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00039752895827405155, \"iteration\": 1090, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020562796271406114, \"iteration\": 1091, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013072470028419048, \"iteration\": 1092, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001316930865868926, \"iteration\": 1093, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003414782404433936, \"iteration\": 1094, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001953462924575433, \"iteration\": 1095, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020452323951758444, \"iteration\": 1096, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016154405602719635, \"iteration\": 1097, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016842724289745092, \"iteration\": 1098, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011107928003184497, \"iteration\": 1099, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001320884475717321, \"iteration\": 1100, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001787682413123548, \"iteration\": 1101, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00017191965889651328, \"iteration\": 1102, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010580399975879118, \"iteration\": 1103, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020949858298990875, \"iteration\": 1104, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00017479161033406854, \"iteration\": 1105, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00022658142552245408, \"iteration\": 1106, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.13795777503401e-05, \"iteration\": 1107, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001322553725913167, \"iteration\": 1108, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013348768698051572, \"iteration\": 1109, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00036638605524785817, \"iteration\": 1110, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002363676903769374, \"iteration\": 1111, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011094343790318817, \"iteration\": 1112, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001530336739961058, \"iteration\": 1113, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012584410433191806, \"iteration\": 1114, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002344530657865107, \"iteration\": 1115, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00023915106430649757, \"iteration\": 1116, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00023615392274223268, \"iteration\": 1117, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001623922580620274, \"iteration\": 1118, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00014698505401611328, \"iteration\": 1119, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00018008789629675448, \"iteration\": 1120, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001319680450251326, \"iteration\": 1121, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013548607239499688, \"iteration\": 1122, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00015399325639009476, \"iteration\": 1123, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00018664906383492053, \"iteration\": 1124, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020573122310452163, \"iteration\": 1125, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012918552965857089, \"iteration\": 1126, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007132196333259344, \"iteration\": 1127, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001373060222249478, \"iteration\": 1128, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.382067946717143e-05, \"iteration\": 1129, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00014234770787879825, \"iteration\": 1130, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001636107626836747, \"iteration\": 1131, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010433416173327714, \"iteration\": 1132, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002061671402771026, \"iteration\": 1133, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012611955753527582, \"iteration\": 1134, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00014987229951657355, \"iteration\": 1135, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00014431383169721812, \"iteration\": 1136, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016785624029580504, \"iteration\": 1137, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.348939834628254e-05, \"iteration\": 1138, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013397751899901778, \"iteration\": 1139, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.037051495397463e-05, \"iteration\": 1140, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001112489146180451, \"iteration\": 1141, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013299722922965884, \"iteration\": 1142, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011027330037904903, \"iteration\": 1143, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00015272997552528977, \"iteration\": 1144, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00021629876573570073, \"iteration\": 1145, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00021886060130782425, \"iteration\": 1146, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010702978761401027, \"iteration\": 1147, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013974351168144494, \"iteration\": 1148, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011888964218087494, \"iteration\": 1149, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001918686757562682, \"iteration\": 1150, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001055328466463834, \"iteration\": 1151, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016784342005848885, \"iteration\": 1152, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.488989988109097e-05, \"iteration\": 1153, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003146293747704476, \"iteration\": 1154, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002164961479138583, \"iteration\": 1155, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.625445530517027e-05, \"iteration\": 1156, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00015015086682979017, \"iteration\": 1157, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010641902190400288, \"iteration\": 1158, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00018691751756705344, \"iteration\": 1159, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002605079207569361, \"iteration\": 1160, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013762609160039574, \"iteration\": 1161, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001987609575735405, \"iteration\": 1162, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010996329365298152, \"iteration\": 1163, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001575787173351273, \"iteration\": 1164, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00018067526980303228, \"iteration\": 1165, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012697992497123778, \"iteration\": 1166, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010656251106411219, \"iteration\": 1167, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011135898239444941, \"iteration\": 1168, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003733773191925138, \"iteration\": 1169, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010631442273734137, \"iteration\": 1170, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000147269107401371, \"iteration\": 1171, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.805522520560771e-05, \"iteration\": 1172, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002630632370710373, \"iteration\": 1173, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.431158883264288e-05, \"iteration\": 1174, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.038800686132163e-05, \"iteration\": 1175, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011096075468230993, \"iteration\": 1176, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.175935752457008e-05, \"iteration\": 1177, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016824608610477298, \"iteration\": 1178, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011116475070593879, \"iteration\": 1179, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001351368409814313, \"iteration\": 1180, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00023526838049292564, \"iteration\": 1181, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011584442108869553, \"iteration\": 1182, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.101832256419584e-05, \"iteration\": 1183, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011100730625912547, \"iteration\": 1184, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012051683006575331, \"iteration\": 1185, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.164970960118808e-05, \"iteration\": 1186, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013486031093634665, \"iteration\": 1187, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.605024049757048e-05, \"iteration\": 1188, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00021440784621518105, \"iteration\": 1189, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.69766081450507e-05, \"iteration\": 1190, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.392801439389586e-05, \"iteration\": 1191, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00021110789384692907, \"iteration\": 1192, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.353498560609296e-05, \"iteration\": 1193, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001280534197576344, \"iteration\": 1194, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.640388892265037e-05, \"iteration\": 1195, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002566008479334414, \"iteration\": 1196, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016499834600836039, \"iteration\": 1197, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00015593932766932994, \"iteration\": 1198, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00018399501277599484, \"iteration\": 1199, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010500012285774574, \"iteration\": 1200, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.178106120089069e-05, \"iteration\": 1201, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.900164589751512e-05, \"iteration\": 1202, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00015050519141368568, \"iteration\": 1203, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011263130727456883, \"iteration\": 1204, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.48209165269509e-05, \"iteration\": 1205, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.912221240578219e-05, \"iteration\": 1206, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.87209831085056e-05, \"iteration\": 1207, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.340903928503394e-05, \"iteration\": 1208, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00018438791448716074, \"iteration\": 1209, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010608114826027304, \"iteration\": 1210, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.678064139327034e-05, \"iteration\": 1211, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.801714622881263e-05, \"iteration\": 1212, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000118479278171435, \"iteration\": 1213, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00015505478950217366, \"iteration\": 1214, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001300695730606094, \"iteration\": 1215, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.786720329429954e-05, \"iteration\": 1216, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001245705207111314, \"iteration\": 1217, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011316876771161333, \"iteration\": 1218, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011685147183015943, \"iteration\": 1219, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.81016715336591e-05, \"iteration\": 1220, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00022231302864383906, \"iteration\": 1221, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011121017450932413, \"iteration\": 1222, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.641802272293717e-05, \"iteration\": 1223, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.539871487300843e-05, \"iteration\": 1224, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016151877935044467, \"iteration\": 1225, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011066536535508931, \"iteration\": 1226, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.829986184835434e-05, \"iteration\": 1227, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.210146188503131e-05, \"iteration\": 1228, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012093852274119854, \"iteration\": 1229, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00017573448712937534, \"iteration\": 1230, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.5859647545730695e-05, \"iteration\": 1231, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001189259928651154, \"iteration\": 1232, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.011172758415341e-05, \"iteration\": 1233, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00015937219723127782, \"iteration\": 1234, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011827501293737441, \"iteration\": 1235, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.1240156861022115e-05, \"iteration\": 1236, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001689470373094082, \"iteration\": 1237, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.419576675398275e-05, \"iteration\": 1238, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010064678644994274, \"iteration\": 1239, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.707755528623238e-05, \"iteration\": 1240, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.137369928183034e-05, \"iteration\": 1241, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.5006483307806775e-05, \"iteration\": 1242, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00019516002794262022, \"iteration\": 1243, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00014469413144979626, \"iteration\": 1244, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.976853961125016e-05, \"iteration\": 1245, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001280303840758279, \"iteration\": 1246, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.100906102801673e-05, \"iteration\": 1247, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.123378650750965e-05, \"iteration\": 1248, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.924069359432906e-05, \"iteration\": 1249, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.046150858514011e-05, \"iteration\": 1250, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00011094784713350236, \"iteration\": 1251, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.689567089779302e-05, \"iteration\": 1252, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00010478196054464206, \"iteration\": 1253, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.38602941762656e-05, \"iteration\": 1254, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.544113032054156e-05, \"iteration\": 1255, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.0741626182571054e-05, \"iteration\": 1256, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.243084524408914e-05, \"iteration\": 1257, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.506911010248587e-05, \"iteration\": 1258, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.341324766865e-05, \"iteration\": 1259, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.007028372958302e-05, \"iteration\": 1260, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00010846955410670489, \"iteration\": 1261, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.801194103900343e-05, \"iteration\": 1262, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.837258403422311e-05, \"iteration\": 1263, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.452048546634614e-05, \"iteration\": 1264, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.809308666153811e-05, \"iteration\": 1265, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.143779319245368e-05, \"iteration\": 1266, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00012467787018977106, \"iteration\": 1267, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00014134118100628257, \"iteration\": 1268, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.2307503715856e-05, \"iteration\": 1269, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.641561463358812e-05, \"iteration\": 1270, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.446219726465642e-05, \"iteration\": 1271, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.066542871645652e-05, \"iteration\": 1272, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00014272508269641548, \"iteration\": 1273, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.278327393578365e-05, \"iteration\": 1274, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.317381096072495e-05, \"iteration\": 1275, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.853597758687101e-05, \"iteration\": 1276, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.796132634510286e-05, \"iteration\": 1277, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00011457945220172405, \"iteration\": 1278, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.476748265209608e-05, \"iteration\": 1279, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.460565782617778e-05, \"iteration\": 1280, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00014095073856879026, \"iteration\": 1281, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.361407289048657e-05, \"iteration\": 1282, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.398464079713449e-05, \"iteration\": 1283, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.376653643907048e-05, \"iteration\": 1284, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.293752423720434e-05, \"iteration\": 1285, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.344024586724117e-05, \"iteration\": 1286, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.092706800904125e-05, \"iteration\": 1287, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.167461106088012e-05, \"iteration\": 1288, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.0481062973849475e-05, \"iteration\": 1289, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.4446413337718695e-05, \"iteration\": 1290, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.683978426735848e-05, \"iteration\": 1291, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000547900446690619, \"iteration\": 1292, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.009688149788417e-05, \"iteration\": 1293, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.6243272410938516e-05, \"iteration\": 1294, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.376190867740661e-05, \"iteration\": 1295, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00011878407531185076, \"iteration\": 1296, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.683868271764368e-05, \"iteration\": 1297, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.44217652734369e-05, \"iteration\": 1298, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.253748819697648e-05, \"iteration\": 1299, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.114863496506587e-05, \"iteration\": 1300, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00016663172573316842, \"iteration\": 1301, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.1391467422945425e-05, \"iteration\": 1302, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.796416735392995e-05, \"iteration\": 1303, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.937466266914271e-05, \"iteration\": 1304, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.4675369281321764e-05, \"iteration\": 1305, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0001492883893661201, \"iteration\": 1306, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.9418108169920743e-05, \"iteration\": 1307, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.871440614806488e-05, \"iteration\": 1308, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.676470078062266e-05, \"iteration\": 1309, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.128260767785832e-05, \"iteration\": 1310, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00010560533701209351, \"iteration\": 1311, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.686309694079682e-05, \"iteration\": 1312, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0001221576239913702, \"iteration\": 1313, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.5212694860529155e-05, \"iteration\": 1314, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00012086566857760772, \"iteration\": 1315, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.111426723189652e-05, \"iteration\": 1316, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.9364957046927884e-05, \"iteration\": 1317, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.6230914196930826e-05, \"iteration\": 1318, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.897916657384485e-05, \"iteration\": 1319, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.0623027820838615e-05, \"iteration\": 1320, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.278430373640731e-05, \"iteration\": 1321, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.770415348000824e-05, \"iteration\": 1322, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.59851801476907e-05, \"iteration\": 1323, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.079525388078764e-05, \"iteration\": 1324, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.7440825912635773e-05, \"iteration\": 1325, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00013638995005749166, \"iteration\": 1326, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00010900407505687326, \"iteration\": 1327, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.516257831710391e-05, \"iteration\": 1328, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.559161970973946e-05, \"iteration\": 1329, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.545832729898393e-05, \"iteration\": 1330, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.744475518236868e-05, \"iteration\": 1331, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.247108881827444e-05, \"iteration\": 1332, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.587412720662542e-05, \"iteration\": 1333, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.88075485615991e-05, \"iteration\": 1334, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.9460923289880157e-05, \"iteration\": 1335, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.557056182529777e-05, \"iteration\": 1336, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00010336138802813366, \"iteration\": 1337, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.962027403758839e-05, \"iteration\": 1338, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.8399415138410404e-05, \"iteration\": 1339, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.505076867644675e-05, \"iteration\": 1340, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00012872688239440322, \"iteration\": 1341, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.4803444830467924e-05, \"iteration\": 1342, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.4788237573811784e-05, \"iteration\": 1343, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.6359584808233194e-05, \"iteration\": 1344, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.73737673019059e-05, \"iteration\": 1345, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.018377851229161e-05, \"iteration\": 1346, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.1102994398679584e-05, \"iteration\": 1347, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.785133907920681e-05, \"iteration\": 1348, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.818044908461161e-05, \"iteration\": 1349, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0001243727165274322, \"iteration\": 1350, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0001260086428374052, \"iteration\": 1351, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.6662837121402845e-05, \"iteration\": 1352, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.9368744435487315e-05, \"iteration\": 1353, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.459219341399148e-05, \"iteration\": 1354, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.273772644111887e-05, \"iteration\": 1355, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00013127451529726386, \"iteration\": 1356, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.926158751710318e-05, \"iteration\": 1357, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.2957264920696616e-05, \"iteration\": 1358, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.486229489790276e-05, \"iteration\": 1359, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.143246042076498e-05, \"iteration\": 1360, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.1892097720410675e-05, \"iteration\": 1361, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.097685400163755e-05, \"iteration\": 1362, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00016879488248378038, \"iteration\": 1363, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.222707790788263e-05, \"iteration\": 1364, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.83675573579967e-05, \"iteration\": 1365, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00019356849952600896, \"iteration\": 1366, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.8930105549516156e-05, \"iteration\": 1367, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00013158768706489354, \"iteration\": 1368, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.0692499169381335e-05, \"iteration\": 1369, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.3198441087733954e-05, \"iteration\": 1370, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.23003681236878e-05, \"iteration\": 1371, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.3661261366214603e-05, \"iteration\": 1372, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.403009759495035e-05, \"iteration\": 1373, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.59081735345535e-05, \"iteration\": 1374, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.941060125129297e-05, \"iteration\": 1375, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.245369488373399e-05, \"iteration\": 1376, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.146551747107878e-05, \"iteration\": 1377, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.777507274411619e-05, \"iteration\": 1378, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.953831012244336e-05, \"iteration\": 1379, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.468093175091781e-05, \"iteration\": 1380, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.6777939638122916e-05, \"iteration\": 1381, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.953527943347581e-05, \"iteration\": 1382, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00010460255725774914, \"iteration\": 1383, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.630134157603607e-05, \"iteration\": 1384, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.868974039913155e-05, \"iteration\": 1385, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.0308419809443876e-05, \"iteration\": 1386, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.030792090110481e-05, \"iteration\": 1387, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.360637517995201e-05, \"iteration\": 1388, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.577202369342558e-05, \"iteration\": 1389, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.5767028748523444e-05, \"iteration\": 1390, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.7775462513091043e-05, \"iteration\": 1391, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.7021669413661584e-05, \"iteration\": 1392, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.650417445693165e-05, \"iteration\": 1393, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.902916043647565e-05, \"iteration\": 1394, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.924886914319359e-05, \"iteration\": 1395, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.661755908979103e-05, \"iteration\": 1396, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.033375055063516e-05, \"iteration\": 1397, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.105192783754319e-05, \"iteration\": 1398, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.1581686926074326e-05, \"iteration\": 1399, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.435353134293109e-05, \"iteration\": 1400, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.508741378434934e-05, \"iteration\": 1401, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.729282227344811e-05, \"iteration\": 1402, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.763917579315603e-05, \"iteration\": 1403, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.74832670786418e-05, \"iteration\": 1404, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00014675046259071678, \"iteration\": 1405, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.855324995238334e-05, \"iteration\": 1406, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.889950600452721e-05, \"iteration\": 1407, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.262153667397797e-05, \"iteration\": 1408, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.729270949610509e-05, \"iteration\": 1409, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.058336031041108e-05, \"iteration\": 1410, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00011401499068597332, \"iteration\": 1411, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.036137761431746e-05, \"iteration\": 1412, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.2077171858400106e-05, \"iteration\": 1413, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.711386645794846e-05, \"iteration\": 1414, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.0812698241788894e-05, \"iteration\": 1415, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.034943049191497e-05, \"iteration\": 1416, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.51114576915279e-05, \"iteration\": 1417, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.650325692840852e-05, \"iteration\": 1418, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.7213323846808635e-05, \"iteration\": 1419, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.369761154521257e-05, \"iteration\": 1420, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.1495685359695926e-05, \"iteration\": 1421, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.621242886874825e-05, \"iteration\": 1422, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.006164064980112e-05, \"iteration\": 1423, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.218559428816661e-05, \"iteration\": 1424, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.593972986796871e-05, \"iteration\": 1425, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.9997969249961898e-05, \"iteration\": 1426, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.2232244848273695e-05, \"iteration\": 1427, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.0200033254222944e-05, \"iteration\": 1428, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.5863285777159035e-05, \"iteration\": 1429, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.596851456677541e-05, \"iteration\": 1430, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.1915354813681915e-05, \"iteration\": 1431, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.129902688669972e-05, \"iteration\": 1432, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7533544450998306e-05, \"iteration\": 1433, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.60600747121498e-05, \"iteration\": 1434, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.8437163311755285e-05, \"iteration\": 1435, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.9127371817594394e-05, \"iteration\": 1436, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00010948165436275303, \"iteration\": 1437, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7484122508903965e-05, \"iteration\": 1438, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.8233668015454896e-05, \"iteration\": 1439, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.969346188474447e-05, \"iteration\": 1440, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.285273022716865e-05, \"iteration\": 1441, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.61421038582921e-05, \"iteration\": 1442, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.2737664039595984e-05, \"iteration\": 1443, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.8290606021764688e-05, \"iteration\": 1444, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.34644413064234e-05, \"iteration\": 1445, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.445230322540738e-05, \"iteration\": 1446, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.522146653267555e-05, \"iteration\": 1447, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.316818740335293e-05, \"iteration\": 1448, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.1287327146856114e-05, \"iteration\": 1449, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7630618458497338e-05, \"iteration\": 1450, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.85388653841801e-05, \"iteration\": 1451, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.181128340656869e-05, \"iteration\": 1452, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.800074046012014e-05, \"iteration\": 1453, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.85557764780242e-05, \"iteration\": 1454, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.6300833269488066e-05, \"iteration\": 1455, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.3658918507862836e-05, \"iteration\": 1456, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.0920762835885398e-05, \"iteration\": 1457, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.4781593310763128e-05, \"iteration\": 1458, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.2358148271450773e-05, \"iteration\": 1459, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.9009122954448685e-05, \"iteration\": 1460, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.471099135931581e-06, \"iteration\": 1461, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.264836414018646e-05, \"iteration\": 1462, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.3008728021522984e-05, \"iteration\": 1463, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.4063150704023428e-05, \"iteration\": 1464, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.4701958207297139e-05, \"iteration\": 1465, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.605799429351464e-05, \"iteration\": 1466, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.450022606761195e-05, \"iteration\": 1467, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.6030513254227117e-05, \"iteration\": 1468, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.000793392653577e-05, \"iteration\": 1469, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.0030918424017727e-05, \"iteration\": 1470, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.0833285563858226e-05, \"iteration\": 1471, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.2803049432695843e-05, \"iteration\": 1472, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.5989054089877754e-05, \"iteration\": 1473, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.976713610929437e-05, \"iteration\": 1474, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7776535969460383e-05, \"iteration\": 1475, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.4130680685630068e-05, \"iteration\": 1476, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.575911821622867e-05, \"iteration\": 1477, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.9819422959699295e-05, \"iteration\": 1478, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.940159356512595e-05, \"iteration\": 1479, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.1218027035938576e-05, \"iteration\": 1480, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.7327990867197514e-05, \"iteration\": 1481, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.1321975509636104e-05, \"iteration\": 1482, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.9810393496300094e-05, \"iteration\": 1483, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.552078694861848e-05, \"iteration\": 1484, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.8960279450984672e-05, \"iteration\": 1485, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.5992111002560705e-05, \"iteration\": 1486, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.8859329177066684e-05, \"iteration\": 1487, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.584516086149961e-05, \"iteration\": 1488, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3001573279325385e-05, \"iteration\": 1489, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.454322748235427e-05, \"iteration\": 1490, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.6205276299151592e-05, \"iteration\": 1491, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.0784591470146552e-05, \"iteration\": 1492, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.242642924305983e-05, \"iteration\": 1493, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.5171239283517934e-05, \"iteration\": 1494, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7782836948754266e-05, \"iteration\": 1495, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.2136113329906948e-05, \"iteration\": 1496, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.032324275409337e-05, \"iteration\": 1497, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021606797236017883, \"iteration\": 1498, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.168616942479275e-05, \"iteration\": 1499, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.1623633074341342e-05, \"iteration\": 1500, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.4880318303767126e-05, \"iteration\": 1501, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.0414983737282455e-05, \"iteration\": 1502, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.718896939768456e-05, \"iteration\": 1503, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.8399763323250227e-05, \"iteration\": 1504, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.122155976598151e-05, \"iteration\": 1505, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.5161022020038217e-05, \"iteration\": 1506, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.904964640038088e-05, \"iteration\": 1507, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.5227089281543158e-05, \"iteration\": 1508, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.24430114030838e-05, \"iteration\": 1509, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3119423783791717e-05, \"iteration\": 1510, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.206068893428892e-05, \"iteration\": 1511, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.624569995328784e-05, \"iteration\": 1512, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.6145906556630507e-05, \"iteration\": 1513, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7017458958434872e-05, \"iteration\": 1514, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.8171273040934466e-05, \"iteration\": 1515, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.294385922141373e-05, \"iteration\": 1516, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.686846892174799e-05, \"iteration\": 1517, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.8187721656868234e-05, \"iteration\": 1518, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.276235889235977e-05, \"iteration\": 1519, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.11043110943865e-05, \"iteration\": 1520, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.878262188867666e-05, \"iteration\": 1521, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.4254093659692444e-05, \"iteration\": 1522, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.4893637601053342e-05, \"iteration\": 1523, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3119784853188321e-05, \"iteration\": 1524, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.706102532101795e-05, \"iteration\": 1525, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.5466752049396746e-05, \"iteration\": 1526, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.89577549463138e-05, \"iteration\": 1527, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.241115478478605e-05, \"iteration\": 1528, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.4349898265209049e-05, \"iteration\": 1529, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.357361518079415e-05, \"iteration\": 1530, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.114385941036744e-05, \"iteration\": 1531, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.11600909603294e-06, \"iteration\": 1532, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.075659621274099e-05, \"iteration\": 1533, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.792182203847915e-05, \"iteration\": 1534, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.465093191654887e-05, \"iteration\": 1535, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.9526152755133808e-05, \"iteration\": 1536, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2900463843834586e-05, \"iteration\": 1537, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.5924662875477225e-05, \"iteration\": 1538, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.575514761498198e-05, \"iteration\": 1539, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.161993986897869e-05, \"iteration\": 1540, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.0384108211146668e-05, \"iteration\": 1541, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.6776109987404197e-05, \"iteration\": 1542, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.7758003094932064e-05, \"iteration\": 1543, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.35655095113907e-05, \"iteration\": 1544, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.4066883270279504e-05, \"iteration\": 1545, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.1415187802631408e-05, \"iteration\": 1546, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.288062725914642e-05, \"iteration\": 1547, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.912876521411818e-06, \"iteration\": 1548, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.4690310965524986e-05, \"iteration\": 1549, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.2739417545381002e-05, \"iteration\": 1550, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.6960204447968863e-05, \"iteration\": 1551, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.6229709217441268e-05, \"iteration\": 1552, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.0562754798447713e-05, \"iteration\": 1553, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.4808397281740326e-05, \"iteration\": 1554, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7595117242308334e-05, \"iteration\": 1555, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.713981515029445e-06, \"iteration\": 1556, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.534931450616568e-06, \"iteration\": 1557, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.4525281332898885e-05, \"iteration\": 1558, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.556782394298352e-05, \"iteration\": 1559, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.844273907016031e-06, \"iteration\": 1560, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.0758450773428194e-05, \"iteration\": 1561, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.000410500448197e-06, \"iteration\": 1562, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.6738402337068692e-05, \"iteration\": 1563, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.82003712124424e-06, \"iteration\": 1564, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1081886441388633e-05, \"iteration\": 1565, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.4394794561667368e-05, \"iteration\": 1566, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1510330296005122e-05, \"iteration\": 1567, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.4827741324552335e-05, \"iteration\": 1568, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3360886441660114e-05, \"iteration\": 1569, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.739235035027377e-05, \"iteration\": 1570, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.141161348845344e-05, \"iteration\": 1571, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.7681366999750026e-06, \"iteration\": 1572, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.81896482699085e-06, \"iteration\": 1573, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.8565146900946274e-05, \"iteration\": 1574, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.17315712486743e-05, \"iteration\": 1575, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.261661837925203e-06, \"iteration\": 1576, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.241568836325314e-05, \"iteration\": 1577, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.7323548895074055e-05, \"iteration\": 1578, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.3652830350329168e-05, \"iteration\": 1579, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.9370616428204812e-05, \"iteration\": 1580, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.5326898796483874e-05, \"iteration\": 1581, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.8334423657506704e-05, \"iteration\": 1582, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.8434981029713526e-05, \"iteration\": 1583, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.5767367585795e-05, \"iteration\": 1584, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.4987438589741942e-05, \"iteration\": 1585, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1650819033093285e-05, \"iteration\": 1586, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.10285837360425e-06, \"iteration\": 1587, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2199827324366197e-05, \"iteration\": 1588, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.0793652108986862e-05, \"iteration\": 1589, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.0088367162097711e-05, \"iteration\": 1590, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.572196717665065e-05, \"iteration\": 1591, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2439901183824986e-05, \"iteration\": 1592, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.662068805482704e-06, \"iteration\": 1593, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.9968611013609916e-05, \"iteration\": 1594, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3983048120280728e-05, \"iteration\": 1595, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2976065590919461e-05, \"iteration\": 1596, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2873336345364805e-05, \"iteration\": 1597, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.859704394126311e-06, \"iteration\": 1598, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3724927157454658e-05, \"iteration\": 1599, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.5602659914293326e-05, \"iteration\": 1600, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.5998108210624196e-05, \"iteration\": 1601, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.737294254184235e-06, \"iteration\": 1602, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.006599273358006e-06, \"iteration\": 1603, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.5412313587148674e-05, \"iteration\": 1604, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.0517783266550396e-05, \"iteration\": 1605, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.184028951684013e-05, \"iteration\": 1606, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.913378562487196e-06, \"iteration\": 1607, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.4613729035772849e-05, \"iteration\": 1608, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.717226021166425e-06, \"iteration\": 1609, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.687560143182054e-05, \"iteration\": 1610, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.1654979061859194e-05, \"iteration\": 1611, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.427279676136095e-05, \"iteration\": 1612, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.189487193187233e-05, \"iteration\": 1613, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.3516552826331463e-05, \"iteration\": 1614, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.491310265730135e-06, \"iteration\": 1615, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.344286586885573e-06, \"iteration\": 1616, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.06647245149361e-06, \"iteration\": 1617, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.3298691555974074e-05, \"iteration\": 1618, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2682117812801152e-05, \"iteration\": 1619, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.116881872410886e-06, \"iteration\": 1620, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.18276534017059e-06, \"iteration\": 1621, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.1701473340508528e-05, \"iteration\": 1622, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2322852853685617e-05, \"iteration\": 1623, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.406269075232558e-05, \"iteration\": 1624, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.062719638866838e-05, \"iteration\": 1625, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.7661241145106032e-05, \"iteration\": 1626, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.523365790490061e-05, \"iteration\": 1627, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011095964873675257, \"iteration\": 1628, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.187839633435942e-06, \"iteration\": 1629, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.715841780329356e-06, \"iteration\": 1630, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2852061445300933e-05, \"iteration\": 1631, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.8115862985723652e-05, \"iteration\": 1632, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.710090590582695e-06, \"iteration\": 1633, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.7788357581594028e-05, \"iteration\": 1634, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.356064765597694e-06, \"iteration\": 1635, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.46532038343139e-05, \"iteration\": 1636, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.0717849363572896e-05, \"iteration\": 1637, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.0324232789571397e-05, \"iteration\": 1638, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.4566731806553435e-05, \"iteration\": 1639, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.267479638045188e-05, \"iteration\": 1640, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.997043444949668e-06, \"iteration\": 1641, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.849829439190216e-06, \"iteration\": 1642, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.1530317098950036e-05, \"iteration\": 1643, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.651964551769197e-06, \"iteration\": 1644, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.9476883608149365e-05, \"iteration\": 1645, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.1601234291447327e-05, \"iteration\": 1646, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.0778991054394282e-05, \"iteration\": 1647, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.141903890646063e-06, \"iteration\": 1648, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.012466423679143e-06, \"iteration\": 1649, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.1180478395544924e-05, \"iteration\": 1650, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.9222845367039554e-05, \"iteration\": 1651, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.2263713617576286e-05, \"iteration\": 1652, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.4759052545705345e-06, \"iteration\": 1653, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.579215328703867e-06, \"iteration\": 1654, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.0406140063423663e-05, \"iteration\": 1655, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.951384658445022e-06, \"iteration\": 1656, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.1795862519647926e-05, \"iteration\": 1657, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.296028681797907e-06, \"iteration\": 1658, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.466778303438332e-05, \"iteration\": 1659, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.792092557996511e-06, \"iteration\": 1660, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.440430984686827e-06, \"iteration\": 1661, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.059947842615657e-06, \"iteration\": 1662, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.046232323977165e-06, \"iteration\": 1663, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.723839421989396e-06, \"iteration\": 1664, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.034416507347487e-06, \"iteration\": 1665, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.027705123618944e-06, \"iteration\": 1666, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.1726347111107316e-05, \"iteration\": 1667, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2973993761988822e-05, \"iteration\": 1668, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.776860340731218e-06, \"iteration\": 1669, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.854715709574521e-06, \"iteration\": 1670, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.5447570553515106e-05, \"iteration\": 1671, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.809523382689804e-05, \"iteration\": 1672, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.910355634521693e-06, \"iteration\": 1673, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2976061043445952e-05, \"iteration\": 1674, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.0587629731162451e-05, \"iteration\": 1675, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.322183930431493e-06, \"iteration\": 1676, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.0263408512400929e-05, \"iteration\": 1677, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.7692385881673545e-05, \"iteration\": 1678, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.52999309648294e-05, \"iteration\": 1679, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.957120548468083e-05, \"iteration\": 1680, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.722273716761265e-06, \"iteration\": 1681, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.483548021496972e-05, \"iteration\": 1682, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.7743213902576827e-05, \"iteration\": 1683, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.061496095644543e-05, \"iteration\": 1684, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.129345587803982e-06, \"iteration\": 1685, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.548448926769197e-05, \"iteration\": 1686, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.186186545965029e-05, \"iteration\": 1687, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.23456412035739e-06, \"iteration\": 1688, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.932181698473869e-06, \"iteration\": 1689, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.154173312708735e-06, \"iteration\": 1690, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.0285162463551387e-05, \"iteration\": 1691, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.9304094166727737e-05, \"iteration\": 1692, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.328872693004087e-06, \"iteration\": 1693, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2955070815223735e-05, \"iteration\": 1694, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.0969070899591316e-05, \"iteration\": 1695, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2996408258914016e-05, \"iteration\": 1696, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.626336239103694e-06, \"iteration\": 1697, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.353485787258251e-06, \"iteration\": 1698, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.231580068240874e-06, \"iteration\": 1699, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2538693226815667e-05, \"iteration\": 1700, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.4804872888780665e-06, \"iteration\": 1701, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.489187166560441e-06, \"iteration\": 1702, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.584390808304306e-06, \"iteration\": 1703, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.797489838092588e-06, \"iteration\": 1704, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.609375759580871e-06, \"iteration\": 1705, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.0287523764418438e-05, \"iteration\": 1706, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.7982852013083175e-06, \"iteration\": 1707, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.91529942539637e-06, \"iteration\": 1708, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.356310677801957e-06, \"iteration\": 1709, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.74147335201269e-05, \"iteration\": 1710, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.4398175305104814e-06, \"iteration\": 1711, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.995712283242028e-06, \"iteration\": 1712, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.234835614624899e-06, \"iteration\": 1713, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.1336060146713862e-06, \"iteration\": 1714, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.2449581744440366e-06, \"iteration\": 1715, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.2396679923986085e-05, \"iteration\": 1716, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.007885566650657e-05, \"iteration\": 1717, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.1216162420168985e-05, \"iteration\": 1718, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.671479928219924e-06, \"iteration\": 1719, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.164708454685751e-06, \"iteration\": 1720, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.8586035366752185e-05, \"iteration\": 1721, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.3733671949012205e-05, \"iteration\": 1722, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.612605026632082e-06, \"iteration\": 1723, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.0661887245078105e-05, \"iteration\": 1724, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.67624624131713e-06, \"iteration\": 1725, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.121406840975396e-06, \"iteration\": 1726, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.063936547841877e-06, \"iteration\": 1727, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.157618478639051e-06, \"iteration\": 1728, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.1548252587090246e-05, \"iteration\": 1729, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.313267138262745e-06, \"iteration\": 1730, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.210828360053711e-06, \"iteration\": 1731, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.334279649105156e-06, \"iteration\": 1732, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.4515686568047386e-06, \"iteration\": 1733, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.36791106039891e-06, \"iteration\": 1734, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.816674719331786e-06, \"iteration\": 1735, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.6424726456752978e-05, \"iteration\": 1736, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.834535037749447e-06, \"iteration\": 1737, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.240631824359298e-06, \"iteration\": 1738, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.562044235470239e-05, \"iteration\": 1739, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.557215445151087e-06, \"iteration\": 1740, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.466990842251107e-06, \"iteration\": 1741, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.1047364902624395e-06, \"iteration\": 1742, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.893087968113832e-06, \"iteration\": 1743, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.455905455979519e-06, \"iteration\": 1744, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2041285117447842e-05, \"iteration\": 1745, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.16272234058124e-06, \"iteration\": 1746, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.352883363229921e-06, \"iteration\": 1747, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.9618943194218446e-06, \"iteration\": 1748, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.293433893413749e-06, \"iteration\": 1749, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.000400157470722e-06, \"iteration\": 1750, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.266427696275059e-06, \"iteration\": 1751, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.1027085747628007e-05, \"iteration\": 1752, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.692094186495524e-06, \"iteration\": 1753, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.636412202467909e-06, \"iteration\": 1754, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2947554751008283e-05, \"iteration\": 1755, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.499181952473009e-06, \"iteration\": 1756, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.467728442454245e-06, \"iteration\": 1757, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.430042842315743e-06, \"iteration\": 1758, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.03098112353473e-06, \"iteration\": 1759, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.944041499285959e-06, \"iteration\": 1760, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.1728345574229024e-06, \"iteration\": 1761, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.816393927991157e-06, \"iteration\": 1762, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.934416655392852e-06, \"iteration\": 1763, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.017761501832865e-06, \"iteration\": 1764, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2889660865766928e-05, \"iteration\": 1765, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2166953638370614e-05, \"iteration\": 1766, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.535064246942056e-06, \"iteration\": 1767, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.384610969689675e-06, \"iteration\": 1768, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.053745553595945e-06, \"iteration\": 1769, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.660339856054634e-06, \"iteration\": 1770, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.490961929259356e-06, \"iteration\": 1771, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.745929461729247e-06, \"iteration\": 1772, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.6123587960901204e-06, \"iteration\": 1773, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.859600711730309e-06, \"iteration\": 1774, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.9189136512286495e-06, \"iteration\": 1775, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.338348728400888e-06, \"iteration\": 1776, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.311367203830741e-06, \"iteration\": 1777, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.452738827851135e-06, \"iteration\": 1778, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.280648216896225e-06, \"iteration\": 1779, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.105023774376605e-06, \"iteration\": 1780, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# POC\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models/hr')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    "    \n",
    ")\n",
    "\n",
    "dataloader = DataLoader(train_data_nn, batch_size=128, shuffle=True)\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(tfidf_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "if (models_dir / 'model_nn.pt').exists() and USE_CACHE:\n",
    "    model_nn = load_model(model_nn, models_dir, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn, models_dir, \"model_nn\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # X_test = torch.stack([dta[0] for dta in test])\n",
    "    X_test = torch.stack([test[0] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_test = torch.stack([test[1] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_pred = model_nn.predict(X_test)\n",
    "\n",
    "\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='binary'))\n",
    "print(\"AUC\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 178/178 [00:04<00:00, 40.90batch/s, batch_accuracy=0.829, loss=0.379]\n",
      "Epoch 2: 100%|██████████| 178/178 [00:04<00:00, 43.08batch/s, batch_accuracy=0.854, loss=0.39] \n",
      "Epoch 3: 100%|██████████| 178/178 [00:03<00:00, 45.38batch/s, batch_accuracy=1, loss=0.0505]    \n",
      "Epoch 4: 100%|██████████| 178/178 [00:03<00:00, 45.41batch/s, batch_accuracy=1, loss=0.00856]   \n",
      "Epoch 5: 100%|██████████| 178/178 [00:03<00:00, 45.77batch/s, batch_accuracy=1, loss=0.000763]  \n",
      "Epoch 6: 100%|██████████| 178/178 [00:03<00:00, 44.68batch/s, batch_accuracy=1, loss=0.000177]\n",
      "Epoch 7: 100%|██████████| 178/178 [00:03<00:00, 45.26batch/s, batch_accuracy=1, loss=0.000114]\n",
      "Epoch 8: 100%|██████████| 178/178 [00:03<00:00, 44.82batch/s, batch_accuracy=1, loss=6.93e-6]\n",
      "Epoch 9: 100%|██████████| 178/178 [00:03<00:00, 46.40batch/s, batch_accuracy=1, loss=4.07e-6]\n",
      "Epoch 10: 100%|██████████| 178/178 [00:04<00:00, 42.50batch/s, batch_accuracy=1, loss=1.85e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6993006993006993, 0.6164685160722149, 0.6552773227240815, None)\n",
      "AUC 0.7191018920307773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-5cefe7d0c5be43e38ddea49406681d2b.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-5cefe7d0c5be43e38ddea49406681d2b.vega-embed details,\n",
       "  #altair-viz-5cefe7d0c5be43e38ddea49406681d2b.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-5cefe7d0c5be43e38ddea49406681d2b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-5cefe7d0c5be43e38ddea49406681d2b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-5cefe7d0c5be43e38ddea49406681d2b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-5b7f9fc73c894701015c680c7e6b9869\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-5b7f9fc73c894701015c680c7e6b9869\": [{\"training_acc\": 0.6640625, \"training_loss\": 0.6780085563659668, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6768420338630676, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6735678911209106, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6743767261505127, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6767634749412537, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6654707193374634, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.6511456966400146, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6591202616691589, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6707132458686829, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.6364620923995972, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.6213477849960327, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6575256586074829, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6396504044532776, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6288814544677734, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6167224645614624, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6408325433731079, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.649499237537384, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.622459352016449, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6140987277030945, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6195507645606995, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.617131233215332, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.701630175113678, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6640921831130981, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6188135147094727, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5730446577072144, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6752681732177734, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6221826076507568, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6159265637397766, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.7019888758659363, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.656926691532135, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6383747458457947, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6781967878341675, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6078487038612366, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6404650807380676, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6368105411529541, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6305892467498779, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6679816246032715, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6328608393669128, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6289525032043457, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.648976743221283, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6326887011528015, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6549414992332458, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6130273342132568, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6076087951660156, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6446691751480103, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6100451350212097, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6055775880813599, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6517881155014038, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.6093719005584717, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.603334367275238, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6356286406517029, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.6560418009757996, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6305307745933533, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5556337237358093, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6104011535644531, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6025745272636414, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.5546875, \"training_loss\": 0.6609188914299011, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6179179549217224, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6543079614639282, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.572239339351654, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6007870435714722, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5750007629394531, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6210430860519409, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6143684983253479, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6270832419395447, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.5762253403663635, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5724287033081055, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6112310886383057, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.5815227031707764, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6036173701286316, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5357735753059387, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5832648277282715, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5533877015113831, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.5830666422843933, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5328835844993591, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.533553957939148, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5753910541534424, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5353620052337646, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5881386399269104, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5465203523635864, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6389037370681763, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5436322689056396, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5377653241157532, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.5918754935264587, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5523379445075989, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5321546196937561, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5461158752441406, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.512418806552887, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5192673206329346, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5441502332687378, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5665728449821472, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5274695158004761, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5032734870910645, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.8671875, \"training_loss\": 0.44772782921791077, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.6228347420692444, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.554991602897644, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5041790008544922, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4336079955101013, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.505038857460022, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5742835998535156, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5275536775588989, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.529514491558075, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.532279372215271, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5192263722419739, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5109020471572876, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.48329460620880127, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5809253454208374, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4743199348449707, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.5147867202758789, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4779735803604126, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.516207754611969, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5754103660583496, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4938686490058899, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.49876242876052856, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5254567265510559, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5130094289779663, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.501545250415802, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4650953412055969, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4543173015117645, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5204569101333618, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5279383659362793, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.503808856010437, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5159088373184204, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4784608781337738, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5109741687774658, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5201870799064636, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.46845686435699463, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.532585859298706, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.4724189341068268, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.41890212893486023, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4911764860153198, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4623399078845978, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.48333269357681274, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.48618045449256897, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4519428610801697, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4491860270500183, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4689963459968567, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.48059576749801636, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4121565818786621, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4715160131454468, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.47383034229278564, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5119677782058716, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4869022071361542, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4447629153728485, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5030699372291565, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.498348206281662, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.8828125, \"training_loss\": 0.4229026734828949, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4312766492366791, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.45721766352653503, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.45169493556022644, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4357496201992035, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.49825072288513184, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.417906790971756, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.47879916429519653, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4775999188423157, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4295883774757385, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.46432849764823914, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4423157572746277, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5259842872619629, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.472108393907547, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5253908634185791, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4608071446418762, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.49027031660079956, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4878372848033905, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4576750099658966, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5783264636993408, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.41753870248794556, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.49311915040016174, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.48706942796707153, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4680604636669159, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.44573795795440674, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4577048420906067, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.43376514315605164, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4753066897392273, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4680798649787903, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4090171754360199, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.47130250930786133, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.8292682926829268, \"training_loss\": 0.3788113594055176, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30762213468551636, \"iteration\": 179, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23251131176948547, \"iteration\": 180, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2466234564781189, \"iteration\": 181, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2861703932285309, \"iteration\": 182, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23186375200748444, \"iteration\": 183, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3130055069923401, \"iteration\": 184, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3123072683811188, \"iteration\": 185, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.1999734789133072, \"iteration\": 186, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.301103800535202, \"iteration\": 187, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24995145201683044, \"iteration\": 188, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.27050721645355225, \"iteration\": 189, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2618778645992279, \"iteration\": 190, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3408008813858032, \"iteration\": 191, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3131396770477295, \"iteration\": 192, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23634196817874908, \"iteration\": 193, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.23757360875606537, \"iteration\": 194, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20038513839244843, \"iteration\": 195, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2777567207813263, \"iteration\": 196, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.30645936727523804, \"iteration\": 197, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23504750430583954, \"iteration\": 198, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31691139936447144, \"iteration\": 199, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.2016889601945877, \"iteration\": 200, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.2044805884361267, \"iteration\": 201, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2594461739063263, \"iteration\": 202, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2315060943365097, \"iteration\": 203, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.21011391282081604, \"iteration\": 204, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2157442271709442, \"iteration\": 205, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3039382994174957, \"iteration\": 206, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.27115872502326965, \"iteration\": 207, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2417353391647339, \"iteration\": 208, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.22319191694259644, \"iteration\": 209, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2735060453414917, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.26976278424263, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2355821430683136, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2818114757537842, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.26664990186691284, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.25973039865493774, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.16396842896938324, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.43538692593574524, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3079898953437805, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.96875, \"training_loss\": 0.2152455449104309, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.23931632936000824, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24351713061332703, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.181778222322464, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2677547335624695, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2804650664329529, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2617712616920471, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2517412006855011, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2735033333301544, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.21895380318164825, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3150629699230194, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2955445945262909, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2591816186904907, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3402974307537079, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21278700232505798, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.28294894099235535, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2768162488937378, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2550926208496094, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.287422776222229, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2557051479816437, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24444176256656647, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2491677701473236, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23162567615509033, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.32650065422058105, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22986480593681335, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20662909746170044, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22367936372756958, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23810051381587982, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30597978830337524, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2554989457130432, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.22096708416938782, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1833791732788086, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2393573820590973, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2879045009613037, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.96875, \"training_loss\": 0.16145017743110657, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.28117266297340393, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2331727147102356, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1860344409942627, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23204723000526428, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29567068815231323, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.23983898758888245, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2730753421783447, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2644452452659607, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.23651540279388428, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26264962553977966, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2604038417339325, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2217857986688614, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.27210357785224915, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1650160700082779, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.21620109677314758, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3759901523590088, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2903980016708374, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2598881423473358, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26313409209251404, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19751861691474915, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24636563658714294, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17606091499328613, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.19973748922348022, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2685280442237854, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.29233595728874207, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3497903347015381, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.19589872658252716, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.25641512870788574, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31103044748306274, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2629525661468506, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.19241827726364136, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3368107080459595, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.21357350051403046, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23624904453754425, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.26633232831954956, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.26619428396224976, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3218894600868225, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2358706146478653, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21456143260002136, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2216532975435257, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2615352272987366, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2820560932159424, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3771620988845825, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2250688374042511, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.25264155864715576, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3059644103050232, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19946815073490143, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23885129392147064, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17911851406097412, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19342853128910065, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.26947540044784546, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3352614641189575, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2847500443458557, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2439248412847519, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3273093104362488, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20619550347328186, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.29461026191711426, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3009483516216278, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2968139052391052, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.2157517969608307, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3303073048591614, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2738669514656067, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2895858585834503, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20507684350013733, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.27585166692733765, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.32831093668937683, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3548339009284973, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.33102530241012573, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.1944776028394699, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3786833882331848, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21198102831840515, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3259640336036682, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.22925500571727753, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.35329559445381165, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.25089317560195923, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2772734761238098, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.23421156406402588, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.33560270071029663, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.25888124108314514, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.36803537607192993, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.19856519997119904, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2609098255634308, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.20513848960399628, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31582799553871155, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24514810740947723, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2661897540092468, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3118637800216675, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.278249055147171, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2894054353237152, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23521879315376282, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21408329904079437, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.26538991928100586, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2704731822013855, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.377638578414917, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27493810653686523, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2770879566669464, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.25377559661865234, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.308657169342041, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.24366751313209534, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2608740031719208, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.25672096014022827, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22638961672782898, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.8536585365853658, \"training_loss\": 0.39024269580841064, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.96875, \"training_loss\": 0.11551183462142944, \"iteration\": 357, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10253449529409409, \"iteration\": 358, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12538138031959534, \"iteration\": 359, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10608133673667908, \"iteration\": 360, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08330504596233368, \"iteration\": 361, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.12209983915090561, \"iteration\": 362, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11891479790210724, \"iteration\": 363, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11168177425861359, \"iteration\": 364, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.058958642184734344, \"iteration\": 365, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08222515881061554, \"iteration\": 366, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10933215171098709, \"iteration\": 367, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16831740736961365, \"iteration\": 368, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.09268312156200409, \"iteration\": 369, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0873250961303711, \"iteration\": 370, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09555990248918533, \"iteration\": 371, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11373074352741241, \"iteration\": 372, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.070907361805439, \"iteration\": 373, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10847354680299759, \"iteration\": 374, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07642751932144165, \"iteration\": 375, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10856875032186508, \"iteration\": 376, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08515991270542145, \"iteration\": 377, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08992314338684082, \"iteration\": 378, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0647631585597992, \"iteration\": 379, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13190878927707672, \"iteration\": 380, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09531325101852417, \"iteration\": 381, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08185457438230515, \"iteration\": 382, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04064624756574631, \"iteration\": 383, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04016617685556412, \"iteration\": 384, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12466685473918915, \"iteration\": 385, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0902746170759201, \"iteration\": 386, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0461631715297699, \"iteration\": 387, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08409171551465988, \"iteration\": 388, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.16855239868164062, \"iteration\": 389, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07290694862604141, \"iteration\": 390, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08149480819702148, \"iteration\": 391, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07508731633424759, \"iteration\": 392, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04519199579954147, \"iteration\": 393, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09334772080183029, \"iteration\": 394, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1476389467716217, \"iteration\": 395, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.057849541306495667, \"iteration\": 396, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13511860370635986, \"iteration\": 397, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05599013715982437, \"iteration\": 398, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12754592299461365, \"iteration\": 399, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04834149777889252, \"iteration\": 400, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0639672502875328, \"iteration\": 401, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06751909106969833, \"iteration\": 402, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03456767275929451, \"iteration\": 403, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07178030908107758, \"iteration\": 404, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04994343966245651, \"iteration\": 405, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.13786602020263672, \"iteration\": 406, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.056423984467983246, \"iteration\": 407, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11117386817932129, \"iteration\": 408, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0822497308254242, \"iteration\": 409, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06700277328491211, \"iteration\": 410, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2059696614742279, \"iteration\": 411, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.058937810361385345, \"iteration\": 412, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06395843625068665, \"iteration\": 413, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.0999835804104805, \"iteration\": 414, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0546761229634285, \"iteration\": 415, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06464832276105881, \"iteration\": 416, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07645367830991745, \"iteration\": 417, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0615604892373085, \"iteration\": 418, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07259037345647812, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13929861783981323, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11130549013614655, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05855569988489151, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10345900803804398, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11451520025730133, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07470329850912094, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08790483325719833, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06901191174983978, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.04905834421515465, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06597399711608887, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08497471362352371, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08589839935302734, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.082309789955616, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07836758345365524, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039399728178977966, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11122988164424896, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08487042039632797, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10162333399057388, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11229727417230606, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09117434173822403, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07352092117071152, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08340057730674744, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07353010773658752, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06549061089754105, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05815663933753967, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.042670149356126785, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07894089072942734, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.039972081780433655, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09346193075180054, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07611486315727234, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07379031926393509, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05242294818162918, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.02704749070107937, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09865821897983551, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04442960023880005, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11435234546661377, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07016132026910782, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07328864932060242, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1277478039264679, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0746934711933136, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05244722217321396, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03492606803774834, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.02065519243478775, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03404725715517998, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05542287603020668, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06892071664333344, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09419059753417969, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09399369359016418, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.102817602455616, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.1367293894290924, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08799220621585846, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.062013257294893265, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09648972004652023, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08840135484933853, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1147056519985199, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0954878106713295, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.038058921694755554, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03701659291982651, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.085847869515419, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1365414410829544, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.061715953052043915, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08757330477237701, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06274642795324326, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.06598981469869614, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10051136463880539, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09962132573127747, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11429498344659805, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10390491783618927, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0969918817281723, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06730043888092041, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.060202933847904205, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07981136441230774, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054674454033374786, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.028716860339045525, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10204990208148956, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04651925712823868, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07102780789136887, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05098256468772888, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07259418070316315, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044369202107191086, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09096737205982208, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.041350074112415314, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05975266546010971, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08052381873130798, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.027092453092336655, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.0476488433778286, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05610509216785431, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04353489354252815, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11531176418066025, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12121139466762543, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07151490449905396, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08302298933267593, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04442794620990753, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06574107706546783, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05911031365394592, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07013826072216034, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08611176162958145, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12767939269542694, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12236500531435013, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04861082881689072, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.08672820776700974, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.0456467904150486, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09054543077945709, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07620727270841599, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0363922156393528, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0584007166326046, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.055622003972530365, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06865301728248596, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08238334953784943, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10757744312286377, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05088292062282562, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.038701772689819336, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.090629942715168, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.14245158433914185, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.050513673573732376, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.013932432979345322, \"iteration\": 535, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01939437910914421, \"iteration\": 536, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01649109646677971, \"iteration\": 537, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02144555374979973, \"iteration\": 538, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011062758043408394, \"iteration\": 539, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012031393125653267, \"iteration\": 540, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030055919662117958, \"iteration\": 541, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01107425894588232, \"iteration\": 542, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019114241003990173, \"iteration\": 543, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023437563329935074, \"iteration\": 544, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01694485917687416, \"iteration\": 545, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.04127724468708038, \"iteration\": 546, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025729838758707047, \"iteration\": 547, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023561302572488785, \"iteration\": 548, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01732005551457405, \"iteration\": 549, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008766341023147106, \"iteration\": 550, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012644370086491108, \"iteration\": 551, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020563477650284767, \"iteration\": 552, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04353068768978119, \"iteration\": 553, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011062787845730782, \"iteration\": 554, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03089573048055172, \"iteration\": 555, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012641607783734798, \"iteration\": 556, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010906841605901718, \"iteration\": 557, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00951871182769537, \"iteration\": 558, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025620291009545326, \"iteration\": 559, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012391380965709686, \"iteration\": 560, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02143099159002304, \"iteration\": 561, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005902111995965242, \"iteration\": 562, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.03762689605355263, \"iteration\": 563, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007650632876902819, \"iteration\": 564, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007937663234770298, \"iteration\": 565, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010875076986849308, \"iteration\": 566, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009008198976516724, \"iteration\": 567, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007707219570875168, \"iteration\": 568, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01813742332160473, \"iteration\": 569, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01804540306329727, \"iteration\": 570, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01040860265493393, \"iteration\": 571, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.017423877492547035, \"iteration\": 572, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.03081103228032589, \"iteration\": 573, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020745541900396347, \"iteration\": 574, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01186946127563715, \"iteration\": 575, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011082397773861885, \"iteration\": 576, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02098238095641136, \"iteration\": 577, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030037283897399902, \"iteration\": 578, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012165995314717293, \"iteration\": 579, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007540867663919926, \"iteration\": 580, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0085926977917552, \"iteration\": 581, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021345429122447968, \"iteration\": 582, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01052567083388567, \"iteration\": 583, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0442098006606102, \"iteration\": 584, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01600092276930809, \"iteration\": 585, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.02460630238056183, \"iteration\": 586, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006976127624511719, \"iteration\": 587, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005971824284642935, \"iteration\": 588, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007132277823984623, \"iteration\": 589, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03504101186990738, \"iteration\": 590, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008750870823860168, \"iteration\": 591, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01840353012084961, \"iteration\": 592, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006946390029042959, \"iteration\": 593, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02057058922946453, \"iteration\": 594, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012027110904455185, \"iteration\": 595, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012046458199620247, \"iteration\": 596, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.044936906546354294, \"iteration\": 597, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007220410741865635, \"iteration\": 598, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018970878794789314, \"iteration\": 599, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03241768106818199, \"iteration\": 600, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01907161809504032, \"iteration\": 601, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011697386391460896, \"iteration\": 602, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008789418265223503, \"iteration\": 603, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007506397552788258, \"iteration\": 604, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016444532200694084, \"iteration\": 605, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014435779303312302, \"iteration\": 606, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011544161476194859, \"iteration\": 607, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02242143265902996, \"iteration\": 608, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01390676386654377, \"iteration\": 609, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010261437855660915, \"iteration\": 610, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012411965057253838, \"iteration\": 611, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007832342758774757, \"iteration\": 612, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004919806960970163, \"iteration\": 613, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0035228447522968054, \"iteration\": 614, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023067133501172066, \"iteration\": 615, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011923509649932384, \"iteration\": 616, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009671784937381744, \"iteration\": 617, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.034018438309431076, \"iteration\": 618, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.027124252170324326, \"iteration\": 619, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0086257578805089, \"iteration\": 620, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012913210317492485, \"iteration\": 621, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005303729325532913, \"iteration\": 622, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0044786687940359116, \"iteration\": 623, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028342338278889656, \"iteration\": 624, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.020970676094293594, \"iteration\": 625, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028628451749682426, \"iteration\": 626, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.03496776521205902, \"iteration\": 627, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02306239679455757, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.022239455953240395, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01319821272045374, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.03179669380187988, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01875343546271324, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.013661811128258705, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026851436123251915, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005086051300168037, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01417059451341629, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.013954101130366325, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011414885520935059, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00460307439789176, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018611829727888107, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005166395101696253, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01477016881108284, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008119236677885056, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009568796493113041, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005573395639657974, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007485578767955303, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012389942072331905, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0055594597943127155, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006893489044159651, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008044781163334846, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.043624185025691986, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012116088531911373, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004571434576064348, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03421960398554802, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009810125455260277, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02316342666745186, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005375813692808151, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004975725896656513, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00756089435890317, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00836742389947176, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005384618882089853, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007810074836015701, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008621565997600555, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.003819077741354704, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007911060005426407, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006429804023355246, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008300223387777805, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004596453160047531, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016960233449935913, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028893636539578438, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02301635406911373, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0049406117759644985, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006849716417491436, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.013165834359824657, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.002972246380522847, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007539798505604267, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.019534658640623093, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05027524754405022, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006625643000006676, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0073816776275634766, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004737631417810917, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.018193742260336876, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0057374280877411366, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.013513215817511082, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009765783324837685, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0077177295461297035, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02303006872534752, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01933545432984829, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005748410243541002, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010108365677297115, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.016482124105095863, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0025711695197969675, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.002437429502606392, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02373475581407547, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005340563599020243, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012479152530431747, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0054097287356853485, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0037406235933303833, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0022304526064544916, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0064811804331839085, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006333433091640472, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009982222691178322, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.027602791786193848, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01124308817088604, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0070206718519330025, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01168772391974926, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008329484611749649, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004876567516475916, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005573820788413286, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0146427471190691, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012675033882260323, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008555063977837563, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0013425454962998629, \"iteration\": 713, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010496320901438594, \"iteration\": 714, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012377529637888074, \"iteration\": 715, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0030578426085412502, \"iteration\": 716, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017297491431236267, \"iteration\": 717, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00209160172380507, \"iteration\": 718, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001605079509317875, \"iteration\": 719, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002167356200516224, \"iteration\": 720, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014771823771297932, \"iteration\": 721, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0016199146630242467, \"iteration\": 722, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00201394222676754, \"iteration\": 723, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014137248508632183, \"iteration\": 724, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0020208421628922224, \"iteration\": 725, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017911687027662992, \"iteration\": 726, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017059092642739415, \"iteration\": 727, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0027429270558059216, \"iteration\": 728, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0016587164718657732, \"iteration\": 729, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012261562515050173, \"iteration\": 730, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015401736600324512, \"iteration\": 731, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015810256591066718, \"iteration\": 732, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001096600666642189, \"iteration\": 733, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001383552560582757, \"iteration\": 734, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.013488754630088806, \"iteration\": 735, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017239173175767064, \"iteration\": 736, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007095543551258743, \"iteration\": 737, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010104167740792036, \"iteration\": 738, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013579672668129206, \"iteration\": 739, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003694874932989478, \"iteration\": 740, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011309325927868485, \"iteration\": 741, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015904498286545277, \"iteration\": 742, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010879735928028822, \"iteration\": 743, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015228402335196733, \"iteration\": 744, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008990040514618158, \"iteration\": 745, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0016366880154237151, \"iteration\": 746, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.008743977174162865, \"iteration\": 747, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011103005381301045, \"iteration\": 748, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002805700758472085, \"iteration\": 749, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017633337993174791, \"iteration\": 750, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005525879678316414, \"iteration\": 751, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012958993902429938, \"iteration\": 752, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001166713424026966, \"iteration\": 753, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014115942176431417, \"iteration\": 754, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001282576355151832, \"iteration\": 755, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011774646118283272, \"iteration\": 756, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007892484427429736, \"iteration\": 757, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009301324607804418, \"iteration\": 758, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0016399812884628773, \"iteration\": 759, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010128201683983207, \"iteration\": 760, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014870158629491925, \"iteration\": 761, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0020592552609741688, \"iteration\": 762, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008824241231195629, \"iteration\": 763, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006638468476012349, \"iteration\": 764, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009139775647781789, \"iteration\": 765, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009910429362207651, \"iteration\": 766, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001530548557639122, \"iteration\": 767, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005140705616213381, \"iteration\": 768, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007204331341199577, \"iteration\": 769, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002081027952954173, \"iteration\": 770, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006113765994086862, \"iteration\": 771, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001037602429278195, \"iteration\": 772, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004743789613712579, \"iteration\": 773, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009555637952871621, \"iteration\": 774, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008060703985393047, \"iteration\": 775, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.009345024824142456, \"iteration\": 776, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009301324025727808, \"iteration\": 777, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008003676775842905, \"iteration\": 778, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010248831240460277, \"iteration\": 779, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003060033079236746, \"iteration\": 780, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012375470250844955, \"iteration\": 781, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009527087677270174, \"iteration\": 782, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005093994550406933, \"iteration\": 783, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007501862710341811, \"iteration\": 784, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009440838475711644, \"iteration\": 785, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010621200781315565, \"iteration\": 786, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015170531114563346, \"iteration\": 787, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007817663718014956, \"iteration\": 788, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017339012119919062, \"iteration\": 789, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010152101749554276, \"iteration\": 790, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007655154331587255, \"iteration\": 791, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009725907002575696, \"iteration\": 792, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0020056075882166624, \"iteration\": 793, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00036859227111563087, \"iteration\": 794, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0035945733543485403, \"iteration\": 795, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010214392095804214, \"iteration\": 796, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010790550149977207, \"iteration\": 797, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00043512776028364897, \"iteration\": 798, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0003926868666894734, \"iteration\": 799, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0021337803918868303, \"iteration\": 800, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011530559277161956, \"iteration\": 801, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011901191901415586, \"iteration\": 802, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005113552324473858, \"iteration\": 803, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012007527984678745, \"iteration\": 804, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007785710622556508, \"iteration\": 805, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005257095326669514, \"iteration\": 806, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008569212513975799, \"iteration\": 807, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005208892398513854, \"iteration\": 808, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000999981421045959, \"iteration\": 809, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000615613185800612, \"iteration\": 810, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006994704599492252, \"iteration\": 811, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006079307640902698, \"iteration\": 812, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008791706641204655, \"iteration\": 813, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000861735490616411, \"iteration\": 814, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00045309137203730643, \"iteration\": 815, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000524704868439585, \"iteration\": 816, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014334743609651923, \"iteration\": 817, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005013460176996887, \"iteration\": 818, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001131268683820963, \"iteration\": 819, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004823175841011107, \"iteration\": 820, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015453995438292623, \"iteration\": 821, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0016367016360163689, \"iteration\": 822, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001022657728753984, \"iteration\": 823, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005473374621942639, \"iteration\": 824, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013899479527026415, \"iteration\": 825, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006000713910907507, \"iteration\": 826, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002764383563771844, \"iteration\": 827, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005928129539825022, \"iteration\": 828, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009500090964138508, \"iteration\": 829, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004728045896627009, \"iteration\": 830, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004933233140036464, \"iteration\": 831, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007398021407425404, \"iteration\": 832, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004430752887856215, \"iteration\": 833, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005586927873082459, \"iteration\": 834, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001430262578651309, \"iteration\": 835, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006011213408783078, \"iteration\": 836, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013316075783222914, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008823095704428852, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012110654497519135, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00047087896382436156, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004954969044774771, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000833706057164818, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001032154425047338, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00038878273335285485, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007308312342502177, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001347260200418532, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009229859570041299, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008394299657084048, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006940141320228577, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0003983770147897303, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007148880395106971, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007239641854539514, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004786026256624609, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000982346129603684, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008768498664721847, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004072697483934462, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012982917251065373, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005627847276628017, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010761136654764414, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00034600653452798724, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.005306520964950323, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005829951260238886, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00040878975414671004, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005952257779426873, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005011913599446416, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004944375832565129, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006226669065654278, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00047385983634740114, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005447099101729691, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006925148190930486, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000545462709851563, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006389607442542911, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00034743742435239255, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000631568196695298, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0003350859915371984, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00029542375705204904, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005730832926928997, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006197728216648102, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.005400777794420719, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010027821408584714, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005944229196757078, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00029056298080831766, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0121392160654068, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005586763145402074, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00048062752466648817, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00019596122729126364, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007228032336570323, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0019111871952190995, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006663004169240594, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007633877685293555, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00025163861573673785, \"iteration\": 891, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00032246331102214754, \"iteration\": 892, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003005345934070647, \"iteration\": 893, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000340702390531078, \"iteration\": 894, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004561582172755152, \"iteration\": 895, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00032336119329556823, \"iteration\": 896, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006685454864054918, \"iteration\": 897, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00032480480149388313, \"iteration\": 898, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00023195835819933563, \"iteration\": 899, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003486817004159093, \"iteration\": 900, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005505577428266406, \"iteration\": 901, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005285803927108645, \"iteration\": 902, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002110554778482765, \"iteration\": 903, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000328743684804067, \"iteration\": 904, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000470998085802421, \"iteration\": 905, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005424129776656628, \"iteration\": 906, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00018270232249051332, \"iteration\": 907, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005424977862276137, \"iteration\": 908, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006463297759182751, \"iteration\": 909, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00021903900778852403, \"iteration\": 910, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00036129949148744345, \"iteration\": 911, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024959404254332185, \"iteration\": 912, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00026157897082157433, \"iteration\": 913, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00031584606040269136, \"iteration\": 914, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00021008214389439672, \"iteration\": 915, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00037505527143366635, \"iteration\": 916, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00044990377500653267, \"iteration\": 917, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002602440654300153, \"iteration\": 918, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002685803337953985, \"iteration\": 919, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003432024677749723, \"iteration\": 920, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003981940681114793, \"iteration\": 921, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024186829978134483, \"iteration\": 922, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00015437013644259423, \"iteration\": 923, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00019182285177521408, \"iteration\": 924, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00029173921211622655, \"iteration\": 925, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00034819295979104936, \"iteration\": 926, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004790604580193758, \"iteration\": 927, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00042369888979010284, \"iteration\": 928, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00020064278214704245, \"iteration\": 929, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00018160049512516707, \"iteration\": 930, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00027411652263253927, \"iteration\": 931, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001996175415115431, \"iteration\": 932, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005207447684369981, \"iteration\": 933, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00025396246928721666, \"iteration\": 934, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001600757968844846, \"iteration\": 935, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003907445352524519, \"iteration\": 936, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003555465373210609, \"iteration\": 937, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00040454542613588274, \"iteration\": 938, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004444505902938545, \"iteration\": 939, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00030438712565228343, \"iteration\": 940, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00020135845988988876, \"iteration\": 941, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002711168199311942, \"iteration\": 942, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001210568007081747, \"iteration\": 943, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002538642438594252, \"iteration\": 944, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00020475525525398552, \"iteration\": 945, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000243054426391609, \"iteration\": 946, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008811720181256533, \"iteration\": 947, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024091116210911423, \"iteration\": 948, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00041015667375177145, \"iteration\": 949, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00038585494621656835, \"iteration\": 950, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003012804954778403, \"iteration\": 951, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00027384821441955864, \"iteration\": 952, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00013735952961724252, \"iteration\": 953, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002583446621429175, \"iteration\": 954, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000299484352581203, \"iteration\": 955, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001677712716627866, \"iteration\": 956, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00031660503009334207, \"iteration\": 957, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00023817397595848888, \"iteration\": 958, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002437914808979258, \"iteration\": 959, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001963689283002168, \"iteration\": 960, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003364932199474424, \"iteration\": 961, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001980877568712458, \"iteration\": 962, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002107016189256683, \"iteration\": 963, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00019711806089617312, \"iteration\": 964, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002265215734951198, \"iteration\": 965, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002685414510779083, \"iteration\": 966, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001596086221979931, \"iteration\": 967, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00018415311933495104, \"iteration\": 968, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00016361982852686197, \"iteration\": 969, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00034362723818048835, \"iteration\": 970, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002848752774298191, \"iteration\": 971, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00023077586956787854, \"iteration\": 972, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00027448864420875907, \"iteration\": 973, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002181209420086816, \"iteration\": 974, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001618583919480443, \"iteration\": 975, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00017049734015017748, \"iteration\": 976, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00013098861381877214, \"iteration\": 977, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00017454651242587715, \"iteration\": 978, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00020845209655817598, \"iteration\": 979, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000253031263127923, \"iteration\": 980, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001983812835533172, \"iteration\": 981, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00013605479034595191, \"iteration\": 982, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00031840827432461083, \"iteration\": 983, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00032455555628985167, \"iteration\": 984, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003043975157197565, \"iteration\": 985, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00014994974480941892, \"iteration\": 986, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00015686276310589164, \"iteration\": 987, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00020917830988764763, \"iteration\": 988, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005074727814644575, \"iteration\": 989, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00040682480903342366, \"iteration\": 990, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00013243575813248754, \"iteration\": 991, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00018537869618739933, \"iteration\": 992, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004785656346939504, \"iteration\": 993, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00011178599379491061, \"iteration\": 994, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00023266048810910434, \"iteration\": 995, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00012008221528958529, \"iteration\": 996, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00022503883519675583, \"iteration\": 997, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00015523159527219832, \"iteration\": 998, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00018878004630096257, \"iteration\": 999, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00012314869672991335, \"iteration\": 1000, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002660204190760851, \"iteration\": 1001, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00021799711976200342, \"iteration\": 1002, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001632818893995136, \"iteration\": 1003, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00027542715542949736, \"iteration\": 1004, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000301017367746681, \"iteration\": 1005, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00018831448687706143, \"iteration\": 1006, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00019562558736652136, \"iteration\": 1007, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00013138336362317204, \"iteration\": 1008, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00013044524530414492, \"iteration\": 1009, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00018504602485336363, \"iteration\": 1010, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000247903197305277, \"iteration\": 1011, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001603729760972783, \"iteration\": 1012, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00039467806345783174, \"iteration\": 1013, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 8.794756286079064e-05, \"iteration\": 1014, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00012151089322287589, \"iteration\": 1015, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00014901557005941868, \"iteration\": 1016, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00036118453135713935, \"iteration\": 1017, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00011678395821945742, \"iteration\": 1018, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00013149678125046194, \"iteration\": 1019, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000523999915458262, \"iteration\": 1020, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 9.057448187377304e-05, \"iteration\": 1021, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00010943759843939915, \"iteration\": 1022, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00015283128595910966, \"iteration\": 1023, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 8.929190516937524e-05, \"iteration\": 1024, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00035393275902606547, \"iteration\": 1025, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00020409253193065524, \"iteration\": 1026, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 5.528513065655716e-05, \"iteration\": 1027, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00010583685070741922, \"iteration\": 1028, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00021328881848603487, \"iteration\": 1029, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00013871681585442275, \"iteration\": 1030, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00020829771528951824, \"iteration\": 1031, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024556685821153224, \"iteration\": 1032, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 8.753365545999259e-05, \"iteration\": 1033, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001706921320874244, \"iteration\": 1034, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00017241525347344577, \"iteration\": 1035, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00010308630589861423, \"iteration\": 1036, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001241929567186162, \"iteration\": 1037, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00013572639727499336, \"iteration\": 1038, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00020486145513132215, \"iteration\": 1039, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00022322763106785715, \"iteration\": 1040, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002610678493510932, \"iteration\": 1041, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 9.347741433884948e-05, \"iteration\": 1042, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00013196072541177273, \"iteration\": 1043, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00010088425187859684, \"iteration\": 1044, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00012633754522539675, \"iteration\": 1045, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002518304390832782, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 9.181143104797229e-05, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00014495171490125358, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00022643449483439326, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00015158086898736656, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002182902826461941, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 9.787268936634064e-05, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00016348724602721632, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00011188918142579496, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00012006468023173511, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002626668429002166, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00031672633485868573, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001789882662706077, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00015612918650731444, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00021151528926566243, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00017361623758915812, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 8.454158523818478e-05, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001881672942545265, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002421583340037614, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00021556823048740625, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00010324380855308846, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 7.773093966534361e-05, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00017726414080243558, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0001802376937121153, \"iteration\": 1069, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002479072427377105, \"iteration\": 1070, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010337613639421761, \"iteration\": 1071, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00018320574599783868, \"iteration\": 1072, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020705930364783853, \"iteration\": 1073, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.488419891567901e-05, \"iteration\": 1074, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010851868864847347, \"iteration\": 1075, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.134744712151587e-05, \"iteration\": 1076, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00014836589980404824, \"iteration\": 1077, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011518488463480026, \"iteration\": 1078, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001011436979752034, \"iteration\": 1079, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013248456525616348, \"iteration\": 1080, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012613004946615547, \"iteration\": 1081, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.384916534647346e-05, \"iteration\": 1082, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001461860811104998, \"iteration\": 1083, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.81878295331262e-05, \"iteration\": 1084, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.123295603785664e-05, \"iteration\": 1085, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001396776206092909, \"iteration\": 1086, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011781159992096946, \"iteration\": 1087, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.011581328697503e-05, \"iteration\": 1088, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010495650349184871, \"iteration\": 1089, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002038357633864507, \"iteration\": 1090, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012108418013667688, \"iteration\": 1091, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002204974734922871, \"iteration\": 1092, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.07811996107921e-05, \"iteration\": 1093, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001374515995848924, \"iteration\": 1094, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010057165491161868, \"iteration\": 1095, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.681663217023015e-05, \"iteration\": 1096, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.635869355406612e-05, \"iteration\": 1097, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.456954285269603e-05, \"iteration\": 1098, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.139486842788756e-05, \"iteration\": 1099, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00033503054874017835, \"iteration\": 1100, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.344963938114233e-05, \"iteration\": 1101, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.463383321417496e-05, \"iteration\": 1102, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002592343371361494, \"iteration\": 1103, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.62717318139039e-05, \"iteration\": 1104, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.391358616994694e-05, \"iteration\": 1105, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.598001634003595e-05, \"iteration\": 1106, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013032823335379362, \"iteration\": 1107, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.569583976874128e-05, \"iteration\": 1108, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000133041015942581, \"iteration\": 1109, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.738558295182884e-05, \"iteration\": 1110, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.087563765002415e-05, \"iteration\": 1111, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.185908179963008e-05, \"iteration\": 1112, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.337578376289457e-05, \"iteration\": 1113, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001606041332706809, \"iteration\": 1114, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.438907439587638e-05, \"iteration\": 1115, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.0746726881479844e-05, \"iteration\": 1116, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.814078657655045e-05, \"iteration\": 1117, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.015687101054937e-05, \"iteration\": 1118, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.105743861757219e-05, \"iteration\": 1119, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001602060510776937, \"iteration\": 1120, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.551637488882989e-05, \"iteration\": 1121, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00015313690528273582, \"iteration\": 1122, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012723346299026161, \"iteration\": 1123, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.874841346871108e-05, \"iteration\": 1124, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010888637916650623, \"iteration\": 1125, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.305339047685266e-05, \"iteration\": 1126, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.938066508155316e-05, \"iteration\": 1127, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010696807294152677, \"iteration\": 1128, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.7792774643749e-05, \"iteration\": 1129, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.612053741468117e-05, \"iteration\": 1130, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.228961425833404e-05, \"iteration\": 1131, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.009902376215905e-05, \"iteration\": 1132, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.904943049652502e-05, \"iteration\": 1133, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.801163206342608e-05, \"iteration\": 1134, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.172096568159759e-05, \"iteration\": 1135, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010295717947883531, \"iteration\": 1136, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.8152487326879054e-05, \"iteration\": 1137, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.259000706952065e-05, \"iteration\": 1138, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.095164619386196e-05, \"iteration\": 1139, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.472840323112905e-05, \"iteration\": 1140, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.202183431014419e-05, \"iteration\": 1141, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016790442168712616, \"iteration\": 1142, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00013287873298395425, \"iteration\": 1143, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00018438584811519831, \"iteration\": 1144, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.427877815440297e-05, \"iteration\": 1145, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.7983114200178534e-05, \"iteration\": 1146, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.065634468337521e-05, \"iteration\": 1147, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.868361379019916e-05, \"iteration\": 1148, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.206447819247842e-05, \"iteration\": 1149, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.9946040235226974e-05, \"iteration\": 1150, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.3840507462155074e-05, \"iteration\": 1151, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.4402549721999094e-05, \"iteration\": 1152, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.457018803805113e-05, \"iteration\": 1153, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.9929563829209656e-05, \"iteration\": 1154, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 2.8512331482488662e-05, \"iteration\": 1155, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 2.5180037482641637e-05, \"iteration\": 1156, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.208042032085359e-05, \"iteration\": 1157, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00012502304161898792, \"iteration\": 1158, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.132893369998783e-05, \"iteration\": 1159, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.497805149294436e-05, \"iteration\": 1160, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.656123539665714e-05, \"iteration\": 1161, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.676239015883766e-05, \"iteration\": 1162, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.800351548008621e-05, \"iteration\": 1163, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.765684232348576e-05, \"iteration\": 1164, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.494210538221523e-05, \"iteration\": 1165, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.4588257626164705e-05, \"iteration\": 1166, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 8.714517025509849e-05, \"iteration\": 1167, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.95441781822592e-05, \"iteration\": 1168, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011666520003927872, \"iteration\": 1169, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00018729132716543972, \"iteration\": 1170, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.991379192797467e-05, \"iteration\": 1171, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010651286720531061, \"iteration\": 1172, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.642632120521739e-05, \"iteration\": 1173, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 2.5428098524571396e-05, \"iteration\": 1174, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.13279230997432e-05, \"iteration\": 1175, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016968336421996355, \"iteration\": 1176, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.0073668312979862e-05, \"iteration\": 1177, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.30632644565776e-05, \"iteration\": 1178, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.340820254990831e-05, \"iteration\": 1179, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010514927271287888, \"iteration\": 1180, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.5398078984580934e-05, \"iteration\": 1181, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.603742415085435e-05, \"iteration\": 1182, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.225494871614501e-05, \"iteration\": 1183, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.152059020474553e-05, \"iteration\": 1184, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.505626126658171e-05, \"iteration\": 1185, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.128977111075073e-05, \"iteration\": 1186, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.2901479648426175e-05, \"iteration\": 1187, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.520364255877212e-05, \"iteration\": 1188, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.060118953930214e-05, \"iteration\": 1189, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.7427449569804594e-05, \"iteration\": 1190, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.86078890087083e-05, \"iteration\": 1191, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00014794408343732357, \"iteration\": 1192, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.6524113460909575e-05, \"iteration\": 1193, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 2.295248123118654e-05, \"iteration\": 1194, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.896976340911351e-05, \"iteration\": 1195, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001700653083389625, \"iteration\": 1196, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011497650120873004, \"iteration\": 1197, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.587234671926126e-05, \"iteration\": 1198, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.038864790345542e-05, \"iteration\": 1199, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.8109406381845474e-05, \"iteration\": 1200, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.2406893296865746e-05, \"iteration\": 1201, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.1927352615166456e-05, \"iteration\": 1202, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000258103187661618, \"iteration\": 1203, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016993253666441888, \"iteration\": 1204, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.912324220640585e-05, \"iteration\": 1205, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.40589283243753e-05, \"iteration\": 1206, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.39838253846392e-05, \"iteration\": 1207, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.1562979933805764e-05, \"iteration\": 1208, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.212458927417174e-05, \"iteration\": 1209, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011958936374867335, \"iteration\": 1210, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.5700522857951e-05, \"iteration\": 1211, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010484350059414282, \"iteration\": 1212, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.248204201459885e-05, \"iteration\": 1213, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 2.9240785806905478e-05, \"iteration\": 1214, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.16124486643821e-05, \"iteration\": 1215, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.9715086788637564e-05, \"iteration\": 1216, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.384162795962766e-05, \"iteration\": 1217, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.773545464966446e-05, \"iteration\": 1218, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.5687418858287856e-05, \"iteration\": 1219, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.705472671659663e-05, \"iteration\": 1220, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010347455099690706, \"iteration\": 1221, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.85296368424315e-05, \"iteration\": 1222, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001810378162190318, \"iteration\": 1223, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001296456321142614, \"iteration\": 1224, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.94781052111648e-05, \"iteration\": 1225, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.450459553278051e-05, \"iteration\": 1226, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.9705737435724586e-05, \"iteration\": 1227, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.540750033920631e-05, \"iteration\": 1228, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 9.70911278272979e-05, \"iteration\": 1229, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.565339183202013e-05, \"iteration\": 1230, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.120809899177402e-05, \"iteration\": 1231, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.496156932669692e-05, \"iteration\": 1232, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 7.247528992593288e-05, \"iteration\": 1233, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011178185377502814, \"iteration\": 1234, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.29184942226857e-05, \"iteration\": 1235, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.762963387998752e-05, \"iteration\": 1236, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.306243838276714e-05, \"iteration\": 1237, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00010409450624138117, \"iteration\": 1238, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.728997009806335e-05, \"iteration\": 1239, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 2.7149199013365433e-05, \"iteration\": 1240, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.30895563820377e-05, \"iteration\": 1241, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.9957448936766014e-05, \"iteration\": 1242, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 3.991746416431852e-05, \"iteration\": 1243, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 4.370516398921609e-05, \"iteration\": 1244, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 6.877554551465437e-05, \"iteration\": 1245, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00011417656787671149, \"iteration\": 1246, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 5.957404209766537e-05, \"iteration\": 1247, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.17057623155415e-05, \"iteration\": 1248, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.210270395153202e-05, \"iteration\": 1249, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.1971121390815824e-05, \"iteration\": 1250, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.0994338885648176e-05, \"iteration\": 1251, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.844925519544631e-05, \"iteration\": 1252, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.195288758841343e-05, \"iteration\": 1253, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.519683948776219e-05, \"iteration\": 1254, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.1870385757647455e-05, \"iteration\": 1255, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.061808456550352e-05, \"iteration\": 1256, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.163941725390032e-05, \"iteration\": 1257, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.1175186197506264e-05, \"iteration\": 1258, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.9010019716224633e-05, \"iteration\": 1259, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.000811193487607e-05, \"iteration\": 1260, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.184676097589545e-05, \"iteration\": 1261, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.214945536456071e-05, \"iteration\": 1262, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.514447447145358e-05, \"iteration\": 1263, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.7569865273544565e-05, \"iteration\": 1264, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.074349170783535e-05, \"iteration\": 1265, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.718834912229795e-05, \"iteration\": 1266, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.603811976267025e-05, \"iteration\": 1267, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.099169255932793e-05, \"iteration\": 1268, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.619196286308579e-05, \"iteration\": 1269, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.0038132030749694e-05, \"iteration\": 1270, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.062753239646554e-05, \"iteration\": 1271, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.8641130484174937e-05, \"iteration\": 1272, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.0274028176791035e-05, \"iteration\": 1273, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.955307329306379e-05, \"iteration\": 1274, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.934810203849338e-05, \"iteration\": 1275, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.077581302728504e-05, \"iteration\": 1276, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.6754434657050297e-05, \"iteration\": 1277, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.832940976484679e-05, \"iteration\": 1278, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.024042937089689e-05, \"iteration\": 1279, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.825205931207165e-05, \"iteration\": 1280, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.145755883655511e-05, \"iteration\": 1281, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.219767884525936e-05, \"iteration\": 1282, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.2294338123174384e-05, \"iteration\": 1283, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.9694549084524624e-05, \"iteration\": 1284, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.136870145681314e-05, \"iteration\": 1285, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.266319830203429e-05, \"iteration\": 1286, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.515614662319422e-05, \"iteration\": 1287, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.4251838112832047e-05, \"iteration\": 1288, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.2640295355813578e-05, \"iteration\": 1289, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.051920404890552e-05, \"iteration\": 1290, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.568517786334269e-05, \"iteration\": 1291, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.7224738005315885e-05, \"iteration\": 1292, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.5395310735329986e-05, \"iteration\": 1293, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.9216162147349678e-05, \"iteration\": 1294, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.1011941498727538e-05, \"iteration\": 1295, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.867567860055715e-05, \"iteration\": 1296, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.4674403903190978e-05, \"iteration\": 1297, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.5310073397122324e-05, \"iteration\": 1298, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.9835058739990927e-05, \"iteration\": 1299, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.964664185536094e-05, \"iteration\": 1300, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.0659619622165337e-05, \"iteration\": 1301, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.5855624699033797e-05, \"iteration\": 1302, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.1608284189132974e-05, \"iteration\": 1303, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.589137461152859e-05, \"iteration\": 1304, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.341296052094549e-05, \"iteration\": 1305, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.6417061235406436e-05, \"iteration\": 1306, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.834491740737576e-05, \"iteration\": 1307, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.6867015549214557e-05, \"iteration\": 1308, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.090216341661289e-05, \"iteration\": 1309, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.914506644126959e-05, \"iteration\": 1310, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.013665941078216e-05, \"iteration\": 1311, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.115349823521683e-05, \"iteration\": 1312, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.9105445719324052e-05, \"iteration\": 1313, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.4818080166587606e-05, \"iteration\": 1314, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.692864968092181e-05, \"iteration\": 1315, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.6106852854136378e-05, \"iteration\": 1316, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.5122927834454458e-05, \"iteration\": 1317, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.7100297302240506e-05, \"iteration\": 1318, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.6929064410505816e-05, \"iteration\": 1319, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.3261974749621004e-05, \"iteration\": 1320, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.315485082566738e-05, \"iteration\": 1321, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.574885936861392e-05, \"iteration\": 1322, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.983174297492951e-05, \"iteration\": 1323, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.4282642698381096e-05, \"iteration\": 1324, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.512086398899555e-05, \"iteration\": 1325, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.77197562152287e-05, \"iteration\": 1326, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 9.03990730876103e-05, \"iteration\": 1327, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.662417318788357e-05, \"iteration\": 1328, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.1284987926483154e-05, \"iteration\": 1329, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.234000178053975e-05, \"iteration\": 1330, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.9869088393752463e-05, \"iteration\": 1331, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.2796713892603293e-05, \"iteration\": 1332, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.1659410120046232e-05, \"iteration\": 1333, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.1697988207452e-05, \"iteration\": 1334, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.812677874113433e-05, \"iteration\": 1335, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.031768574146554e-05, \"iteration\": 1336, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.614496745285578e-05, \"iteration\": 1337, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.705131868831813e-05, \"iteration\": 1338, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.6846038963412866e-05, \"iteration\": 1339, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.600467117503285e-05, \"iteration\": 1340, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.0420884538907558e-05, \"iteration\": 1341, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.4399550966336392e-05, \"iteration\": 1342, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.9487422074889764e-05, \"iteration\": 1343, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.9806574932299554e-05, \"iteration\": 1344, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.3991444322746247e-05, \"iteration\": 1345, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.933796713477932e-05, \"iteration\": 1346, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.2824329789727926e-05, \"iteration\": 1347, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.543528509908356e-05, \"iteration\": 1348, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.692553870379925e-05, \"iteration\": 1349, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.6788475477369502e-05, \"iteration\": 1350, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.595486047444865e-05, \"iteration\": 1351, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.109199315076694e-05, \"iteration\": 1352, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.075772499665618e-05, \"iteration\": 1353, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.8683842426980846e-05, \"iteration\": 1354, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.50771645369241e-05, \"iteration\": 1355, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.324653491494246e-05, \"iteration\": 1356, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.916194196383003e-05, \"iteration\": 1357, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.403953294560779e-05, \"iteration\": 1358, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.3763798961008433e-05, \"iteration\": 1359, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.8975025998079218e-05, \"iteration\": 1360, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.4780857782170642e-05, \"iteration\": 1361, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.1264086171868257e-05, \"iteration\": 1362, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.445801485213451e-05, \"iteration\": 1363, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.068921068916097e-05, \"iteration\": 1364, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.1799416572321206e-05, \"iteration\": 1365, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.5335128409788013e-05, \"iteration\": 1366, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 5.992531805532053e-05, \"iteration\": 1367, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.2056847481289878e-05, \"iteration\": 1368, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.4022311916050967e-05, \"iteration\": 1369, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.469562918529846e-05, \"iteration\": 1370, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.602832500997465e-05, \"iteration\": 1371, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.8251597794005647e-05, \"iteration\": 1372, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.8172522181412205e-05, \"iteration\": 1373, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.2522953511506785e-05, \"iteration\": 1374, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.3014392607146874e-05, \"iteration\": 1375, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.724541238625534e-05, \"iteration\": 1376, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.2870977116108406e-05, \"iteration\": 1377, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.2891606931807473e-05, \"iteration\": 1378, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.657670019194484e-05, \"iteration\": 1379, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.6598973161308095e-05, \"iteration\": 1380, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.9848786653019488e-05, \"iteration\": 1381, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.882009696098976e-05, \"iteration\": 1382, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.580124419182539e-05, \"iteration\": 1383, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.1239950001472607e-05, \"iteration\": 1384, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.9099801647826098e-05, \"iteration\": 1385, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.183739318046719e-05, \"iteration\": 1386, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.94243964162888e-05, \"iteration\": 1387, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.2630953278858215e-05, \"iteration\": 1388, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 4.110757072339766e-05, \"iteration\": 1389, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.2945045455126092e-05, \"iteration\": 1390, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.1555480341485236e-05, \"iteration\": 1391, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.470127558102831e-05, \"iteration\": 1392, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 7.442671630997211e-05, \"iteration\": 1393, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.0983358151861466e-05, \"iteration\": 1394, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.4181176993588451e-05, \"iteration\": 1395, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.6865124052856117e-05, \"iteration\": 1396, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.832136149459984e-05, \"iteration\": 1397, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.42088772210991e-05, \"iteration\": 1398, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.6839663658174686e-05, \"iteration\": 1399, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.2579386748257093e-05, \"iteration\": 1400, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.859593769244384e-05, \"iteration\": 1401, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.4087434465182014e-05, \"iteration\": 1402, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.2681968150427565e-05, \"iteration\": 1403, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.559884135029279e-05, \"iteration\": 1404, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.728013376123272e-05, \"iteration\": 1405, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.0565138836682308e-05, \"iteration\": 1406, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.2320577045320533e-05, \"iteration\": 1407, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.046481313300319e-05, \"iteration\": 1408, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.0910725652356632e-05, \"iteration\": 1409, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.157710878236685e-05, \"iteration\": 1410, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.328283815382747e-05, \"iteration\": 1411, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.8885000574518926e-05, \"iteration\": 1412, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.44417172629619e-06, \"iteration\": 1413, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 3.590305641409941e-05, \"iteration\": 1414, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.725774387130514e-05, \"iteration\": 1415, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.5766627257107757e-05, \"iteration\": 1416, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.7122016288340092e-05, \"iteration\": 1417, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.0703111001930665e-05, \"iteration\": 1418, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.0845091057708487e-05, \"iteration\": 1419, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.939946014317684e-05, \"iteration\": 1420, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 8.432837603322696e-06, \"iteration\": 1421, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 1.0413010386400856e-05, \"iteration\": 1422, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.2351669031195343e-05, \"iteration\": 1423, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 6.934496013855096e-06, \"iteration\": 1424, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 2.0762503481819294e-05, \"iteration\": 1425, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.8627013560035266e-05, \"iteration\": 1426, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.957310269062873e-05, \"iteration\": 1427, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.803163806675002e-05, \"iteration\": 1428, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1153446394018829e-05, \"iteration\": 1429, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.0997813660651445e-05, \"iteration\": 1430, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.797921686375048e-05, \"iteration\": 1431, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.8033335183863528e-05, \"iteration\": 1432, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.5043749954202212e-05, \"iteration\": 1433, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.9288390831206925e-05, \"iteration\": 1434, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.099597466236446e-05, \"iteration\": 1435, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.4853982065687887e-05, \"iteration\": 1436, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.9755252651521005e-05, \"iteration\": 1437, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.406151113769738e-05, \"iteration\": 1438, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.0344300790166017e-05, \"iteration\": 1439, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.265199898625724e-05, \"iteration\": 1440, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.0512884728086647e-05, \"iteration\": 1441, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2503027392085642e-05, \"iteration\": 1442, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.287171421106905e-05, \"iteration\": 1443, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.3268603399628773e-05, \"iteration\": 1444, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.1291136363288388e-05, \"iteration\": 1445, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.8802655985346064e-05, \"iteration\": 1446, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.6842885088408366e-05, \"iteration\": 1447, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.928494364430662e-06, \"iteration\": 1448, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.0583014702424407e-05, \"iteration\": 1449, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.142814294842537e-06, \"iteration\": 1450, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.8107855794369243e-05, \"iteration\": 1451, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.0014699000748806e-05, \"iteration\": 1452, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7350217603961937e-05, \"iteration\": 1453, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.397225034656003e-05, \"iteration\": 1454, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3535096513805911e-05, \"iteration\": 1455, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.319640978181269e-05, \"iteration\": 1456, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.4662288776889909e-05, \"iteration\": 1457, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.888882409024518e-05, \"iteration\": 1458, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.084755578835029e-05, \"iteration\": 1459, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.175113518722355e-06, \"iteration\": 1460, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.2077347239246592e-05, \"iteration\": 1461, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.453860351030016e-06, \"iteration\": 1462, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.685157237981912e-06, \"iteration\": 1463, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.9002649423782714e-05, \"iteration\": 1464, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7934375136974268e-05, \"iteration\": 1465, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7745484001352452e-05, \"iteration\": 1466, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.0906420357059687e-05, \"iteration\": 1467, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.080784366233274e-06, \"iteration\": 1468, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.118380613566842e-06, \"iteration\": 1469, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.6839221643749624e-05, \"iteration\": 1470, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.98628638626542e-06, \"iteration\": 1471, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.0761198609543499e-05, \"iteration\": 1472, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.146500138333067e-06, \"iteration\": 1473, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.556390973040834e-05, \"iteration\": 1474, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.090639125322923e-05, \"iteration\": 1475, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.40063182497397e-06, \"iteration\": 1476, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.039435483107809e-05, \"iteration\": 1477, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.681200046732556e-05, \"iteration\": 1478, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.455803264136193e-06, \"iteration\": 1479, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.8914652173407376e-05, \"iteration\": 1480, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.0576289241726045e-05, \"iteration\": 1481, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1229623851249926e-05, \"iteration\": 1482, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.017938853299711e-06, \"iteration\": 1483, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2338605301920325e-05, \"iteration\": 1484, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2998897545912769e-05, \"iteration\": 1485, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7973359717871062e-05, \"iteration\": 1486, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3982759810460266e-05, \"iteration\": 1487, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.699744284967892e-06, \"iteration\": 1488, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.8219983252929524e-05, \"iteration\": 1489, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.58262535277754e-06, \"iteration\": 1490, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.01286262483336e-06, \"iteration\": 1491, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.735826299409382e-05, \"iteration\": 1492, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.103924311493756e-06, \"iteration\": 1493, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.127865617600037e-06, \"iteration\": 1494, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.394752507621888e-05, \"iteration\": 1495, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3074407434032764e-05, \"iteration\": 1496, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.069206160143949e-06, \"iteration\": 1497, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.32696116756415e-06, \"iteration\": 1498, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3336730262381025e-05, \"iteration\": 1499, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.6156300262082368e-05, \"iteration\": 1500, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.5633964469307102e-05, \"iteration\": 1501, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.089150469459128e-06, \"iteration\": 1502, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1517860912135802e-05, \"iteration\": 1503, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3265852430777159e-05, \"iteration\": 1504, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.083243296307046e-05, \"iteration\": 1505, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.077485290414188e-06, \"iteration\": 1506, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2239231182320509e-05, \"iteration\": 1507, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.531980034196749e-06, \"iteration\": 1508, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.715391231817193e-06, \"iteration\": 1509, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1692407497321256e-05, \"iteration\": 1510, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.6800558922986966e-06, \"iteration\": 1511, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.898401246260619e-06, \"iteration\": 1512, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.48374646314187e-06, \"iteration\": 1513, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.899620530020911e-06, \"iteration\": 1514, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.273253838007804e-05, \"iteration\": 1515, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.066684464807622e-05, \"iteration\": 1516, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.561709945643088e-06, \"iteration\": 1517, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1704754797392525e-05, \"iteration\": 1518, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.357795528951101e-05, \"iteration\": 1519, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.9826236894004978e-05, \"iteration\": 1520, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.7258890845114365e-06, \"iteration\": 1521, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2799515388906002e-05, \"iteration\": 1522, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1907097359653562e-05, \"iteration\": 1523, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.263329618785065e-06, \"iteration\": 1524, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.703033704980044e-06, \"iteration\": 1525, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.01459111951408e-06, \"iteration\": 1526, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.286128831969108e-06, \"iteration\": 1527, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.10157905309461e-06, \"iteration\": 1528, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3263251275930088e-05, \"iteration\": 1529, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2087636605428997e-05, \"iteration\": 1530, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.74273247164092e-06, \"iteration\": 1531, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.7088617823901586e-05, \"iteration\": 1532, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.806316949019674e-06, \"iteration\": 1533, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.4248683328332845e-05, \"iteration\": 1534, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.424678526353091e-06, \"iteration\": 1535, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1781437024183106e-05, \"iteration\": 1536, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.715280283562606e-06, \"iteration\": 1537, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.309248818870401e-05, \"iteration\": 1538, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.56186670716852e-06, \"iteration\": 1539, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.1489629438729025e-06, \"iteration\": 1540, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.6812459661159664e-06, \"iteration\": 1541, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.627032573509496e-06, \"iteration\": 1542, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.802091552846832e-06, \"iteration\": 1543, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.455920134205371e-06, \"iteration\": 1544, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.225390279723797e-06, \"iteration\": 1545, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.580685749213444e-06, \"iteration\": 1546, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.834748440567637e-06, \"iteration\": 1547, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.970497229805915e-06, \"iteration\": 1548, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.649135113751981e-06, \"iteration\": 1549, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.2118502127123065e-05, \"iteration\": 1550, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.729983397235628e-06, \"iteration\": 1551, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.5277710190275684e-05, \"iteration\": 1552, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.416296739393147e-06, \"iteration\": 1553, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.436050090182107e-05, \"iteration\": 1554, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.93659125722479e-06, \"iteration\": 1555, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.0071733413496986e-05, \"iteration\": 1556, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.43700251809787e-06, \"iteration\": 1557, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.38453423359897e-06, \"iteration\": 1558, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.398749064828735e-06, \"iteration\": 1559, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.80270591651788e-06, \"iteration\": 1560, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.0975552363088354e-06, \"iteration\": 1561, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.5269590221578255e-05, \"iteration\": 1562, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.50717743660789e-06, \"iteration\": 1563, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.451246918004472e-06, \"iteration\": 1564, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.9705816966015846e-06, \"iteration\": 1565, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.927047929319087e-06, \"iteration\": 1566, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.3562412277678959e-05, \"iteration\": 1567, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.590629108250141e-05, \"iteration\": 1568, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.560958460497204e-06, \"iteration\": 1569, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.907116014393978e-06, \"iteration\": 1570, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.289383352646837e-06, \"iteration\": 1571, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.865279268211452e-06, \"iteration\": 1572, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.228627742326353e-06, \"iteration\": 1573, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.412556780967861e-06, \"iteration\": 1574, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.976446689397562e-06, \"iteration\": 1575, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.923253643733915e-06, \"iteration\": 1576, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.122355221625185e-06, \"iteration\": 1577, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.744402758660726e-06, \"iteration\": 1578, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.71488500200212e-05, \"iteration\": 1579, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.159949715656694e-05, \"iteration\": 1580, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.5206363615288865e-06, \"iteration\": 1581, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 7.3086625889118295e-06, \"iteration\": 1582, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.358524165581912e-06, \"iteration\": 1583, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.091210560844047e-05, \"iteration\": 1584, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.1790501048380975e-05, \"iteration\": 1585, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.8909702703240328e-05, \"iteration\": 1586, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.499941941408906e-06, \"iteration\": 1587, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.993315087631345e-06, \"iteration\": 1588, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 9.530734132567886e-06, \"iteration\": 1589, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.758989911759272e-06, \"iteration\": 1590, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.478171720416867e-06, \"iteration\": 1591, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.01741305924952e-06, \"iteration\": 1592, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 5.171045359020354e-06, \"iteration\": 1593, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.544108378468081e-06, \"iteration\": 1594, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 8.188624633476138e-06, \"iteration\": 1595, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 2.7142330054630293e-06, \"iteration\": 1596, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 6.939890681678662e-06, \"iteration\": 1597, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.529445504886098e-06, \"iteration\": 1598, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.9863512029114645e-06, \"iteration\": 1599, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 3.891583673976129e-06, \"iteration\": 1600, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.039392479171511e-06, \"iteration\": 1601, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 4.065171196998563e-06, \"iteration\": 1602, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 1.112606332753785e-05, \"iteration\": 1603, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.446021638519596e-06, \"iteration\": 1604, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.6356714695575647e-05, \"iteration\": 1605, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.3120952644385397e-05, \"iteration\": 1606, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.5078475371410605e-05, \"iteration\": 1607, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.2531441825558431e-05, \"iteration\": 1608, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.829921752185328e-06, \"iteration\": 1609, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.9975861909624655e-06, \"iteration\": 1610, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.75884553452488e-06, \"iteration\": 1611, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.928180250222795e-06, \"iteration\": 1612, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.7046745546831517e-06, \"iteration\": 1613, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.6552776236931095e-06, \"iteration\": 1614, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.2837933657865506e-06, \"iteration\": 1615, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.5764705899055116e-06, \"iteration\": 1616, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.326131940819323e-06, \"iteration\": 1617, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.3396635949902702e-05, \"iteration\": 1618, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.479836545418948e-06, \"iteration\": 1619, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.43941144112614e-06, \"iteration\": 1620, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.682582352368627e-06, \"iteration\": 1621, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.315495516493684e-06, \"iteration\": 1622, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.866753887559753e-06, \"iteration\": 1623, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.834799256059341e-06, \"iteration\": 1624, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.3469291843648534e-05, \"iteration\": 1625, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.690957085695118e-06, \"iteration\": 1626, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.3808150874392595e-06, \"iteration\": 1627, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.196155027282657e-06, \"iteration\": 1628, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.898154086025897e-06, \"iteration\": 1629, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.0240374801214784e-06, \"iteration\": 1630, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.411874088982586e-06, \"iteration\": 1631, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.273099749407265e-06, \"iteration\": 1632, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.575150342134293e-06, \"iteration\": 1633, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.5833249563002028e-05, \"iteration\": 1634, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.604335910902591e-06, \"iteration\": 1635, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.4874364069328294e-06, \"iteration\": 1636, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.166743110545212e-06, \"iteration\": 1637, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.171323431975907e-06, \"iteration\": 1638, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.9747234293608926e-06, \"iteration\": 1639, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.274928298604209e-06, \"iteration\": 1640, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.448984666145407e-06, \"iteration\": 1641, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.4829582798702177e-06, \"iteration\": 1642, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.686060952328262e-06, \"iteration\": 1643, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.5511930289212614e-05, \"iteration\": 1644, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.869128588325111e-06, \"iteration\": 1645, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.303423793317052e-06, \"iteration\": 1646, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.9328759814670775e-06, \"iteration\": 1647, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.6938540688424837e-06, \"iteration\": 1648, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.6081200960325077e-06, \"iteration\": 1649, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.7767200562229846e-06, \"iteration\": 1650, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.182758741284488e-06, \"iteration\": 1651, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.168100607173983e-05, \"iteration\": 1652, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.814812316704774e-06, \"iteration\": 1653, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.998624379164539e-06, \"iteration\": 1654, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.822318947437452e-06, \"iteration\": 1655, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.922503881563898e-06, \"iteration\": 1656, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.334755769581534e-06, \"iteration\": 1657, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.8556071356433677e-06, \"iteration\": 1658, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.910598024958745e-06, \"iteration\": 1659, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.3151395554305054e-06, \"iteration\": 1660, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.377388217515545e-06, \"iteration\": 1661, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.378040441428311e-06, \"iteration\": 1662, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.6493034965824336e-06, \"iteration\": 1663, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.5985631257062778e-06, \"iteration\": 1664, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.81507413496729e-06, \"iteration\": 1665, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.635795448848512e-06, \"iteration\": 1666, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.0723495001439005e-06, \"iteration\": 1667, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.38363656232832e-06, \"iteration\": 1668, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.129064907625434e-06, \"iteration\": 1669, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.147370302438503e-06, \"iteration\": 1670, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.354335831318167e-06, \"iteration\": 1671, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.5309258237248287e-06, \"iteration\": 1672, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.417155418603215e-06, \"iteration\": 1673, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.752642780658789e-06, \"iteration\": 1674, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.397578206611797e-06, \"iteration\": 1675, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.729093694142648e-06, \"iteration\": 1676, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.7013427370548015e-06, \"iteration\": 1677, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.991539415437728e-06, \"iteration\": 1678, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.7459466309665004e-06, \"iteration\": 1679, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.490951818705071e-06, \"iteration\": 1680, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.0970103327708784e-06, \"iteration\": 1681, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.8210554344477714e-06, \"iteration\": 1682, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.619402716343757e-06, \"iteration\": 1683, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.8129115915144212e-06, \"iteration\": 1684, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.770138507912634e-06, \"iteration\": 1685, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.246499651751947e-06, \"iteration\": 1686, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.2307194740278646e-06, \"iteration\": 1687, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.9408759019133868e-06, \"iteration\": 1688, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.887840416107792e-06, \"iteration\": 1689, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.183350135164801e-06, \"iteration\": 1690, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.8582114737218944e-06, \"iteration\": 1691, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.869688720849808e-06, \"iteration\": 1692, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.2045054467744194e-06, \"iteration\": 1693, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.1785622266179416e-06, \"iteration\": 1694, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.847273885388859e-06, \"iteration\": 1695, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.522168172930833e-06, \"iteration\": 1696, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.481847554416163e-06, \"iteration\": 1697, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.4384265745757148e-06, \"iteration\": 1698, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.2906764317885973e-06, \"iteration\": 1699, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.052171334478771e-06, \"iteration\": 1700, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.167697170487372e-06, \"iteration\": 1701, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.278387799175107e-06, \"iteration\": 1702, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.7961435737088323e-06, \"iteration\": 1703, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.619450919562951e-06, \"iteration\": 1704, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.282781785354018e-06, \"iteration\": 1705, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.894653107432532e-06, \"iteration\": 1706, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.4784846977563575e-06, \"iteration\": 1707, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.1480369671044173e-06, \"iteration\": 1708, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.966694748669397e-06, \"iteration\": 1709, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.1291261873557232e-06, \"iteration\": 1710, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.601438493205933e-06, \"iteration\": 1711, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.474371513017104e-06, \"iteration\": 1712, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.5401124023337616e-06, \"iteration\": 1713, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.749262759811245e-06, \"iteration\": 1714, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.204483957437333e-06, \"iteration\": 1715, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.6931568299914943e-06, \"iteration\": 1716, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.283255748305237e-06, \"iteration\": 1717, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.796701093961019e-06, \"iteration\": 1718, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.084067313669948e-06, \"iteration\": 1719, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.1569688871968538e-06, \"iteration\": 1720, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.9457938833511434e-06, \"iteration\": 1721, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.421747467451496e-06, \"iteration\": 1722, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.6894540496869013e-06, \"iteration\": 1723, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.8588310669874772e-06, \"iteration\": 1724, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.700770998373628e-06, \"iteration\": 1725, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.905992007777968e-06, \"iteration\": 1726, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.3144158351205988e-06, \"iteration\": 1727, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.817626412048412e-06, \"iteration\": 1728, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.866077349812258e-06, \"iteration\": 1729, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.505797616933705e-06, \"iteration\": 1730, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.572170372644905e-06, \"iteration\": 1731, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.55966380488826e-06, \"iteration\": 1732, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.766222552163526e-06, \"iteration\": 1733, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.5767186596349347e-06, \"iteration\": 1734, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.415975814074045e-06, \"iteration\": 1735, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.9930251912446693e-06, \"iteration\": 1736, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.8961583236887236e-06, \"iteration\": 1737, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.3255251916416455e-06, \"iteration\": 1738, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.5059662220883183e-06, \"iteration\": 1739, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.916716534353327e-06, \"iteration\": 1740, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.523527877609013e-06, \"iteration\": 1741, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.7745658119092695e-06, \"iteration\": 1742, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.375199624628294e-06, \"iteration\": 1743, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.0002089513582177e-06, \"iteration\": 1744, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.178384420403745e-06, \"iteration\": 1745, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.506565230462002e-06, \"iteration\": 1746, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.4171032388694584e-06, \"iteration\": 1747, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.864647507929476e-06, \"iteration\": 1748, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.2026157441578107e-06, \"iteration\": 1749, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.840731667674845e-06, \"iteration\": 1750, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.7677798496151809e-06, \"iteration\": 1751, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.3933978354762075e-06, \"iteration\": 1752, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.72921533905901e-06, \"iteration\": 1753, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 4.382380666356767e-06, \"iteration\": 1754, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.349514478642959e-06, \"iteration\": 1755, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.6510249452039716e-06, \"iteration\": 1756, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.332163815794047e-06, \"iteration\": 1757, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.9947819863737095e-06, \"iteration\": 1758, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.0928127923980355e-06, \"iteration\": 1759, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.164089321217034e-06, \"iteration\": 1760, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.7263479321627528e-06, \"iteration\": 1761, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.2359622562362347e-06, \"iteration\": 1762, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.7944046198390424e-06, \"iteration\": 1763, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.6151044494326925e-06, \"iteration\": 1764, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.717696927196812e-06, \"iteration\": 1765, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.291445980517892e-06, \"iteration\": 1766, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.365851059948909e-06, \"iteration\": 1767, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.743607637967216e-06, \"iteration\": 1768, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.91370678396197e-06, \"iteration\": 1769, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.163023605651688e-06, \"iteration\": 1770, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.180098014534451e-06, \"iteration\": 1771, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.1632132554950658e-06, \"iteration\": 1772, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 6.843802111689001e-06, \"iteration\": 1773, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.9565969725808827e-06, \"iteration\": 1774, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 7.558152901765425e-06, \"iteration\": 1775, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.7979007174726576e-06, \"iteration\": 1776, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.6520075405423995e-06, \"iteration\": 1777, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 2.141128561561345e-06, \"iteration\": 1778, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 3.830316472885897e-06, \"iteration\": 1779, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 1.8467794689058792e-06, \"iteration\": 1780, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters finding\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models/hr')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    "    optimizer_params= {\"lr\": 0.0001, \"weight_decay\": 0.001, }\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(train_data_nn, batch_size=128, shuffle=True)\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(tfidf_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "if (models_dir / 'model_nn.pt').exists() and USE_CACHE:\n",
    "    model_nn = load_model(model_nn, models_dir, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn, models_dir, \"model_nn\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # X_test = torch.stack([dta[0] for dta in test])\n",
    "    X_test = torch.stack([test[0] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_test = torch.stack([test[1] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_pred = model_nn.predict(X_test)\n",
    "\n",
    "\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='binary'))\n",
    "print(\"AUC\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/178 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 178/178 [00:04<00:00, 41.99batch/s, batch_accuracy=0.793, loss=0.503]\n",
      "Epoch 2: 100%|██████████| 178/178 [00:04<00:00, 42.16batch/s, batch_accuracy=0.878, loss=0.294]\n",
      "Epoch 3: 100%|██████████| 178/178 [00:03<00:00, 44.68batch/s, batch_accuracy=0.976, loss=0.0952]\n",
      "Epoch 4: 100%|██████████| 178/178 [00:03<00:00, 46.00batch/s, batch_accuracy=1, loss=0.00309]   \n",
      "Epoch 5: 100%|██████████| 178/178 [00:04<00:00, 42.29batch/s, batch_accuracy=1, loss=0.00049]   \n",
      "Epoch 6: 100%|██████████| 178/178 [00:04<00:00, 44.43batch/s, batch_accuracy=1, loss=0.00024]   \n",
      "Epoch 7: 100%|██████████| 178/178 [00:04<00:00, 43.30batch/s, batch_accuracy=1, loss=0.000525]\n",
      "Epoch 8: 100%|██████████| 178/178 [00:03<00:00, 45.18batch/s, batch_accuracy=1, loss=0.000444]\n",
      "Epoch 9: 100%|██████████| 178/178 [00:04<00:00, 44.34batch/s, batch_accuracy=1, loss=0.000269]  \n",
      "Epoch 10: 100%|██████████| 178/178 [00:04<00:00, 44.14batch/s, batch_accuracy=1, loss=0.000201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6819457436856876, 0.6420079260237781, 0.6613744613290996, None)\n",
      "AUC 0.7203228851321141\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-93a1afd1a0b140a398c67508e0039e51.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-93a1afd1a0b140a398c67508e0039e51.vega-embed details,\n",
       "  #altair-viz-93a1afd1a0b140a398c67508e0039e51.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-93a1afd1a0b140a398c67508e0039e51\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-93a1afd1a0b140a398c67508e0039e51\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-93a1afd1a0b140a398c67508e0039e51\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-bcc88015c36c6722e07ccb286933f0ea\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-bcc88015c36c6722e07ccb286933f0ea\": [{\"training_acc\": 0.671875, \"training_loss\": 0.6879805326461792, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6857002973556519, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6854370832443237, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6824445128440857, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6810376048088074, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6753959059715271, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6739208698272705, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6835078001022339, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6749850511550903, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6722738146781921, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6773169636726379, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.675391674041748, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6587935090065002, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6649575233459473, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.6468526124954224, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.660949170589447, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6699128746986389, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6476341485977173, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6494215726852417, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6603684425354004, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.620766282081604, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6473394632339478, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6460914611816406, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6506587862968445, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6549453139305115, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6019519567489624, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6190205216407776, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5778743624687195, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6413164138793945, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6279481053352356, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.6005808115005493, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6435379385948181, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6469947099685669, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.677624523639679, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6149100065231323, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6185697317123413, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5811527371406555, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6096938848495483, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6294540762901306, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.5992143154144287, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6380339860916138, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6392988562583923, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6190146207809448, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5914004445075989, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6198894381523132, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.6586174964904785, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.56546950340271, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6426935195922852, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6042646169662476, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5757976174354553, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6179335117340088, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6417189240455627, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6399676203727722, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.5865889191627502, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6154625415802002, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6111013293266296, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.5234375, \"training_loss\": 0.6813843250274658, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5815289616584778, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6364720463752747, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6050029993057251, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.5740607976913452, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.5698891282081604, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.5835053324699402, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6067783236503601, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6093090772628784, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.561995804309845, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.5451053977012634, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.5901962518692017, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.5828405022621155, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 0.5707548260688782, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.5605103373527527, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.5820980072021484, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.5712466239929199, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.5895351767539978, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.5762161612510681, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.5858098268508911, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.5534186363220215, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.5561537742614746, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5437835454940796, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5016062259674072, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.5932989120483398, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6089812517166138, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5419564247131348, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.49448543787002563, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6309157013893127, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.549356997013092, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.5769870281219482, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5471574068069458, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5480526089668274, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5124079585075378, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5857369303703308, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5339268445968628, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5668922662734985, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5573936104774475, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5470346808433533, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5381692051887512, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5409573316574097, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5521146059036255, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5321835875511169, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.512986958026886, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5695494413375854, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5559412837028503, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5708033442497253, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5193420052528381, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.47615480422973633, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.5120720863342285, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5085012912750244, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4921409487724304, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5462684631347656, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5495367646217346, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.49419105052948, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5008677244186401, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4762980341911316, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4628506600856781, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5146554708480835, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.516945481300354, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6645795702934265, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5337940454483032, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.49046167731285095, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5351437330245972, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.5246938467025757, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.49811574816703796, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5968201756477356, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.501728355884552, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.5249836444854736, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.483148455619812, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5139099359512329, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.49746865034103394, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5343349575996399, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.511163055896759, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4782823622226715, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.48307642340660095, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.47216975688934326, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4981851577758789, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4491356611251831, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.43095117807388306, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.47034361958503723, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4371374845504761, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4752689003944397, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.43582457304000854, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.4190082848072052, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4844209551811218, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4837946891784668, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.44676071405410767, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.8671875, \"training_loss\": 0.39169949293136597, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.48059701919555664, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5242710709571838, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5110369324684143, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4484022855758667, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.45823246240615845, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4863681197166443, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5123136043548584, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.48039424419403076, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.48824459314346313, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.46442723274230957, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.42314767837524414, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.47972527146339417, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5162733197212219, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.43673378229141235, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.44512179493904114, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.45869722962379456, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.4075548052787781, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4758213758468628, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.4273988902568817, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5175207257270813, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4353259205818176, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4650024473667145, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5285820364952087, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.38353633880615234, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.4936808943748474, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4546566307544708, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.46499183773994446, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.46880796551704407, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4743387699127197, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4476777911186218, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4945472478866577, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5459662079811096, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.7926829268292683, \"training_loss\": 0.5031724572181702, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.90625, \"training_loss\": 0.34311673045158386, \"iteration\": 179, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2975848317146301, \"iteration\": 180, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.30938079953193665, \"iteration\": 181, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26240041851997375, \"iteration\": 182, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26469385623931885, \"iteration\": 183, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23902717232704163, \"iteration\": 184, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3276407718658447, \"iteration\": 185, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2900417149066925, \"iteration\": 186, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3369620144367218, \"iteration\": 187, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3077488839626312, \"iteration\": 188, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24122929573059082, \"iteration\": 189, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.26047050952911377, \"iteration\": 190, \"epoch\": 2}, {\"training_acc\": 0.9609375, \"training_loss\": 0.20999830961227417, \"iteration\": 191, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2752804756164551, \"iteration\": 192, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28376850485801697, \"iteration\": 193, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.26247677206993103, \"iteration\": 194, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2967473268508911, \"iteration\": 195, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2335902452468872, \"iteration\": 196, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.25297847390174866, \"iteration\": 197, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3758213222026825, \"iteration\": 198, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.30713385343551636, \"iteration\": 199, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.332444429397583, \"iteration\": 200, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3211740255355835, \"iteration\": 201, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3061550557613373, \"iteration\": 202, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3202446401119232, \"iteration\": 203, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2685753107070923, \"iteration\": 204, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2405955195426941, \"iteration\": 205, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2535632848739624, \"iteration\": 206, \"epoch\": 2}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16956594586372375, \"iteration\": 207, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2188044786453247, \"iteration\": 208, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2383909523487091, \"iteration\": 209, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2088940441608429, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2623336911201477, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2137606143951416, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2333146184682846, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2465495765209198, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24273166060447693, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2626284956932068, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.18587954342365265, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1984443962574005, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.33322015404701233, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24126103520393372, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.23807361721992493, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3343737721443176, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3093773424625397, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.29378625750541687, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2812834680080414, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2719906270503998, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.22622276842594147, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24986732006072998, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21930573880672455, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2952582538127899, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3329809010028839, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25533246994018555, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2586076259613037, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.25415635108947754, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.22817456722259521, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18406039476394653, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26874756813049316, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2523539960384369, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26574942469596863, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.9609375, \"training_loss\": 0.22983942925930023, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.96875, \"training_loss\": 0.15775354206562042, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.168275848031044, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20825766026973724, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21690453588962555, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26926037669181824, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2824268341064453, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22837761044502258, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23159614205360413, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2642483711242676, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2707335352897644, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.22644518315792084, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29865384101867676, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.21616998314857483, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3507061004638672, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24577929079532623, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20381012558937073, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.25851893424987793, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.207164004445076, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2648411989212036, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.32698553800582886, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.33680516481399536, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.26008978486061096, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.1942925751209259, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18185672163963318, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.26553016901016235, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21729765832424164, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.24534666538238525, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2138039916753769, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3181050419807434, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2112421840429306, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2825078070163727, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3341369330883026, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20768460631370544, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24118657410144806, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.20831625163555145, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27681389451026917, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.2991354167461395, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3127288222312927, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29665789008140564, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.20117802917957306, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27813616394996643, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2572212517261505, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2473376989364624, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2364763617515564, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.31024572253227234, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3077101707458496, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2770424485206604, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2632690668106079, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2352391630411148, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.35147830843925476, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.21871037781238556, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23950102925300598, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.30788689851760864, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3207547664642334, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.32402825355529785, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.25937411189079285, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.3027270436286926, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.30454498529434204, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23899249732494354, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.25853967666625977, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3439977765083313, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2743794322013855, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.245377779006958, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.953125, \"training_loss\": 0.19302092492580414, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2933947443962097, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23064936697483063, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.23458096385002136, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2664743959903717, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20175480842590332, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.29887229204177856, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.21482521295547485, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2802986204624176, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2888541519641876, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24399475753307343, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3241264820098877, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.25548309087753296, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28365689516067505, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2278735190629959, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2992246150970459, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2774369418621063, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28891247510910034, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.37258702516555786, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.28255942463874817, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.24565070867538452, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.9375, \"training_loss\": 0.2204306423664093, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2637125849723816, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.28287896513938904, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24669905006885529, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.36259210109710693, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.31843864917755127, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.2537028193473816, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.31299400329589844, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.27633607387542725, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3082576394081116, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2962597608566284, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29932811856269836, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.25806522369384766, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3401539921760559, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.921875, \"training_loss\": 0.23146627843379974, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3239484131336212, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24864141643047333, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3016161322593689, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.28925058245658875, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.3159348666667938, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.2841815948486328, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3421955108642578, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.30433210730552673, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22057150304317474, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.27779650688171387, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3449242115020752, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3901447653770447, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3069010376930237, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.33706188201904297, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2729431390762329, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3840691149234772, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.8780487804878049, \"training_loss\": 0.29403766989707947, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.9453125, \"training_loss\": 0.3520667552947998, \"iteration\": 357, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.11166417598724365, \"iteration\": 358, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15019309520721436, \"iteration\": 359, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.13057954609394073, \"iteration\": 360, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.12665213644504547, \"iteration\": 361, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08962862193584442, \"iteration\": 362, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10977190732955933, \"iteration\": 363, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1209971010684967, \"iteration\": 364, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10863970965147018, \"iteration\": 365, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07899683713912964, \"iteration\": 366, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.11058171838521957, \"iteration\": 367, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.09067884087562561, \"iteration\": 368, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10155487060546875, \"iteration\": 369, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.101156085729599, \"iteration\": 370, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.17338962852954865, \"iteration\": 371, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08164336532354355, \"iteration\": 372, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14159780740737915, \"iteration\": 373, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10032276809215546, \"iteration\": 374, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08408277481794357, \"iteration\": 375, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11231331527233124, \"iteration\": 376, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07958333194255829, \"iteration\": 377, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14062970876693726, \"iteration\": 378, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12679976224899292, \"iteration\": 379, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.14868676662445068, \"iteration\": 380, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10518152266740799, \"iteration\": 381, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0797155573964119, \"iteration\": 382, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09998467564582825, \"iteration\": 383, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12445223331451416, \"iteration\": 384, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.05518272519111633, \"iteration\": 385, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.056696802377700806, \"iteration\": 386, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08157513290643692, \"iteration\": 387, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07214683294296265, \"iteration\": 388, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07793556153774261, \"iteration\": 389, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07616288214921951, \"iteration\": 390, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07590105384588242, \"iteration\": 391, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04791904613375664, \"iteration\": 392, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.195511132478714, \"iteration\": 393, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07669589668512344, \"iteration\": 394, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12692613899707794, \"iteration\": 395, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08241213113069534, \"iteration\": 396, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10133661329746246, \"iteration\": 397, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08628935366868973, \"iteration\": 398, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10118748247623444, \"iteration\": 399, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.05897021293640137, \"iteration\": 400, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08659444004297256, \"iteration\": 401, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07097257673740387, \"iteration\": 402, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04215622320771217, \"iteration\": 403, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.08828315883874893, \"iteration\": 404, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09609390795230865, \"iteration\": 405, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14636166393756866, \"iteration\": 406, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08808765560388565, \"iteration\": 407, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11617600917816162, \"iteration\": 408, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06645287573337555, \"iteration\": 409, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.12923185527324677, \"iteration\": 410, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10183603316545486, \"iteration\": 411, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.046478260308504105, \"iteration\": 412, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12423798441886902, \"iteration\": 413, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08742962032556534, \"iteration\": 414, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10105840116739273, \"iteration\": 415, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11014515906572342, \"iteration\": 416, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.0883261039853096, \"iteration\": 417, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10871520638465881, \"iteration\": 418, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07651986926794052, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04045164957642555, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10064556449651718, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10303840786218643, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.050748541951179504, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.03488767147064209, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07827889919281006, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11750388890504837, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.09738573431968689, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1081206277012825, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05806426703929901, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0799204483628273, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1020369678735733, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11940834671258926, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08362777531147003, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06720466166734695, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0495079904794693, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.043965600430965424, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10045389086008072, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06720945239067078, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.09713149070739746, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04624249041080475, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07352020591497421, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06937813758850098, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.13524411618709564, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05556101351976395, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054733067750930786, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.0413699708878994, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.09209233522415161, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0809553787112236, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07445543259382248, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09105576574802399, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09531741589307785, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15354734659194946, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.06531883031129837, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11422789096832275, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09174424409866333, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08707201480865479, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12950760126113892, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.12220927327871323, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.044026438146829605, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07801923900842667, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04200896620750427, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05363257974386215, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06373948603868484, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11764920502901077, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08955243974924088, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10796042531728745, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08212998509407043, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04541562497615814, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05951644480228424, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.15126043558120728, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08768153190612793, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08136358857154846, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06526625156402588, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.09150318801403046, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07118897140026093, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.11289376020431519, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11049505323171616, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06413417309522629, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09929607063531876, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08527114987373352, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.06266133487224579, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09925291687250137, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03654799982905388, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08350566774606705, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.102598637342453, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.05697667598724365, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0945509672164917, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.11734390258789062, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10009448230266571, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1126670315861702, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05775574967265129, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08478913456201553, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054380062967538834, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046798884868621826, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06535220146179199, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.15003764629364014, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07800964266061783, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08188889920711517, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.049580059945583344, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.0944351851940155, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.15873733162879944, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.07940047979354858, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16040444374084473, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07388900965452194, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06632424145936966, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.10238602757453918, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040993668138980865, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08401112258434296, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09187056869268417, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07870087027549744, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10804126411676407, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.048967476934194565, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.10513752698898315, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09366319328546524, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.06923232972621918, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.06286515295505524, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07913915812969208, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08472716808319092, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.14456962049007416, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.96875, \"training_loss\": 0.1418556272983551, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06048394739627838, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15815161168575287, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04055719077587128, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07254800945520401, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07159540802240372, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.04385186359286308, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.060196224600076675, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.9609375, \"training_loss\": 0.11524426937103271, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.08264261484146118, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04297160729765892, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.984375, \"training_loss\": 0.07128836959600449, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07282496988773346, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.12966479361057281, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.975609756097561, \"training_loss\": 0.09522531926631927, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 1.0, \"training_loss\": 0.18920736014842987, \"iteration\": 535, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028249498456716537, \"iteration\": 536, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03194963186979294, \"iteration\": 537, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03467487171292305, \"iteration\": 538, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.027893459424376488, \"iteration\": 539, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.015210886485874653, \"iteration\": 540, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.016053250059485435, \"iteration\": 541, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05003403127193451, \"iteration\": 542, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02025499939918518, \"iteration\": 543, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012689760886132717, \"iteration\": 544, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.015421961434185505, \"iteration\": 545, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.038435254245996475, \"iteration\": 546, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03871770203113556, \"iteration\": 547, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02241521328687668, \"iteration\": 548, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.019841404631733894, \"iteration\": 549, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.031164169311523438, \"iteration\": 550, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03634130209684372, \"iteration\": 551, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.020456373691558838, \"iteration\": 552, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011838939040899277, \"iteration\": 553, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03493791073560715, \"iteration\": 554, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03218063339591026, \"iteration\": 555, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009121425449848175, \"iteration\": 556, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01553196832537651, \"iteration\": 557, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030337078496813774, \"iteration\": 558, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.033841170370578766, \"iteration\": 559, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.023034952580928802, \"iteration\": 560, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010138015262782574, \"iteration\": 561, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008378637954592705, \"iteration\": 562, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05122293531894684, \"iteration\": 563, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02202564850449562, \"iteration\": 564, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05604640394449234, \"iteration\": 565, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.013546565547585487, \"iteration\": 566, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0218794085085392, \"iteration\": 567, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03197179734706879, \"iteration\": 568, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03075186163187027, \"iteration\": 569, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01623929664492607, \"iteration\": 570, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.015863724052906036, \"iteration\": 571, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.02900739572942257, \"iteration\": 572, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008256860077381134, \"iteration\": 573, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010728204622864723, \"iteration\": 574, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.021770276129245758, \"iteration\": 575, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024073142558336258, \"iteration\": 576, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.043173547834157944, \"iteration\": 577, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006759553216397762, \"iteration\": 578, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.013539852574467659, \"iteration\": 579, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008269527927041054, \"iteration\": 580, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014677057042717934, \"iteration\": 581, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011663248762488365, \"iteration\": 582, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014819418080151081, \"iteration\": 583, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.015657851472496986, \"iteration\": 584, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010803893208503723, \"iteration\": 585, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010304968804121017, \"iteration\": 586, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.030611960217356682, \"iteration\": 587, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01234246976673603, \"iteration\": 588, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011821266263723373, \"iteration\": 589, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.017914291471242905, \"iteration\": 590, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005925070960074663, \"iteration\": 591, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01653474010527134, \"iteration\": 592, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005468884017318487, \"iteration\": 593, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009999092668294907, \"iteration\": 594, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01026780903339386, \"iteration\": 595, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032433148473501205, \"iteration\": 596, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020683662965893745, \"iteration\": 597, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010887700133025646, \"iteration\": 598, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.017620965838432312, \"iteration\": 599, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005468807648867369, \"iteration\": 600, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03586720675230026, \"iteration\": 601, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0076797776855528355, \"iteration\": 602, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006528419908136129, \"iteration\": 603, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.018122654408216476, \"iteration\": 604, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006336480379104614, \"iteration\": 605, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03767237067222595, \"iteration\": 606, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0034008047077804804, \"iteration\": 607, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006595962215214968, \"iteration\": 608, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01965305022895336, \"iteration\": 609, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.02176736481487751, \"iteration\": 610, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05319546163082123, \"iteration\": 611, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04942789301276207, \"iteration\": 612, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02299412526190281, \"iteration\": 613, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.003972627222537994, \"iteration\": 614, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008144190534949303, \"iteration\": 615, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01059754192829132, \"iteration\": 616, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.04124714061617851, \"iteration\": 617, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.016087982803583145, \"iteration\": 618, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00940487440675497, \"iteration\": 619, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010195582173764706, \"iteration\": 620, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.022687004879117012, \"iteration\": 621, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005164846312254667, \"iteration\": 622, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011617648415267467, \"iteration\": 623, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.036192163825035095, \"iteration\": 624, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.013916756957769394, \"iteration\": 625, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006506479810923338, \"iteration\": 626, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00693232798948884, \"iteration\": 627, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029336676001548767, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.024020137265324593, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011305464431643486, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02015218324959278, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005891674663871527, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007447529584169388, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00796104408800602, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009687678888440132, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07245035469532013, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006770602427423, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014196408912539482, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020314473658800125, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010407068766653538, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.04178372025489807, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008114578202366829, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.022199878469109535, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007556374650448561, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.052306707948446274, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01207567099481821, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.011270798742771149, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.018085317686200142, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.028706589713692665, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.05411974713206291, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0052053360268473625, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012995301745831966, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005929768085479736, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.028237348422408104, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.017328443005681038, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00900769978761673, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010559041053056717, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005887112580239773, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0040311627089977264, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005292932502925396, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.012942581437528133, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00989561341702938, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008330557495355606, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.012019125744700432, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03879367932677269, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004331004805862904, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.02867225371301174, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004892291035503149, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03815510869026184, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004064454231411219, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.01653698831796646, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006714183371514082, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.033611420542001724, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009159804321825504, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005419423338025808, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007172001525759697, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0079738674685359, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0329238586127758, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.017823433503508568, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.020624030381441116, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004317128099501133, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007949999533593655, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03181968256831169, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021146515384316444, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.015107106417417526, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.02140911854803562, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005699231289327145, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005359872244298458, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.013736482709646225, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009160052984952927, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.00904448889195919, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.009042801335453987, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.004440138582140207, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006274145096540451, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.007502900902181864, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014737402088940144, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025858361274003983, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.037946391850709915, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.006388988345861435, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.010105744004249573, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01919410564005375, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01573982834815979, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.008529064245522022, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.005043360870331526, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0031306748278439045, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.984375, \"training_loss\": 0.045148130506277084, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.0068286629393696785, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.003440698143094778, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.029308702796697617, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.014103228226304054, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021901577711105347, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.003091708989813924, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 1.0, \"training_loss\": 0.30917638540267944, \"iteration\": 713, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0025508697144687176, \"iteration\": 714, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0022177917417138815, \"iteration\": 715, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0029832858126610518, \"iteration\": 716, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002895795041695237, \"iteration\": 717, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0027578792069107294, \"iteration\": 718, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.005101627670228481, \"iteration\": 719, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017795313615351915, \"iteration\": 720, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0032136603258550167, \"iteration\": 721, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.004603331442922354, \"iteration\": 722, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0038586098235100508, \"iteration\": 723, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0033290786668658257, \"iteration\": 724, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003469617571681738, \"iteration\": 725, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.004481462761759758, \"iteration\": 726, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0027707424014806747, \"iteration\": 727, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.004745724145323038, \"iteration\": 728, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.004469251725822687, \"iteration\": 729, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002534350613132119, \"iteration\": 730, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003381065558642149, \"iteration\": 731, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002160947769880295, \"iteration\": 732, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.007200528401881456, \"iteration\": 733, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.005958179943263531, \"iteration\": 734, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00223248777911067, \"iteration\": 735, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015237316256389022, \"iteration\": 736, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0019956198520958424, \"iteration\": 737, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00163015048019588, \"iteration\": 738, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0033215642906725407, \"iteration\": 739, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.005415142513811588, \"iteration\": 740, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.005078848917037249, \"iteration\": 741, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002120383083820343, \"iteration\": 742, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003164161927998066, \"iteration\": 743, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003911182284355164, \"iteration\": 744, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.005339981056749821, \"iteration\": 745, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0028645864222198725, \"iteration\": 746, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0021386235021054745, \"iteration\": 747, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013041950296610594, \"iteration\": 748, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012191467685624957, \"iteration\": 749, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0019421238685026765, \"iteration\": 750, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012264841934666038, \"iteration\": 751, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002241062931716442, \"iteration\": 752, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002178906463086605, \"iteration\": 753, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.006344172637909651, \"iteration\": 754, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008033794001676142, \"iteration\": 755, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002938196761533618, \"iteration\": 756, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0018981662578880787, \"iteration\": 757, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001445387490093708, \"iteration\": 758, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.011361770331859589, \"iteration\": 759, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0018622775096446276, \"iteration\": 760, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006233745370991528, \"iteration\": 761, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001937772030942142, \"iteration\": 762, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011490187607705593, \"iteration\": 763, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011555386008694768, \"iteration\": 764, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014546115417033434, \"iteration\": 765, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0016747121699154377, \"iteration\": 766, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01988460309803486, \"iteration\": 767, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.004803991876542568, \"iteration\": 768, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013688510516658425, \"iteration\": 769, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013258024118840694, \"iteration\": 770, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012637516483664513, \"iteration\": 771, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0024765150155872107, \"iteration\": 772, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017837205668911338, \"iteration\": 773, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011018116492778063, \"iteration\": 774, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003375039901584387, \"iteration\": 775, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010032179998233914, \"iteration\": 776, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003255880670621991, \"iteration\": 777, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0058350819163024426, \"iteration\": 778, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002204901771619916, \"iteration\": 779, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012877087574452162, \"iteration\": 780, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011240539606660604, \"iteration\": 781, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009657016489654779, \"iteration\": 782, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001006023958325386, \"iteration\": 783, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.007249066606163979, \"iteration\": 784, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005931666237302125, \"iteration\": 785, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002035476267337799, \"iteration\": 786, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009930368978530169, \"iteration\": 787, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011826928239315748, \"iteration\": 788, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0019501697970554233, \"iteration\": 789, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003050245111808181, \"iteration\": 790, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010590580059215426, \"iteration\": 791, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003273832844570279, \"iteration\": 792, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010147467255592346, \"iteration\": 793, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000997811323031783, \"iteration\": 794, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0043492685072124004, \"iteration\": 795, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0055547854863107204, \"iteration\": 796, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015312706818804145, \"iteration\": 797, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014886829303577542, \"iteration\": 798, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011620032601058483, \"iteration\": 799, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005916771478950977, \"iteration\": 800, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012398625258356333, \"iteration\": 801, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011386945843696594, \"iteration\": 802, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010546500561758876, \"iteration\": 803, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006568937096744776, \"iteration\": 804, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001624442171305418, \"iteration\": 805, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008076435187831521, \"iteration\": 806, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014900481328368187, \"iteration\": 807, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0014015259221196175, \"iteration\": 808, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001395554281771183, \"iteration\": 809, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009180310880765319, \"iteration\": 810, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012656720355153084, \"iteration\": 811, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007295028190128505, \"iteration\": 812, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009623274672776461, \"iteration\": 813, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00227714772336185, \"iteration\": 814, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007706736214458942, \"iteration\": 815, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012054701801389456, \"iteration\": 816, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0020462647080421448, \"iteration\": 817, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009710576850920916, \"iteration\": 818, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004963521496392787, \"iteration\": 819, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009711873135529459, \"iteration\": 820, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010892205173149705, \"iteration\": 821, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012049046345055103, \"iteration\": 822, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0019035720033571124, \"iteration\": 823, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000761795905418694, \"iteration\": 824, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000630686292424798, \"iteration\": 825, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000999652547761798, \"iteration\": 826, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013675324153155088, \"iteration\": 827, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009193620062433183, \"iteration\": 828, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001104555674828589, \"iteration\": 829, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0018402760615572333, \"iteration\": 830, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0071408492513000965, \"iteration\": 831, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0017679625889286399, \"iteration\": 832, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012224010424688458, \"iteration\": 833, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007044140947982669, \"iteration\": 834, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013107258128002286, \"iteration\": 835, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005715999868698418, \"iteration\": 836, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0010460681514814496, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00048010365571826696, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009260381339117885, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00043727332376874983, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015316163189709187, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004339398583397269, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006723329424858093, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005125908646732569, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00038646647590212524, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005082829156890512, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005014660418964922, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0016912351129576564, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007744363392703235, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005914077046327293, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001232195645570755, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005638028378598392, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001937242690473795, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005827615386806428, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007140099769458175, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.021856771782040596, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0013455523876473308, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0005838393117301166, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001026092329993844, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006612277938984334, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006079562590457499, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0015108485240489244, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004799230955541134, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0003211026778444648, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004755828995257616, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00213336618617177, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004298481799196452, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0008509837789461017, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007403160561807454, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009095261339098215, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.000684446538798511, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009898869320750237, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007886220118962228, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0009298886870965362, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006596138700842857, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.002318013459444046, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001127869007177651, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004549196164589375, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.007860474288463593, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.005093199200928211, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001426344271749258, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0012194575974717736, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0007362862234003842, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.004047080408781767, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0006762724369764328, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.003061543684452772, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0011626712512224913, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.00043583440128713846, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.001274128328077495, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.0004900713684037328, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.4439653754234314, \"iteration\": 891, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00032266060588881373, \"iteration\": 892, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004187650338280946, \"iteration\": 893, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00029979480314068496, \"iteration\": 894, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005121104186400771, \"iteration\": 895, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005486939335241914, \"iteration\": 896, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008670989773236215, \"iteration\": 897, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00047901261132210493, \"iteration\": 898, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008598463609814644, \"iteration\": 899, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005329191917553544, \"iteration\": 900, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005571036599576473, \"iteration\": 901, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007986368727870286, \"iteration\": 902, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0012815363006666303, \"iteration\": 903, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0012165928492322564, \"iteration\": 904, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008684014319442213, \"iteration\": 905, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009205510141327977, \"iteration\": 906, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0015466108452528715, \"iteration\": 907, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.001378262764774263, \"iteration\": 908, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0013774993130937219, \"iteration\": 909, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005773304146714509, \"iteration\": 910, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0016397745348513126, \"iteration\": 911, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00043557953904382885, \"iteration\": 912, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00046570802805945277, \"iteration\": 913, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008597060805186629, \"iteration\": 914, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007625074358657002, \"iteration\": 915, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0010428860550746322, \"iteration\": 916, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0016720045823603868, \"iteration\": 917, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0011227572103962302, \"iteration\": 918, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007954251486808062, \"iteration\": 919, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006443001329898834, \"iteration\": 920, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0011881919344887137, \"iteration\": 921, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005562710575759411, \"iteration\": 922, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005869542364962399, \"iteration\": 923, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0011989224003627896, \"iteration\": 924, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0011203602189198136, \"iteration\": 925, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.001438444945961237, \"iteration\": 926, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008662414620630443, \"iteration\": 927, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004583624831866473, \"iteration\": 928, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0011251026298850775, \"iteration\": 929, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006809351034462452, \"iteration\": 930, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006674192845821381, \"iteration\": 931, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0012489850632846355, \"iteration\": 932, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006505800411105156, \"iteration\": 933, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0019599550869315863, \"iteration\": 934, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005936388624832034, \"iteration\": 935, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004448216932360083, \"iteration\": 936, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007419263711199164, \"iteration\": 937, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007486807880923152, \"iteration\": 938, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.038169972598552704, \"iteration\": 939, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0010042137000709772, \"iteration\": 940, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006372777861543, \"iteration\": 941, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008627655333839357, \"iteration\": 942, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.002797379158437252, \"iteration\": 943, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0011664914200082421, \"iteration\": 944, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0015955696580931544, \"iteration\": 945, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0011093893554061651, \"iteration\": 946, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.002929545007646084, \"iteration\": 947, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006802796851843596, \"iteration\": 948, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0019182647811248899, \"iteration\": 949, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0019201206741854548, \"iteration\": 950, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.001819501630961895, \"iteration\": 951, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.007375250104814768, \"iteration\": 952, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006700282683596015, \"iteration\": 953, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006638042395934463, \"iteration\": 954, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006008543423376977, \"iteration\": 955, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007396996952593327, \"iteration\": 956, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00046070863027125597, \"iteration\": 957, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00040067610098049045, \"iteration\": 958, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009390300838276744, \"iteration\": 959, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007127319695428014, \"iteration\": 960, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0016544390236958861, \"iteration\": 961, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00032808419200591743, \"iteration\": 962, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009599042241461575, \"iteration\": 963, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009994099382311106, \"iteration\": 964, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.003175071906298399, \"iteration\": 965, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009958938462659717, \"iteration\": 966, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0017921228427439928, \"iteration\": 967, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005250595859251916, \"iteration\": 968, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00045368977589532733, \"iteration\": 969, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0016992612509056926, \"iteration\": 970, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004786771605722606, \"iteration\": 971, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004304038593545556, \"iteration\": 972, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006046876078471541, \"iteration\": 973, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00803713034838438, \"iteration\": 974, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005331442807801068, \"iteration\": 975, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002630731032695621, \"iteration\": 976, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006340566324070096, \"iteration\": 977, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005853764596395195, \"iteration\": 978, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003538098244462162, \"iteration\": 979, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005874507478438318, \"iteration\": 980, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004908578703179955, \"iteration\": 981, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00032349873799830675, \"iteration\": 982, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00047649157932028174, \"iteration\": 983, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003510212409310043, \"iteration\": 984, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024168644449673593, \"iteration\": 985, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007769914227537811, \"iteration\": 986, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0039054190274327993, \"iteration\": 987, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00044288908247835934, \"iteration\": 988, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006661492516286671, \"iteration\": 989, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006054406403563917, \"iteration\": 990, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00046584627125412226, \"iteration\": 991, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008114984957501292, \"iteration\": 992, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00048720205086283386, \"iteration\": 993, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007618394447490573, \"iteration\": 994, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00029967926093377173, \"iteration\": 995, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003614842426031828, \"iteration\": 996, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006241108640097082, \"iteration\": 997, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002965441963169724, \"iteration\": 998, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00046774864313192666, \"iteration\": 999, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004963979008607566, \"iteration\": 1000, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00026606651954352856, \"iteration\": 1001, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024654658045619726, \"iteration\": 1002, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00439415080472827, \"iteration\": 1003, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009229207644239068, \"iteration\": 1004, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008028187439776957, \"iteration\": 1005, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003758672974072397, \"iteration\": 1006, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002396585769020021, \"iteration\": 1007, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00042494191438890994, \"iteration\": 1008, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005784895038232207, \"iteration\": 1009, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0011880581732839346, \"iteration\": 1010, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002228267549071461, \"iteration\": 1011, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00022668263409286737, \"iteration\": 1012, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0019493340514600277, \"iteration\": 1013, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003319093957543373, \"iteration\": 1014, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005896458169445395, \"iteration\": 1015, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004964064573869109, \"iteration\": 1016, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003463786852080375, \"iteration\": 1017, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00031354548991657794, \"iteration\": 1018, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006267824792303145, \"iteration\": 1019, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003600954660214484, \"iteration\": 1020, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00019126060942653567, \"iteration\": 1021, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00029149543843232095, \"iteration\": 1022, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000405517261242494, \"iteration\": 1023, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003289146698080003, \"iteration\": 1024, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00042665473301894963, \"iteration\": 1025, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000434508197940886, \"iteration\": 1026, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005841644597239792, \"iteration\": 1027, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004860902554355562, \"iteration\": 1028, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007769705844111741, \"iteration\": 1029, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005958318361081183, \"iteration\": 1030, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006062205648049712, \"iteration\": 1031, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00041872565634548664, \"iteration\": 1032, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000351587135810405, \"iteration\": 1033, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00029820308554917574, \"iteration\": 1034, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005849786102771759, \"iteration\": 1035, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003204157983418554, \"iteration\": 1036, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00037928929668851197, \"iteration\": 1037, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003324868157505989, \"iteration\": 1038, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002525285235606134, \"iteration\": 1039, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004267642798367888, \"iteration\": 1040, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0007885961676947773, \"iteration\": 1041, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006440704455599189, \"iteration\": 1042, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.000226961201406084, \"iteration\": 1043, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008536976529285312, \"iteration\": 1044, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005094627849757671, \"iteration\": 1045, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009982750052586198, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00029656922561116517, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00024943670723587275, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005849692970514297, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00028441529138945043, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01148665975779295, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004063720116391778, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004301053995732218, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00026149983750656247, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0008253527921624482, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00019293584045954049, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004506632103584707, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0009119457099586725, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0003978043096140027, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00031903208582662046, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0004553687176667154, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00047116022324189544, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00022226484725251794, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0005175502737984061, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002809923025779426, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0002936909149866551, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0006354045472107828, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.00023954757489264011, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.4645635485649109, \"iteration\": 1069, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00019790587248280644, \"iteration\": 1070, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020316567679401487, \"iteration\": 1071, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00034491438418626785, \"iteration\": 1072, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00034578016493469477, \"iteration\": 1073, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00023505247372668236, \"iteration\": 1074, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003983972128480673, \"iteration\": 1075, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00021524910698644817, \"iteration\": 1076, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00033969030482694507, \"iteration\": 1077, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003325912985019386, \"iteration\": 1078, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0011952432105317712, \"iteration\": 1079, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004823552444577217, \"iteration\": 1080, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00022240847465582192, \"iteration\": 1081, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005294510629028082, \"iteration\": 1082, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0008401653030887246, \"iteration\": 1083, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00041567691368982196, \"iteration\": 1084, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005891225882805884, \"iteration\": 1085, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005223889602348208, \"iteration\": 1086, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007878553587943316, \"iteration\": 1087, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00042468454921618104, \"iteration\": 1088, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0008439430966973305, \"iteration\": 1089, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004880578489974141, \"iteration\": 1090, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00043503736378625035, \"iteration\": 1091, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004748938081320375, \"iteration\": 1092, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005400408408604562, \"iteration\": 1093, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006195207592099905, \"iteration\": 1094, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005729778204113245, \"iteration\": 1095, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005035880021750927, \"iteration\": 1096, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002645404019858688, \"iteration\": 1097, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005041565163992345, \"iteration\": 1098, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0006792258354835212, \"iteration\": 1099, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005000804667361081, \"iteration\": 1100, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004851689445786178, \"iteration\": 1101, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007269292837008834, \"iteration\": 1102, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00033864116994664073, \"iteration\": 1103, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005632748361676931, \"iteration\": 1104, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0006562925409525633, \"iteration\": 1105, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007506952388212085, \"iteration\": 1106, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005774165038019419, \"iteration\": 1107, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00042716923053376377, \"iteration\": 1108, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005671062972396612, \"iteration\": 1109, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00036248902324587107, \"iteration\": 1110, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00047860186896286905, \"iteration\": 1111, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000674622249789536, \"iteration\": 1112, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00036662284401245415, \"iteration\": 1113, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003421316796448082, \"iteration\": 1114, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004046897520311177, \"iteration\": 1115, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023802751675248146, \"iteration\": 1116, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007464184891432524, \"iteration\": 1117, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005521102575585246, \"iteration\": 1118, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003930544771719724, \"iteration\": 1119, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002627858775667846, \"iteration\": 1120, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00048618006985634565, \"iteration\": 1121, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.001047310302965343, \"iteration\": 1122, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003718259686138481, \"iteration\": 1123, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0008172193192876875, \"iteration\": 1124, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004571885510813445, \"iteration\": 1125, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005314688314683735, \"iteration\": 1126, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003139840206131339, \"iteration\": 1127, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005840788362547755, \"iteration\": 1128, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000559637148398906, \"iteration\": 1129, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005463380948640406, \"iteration\": 1130, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014584117569029331, \"iteration\": 1131, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004223468713462353, \"iteration\": 1132, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005628544604405761, \"iteration\": 1133, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00028611187008209527, \"iteration\": 1134, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000411356013501063, \"iteration\": 1135, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00018193280266132206, \"iteration\": 1136, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007950005237944424, \"iteration\": 1137, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0010663395514711738, \"iteration\": 1138, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005689978133887053, \"iteration\": 1139, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00046024678158573806, \"iteration\": 1140, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00239470973610878, \"iteration\": 1141, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020751473493874073, \"iteration\": 1142, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0008022625697776675, \"iteration\": 1143, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00032856169855222106, \"iteration\": 1144, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005875856149941683, \"iteration\": 1145, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00048133169184438884, \"iteration\": 1146, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0009513891418464482, \"iteration\": 1147, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007448693504557014, \"iteration\": 1148, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004118082579225302, \"iteration\": 1149, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004375384596642107, \"iteration\": 1150, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003021529410034418, \"iteration\": 1151, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00041132982005365193, \"iteration\": 1152, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005204107728786767, \"iteration\": 1153, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005527216708287597, \"iteration\": 1154, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0006770835025236011, \"iteration\": 1155, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003559991891961545, \"iteration\": 1156, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020288089581299573, \"iteration\": 1157, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014352095313370228, \"iteration\": 1158, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005912884953431785, \"iteration\": 1159, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00047647234168834984, \"iteration\": 1160, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0006514455890282989, \"iteration\": 1161, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00037429743679240346, \"iteration\": 1162, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005851713940501213, \"iteration\": 1163, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003261724195908755, \"iteration\": 1164, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0023668110370635986, \"iteration\": 1165, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0009939842857420444, \"iteration\": 1166, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00035314628621563315, \"iteration\": 1167, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00029863708186894655, \"iteration\": 1168, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005140219000168145, \"iteration\": 1169, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000620877428445965, \"iteration\": 1170, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0006198114715516567, \"iteration\": 1171, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00048591813538223505, \"iteration\": 1172, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005331906140781939, \"iteration\": 1173, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0016261767596006393, \"iteration\": 1174, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002823609975166619, \"iteration\": 1175, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00044423789950087667, \"iteration\": 1176, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003594502923078835, \"iteration\": 1177, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0006345127476379275, \"iteration\": 1178, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007377555593848228, \"iteration\": 1179, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014194033574312925, \"iteration\": 1180, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003968173696193844, \"iteration\": 1181, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000298839237075299, \"iteration\": 1182, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003466139896772802, \"iteration\": 1183, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00037922943010926247, \"iteration\": 1184, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00036539637949317694, \"iteration\": 1185, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005227194051258266, \"iteration\": 1186, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00042113260133191943, \"iteration\": 1187, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000376524607418105, \"iteration\": 1188, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003575997252482921, \"iteration\": 1189, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002673944691196084, \"iteration\": 1190, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007068650447763503, \"iteration\": 1191, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000518890330567956, \"iteration\": 1192, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004488130798563361, \"iteration\": 1193, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00030545832123607397, \"iteration\": 1194, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00028679115348495543, \"iteration\": 1195, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003212762821931392, \"iteration\": 1196, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00029229719075374305, \"iteration\": 1197, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00021604716312140226, \"iteration\": 1198, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003032310341950506, \"iteration\": 1199, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0007455564918927848, \"iteration\": 1200, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00033026267192326486, \"iteration\": 1201, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004842219641432166, \"iteration\": 1202, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004503675736486912, \"iteration\": 1203, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005476823425851762, \"iteration\": 1204, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00021117657888680696, \"iteration\": 1205, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002613221004139632, \"iteration\": 1206, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00044539693044498563, \"iteration\": 1207, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003857939736917615, \"iteration\": 1208, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002505270822439343, \"iteration\": 1209, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020465999841690063, \"iteration\": 1210, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00019697053357958794, \"iteration\": 1211, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002559345157351345, \"iteration\": 1212, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00017056093201972544, \"iteration\": 1213, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00028302238206379116, \"iteration\": 1214, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0006868005730211735, \"iteration\": 1215, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016565510304644704, \"iteration\": 1216, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000279983039945364, \"iteration\": 1217, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00022673752391710877, \"iteration\": 1218, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00019183126278221607, \"iteration\": 1219, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00029412491130642593, \"iteration\": 1220, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003103073686361313, \"iteration\": 1221, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00035750409006141126, \"iteration\": 1222, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00036341886152513325, \"iteration\": 1223, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00034345430321991444, \"iteration\": 1224, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0014216561103239655, \"iteration\": 1225, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00025228774757124484, \"iteration\": 1226, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00036181529867462814, \"iteration\": 1227, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020801911887247115, \"iteration\": 1228, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00016043346840888262, \"iteration\": 1229, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0018059485591948032, \"iteration\": 1230, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0002404404804110527, \"iteration\": 1231, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000291243166429922, \"iteration\": 1232, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003235149197280407, \"iteration\": 1233, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0003778669924940914, \"iteration\": 1234, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00051448296289891, \"iteration\": 1235, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0006124395877122879, \"iteration\": 1236, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00042482433491386473, \"iteration\": 1237, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00041172487544827163, \"iteration\": 1238, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0004618543025571853, \"iteration\": 1239, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00043417190317995846, \"iteration\": 1240, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0001676601095823571, \"iteration\": 1241, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00024188024690374732, \"iteration\": 1242, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00047772808466106653, \"iteration\": 1243, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00020541425328701735, \"iteration\": 1244, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.000728630053345114, \"iteration\": 1245, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0005254254792816937, \"iteration\": 1246, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.49011701345443726, \"iteration\": 1247, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00024333132023457438, \"iteration\": 1248, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00034639425575733185, \"iteration\": 1249, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000537922082003206, \"iteration\": 1250, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006517851259559393, \"iteration\": 1251, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.009410306811332703, \"iteration\": 1252, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002570643089711666, \"iteration\": 1253, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006764069199562073, \"iteration\": 1254, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002229546895250678, \"iteration\": 1255, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0037342519499361515, \"iteration\": 1256, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006523581687361002, \"iteration\": 1257, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007491769501939416, \"iteration\": 1258, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006047862116247416, \"iteration\": 1259, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005714527214877307, \"iteration\": 1260, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011101735290139914, \"iteration\": 1261, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00035289261722937226, \"iteration\": 1262, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00034421158488839865, \"iteration\": 1263, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00034451071405783296, \"iteration\": 1264, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00040605897083878517, \"iteration\": 1265, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008612050442025065, \"iteration\": 1266, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004701236030086875, \"iteration\": 1267, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004158192314207554, \"iteration\": 1268, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010431762784719467, \"iteration\": 1269, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003162821987643838, \"iteration\": 1270, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014532352797687054, \"iteration\": 1271, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001905397162772715, \"iteration\": 1272, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009221510263159871, \"iteration\": 1273, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005621770396828651, \"iteration\": 1274, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015654326416552067, \"iteration\": 1275, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00039158863364718854, \"iteration\": 1276, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006218836060725152, \"iteration\": 1277, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005036852089688182, \"iteration\": 1278, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005257296725176275, \"iteration\": 1279, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008056338992901146, \"iteration\": 1280, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008111748611554503, \"iteration\": 1281, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015862641157582402, \"iteration\": 1282, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010494454763829708, \"iteration\": 1283, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00238104653544724, \"iteration\": 1284, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003583089273888618, \"iteration\": 1285, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000982795492745936, \"iteration\": 1286, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006886694463901222, \"iteration\": 1287, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005950410268269479, \"iteration\": 1288, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009251288138329983, \"iteration\": 1289, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00034166660043410957, \"iteration\": 1290, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005348806735128164, \"iteration\": 1291, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004793653206434101, \"iteration\": 1292, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004347511101514101, \"iteration\": 1293, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006167812389321625, \"iteration\": 1294, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00037700720713473856, \"iteration\": 1295, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005376412882469594, \"iteration\": 1296, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000458765949588269, \"iteration\": 1297, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005417442880570889, \"iteration\": 1298, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004303062742110342, \"iteration\": 1299, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009609380504116416, \"iteration\": 1300, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003721751272678375, \"iteration\": 1301, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00024106701312121004, \"iteration\": 1302, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005951554048806429, \"iteration\": 1303, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020819292403757572, \"iteration\": 1304, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003648390993475914, \"iteration\": 1305, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002692361013032496, \"iteration\": 1306, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002137445379048586, \"iteration\": 1307, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00021862662106286734, \"iteration\": 1308, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00034417276037856936, \"iteration\": 1309, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001227080705575645, \"iteration\": 1310, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003869377833325416, \"iteration\": 1311, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019829715602099895, \"iteration\": 1312, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011084104189649224, \"iteration\": 1313, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00020330128609202802, \"iteration\": 1314, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007212579948827624, \"iteration\": 1315, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004972867900505662, \"iteration\": 1316, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006418092176318169, \"iteration\": 1317, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00044586756848730147, \"iteration\": 1318, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007047542603686452, \"iteration\": 1319, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000655667157843709, \"iteration\": 1320, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014195448020473123, \"iteration\": 1321, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003493691619951278, \"iteration\": 1322, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00042168772779405117, \"iteration\": 1323, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006883604801259935, \"iteration\": 1324, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004400484904181212, \"iteration\": 1325, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007259827107191086, \"iteration\": 1326, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003190161951351911, \"iteration\": 1327, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004782494797836989, \"iteration\": 1328, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004739426076412201, \"iteration\": 1329, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0030654477886855602, \"iteration\": 1330, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004056425823364407, \"iteration\": 1331, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004080068611074239, \"iteration\": 1332, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003224964311812073, \"iteration\": 1333, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00038679264253005385, \"iteration\": 1334, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00031738911638967693, \"iteration\": 1335, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004622152482625097, \"iteration\": 1336, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007148179574869573, \"iteration\": 1337, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002436289214529097, \"iteration\": 1338, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002603086468297988, \"iteration\": 1339, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003475988924037665, \"iteration\": 1340, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007028864929452538, \"iteration\": 1341, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002995016402564943, \"iteration\": 1342, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003643800737336278, \"iteration\": 1343, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00026342898490838706, \"iteration\": 1344, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0034667430445551872, \"iteration\": 1345, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004759176808875054, \"iteration\": 1346, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00033276170142926276, \"iteration\": 1347, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004899211344309151, \"iteration\": 1348, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00021220788767095655, \"iteration\": 1349, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.013211680576205254, \"iteration\": 1350, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00028585168183781207, \"iteration\": 1351, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003313726920168847, \"iteration\": 1352, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013461015187203884, \"iteration\": 1353, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006367636960931122, \"iteration\": 1354, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00302544585429132, \"iteration\": 1355, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006400709389708936, \"iteration\": 1356, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005329877021722496, \"iteration\": 1357, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00023682540631853044, \"iteration\": 1358, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000399006181396544, \"iteration\": 1359, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010866078082472086, \"iteration\": 1360, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00017068280430976301, \"iteration\": 1361, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00036350684240460396, \"iteration\": 1362, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00035116076469421387, \"iteration\": 1363, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005093833897262812, \"iteration\": 1364, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008387434063479304, \"iteration\": 1365, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006062585161998868, \"iteration\": 1366, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00021554318664129823, \"iteration\": 1367, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007670369814150035, \"iteration\": 1368, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013895309530198574, \"iteration\": 1369, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005817795172333717, \"iteration\": 1370, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004588775336742401, \"iteration\": 1371, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00034864386543631554, \"iteration\": 1372, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00027392219635657966, \"iteration\": 1373, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00030378284282051027, \"iteration\": 1374, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007911312859505415, \"iteration\": 1375, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006208903505466878, \"iteration\": 1376, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003541132900863886, \"iteration\": 1377, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005570712964981794, \"iteration\": 1378, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003657424240373075, \"iteration\": 1379, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00039513068622909486, \"iteration\": 1380, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00021058738639112562, \"iteration\": 1381, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006741185788996518, \"iteration\": 1382, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00044407404493540525, \"iteration\": 1383, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004235336964484304, \"iteration\": 1384, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007683358853682876, \"iteration\": 1385, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001933088875375688, \"iteration\": 1386, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00043124984949827194, \"iteration\": 1387, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004365882836282253, \"iteration\": 1388, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003760281251743436, \"iteration\": 1389, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00022791048104409128, \"iteration\": 1390, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006541174952872097, \"iteration\": 1391, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002989204949699342, \"iteration\": 1392, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.03713969513773918, \"iteration\": 1393, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00040582750807516277, \"iteration\": 1394, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008203244069591165, \"iteration\": 1395, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001365124830044806, \"iteration\": 1396, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016642485279589891, \"iteration\": 1397, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001722739078104496, \"iteration\": 1398, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011737620225176215, \"iteration\": 1399, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0006212569423951209, \"iteration\": 1400, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005951260682195425, \"iteration\": 1401, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002459554234519601, \"iteration\": 1402, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0055661993101239204, \"iteration\": 1403, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01330811157822609, \"iteration\": 1404, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00029152349452488124, \"iteration\": 1405, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005207415670156479, \"iteration\": 1406, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004074953612871468, \"iteration\": 1407, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003592635039240122, \"iteration\": 1408, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004929606802761555, \"iteration\": 1409, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00023947579029481858, \"iteration\": 1410, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0003954178828280419, \"iteration\": 1411, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013390477979555726, \"iteration\": 1412, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01713349111378193, \"iteration\": 1413, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009728218428790569, \"iteration\": 1414, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.020092513412237167, \"iteration\": 1415, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0002985399914905429, \"iteration\": 1416, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0005368026904761791, \"iteration\": 1417, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008960067294538021, \"iteration\": 1418, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001590333180502057, \"iteration\": 1419, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000358565739588812, \"iteration\": 1420, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0004887573304586112, \"iteration\": 1421, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.000905867200344801, \"iteration\": 1422, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007578721269965172, \"iteration\": 1423, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00044353283010423183, \"iteration\": 1424, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.38655632734298706, \"iteration\": 1425, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045238566235639155, \"iteration\": 1426, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026954812346957624, \"iteration\": 1427, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003269545268267393, \"iteration\": 1428, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019669468747451901, \"iteration\": 1429, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035647745244205, \"iteration\": 1430, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033042451832443476, \"iteration\": 1431, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005466416478157043, \"iteration\": 1432, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003246871056035161, \"iteration\": 1433, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003672633320093155, \"iteration\": 1434, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010239561088383198, \"iteration\": 1435, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005183222820051014, \"iteration\": 1436, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024080098955892026, \"iteration\": 1437, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002966672764159739, \"iteration\": 1438, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003190264105796814, \"iteration\": 1439, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002553556696511805, \"iteration\": 1440, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005625041667371988, \"iteration\": 1441, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007406778750009835, \"iteration\": 1442, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003906552738044411, \"iteration\": 1443, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006533438572660089, \"iteration\": 1444, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012567882658913732, \"iteration\": 1445, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001047039171680808, \"iteration\": 1446, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006679284851998091, \"iteration\": 1447, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006102907937020063, \"iteration\": 1448, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00066055275965482, \"iteration\": 1449, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003537705051712692, \"iteration\": 1450, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008781114011071622, \"iteration\": 1451, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005828540888614953, \"iteration\": 1452, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003184477682225406, \"iteration\": 1453, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001060742186382413, \"iteration\": 1454, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006122995400801301, \"iteration\": 1455, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005018638330511749, \"iteration\": 1456, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0037270113825798035, \"iteration\": 1457, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002554999082349241, \"iteration\": 1458, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012367062736302614, \"iteration\": 1459, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014336101012304425, \"iteration\": 1460, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0016310559585690498, \"iteration\": 1461, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004996178904548287, \"iteration\": 1462, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004037356411572546, \"iteration\": 1463, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005527265602722764, \"iteration\": 1464, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004978080396540463, \"iteration\": 1465, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004081011866219342, \"iteration\": 1466, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006588479154743254, \"iteration\": 1467, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002655044081620872, \"iteration\": 1468, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005990394274704158, \"iteration\": 1469, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0001968414435395971, \"iteration\": 1470, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003196552861481905, \"iteration\": 1471, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00040496373549103737, \"iteration\": 1472, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043157872278243303, \"iteration\": 1473, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035550814936868846, \"iteration\": 1474, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0012397690443322062, \"iteration\": 1475, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008114526281133294, \"iteration\": 1476, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004041656502522528, \"iteration\": 1477, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005125283496454358, \"iteration\": 1478, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009009657660499215, \"iteration\": 1479, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00013529132411349565, \"iteration\": 1480, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0024716071784496307, \"iteration\": 1481, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028964068042114377, \"iteration\": 1482, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021080306032672524, \"iteration\": 1483, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008232002146542072, \"iteration\": 1484, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006907957722432911, \"iteration\": 1485, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004107534477952868, \"iteration\": 1486, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007801419706083834, \"iteration\": 1487, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003868608037009835, \"iteration\": 1488, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003360494738444686, \"iteration\": 1489, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007062661461532116, \"iteration\": 1490, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00019242573762312531, \"iteration\": 1491, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0039776163175702095, \"iteration\": 1492, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00590885803103447, \"iteration\": 1493, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009262797539122403, \"iteration\": 1494, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004179296374786645, \"iteration\": 1495, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005689206067472696, \"iteration\": 1496, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006566602969542146, \"iteration\": 1497, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002429867017781362, \"iteration\": 1498, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000642086670268327, \"iteration\": 1499, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005622785538434982, \"iteration\": 1500, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003848695196211338, \"iteration\": 1501, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004687635519076139, \"iteration\": 1502, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006608247058466077, \"iteration\": 1503, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002247369848191738, \"iteration\": 1504, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00032121752155944705, \"iteration\": 1505, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0022663683630526066, \"iteration\": 1506, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009653700981289148, \"iteration\": 1507, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005111557547934353, \"iteration\": 1508, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.004598554223775864, \"iteration\": 1509, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003502842737361789, \"iteration\": 1510, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003942954062949866, \"iteration\": 1511, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00020429285359568894, \"iteration\": 1512, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005337590700946748, \"iteration\": 1513, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0014430477749556303, \"iteration\": 1514, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002304283407283947, \"iteration\": 1515, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010468706022948027, \"iteration\": 1516, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00038025298272259533, \"iteration\": 1517, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011673113331198692, \"iteration\": 1518, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005605858750641346, \"iteration\": 1519, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005736404564231634, \"iteration\": 1520, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002582257438916713, \"iteration\": 1521, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0022061525378376245, \"iteration\": 1522, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045597547432407737, \"iteration\": 1523, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.005763044115155935, \"iteration\": 1524, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008234957931563258, \"iteration\": 1525, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006939762970432639, \"iteration\": 1526, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000121313649287913, \"iteration\": 1527, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003081890463363379, \"iteration\": 1528, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007052409346215427, \"iteration\": 1529, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003759061510208994, \"iteration\": 1530, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011087441816926003, \"iteration\": 1531, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033862621057778597, \"iteration\": 1532, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007651318446733057, \"iteration\": 1533, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000503378629218787, \"iteration\": 1534, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003493745462037623, \"iteration\": 1535, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002983530575875193, \"iteration\": 1536, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00016769286594353616, \"iteration\": 1537, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.008162232115864754, \"iteration\": 1538, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023996777599677444, \"iteration\": 1539, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005866468418389559, \"iteration\": 1540, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002465996192768216, \"iteration\": 1541, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002573624951764941, \"iteration\": 1542, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005192357930354774, \"iteration\": 1543, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00048715691082179546, \"iteration\": 1544, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008450861787423491, \"iteration\": 1545, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002830023877322674, \"iteration\": 1546, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00020603981101885438, \"iteration\": 1547, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00024269285495392978, \"iteration\": 1548, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005161917652003467, \"iteration\": 1549, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00016743525338824838, \"iteration\": 1550, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00273947324603796, \"iteration\": 1551, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005751300486736, \"iteration\": 1552, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008772085420787334, \"iteration\": 1553, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00018318263755645603, \"iteration\": 1554, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002626496716402471, \"iteration\": 1555, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010361340828239918, \"iteration\": 1556, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00022027450904715806, \"iteration\": 1557, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002149120409740135, \"iteration\": 1558, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001443560584448278, \"iteration\": 1559, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000429085484938696, \"iteration\": 1560, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00011322417412884533, \"iteration\": 1561, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003045294142793864, \"iteration\": 1562, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03369878605008125, \"iteration\": 1563, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00016878751921467483, \"iteration\": 1564, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00027642521308735013, \"iteration\": 1565, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003807797620538622, \"iteration\": 1566, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004533528699539602, \"iteration\": 1567, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.003161123488098383, \"iteration\": 1568, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.002093442715704441, \"iteration\": 1569, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00020332793064881116, \"iteration\": 1570, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00047882567741908133, \"iteration\": 1571, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004844323848374188, \"iteration\": 1572, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045407272409647703, \"iteration\": 1573, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026997728855349123, \"iteration\": 1574, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00030302739469334483, \"iteration\": 1575, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005231311079114676, \"iteration\": 1576, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003123882052022964, \"iteration\": 1577, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0015669449931010604, \"iteration\": 1578, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026341210468672216, \"iteration\": 1579, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007205120637081563, \"iteration\": 1580, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013899721670895815, \"iteration\": 1581, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003204258100595325, \"iteration\": 1582, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000357367709511891, \"iteration\": 1583, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004125495033804327, \"iteration\": 1584, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00018167370581068099, \"iteration\": 1585, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00011300543701509014, \"iteration\": 1586, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003670872829388827, \"iteration\": 1587, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002722823992371559, \"iteration\": 1588, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000288123672362417, \"iteration\": 1589, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003799698897637427, \"iteration\": 1590, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037177695776335895, \"iteration\": 1591, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008773501613177359, \"iteration\": 1592, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00026821368373930454, \"iteration\": 1593, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008505000732839108, \"iteration\": 1594, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037325400626286864, \"iteration\": 1595, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00023192005755845457, \"iteration\": 1596, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007744801696389914, \"iteration\": 1597, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00021049115457572043, \"iteration\": 1598, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000711827480699867, \"iteration\": 1599, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001955695915967226, \"iteration\": 1600, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008453403715975583, \"iteration\": 1601, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002692539128474891, \"iteration\": 1602, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.2878989577293396, \"iteration\": 1603, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002850122982636094, \"iteration\": 1604, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003391796490177512, \"iteration\": 1605, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004993474576622248, \"iteration\": 1606, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004548585973680019, \"iteration\": 1607, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005384931340813637, \"iteration\": 1608, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00791175477206707, \"iteration\": 1609, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0019111005822196603, \"iteration\": 1610, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011906991712749004, \"iteration\": 1611, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003742885310202837, \"iteration\": 1612, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004502586671151221, \"iteration\": 1613, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021925615146756172, \"iteration\": 1614, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002957226475700736, \"iteration\": 1615, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013574495096690953, \"iteration\": 1616, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001340633723884821, \"iteration\": 1617, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002677234588190913, \"iteration\": 1618, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002935520024038851, \"iteration\": 1619, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001163441687822342, \"iteration\": 1620, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001132881734520197, \"iteration\": 1621, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023442959354724735, \"iteration\": 1622, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018711370648816228, \"iteration\": 1623, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003900309675373137, \"iteration\": 1624, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00195564073510468, \"iteration\": 1625, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002545333409216255, \"iteration\": 1626, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001374410931020975, \"iteration\": 1627, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006249743746593595, \"iteration\": 1628, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.019846362993121147, \"iteration\": 1629, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010189947206526995, \"iteration\": 1630, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019826031348202378, \"iteration\": 1631, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003011318331118673, \"iteration\": 1632, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002297834143973887, \"iteration\": 1633, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005555849056690931, \"iteration\": 1634, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.007117553148418665, \"iteration\": 1635, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032420599018223584, \"iteration\": 1636, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.004418339114636183, \"iteration\": 1637, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008384977700188756, \"iteration\": 1638, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005774048622697592, \"iteration\": 1639, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0021110870875418186, \"iteration\": 1640, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028816828853450716, \"iteration\": 1641, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006843441515229642, \"iteration\": 1642, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002426575229037553, \"iteration\": 1643, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002201256575062871, \"iteration\": 1644, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002153720415662974, \"iteration\": 1645, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024567192303948104, \"iteration\": 1646, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016839356976561248, \"iteration\": 1647, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021432047651614994, \"iteration\": 1648, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.002950681373476982, \"iteration\": 1649, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0015384285943582654, \"iteration\": 1650, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00043092589476145804, \"iteration\": 1651, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003563421487342566, \"iteration\": 1652, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026589821209199727, \"iteration\": 1653, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032018846832215786, \"iteration\": 1654, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032314524287357926, \"iteration\": 1655, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0018278734060004354, \"iteration\": 1656, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000489386438857764, \"iteration\": 1657, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024957291316241026, \"iteration\": 1658, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020473099721129984, \"iteration\": 1659, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002299568004673347, \"iteration\": 1660, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007542275125160813, \"iteration\": 1661, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006195682799443603, \"iteration\": 1662, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00038306586793623865, \"iteration\": 1663, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022471243573818356, \"iteration\": 1664, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027547628269530833, \"iteration\": 1665, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024016568204388022, \"iteration\": 1666, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016563356621190906, \"iteration\": 1667, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00036564702168107033, \"iteration\": 1668, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000151296699186787, \"iteration\": 1669, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006402113940566778, \"iteration\": 1670, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003788231988437474, \"iteration\": 1671, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030021887505427003, \"iteration\": 1672, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002517752000130713, \"iteration\": 1673, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002238350862171501, \"iteration\": 1674, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002117102558258921, \"iteration\": 1675, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009297975921072066, \"iteration\": 1676, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004107575514353812, \"iteration\": 1677, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006104239728301764, \"iteration\": 1678, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021834290237165987, \"iteration\": 1679, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004375897697173059, \"iteration\": 1680, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031714505166746676, \"iteration\": 1681, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010011050617322326, \"iteration\": 1682, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018092026584781706, \"iteration\": 1683, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023278819571714848, \"iteration\": 1684, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019187347788829356, \"iteration\": 1685, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007792070973664522, \"iteration\": 1686, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002596009289845824, \"iteration\": 1687, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003729781892616302, \"iteration\": 1688, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017920909158419818, \"iteration\": 1689, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003970284014940262, \"iteration\": 1690, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002802594972308725, \"iteration\": 1691, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000364967854693532, \"iteration\": 1692, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00463092653080821, \"iteration\": 1693, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005286166910082102, \"iteration\": 1694, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013349328946787864, \"iteration\": 1695, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006326146540232003, \"iteration\": 1696, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012494134716689587, \"iteration\": 1697, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017607594782020897, \"iteration\": 1698, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00818040780723095, \"iteration\": 1699, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005437690415419638, \"iteration\": 1700, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002745009842328727, \"iteration\": 1701, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0010361116146668792, \"iteration\": 1702, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014984440349508077, \"iteration\": 1703, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030475700623355806, \"iteration\": 1704, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016086814866866916, \"iteration\": 1705, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00042230915278196335, \"iteration\": 1706, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008992791408672929, \"iteration\": 1707, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0016339938156306744, \"iteration\": 1708, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009550069808028638, \"iteration\": 1709, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028255479992367327, \"iteration\": 1710, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003784718574024737, \"iteration\": 1711, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025219691451638937, \"iteration\": 1712, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002862234541680664, \"iteration\": 1713, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008825536351650953, \"iteration\": 1714, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014792720321565866, \"iteration\": 1715, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000801329908426851, \"iteration\": 1716, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0007721802685409784, \"iteration\": 1717, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017493362247478217, \"iteration\": 1718, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001408942771377042, \"iteration\": 1719, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005376465851441026, \"iteration\": 1720, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001662203430896625, \"iteration\": 1721, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012684680405072868, \"iteration\": 1722, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004758914583362639, \"iteration\": 1723, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018395099323242903, \"iteration\": 1724, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027404166758060455, \"iteration\": 1725, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019376220006961375, \"iteration\": 1726, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016487321408931166, \"iteration\": 1727, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013500646455213428, \"iteration\": 1728, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0014712230768054724, \"iteration\": 1729, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003588822146411985, \"iteration\": 1730, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.549609628971666e-05, \"iteration\": 1731, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024785654386505485, \"iteration\": 1732, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.006457800045609474, \"iteration\": 1733, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005825158441439271, \"iteration\": 1734, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006331584299914539, \"iteration\": 1735, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008568783523514867, \"iteration\": 1736, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000880689243786037, \"iteration\": 1737, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005373877356760204, \"iteration\": 1738, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008948329486884177, \"iteration\": 1739, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000238240318140015, \"iteration\": 1740, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00035238254349678755, \"iteration\": 1741, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019272077770438045, \"iteration\": 1742, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0022578968200832605, \"iteration\": 1743, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0009329885942861438, \"iteration\": 1744, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024891967768780887, \"iteration\": 1745, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012931534729432315, \"iteration\": 1746, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032078681397251785, \"iteration\": 1747, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003101885668002069, \"iteration\": 1748, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001662430149735883, \"iteration\": 1749, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00029159331461414695, \"iteration\": 1750, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013983949611429125, \"iteration\": 1751, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006114780553616583, \"iteration\": 1752, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030751072335988283, \"iteration\": 1753, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00034789249184541404, \"iteration\": 1754, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011252633994445205, \"iteration\": 1755, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030229976982809603, \"iteration\": 1756, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030361878452822566, \"iteration\": 1757, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002212958934251219, \"iteration\": 1758, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0013964902609586716, \"iteration\": 1759, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001580184034537524, \"iteration\": 1760, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0005189551156945527, \"iteration\": 1761, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011590251233428717, \"iteration\": 1762, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011434283806011081, \"iteration\": 1763, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027126530767418444, \"iteration\": 1764, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021245723473839462, \"iteration\": 1765, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028161483351141214, \"iteration\": 1766, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00012873901869170368, \"iteration\": 1767, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0008605261100456119, \"iteration\": 1768, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.003711130004376173, \"iteration\": 1769, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.005335649941116571, \"iteration\": 1770, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003598757029976696, \"iteration\": 1771, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020627383491955698, \"iteration\": 1772, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.001167887938208878, \"iteration\": 1773, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004023553628940135, \"iteration\": 1774, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0004917710903100669, \"iteration\": 1775, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00044084238470532, \"iteration\": 1776, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0011543695582076907, \"iteration\": 1777, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025054693105630577, \"iteration\": 1778, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002958790282718837, \"iteration\": 1779, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002006892318604514, \"iteration\": 1780, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop out\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models/hr')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    "    optimizer_params= {\"lr\": 0.001, \"weight_decay\": 0.01, }\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(train_data_nn, batch_size=128, shuffle=True)\n",
    "\n",
    "USE_CACHE = False\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(tfidf_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    dropout=0.5,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "if (models_dir / 'model_nn.pt').exists() and USE_CACHE:\n",
    "    model_nn = load_model(model_nn, models_dir, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn, models_dir, \"model_nn\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # X_test = torch.stack([dta[0] for dta in test])\n",
    "    X_test = torch.stack([test[0] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_test = torch.stack([test[1] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_pred = model_nn.predict(X_test)\n",
    "\n",
    "\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='binary'))\n",
    "print(\"AUC\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other classifiers\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "\"Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC, SVM\n",
    "Effective in high dimensional spaces.\n",
    "\n",
    "Still effective in cases where number of dimensions is greater than the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC with TfIdf did good on balanced English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoanghapham/.pyenv/versions/3.11.5/envs/power-identification/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7292759706190975, 0.6120651695288419, 0.6655494373952597, None)\n",
      "AUC: 0.7296334139027094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# LinearSVC, tfidf\n",
    "X_train = tfidf_encoder.transform(train_raw.texts)\n",
    "print(\"Fit model\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_train, train_raw.labels)\n",
    "\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(tfidf_encoder.transform(test_raw.texts))\n",
    "\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_LinearSVC_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier\n",
    "SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "\n",
    "SGD is sensitive to feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.790434235368156, 0.5530603258476442, 0.6507772020725389, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7272260468444618"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_train, train_raw.labels)\n",
    "\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(tfidf_encoder.transform(test_raw.texts))\n",
    "\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Overall bad performance, not worth pursuing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model_GaussianNB_tfidf = GaussianNB()\n",
    "model_GaussianNB_tfidf.fit(X_train.toarray(), train_raw.labels)\n",
    "\n",
    "pred_GaussianNB_tfidf = model_GaussianNB_tfidf.predict(tfidf_encoder.transform(test_raw.texts).toarray())\n",
    "\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_GaussianNB_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_GaussianNB_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- Neural network is still a good option\n",
    "- sklearn's SGD is also good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard count vectors & scale\n",
    "Not good on both LinearSVC and SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "encoding_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('scaler', StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "encoding_pipeline.fit(train_raw.texts)\n",
    "\n",
    "X_train = encoding_pipeline.transform(train_raw.texts)\n",
    "\n",
    "\n",
    "print(\"Fit model\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_train, train_raw.labels)\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(encoding_pipeline.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_LinearSVC_tfidf))\n",
    "\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_train, train_raw.labels)\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(encoding_pipeline.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoanghapham/.pyenv/versions/3.11.5/envs/power-identification/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6410123966942148, 0.5464553060325847, 0.5899690991205134, None)\n",
      "AUC: 0.6703256690068166\n",
      "SGDClassifier\n",
      "(0.7664526484751204, 0.420519594892118, 0.5430764856411715, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6671742185298611"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tfidf = TfidfVectorizer(sublinear_tf=True, analyzer=\"word\", ngram_range=(3,5), max_features=10000)\n",
    "\n",
    "X_train = word_tfidf.fit_transform(train_raw.texts)\n",
    "\n",
    "\n",
    "print(\"LinearSVC\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_train, train_raw.labels)\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(word_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred_LinearSVC_tfidf))\n",
    "\n",
    "print(\"SGDClassifier\")\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_train, train_raw.labels)\n",
    "\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(word_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use more tfidf word (50000) features improve 1%, but takes much more time to transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/tfidf/ngram_word_3to7_50000.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m X_train \u001b[38;5;241m=\u001b[39m word_tfidf\u001b[38;5;241m.\u001b[39mfit_transform(train_raw\u001b[38;5;241m.\u001b[39mtexts)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_npz\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/tfidf/ngram_word_3to7_50000.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m model_LinearSVC_tfidf \u001b[38;5;241m=\u001b[39m LinearSVC()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/power/lib/python3.11/site-packages/scipy/sparse/_matrix_io.py:75\u001b[0m, in \u001b[0;36msave_npz\u001b[0;34m(file, matrix, compressed)\u001b[0m\n\u001b[1;32m     73\u001b[0m     arrays_dict\u001b[38;5;241m.\u001b[39mupdate(_is_array\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compressed:\n\u001b[0;32m---> 75\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavez_compressed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     np\u001b[38;5;241m.\u001b[39msavez(file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marrays_dict)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/power/lib/python3.11/site-packages/numpy/lib/npyio.py:710\u001b[0m, in \u001b[0;36msavez_compressed\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_savez_compressed_dispatcher)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavez_compressed\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    649\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;124;03m    Save several arrays into a single file in compressed ``.npz`` format.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[43m_savez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/power/lib/python3.11/site-packages/numpy/lib/npyio.py:736\u001b[0m, in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     compression \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZIP_STORED\n\u001b[0;32m--> 736\u001b[0m zipf \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m namedict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    739\u001b[0m     fname \u001b[38;5;241m=\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/envs/power/lib/python3.11/site-packages/numpy/lib/npyio.py:103\u001b[0m, in \u001b[0;36mzipfile_factory\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m    102\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallowZip64\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.5/lib/python3.11/zipfile.py:1284\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/tfidf/ngram_word_3to7_50000.npz'"
     ]
    }
   ],
   "source": [
    "word_tfidf = TfidfVectorizer(sublinear_tf=True, analyzer=\"word\", ngram_range=(3,5), max_features=50000)\n",
    "\n",
    "X_train = word_tfidf.fit_transform(train_raw.texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "(0.6931690929451287, 0.5451343020695729, 0.6103031796894257, None)\n",
      "AUC: 0.6914300470963796\n",
      "SGDClassifier\n",
      "(0.8221343873517787, 0.3663584324086306, 0.5068534876637222, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6565283426479044"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# import scipy\n",
    "# scipy.sparse.save_npz(\"models/tfidf/ngram_word_3to7_50000.npz\", X_train)\n",
    "\n",
    "print(\"LinearSVC\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_train, train_raw.labels)\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(word_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n",
    "print(\"AUC:\", roc_auc_score(test_raw.labels, pred_LinearSVC_tfidf))\n",
    "\n",
    "print(\"SGDClassifier\")\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_train, train_raw.labels)\n",
    "\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(word_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Char ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "(0.7396907216494846, 0.6318802289740203, 0.681548325813346, None)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m pred_LinearSVC_tfidf \u001b[38;5;241m=\u001b[39m model_LinearSVC_tfidf\u001b[38;5;241m.\u001b[39mpredict(char_tfidf\u001b[38;5;241m.\u001b[39mtransform(test_raw\u001b[38;5;241m.\u001b[39mtexts))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(precision_recall_fscore_support(test_raw\u001b[38;5;241m.\u001b[39mlabels, pred_LinearSVC_tfidf, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, roc_auc_score(\u001b[43my_test\u001b[49m, pred_LinearSVC_tfidf))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSGDClassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m model_SGDClassifier_tfidf \u001b[38;5;241m=\u001b[39m SGDClassifier()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "char_tfidf = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(3,7), max_features=50000)\n",
    "\n",
    "X_train = char_tfidf.fit_transform(train_raw.texts)\n",
    "\n",
    "import scipy\n",
    "scipy.sparse.save_npz(\"models/tfidf/ngram_char_3to7_50000.npz\", X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "(0.7396907216494846, 0.6318802289740203, 0.681548325813346, None)\n",
      "AUC: 1.0\n",
      "SGDClassifier\n",
      "(0.7989661114302126, 0.6125055041831792, 0.693419740777667, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7544316090652349"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"LinearSVC\")\n",
    "model_LinearSVC_tfidf = LinearSVC()\n",
    "model_LinearSVC_tfidf.fit(X_train, train_raw.labels)\n",
    "pred_LinearSVC_tfidf = model_LinearSVC_tfidf.predict(char_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_LinearSVC_tfidf, average='binary'))\n",
    "print(\"AUC:\", roc_auc_score(test_raw.labels, pred_LinearSVC_tfidf))\n",
    "\n",
    "print(\"SGDClassifier\")\n",
    "model_SGDClassifier_tfidf = SGDClassifier()\n",
    "model_SGDClassifier_tfidf.fit(X_train, train_raw.labels)\n",
    "\n",
    "pred_SGDClassifier_tfidf = model_SGDClassifier_tfidf.predict(char_tfidf.transform(test_raw.texts))\n",
    "print(precision_recall_fscore_support(test_raw.labels, pred_SGDClassifier_tfidf, average='binary'))\n",
    "roc_auc_score(test_raw.labels, pred_SGDClassifier_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7411696081204127\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC:\", roc_auc_score(test_raw.labels, pred_LinearSVC_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     13\u001b[0m USE_CACHE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model_nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(\n\u001b[1;32m     17\u001b[0m     input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(char_tfidf\u001b[38;5;241m.\u001b[39mvocabulary_),\n\u001b[1;32m     18\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     19\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mmodels_dir\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_nn.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m USE_CACHE:\n\u001b[1;32m     23\u001b[0m     model_nn \u001b[38;5;241m=\u001b[39m load_model(model_nn, models_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_nn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Test char tfidf feature on NN\n",
    "train_data_nn = encode_data(train_raw, char_tfidf)\n",
    "test_data_nn = encode_data(test_raw, char_tfidf)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(train_data_nn, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 178/178 [00:08<00:00, 19.83batch/s, batch_accuracy=0.768, loss=0.474]\n",
      "Epoch 2: 100%|██████████| 178/178 [00:08<00:00, 20.10batch/s, batch_accuracy=0.829, loss=0.37] \n",
      "Epoch 3: 100%|██████████| 178/178 [00:08<00:00, 20.51batch/s, batch_accuracy=0.866, loss=0.353]\n",
      "Epoch 4: 100%|██████████| 178/178 [00:09<00:00, 19.05batch/s, batch_accuracy=0.951, loss=0.222]\n",
      "Epoch 5: 100%|██████████| 178/178 [00:08<00:00, 20.49batch/s, batch_accuracy=0.963, loss=0.149] \n",
      "Epoch 6: 100%|██████████| 178/178 [00:09<00:00, 19.18batch/s, batch_accuracy=1, loss=0.0364]    \n",
      "Epoch 7: 100%|██████████| 178/178 [00:09<00:00, 18.84batch/s, batch_accuracy=1, loss=0.0102]    \n",
      "Epoch 8: 100%|██████████| 178/178 [00:09<00:00, 18.27batch/s, batch_accuracy=1, loss=0.00124]   \n",
      "Epoch 9: 100%|██████████| 178/178 [00:08<00:00, 20.36batch/s, batch_accuracy=1, loss=0.000476]\n",
      "Epoch 10: 100%|██████████| 178/178 [00:08<00:00, 20.40batch/s, batch_accuracy=1, loss=0.000152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7087424029920524, 0.6675473359753412, 0.6875283446712018, None)\n",
      "AUC 0.7415320334007591\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-6324d23dcb44427883934b704fc20bab.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-6324d23dcb44427883934b704fc20bab.vega-embed details,\n",
       "  #altair-viz-6324d23dcb44427883934b704fc20bab.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-6324d23dcb44427883934b704fc20bab\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6324d23dcb44427883934b704fc20bab\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6324d23dcb44427883934b704fc20bab\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-63a1a29fddce2f3e4eda0edc91def8ce\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-63a1a29fddce2f3e4eda0edc91def8ce\": [{\"training_acc\": 0.65625, \"training_loss\": 0.6812778115272522, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.6630231738090515, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6560719013214111, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 0.6589977741241455, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.6289405822753906, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6711981296539307, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.578125, \"training_loss\": 0.676774263381958, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6330397129058838, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6561977863311768, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6755161881446838, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.6016520261764526, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 0.7061780095100403, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6726291179656982, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6263394951820374, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5920845866203308, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.712075412273407, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.5879489183425903, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6252201199531555, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6102754473686218, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6402997374534607, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5771414637565613, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6562826633453369, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6712554693222046, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 0.6508142948150635, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.690447986125946, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6108972430229187, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6494753360748291, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.663528323173523, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 0.6456672549247742, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 0.6024423837661743, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5682672262191772, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6295964121818542, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6477475762367249, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6175852417945862, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6034178733825684, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5887466669082642, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6010624766349792, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6666173338890076, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6172276735305786, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6213220357894897, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.5976762771606445, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.5390625, \"training_loss\": 0.6987519860267639, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6431697607040405, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.59375, \"training_loss\": 0.6179722547531128, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.6319724321365356, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5801393985748291, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6658637523651123, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.6228300929069519, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 0.6383075714111328, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.6080207824707031, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 0.6073958277702332, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5523696541786194, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5656224489212036, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 0.6040779948234558, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5450924634933472, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.6328125, \"training_loss\": 0.575673520565033, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.5625, \"training_loss\": 0.6530274748802185, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 0.6260618567466736, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5457375645637512, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.528369665145874, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 0.5493494272232056, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 0.5700305700302124, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.4842473268508911, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5618958473205566, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.5688064694404602, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.5910114049911499, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5771816968917847, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5703185200691223, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.5817605257034302, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 0.5953125357627869, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5341616868972778, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5076524019241333, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5370322465896606, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5556601285934448, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5334933400154114, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5368972420692444, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5301505923271179, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5190707445144653, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5055045485496521, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5679236054420471, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.547914981842041, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.5337203741073608, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.49561721086502075, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.47441366314888, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5178438425064087, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5266492366790771, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.5288437008857727, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5168453454971313, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5149834752082825, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5351575016975403, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.5127155184745789, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5210006833076477, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5675367116928101, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5541324019432068, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5317404866218567, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.4988170266151428, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.5015692710876465, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5340735912322998, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5661814212799072, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5191775560379028, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 0.5777701139450073, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4704054594039917, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.4936947226524353, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5187126994132996, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4639170169830322, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4571135640144348, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.525383710861206, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4083302617073059, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5387542247772217, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.46306201815605164, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4803397059440613, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 0.5195549726486206, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.46460291743278503, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4160934388637543, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5232019424438477, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5237452387809753, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4563688337802887, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5416560769081116, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5068250894546509, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5004093647003174, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.48307478427886963, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.4956137537956238, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.48926013708114624, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.52906334400177, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.44994625449180603, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.44467678666114807, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.859375, \"training_loss\": 0.38685840368270874, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.5671610236167908, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5402255654335022, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4627639353275299, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4525941014289856, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4351804256439209, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 0.588659405708313, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4697227478027344, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4407506287097931, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5005006194114685, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.42857205867767334, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 0.4815398156642914, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4089421033859253, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5397239923477173, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 0.5823083519935608, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4806864857673645, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4562486410140991, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5163126587867737, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4290132522583008, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5535515546798706, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 0.5277633666992188, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5637935996055603, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4823865294456482, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.488733172416687, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.49776574969291687, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.41598761081695557, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 0.6340736150741577, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 0.46932265162467957, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.49201855063438416, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4662482440471649, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 0.4380643367767334, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4574640691280365, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5162748098373413, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.512479841709137, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.45081162452697754, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.40572062134742737, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.8125, \"training_loss\": 0.4376242160797119, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.431078165769577, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.828125, \"training_loss\": 0.4361453652381897, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 0.5268124938011169, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 0.5310658812522888, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.5435284972190857, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 0.44638895988464355, \"iteration\": 169, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.49720293283462524, \"iteration\": 170, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 0.5011256337165833, \"iteration\": 171, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 0.4647415280342102, \"iteration\": 172, \"epoch\": 1}, {\"training_acc\": 0.8515625, \"training_loss\": 0.42562055587768555, \"iteration\": 173, \"epoch\": 1}, {\"training_acc\": 0.84375, \"training_loss\": 0.4477105438709259, \"iteration\": 174, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.435162752866745, \"iteration\": 175, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4420223832130432, \"iteration\": 176, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 0.4796625077724457, \"iteration\": 177, \"epoch\": 1}, {\"training_acc\": 0.7682926829268293, \"training_loss\": 0.47356271743774414, \"iteration\": 178, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4524437189102173, \"iteration\": 179, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4158155024051666, \"iteration\": 180, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3839465379714966, \"iteration\": 181, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.43594005703926086, \"iteration\": 182, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4104662835597992, \"iteration\": 183, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.4666004478931427, \"iteration\": 184, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4725923240184784, \"iteration\": 185, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 0.38769030570983887, \"iteration\": 186, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.350613534450531, \"iteration\": 187, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3967489004135132, \"iteration\": 188, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3835107386112213, \"iteration\": 189, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.36210525035858154, \"iteration\": 190, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.33709070086479187, \"iteration\": 191, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4425211548805237, \"iteration\": 192, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4461210370063782, \"iteration\": 193, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3294033408164978, \"iteration\": 194, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3757643401622772, \"iteration\": 195, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3867727816104889, \"iteration\": 196, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.41534966230392456, \"iteration\": 197, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4413483440876007, \"iteration\": 198, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3628900945186615, \"iteration\": 199, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4235820472240448, \"iteration\": 200, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.33245453238487244, \"iteration\": 201, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3489072322845459, \"iteration\": 202, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3652938902378082, \"iteration\": 203, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.405266135931015, \"iteration\": 204, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4383948743343353, \"iteration\": 205, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.35557109117507935, \"iteration\": 206, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.389423131942749, \"iteration\": 207, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.43816888332366943, \"iteration\": 208, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.392339825630188, \"iteration\": 209, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.35226190090179443, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3982809782028198, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3245992660522461, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.32876476645469666, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.42685842514038086, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4408915340900421, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3721308708190918, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.401894211769104, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.35940295457839966, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.38665276765823364, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3744499981403351, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.34069475531578064, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3967526853084564, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3369939625263214, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3644798696041107, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3626198172569275, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.4311707615852356, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.38624975085258484, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.2622934579849243, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4093133211135864, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4016175866127014, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.38270512223243713, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4045262932777405, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.33334314823150635, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3590210974216461, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4401457905769348, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.44781985878944397, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.40871894359588623, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.33782288432121277, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3363470435142517, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4440133273601532, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5525793433189392, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3489704728126526, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 0.5295242667198181, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 0.4986173212528229, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4093262851238251, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.360826313495636, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.39149540662765503, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.42952945828437805, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3986520767211914, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 0.48043394088745117, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 0.499220609664917, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.35795092582702637, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.3981255888938904, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4100819528102875, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4191533029079437, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3644571006298065, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.34818872809410095, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3907809555530548, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4025592505931854, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3015367388725281, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40044263005256653, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4629065990447998, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.36856502294540405, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.34158381819725037, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.42871448397636414, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3615451455116272, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.40787896513938904, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.38918641209602356, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.4500182867050171, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3347700536251068, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2940308749675751, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.39022335410118103, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.375156432390213, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.3842597007751465, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.39927810430526733, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3920726180076599, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.38671058416366577, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.412605881690979, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.4267624020576477, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.41671350598335266, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.37769031524658203, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3829006552696228, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3878205716609955, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.37501055002212524, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.33548158407211304, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.41933372616767883, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3353706896305084, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 0.42290711402893066, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.4549439549446106, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.46302419900894165, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.35772156715393066, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.40907779335975647, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.43152904510498047, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4056498408317566, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4117511212825775, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3838401436805725, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.372369647026062, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.4617532789707184, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.440299928188324, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.3742605745792389, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3671714961528778, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.42858025431632996, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.35856834053993225, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3284331262111664, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.37181273102760315, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3349054157733917, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.28627485036849976, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.41802921891212463, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.41438761353492737, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3614215552806854, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.324949711561203, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3255331814289093, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4247286915779114, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3662642240524292, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.350219190120697, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.43867945671081543, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.3851213753223419, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.40981006622314453, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.41041994094848633, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.3787688910961151, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3838616609573364, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.44120433926582336, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.4339030981063843, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.41917529702186584, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.3497832119464874, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 0.44797056913375854, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.35464999079704285, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 0.4920671582221985, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.42593640089035034, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 0.27477142214775085, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.34799110889434814, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.42966029047966003, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.414978563785553, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4408312737941742, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.32321855425834656, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.3842355012893677, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.360076367855072, \"iteration\": 337, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3475927710533142, \"iteration\": 338, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 0.36243003606796265, \"iteration\": 339, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 0.40819889307022095, \"iteration\": 340, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 0.3863775134086609, \"iteration\": 341, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32408273220062256, \"iteration\": 342, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.34549111127853394, \"iteration\": 343, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3776881992816925, \"iteration\": 344, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 0.4480891525745392, \"iteration\": 345, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.5149211883544922, \"iteration\": 346, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.31077635288238525, \"iteration\": 347, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 0.5237718820571899, \"iteration\": 348, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 0.421496719121933, \"iteration\": 349, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 0.4785975515842438, \"iteration\": 350, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4177318513393402, \"iteration\": 351, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 0.3860536813735962, \"iteration\": 352, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 0.453288197517395, \"iteration\": 353, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 0.4137224853038788, \"iteration\": 354, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 0.39425963163375854, \"iteration\": 355, \"epoch\": 2}, {\"training_acc\": 0.8292682926829268, \"training_loss\": 0.3699830174446106, \"iteration\": 356, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3376099169254303, \"iteration\": 357, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23196105659008026, \"iteration\": 358, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.30867886543273926, \"iteration\": 359, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.33839181065559387, \"iteration\": 360, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.33562806248664856, \"iteration\": 361, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2989700138568878, \"iteration\": 362, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3040526509284973, \"iteration\": 363, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.40673866868019104, \"iteration\": 364, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3502068519592285, \"iteration\": 365, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3379237949848175, \"iteration\": 366, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.34760528802871704, \"iteration\": 367, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2724820673465729, \"iteration\": 368, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.33962908387184143, \"iteration\": 369, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3164321184158325, \"iteration\": 370, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2942728102207184, \"iteration\": 371, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.32640010118484497, \"iteration\": 372, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3368590176105499, \"iteration\": 373, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31649690866470337, \"iteration\": 374, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.21585388481616974, \"iteration\": 375, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3713524341583252, \"iteration\": 376, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3229486644268036, \"iteration\": 377, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3098905086517334, \"iteration\": 378, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.2862727642059326, \"iteration\": 379, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30433952808380127, \"iteration\": 380, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2476879209280014, \"iteration\": 381, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.25193971395492554, \"iteration\": 382, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3142809569835663, \"iteration\": 383, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.23484954237937927, \"iteration\": 384, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23859909176826477, \"iteration\": 385, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2632658779621124, \"iteration\": 386, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27411067485809326, \"iteration\": 387, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2697294354438782, \"iteration\": 388, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2836393415927887, \"iteration\": 389, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.24479417502880096, \"iteration\": 390, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2647743225097656, \"iteration\": 391, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28584587574005127, \"iteration\": 392, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3241395950317383, \"iteration\": 393, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.28148630261421204, \"iteration\": 394, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3917684555053711, \"iteration\": 395, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2826046943664551, \"iteration\": 396, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2578236162662506, \"iteration\": 397, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2642596960067749, \"iteration\": 398, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.25972801446914673, \"iteration\": 399, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.3188101053237915, \"iteration\": 400, \"epoch\": 3}, {\"training_acc\": 0.953125, \"training_loss\": 0.20640553534030914, \"iteration\": 401, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2551227807998657, \"iteration\": 402, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.40050238370895386, \"iteration\": 403, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2529539167881012, \"iteration\": 404, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22421711683273315, \"iteration\": 405, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3212597370147705, \"iteration\": 406, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.2214941680431366, \"iteration\": 407, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2686766982078552, \"iteration\": 408, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3464818000793457, \"iteration\": 409, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2990257740020752, \"iteration\": 410, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.27210280299186707, \"iteration\": 411, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.24487440288066864, \"iteration\": 412, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.23028728365898132, \"iteration\": 413, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3599854111671448, \"iteration\": 414, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.2991681694984436, \"iteration\": 415, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.29319486021995544, \"iteration\": 416, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.40352341532707214, \"iteration\": 417, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27234160900115967, \"iteration\": 418, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.27495530247688293, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.32145291566848755, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.21885640919208527, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2618822157382965, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.23155102133750916, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26068541407585144, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3559821546077728, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3129274547100067, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28497937321662903, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.35340046882629395, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26597660779953003, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3209724426269531, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.33997729420661926, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28467002511024475, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3165372610092163, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3636215329170227, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.22502201795578003, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.38041356205940247, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.29301416873931885, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.35735276341438293, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3028421700000763, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.30176451802253723, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.31124114990234375, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28507497906684875, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.21973614394664764, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2974398732185364, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3085159957408905, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.30311673879623413, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.34838107228279114, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3020656108856201, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.31216973066329956, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.25475361943244934, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.36405038833618164, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.37880995869636536, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3741667568683624, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2571411728858948, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.2941717505455017, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.40612661838531494, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2957763075828552, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2840433716773987, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2755429148674011, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.35414761304855347, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3131946623325348, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.340355783700943, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24714383482933044, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.32394319772720337, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.30715227127075195, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.33187007904052734, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.29185256361961365, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3332294225692749, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3452514410018921, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.27375805377960205, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.36850619316101074, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.37171265482902527, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.2978633940219879, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.3392970561981201, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32176175713539124, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.3837161958217621, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3418797254562378, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3377719223499298, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.4122755229473114, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.32927942276000977, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23863722383975983, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.2922666072845459, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.32339081168174744, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.3340962529182434, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.26141899824142456, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 0.4339440166950226, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29008322954177856, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.31712400913238525, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2380955070257187, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.33467501401901245, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.34302717447280884, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.2985098958015442, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.332608699798584, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2900509238243103, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.37809547781944275, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3492063581943512, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.26238709688186646, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.29195934534072876, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 0.38779327273368835, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.28081852197647095, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.34005028009414673, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.37964028120040894, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.36879169940948486, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.3003862202167511, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.38572025299072266, \"iteration\": 505, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.31664523482322693, \"iteration\": 506, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.338726282119751, \"iteration\": 507, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.28344446420669556, \"iteration\": 508, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.32096338272094727, \"iteration\": 509, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.23667101562023163, \"iteration\": 510, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20609773695468903, \"iteration\": 511, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3011188805103302, \"iteration\": 512, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 0.32159972190856934, \"iteration\": 513, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.3518065810203552, \"iteration\": 514, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3652382493019104, \"iteration\": 515, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.3552323579788208, \"iteration\": 516, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 0.2784911096096039, \"iteration\": 517, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.30612820386886597, \"iteration\": 518, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3398106098175049, \"iteration\": 519, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.37056252360343933, \"iteration\": 520, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.32459551095962524, \"iteration\": 521, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.42611315846443176, \"iteration\": 522, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.31577709317207336, \"iteration\": 523, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22242547571659088, \"iteration\": 524, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 0.27679044008255005, \"iteration\": 525, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.35333451628685, \"iteration\": 526, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 0.34490442276000977, \"iteration\": 527, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 0.30427250266075134, \"iteration\": 528, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 0.30304211378097534, \"iteration\": 529, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 0.25581929087638855, \"iteration\": 530, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 0.31633442640304565, \"iteration\": 531, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 0.3109736442565918, \"iteration\": 532, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 0.3278658986091614, \"iteration\": 533, \"epoch\": 3}, {\"training_acc\": 0.8658536585365854, \"training_loss\": 0.35271555185317993, \"iteration\": 534, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 0.20436377823352814, \"iteration\": 535, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2425280511379242, \"iteration\": 536, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2703551948070526, \"iteration\": 537, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.22871547937393188, \"iteration\": 538, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.23385897278785706, \"iteration\": 539, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.24290351569652557, \"iteration\": 540, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.2075897753238678, \"iteration\": 541, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2202177196741104, \"iteration\": 542, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.23385566473007202, \"iteration\": 543, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.23369212448596954, \"iteration\": 544, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.17948266863822937, \"iteration\": 545, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.26249170303344727, \"iteration\": 546, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2415563315153122, \"iteration\": 547, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.21507209539413452, \"iteration\": 548, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.1738726645708084, \"iteration\": 549, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.17892864346504211, \"iteration\": 550, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.23703189194202423, \"iteration\": 551, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15995118021965027, \"iteration\": 552, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.25194305181503296, \"iteration\": 553, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.19669383764266968, \"iteration\": 554, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1630614697933197, \"iteration\": 555, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.21694029867649078, \"iteration\": 556, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2024398148059845, \"iteration\": 557, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.266252338886261, \"iteration\": 558, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2697044610977173, \"iteration\": 559, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1461872011423111, \"iteration\": 560, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16280150413513184, \"iteration\": 561, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.23023881018161774, \"iteration\": 562, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13974738121032715, \"iteration\": 563, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2472335547208786, \"iteration\": 564, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.18467815220355988, \"iteration\": 565, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.19021329283714294, \"iteration\": 566, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.19444642961025238, \"iteration\": 567, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18911533057689667, \"iteration\": 568, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24396304786205292, \"iteration\": 569, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.23444116115570068, \"iteration\": 570, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.19281594455242157, \"iteration\": 571, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.17901010811328888, \"iteration\": 572, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.25355198979377747, \"iteration\": 573, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2051253318786621, \"iteration\": 574, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21410571038722992, \"iteration\": 575, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2146705538034439, \"iteration\": 576, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1532648801803589, \"iteration\": 577, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.20359142124652863, \"iteration\": 578, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.17702770233154297, \"iteration\": 579, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.29999154806137085, \"iteration\": 580, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.1802346408367157, \"iteration\": 581, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1953335702419281, \"iteration\": 582, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.21959255635738373, \"iteration\": 583, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.34419330954551697, \"iteration\": 584, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.22224031388759613, \"iteration\": 585, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.22372257709503174, \"iteration\": 586, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.31666600704193115, \"iteration\": 587, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22547191381454468, \"iteration\": 588, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.16765142977237701, \"iteration\": 589, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.18818490207195282, \"iteration\": 590, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.24402223527431488, \"iteration\": 591, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.19485975801944733, \"iteration\": 592, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.20036374032497406, \"iteration\": 593, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17006903886795044, \"iteration\": 594, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2124491035938263, \"iteration\": 595, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1662089228630066, \"iteration\": 596, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18069906532764435, \"iteration\": 597, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23823103308677673, \"iteration\": 598, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19768837094306946, \"iteration\": 599, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.23761285841464996, \"iteration\": 600, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21450363099575043, \"iteration\": 601, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.23324134945869446, \"iteration\": 602, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26696574687957764, \"iteration\": 603, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.27741459012031555, \"iteration\": 604, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.22897301614284515, \"iteration\": 605, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.26781147718429565, \"iteration\": 606, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.22160547971725464, \"iteration\": 607, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.21673959493637085, \"iteration\": 608, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21084457635879517, \"iteration\": 609, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 0.29806089401245117, \"iteration\": 610, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.22915798425674438, \"iteration\": 611, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15109440684318542, \"iteration\": 612, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.19045786559581757, \"iteration\": 613, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.27863046526908875, \"iteration\": 614, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.230332612991333, \"iteration\": 615, \"epoch\": 4}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13137270510196686, \"iteration\": 616, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.23810313642024994, \"iteration\": 617, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.22241735458374023, \"iteration\": 618, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.21261246502399445, \"iteration\": 619, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.20723609626293182, \"iteration\": 620, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.17119000852108002, \"iteration\": 621, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2696448862552643, \"iteration\": 622, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.23968476057052612, \"iteration\": 623, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2086022049188614, \"iteration\": 624, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2474086880683899, \"iteration\": 625, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.15619052946567535, \"iteration\": 626, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22108370065689087, \"iteration\": 627, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.228220134973526, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2525798976421356, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.189408540725708, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2535549998283386, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.19345156848430634, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20880205929279327, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2416529357433319, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 0.2696806788444519, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17620781064033508, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1941557377576828, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.19363418221473694, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.22870409488677979, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2524093687534332, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.17574051022529602, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.22080153226852417, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18990476429462433, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2406141310930252, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24765892326831818, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.24217571318149567, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.20649415254592896, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.21503141522407532, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22551943361759186, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.18057876825332642, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.21555578708648682, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.18615980446338654, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.1867775022983551, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2848018407821655, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.2369438260793686, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.174099862575531, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.19191353023052216, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.25452572107315063, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2131301760673523, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.22686278820037842, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2330973744392395, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2026342898607254, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.18047575652599335, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.17355991899967194, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.20207464694976807, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.2780205011367798, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2694186568260193, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.23109973967075348, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.20997826755046844, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1712002158164978, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.2035030722618103, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.26050594449043274, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18849438428878784, \"iteration\": 673, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2591792941093445, \"iteration\": 674, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2315806746482849, \"iteration\": 675, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.20973972976207733, \"iteration\": 676, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.23339444398880005, \"iteration\": 677, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.3320696949958801, \"iteration\": 678, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 0.18605443835258484, \"iteration\": 679, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.26467645168304443, \"iteration\": 680, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.3394531011581421, \"iteration\": 681, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.24218448996543884, \"iteration\": 682, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27515578269958496, \"iteration\": 683, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.28744959831237793, \"iteration\": 684, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 0.2627280056476593, \"iteration\": 685, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.24481430649757385, \"iteration\": 686, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.23184406757354736, \"iteration\": 687, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.20231276750564575, \"iteration\": 688, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 0.23323695361614227, \"iteration\": 689, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.20137585699558258, \"iteration\": 690, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2574820816516876, \"iteration\": 691, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 0.2842922806739807, \"iteration\": 692, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.20367570221424103, \"iteration\": 693, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2351967990398407, \"iteration\": 694, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 0.35712212324142456, \"iteration\": 695, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.22774557769298553, \"iteration\": 696, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 0.21953094005584717, \"iteration\": 697, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2418403923511505, \"iteration\": 698, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.2138212025165558, \"iteration\": 699, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.1934414952993393, \"iteration\": 700, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.20322604477405548, \"iteration\": 701, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2549606263637543, \"iteration\": 702, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.21293328702449799, \"iteration\": 703, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 0.16969290375709534, \"iteration\": 704, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.26120105385780334, \"iteration\": 705, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.2785593271255493, \"iteration\": 706, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.19853180646896362, \"iteration\": 707, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 0.21985618770122528, \"iteration\": 708, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 0.27901557087898254, \"iteration\": 709, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 0.25347843766212463, \"iteration\": 710, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 0.24438077211380005, \"iteration\": 711, \"epoch\": 4}, {\"training_acc\": 0.9512195121951219, \"training_loss\": 0.22182148694992065, \"iteration\": 712, \"epoch\": 4}, {\"training_acc\": 0.96875, \"training_loss\": 0.16138392686843872, \"iteration\": 713, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13875561952590942, \"iteration\": 714, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10855656862258911, \"iteration\": 715, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.12104782462120056, \"iteration\": 716, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1379038393497467, \"iteration\": 717, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.09523162245750427, \"iteration\": 718, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11688778549432755, \"iteration\": 719, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06814506649971008, \"iteration\": 720, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13132043182849884, \"iteration\": 721, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09590157866477966, \"iteration\": 722, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13486848771572113, \"iteration\": 723, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09689173102378845, \"iteration\": 724, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09121343493461609, \"iteration\": 725, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07774413377046585, \"iteration\": 726, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10963224619626999, \"iteration\": 727, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14832714200019836, \"iteration\": 728, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1620829999446869, \"iteration\": 729, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10751695930957794, \"iteration\": 730, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07833666354417801, \"iteration\": 731, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09685131907463074, \"iteration\": 732, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09259522706270218, \"iteration\": 733, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08262547850608826, \"iteration\": 734, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11594005674123764, \"iteration\": 735, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08133938908576965, \"iteration\": 736, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14255042374134064, \"iteration\": 737, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08550377935171127, \"iteration\": 738, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.14105281233787537, \"iteration\": 739, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.12566354870796204, \"iteration\": 740, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.12325382977724075, \"iteration\": 741, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.16751763224601746, \"iteration\": 742, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13353458046913147, \"iteration\": 743, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1344572901725769, \"iteration\": 744, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09239654242992401, \"iteration\": 745, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1769176572561264, \"iteration\": 746, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08770117163658142, \"iteration\": 747, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09134028851985931, \"iteration\": 748, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.10719620436429977, \"iteration\": 749, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09637992829084396, \"iteration\": 750, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1212916374206543, \"iteration\": 751, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.0946427658200264, \"iteration\": 752, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.060669876635074615, \"iteration\": 753, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07900692522525787, \"iteration\": 754, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09973576664924622, \"iteration\": 755, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.11450228095054626, \"iteration\": 756, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09774145483970642, \"iteration\": 757, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.12078793346881866, \"iteration\": 758, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.13927386701107025, \"iteration\": 759, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0700143426656723, \"iteration\": 760, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.16710740327835083, \"iteration\": 761, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.1114470511674881, \"iteration\": 762, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.17676368355751038, \"iteration\": 763, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.09600016474723816, \"iteration\": 764, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.15833647549152374, \"iteration\": 765, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.18878643214702606, \"iteration\": 766, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.15544946491718292, \"iteration\": 767, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05885303393006325, \"iteration\": 768, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13425223529338837, \"iteration\": 769, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11581940203905106, \"iteration\": 770, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.11596519500017166, \"iteration\": 771, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13039015233516693, \"iteration\": 772, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.08086474984884262, \"iteration\": 773, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.10954459756612778, \"iteration\": 774, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.12466850876808167, \"iteration\": 775, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.100762739777565, \"iteration\": 776, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.11439181119203568, \"iteration\": 777, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07922901958227158, \"iteration\": 778, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.08608206361532211, \"iteration\": 779, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.1482943892478943, \"iteration\": 780, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11335281282663345, \"iteration\": 781, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.14253225922584534, \"iteration\": 782, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.10904926806688309, \"iteration\": 783, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07361569255590439, \"iteration\": 784, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08190834522247314, \"iteration\": 785, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1114799827337265, \"iteration\": 786, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.10983961075544357, \"iteration\": 787, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08477861434221268, \"iteration\": 788, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09691662341356277, \"iteration\": 789, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.08570174127817154, \"iteration\": 790, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12035413086414337, \"iteration\": 791, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07187876105308533, \"iteration\": 792, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06670943647623062, \"iteration\": 793, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09451699256896973, \"iteration\": 794, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.13731089234352112, \"iteration\": 795, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07005177438259125, \"iteration\": 796, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09288132190704346, \"iteration\": 797, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11224312335252762, \"iteration\": 798, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14601126313209534, \"iteration\": 799, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14790773391723633, \"iteration\": 800, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1513700932264328, \"iteration\": 801, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10232185572385788, \"iteration\": 802, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14455588161945343, \"iteration\": 803, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07863245159387589, \"iteration\": 804, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1420697122812271, \"iteration\": 805, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09454765915870667, \"iteration\": 806, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11580833792686462, \"iteration\": 807, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07627438753843307, \"iteration\": 808, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08640650659799576, \"iteration\": 809, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11364926397800446, \"iteration\": 810, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 0.2737010419368744, \"iteration\": 811, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15538707375526428, \"iteration\": 812, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08728033304214478, \"iteration\": 813, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15110036730766296, \"iteration\": 814, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.19770130515098572, \"iteration\": 815, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.10231298953294754, \"iteration\": 816, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08563025295734406, \"iteration\": 817, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13355331122875214, \"iteration\": 818, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11926357448101044, \"iteration\": 819, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.10274016112089157, \"iteration\": 820, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.13739469647407532, \"iteration\": 821, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09832454472780228, \"iteration\": 822, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0953890010714531, \"iteration\": 823, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11168548464775085, \"iteration\": 824, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.08801339566707611, \"iteration\": 825, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08711238205432892, \"iteration\": 826, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06558215618133545, \"iteration\": 827, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0812913030385971, \"iteration\": 828, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.21410329639911652, \"iteration\": 829, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.14970745146274567, \"iteration\": 830, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09642891585826874, \"iteration\": 831, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1316489577293396, \"iteration\": 832, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0829109326004982, \"iteration\": 833, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13675430417060852, \"iteration\": 834, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 0.18756623566150665, \"iteration\": 835, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08320809155702591, \"iteration\": 836, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13544505834579468, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13319683074951172, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.06721504032611847, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11483188718557358, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09386458992958069, \"iteration\": 841, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.12693098187446594, \"iteration\": 842, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09200532734394073, \"iteration\": 843, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.07187902927398682, \"iteration\": 844, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1339179426431656, \"iteration\": 845, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05495232343673706, \"iteration\": 846, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13273149728775024, \"iteration\": 847, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1314857304096222, \"iteration\": 848, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.06068328022956848, \"iteration\": 849, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.0669272318482399, \"iteration\": 850, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.12140575796365738, \"iteration\": 851, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.15778300166130066, \"iteration\": 852, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.11868711560964584, \"iteration\": 853, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.17326506972312927, \"iteration\": 854, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.23495911061763763, \"iteration\": 855, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.12837737798690796, \"iteration\": 856, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13924482464790344, \"iteration\": 857, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11181912571191788, \"iteration\": 858, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 0.149003803730011, \"iteration\": 859, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09286990761756897, \"iteration\": 860, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.062516950070858, \"iteration\": 861, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.1026865541934967, \"iteration\": 862, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.12845435738563538, \"iteration\": 863, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11258727312088013, \"iteration\": 864, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09693273156881332, \"iteration\": 865, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10877528786659241, \"iteration\": 866, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.08367399871349335, \"iteration\": 867, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1344819813966751, \"iteration\": 868, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.17303399741649628, \"iteration\": 869, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.10559625178575516, \"iteration\": 870, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15647640824317932, \"iteration\": 871, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.15589316189289093, \"iteration\": 872, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.15063680708408356, \"iteration\": 873, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 0.1046801507472992, \"iteration\": 874, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.15049245953559875, \"iteration\": 875, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.11678178608417511, \"iteration\": 876, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.09519466757774353, \"iteration\": 877, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 0.19744011759757996, \"iteration\": 878, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.08421824872493744, \"iteration\": 879, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.18801693618297577, \"iteration\": 880, \"epoch\": 5}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08588635176420212, \"iteration\": 881, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.11708695441484451, \"iteration\": 882, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.13646401464939117, \"iteration\": 883, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.13600647449493408, \"iteration\": 884, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.18412494659423828, \"iteration\": 885, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1436680108308792, \"iteration\": 886, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 0.12182435393333435, \"iteration\": 887, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 0.1784268319606781, \"iteration\": 888, \"epoch\": 5}, {\"training_acc\": 0.984375, \"training_loss\": 0.14924220740795135, \"iteration\": 889, \"epoch\": 5}, {\"training_acc\": 0.9634146341463414, \"training_loss\": 0.14875280857086182, \"iteration\": 890, \"epoch\": 5}, {\"training_acc\": 1.0, \"training_loss\": 0.042884521186351776, \"iteration\": 891, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09217629581689835, \"iteration\": 892, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.06406354159116745, \"iteration\": 893, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07138590514659882, \"iteration\": 894, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07059215009212494, \"iteration\": 895, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.046356201171875, \"iteration\": 896, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.07693076878786087, \"iteration\": 897, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.052281469106674194, \"iteration\": 898, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04665395990014076, \"iteration\": 899, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04112223908305168, \"iteration\": 900, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08477815240621567, \"iteration\": 901, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0748281255364418, \"iteration\": 902, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.030341319739818573, \"iteration\": 903, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.026395458728075027, \"iteration\": 904, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.054526932537555695, \"iteration\": 905, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.028591688722372055, \"iteration\": 906, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06418043375015259, \"iteration\": 907, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05212804675102234, \"iteration\": 908, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03919989615678787, \"iteration\": 909, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.027609853073954582, \"iteration\": 910, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.034038908779621124, \"iteration\": 911, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06613773852586746, \"iteration\": 912, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.025361165404319763, \"iteration\": 913, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.028763018548488617, \"iteration\": 914, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.046822842210531235, \"iteration\": 915, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01975785568356514, \"iteration\": 916, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.07544189691543579, \"iteration\": 917, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09430456161499023, \"iteration\": 918, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.050777871161699295, \"iteration\": 919, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02761247009038925, \"iteration\": 920, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04559497535228729, \"iteration\": 921, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.037121016532182693, \"iteration\": 922, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04144347459077835, \"iteration\": 923, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03024042211472988, \"iteration\": 924, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06664195656776428, \"iteration\": 925, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023871608078479767, \"iteration\": 926, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.021518098190426826, \"iteration\": 927, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03463276848196983, \"iteration\": 928, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05120401829481125, \"iteration\": 929, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020529095083475113, \"iteration\": 930, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06964220106601715, \"iteration\": 931, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.039203595370054245, \"iteration\": 932, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04232551530003548, \"iteration\": 933, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04538033902645111, \"iteration\": 934, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.031708866357803345, \"iteration\": 935, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.039590053260326385, \"iteration\": 936, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0259406678378582, \"iteration\": 937, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02914114110171795, \"iteration\": 938, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02800663374364376, \"iteration\": 939, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0444328598678112, \"iteration\": 940, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.026193713769316673, \"iteration\": 941, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06762736290693283, \"iteration\": 942, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03403160721063614, \"iteration\": 943, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.10217079520225525, \"iteration\": 944, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.058907508850097656, \"iteration\": 945, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.054711174219846725, \"iteration\": 946, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05335976928472519, \"iteration\": 947, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.043486036360263824, \"iteration\": 948, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.059608399868011475, \"iteration\": 949, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03498706594109535, \"iteration\": 950, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0751398503780365, \"iteration\": 951, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03439347445964813, \"iteration\": 952, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03713035583496094, \"iteration\": 953, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03166646882891655, \"iteration\": 954, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06060618907213211, \"iteration\": 955, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03518678620457649, \"iteration\": 956, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.030338099226355553, \"iteration\": 957, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.0356999896466732, \"iteration\": 958, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04008554667234421, \"iteration\": 959, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04570228233933449, \"iteration\": 960, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023294083774089813, \"iteration\": 961, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03709753602743149, \"iteration\": 962, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08428449928760529, \"iteration\": 963, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04402603209018707, \"iteration\": 964, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.031429391354322433, \"iteration\": 965, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04996199905872345, \"iteration\": 966, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.053966160863637924, \"iteration\": 967, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.05867072567343712, \"iteration\": 968, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02829577587544918, \"iteration\": 969, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05964476615190506, \"iteration\": 970, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.054868221282958984, \"iteration\": 971, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03533168509602547, \"iteration\": 972, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03172575309872627, \"iteration\": 973, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.052847158163785934, \"iteration\": 974, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05002932250499725, \"iteration\": 975, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.030987685546278954, \"iteration\": 976, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06066437438130379, \"iteration\": 977, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.09459437429904938, \"iteration\": 978, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03150961920619011, \"iteration\": 979, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06345269829034805, \"iteration\": 980, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.028863130137324333, \"iteration\": 981, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02594549022614956, \"iteration\": 982, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.027755368500947952, \"iteration\": 983, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03474007919430733, \"iteration\": 984, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.021676892414689064, \"iteration\": 985, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02577364258468151, \"iteration\": 986, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02975541353225708, \"iteration\": 987, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.015549726784229279, \"iteration\": 988, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.01776416227221489, \"iteration\": 989, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04681071266531944, \"iteration\": 990, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05580854043364525, \"iteration\": 991, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.036210935562849045, \"iteration\": 992, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.029452506452798843, \"iteration\": 993, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03384974226355553, \"iteration\": 994, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03436882421374321, \"iteration\": 995, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03154369071125984, \"iteration\": 996, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06020401790738106, \"iteration\": 997, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03046681545674801, \"iteration\": 998, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.026336032897233963, \"iteration\": 999, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.0624559111893177, \"iteration\": 1000, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.042805179953575134, \"iteration\": 1001, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.028683919459581375, \"iteration\": 1002, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.057669512927532196, \"iteration\": 1003, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0718553438782692, \"iteration\": 1004, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05276546999812126, \"iteration\": 1005, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03448483347892761, \"iteration\": 1006, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022085674107074738, \"iteration\": 1007, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.027557816356420517, \"iteration\": 1008, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03104359097778797, \"iteration\": 1009, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04953853785991669, \"iteration\": 1010, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04817267879843712, \"iteration\": 1011, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.049784980714321136, \"iteration\": 1012, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 0.09098239243030548, \"iteration\": 1013, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03386993333697319, \"iteration\": 1014, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06758330762386322, \"iteration\": 1015, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.026634329929947853, \"iteration\": 1016, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03852474316954613, \"iteration\": 1017, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02424916811287403, \"iteration\": 1018, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.044719621539115906, \"iteration\": 1019, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02897348441183567, \"iteration\": 1020, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04262928664684296, \"iteration\": 1021, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022173400968313217, \"iteration\": 1022, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03301358222961426, \"iteration\": 1023, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06356456130743027, \"iteration\": 1024, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.033151984214782715, \"iteration\": 1025, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.030063582584261894, \"iteration\": 1026, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02772098034620285, \"iteration\": 1027, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023709595203399658, \"iteration\": 1028, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.019158795475959778, \"iteration\": 1029, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.024201342836022377, \"iteration\": 1030, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08385021239519119, \"iteration\": 1031, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08038842678070068, \"iteration\": 1032, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.043739430606365204, \"iteration\": 1033, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02211328223347664, \"iteration\": 1034, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05756409838795662, \"iteration\": 1035, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.09334211051464081, \"iteration\": 1036, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07195305079221725, \"iteration\": 1037, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.047567497938871384, \"iteration\": 1038, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07473216950893402, \"iteration\": 1039, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.040904853492975235, \"iteration\": 1040, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0346660278737545, \"iteration\": 1041, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03382173925638199, \"iteration\": 1042, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02333410084247589, \"iteration\": 1043, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.037808679044246674, \"iteration\": 1044, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.06622322648763657, \"iteration\": 1045, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03985403850674629, \"iteration\": 1046, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.08366979658603668, \"iteration\": 1047, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03693201020359993, \"iteration\": 1048, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.029406553134322166, \"iteration\": 1049, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.06694083660840988, \"iteration\": 1050, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020519094541668892, \"iteration\": 1051, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.013299493119120598, \"iteration\": 1052, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.08146999031305313, \"iteration\": 1053, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04526897519826889, \"iteration\": 1054, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.04686129093170166, \"iteration\": 1055, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03527633473277092, \"iteration\": 1056, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.05133599787950516, \"iteration\": 1057, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.07758153975009918, \"iteration\": 1058, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.022313889116048813, \"iteration\": 1059, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.032670874148607254, \"iteration\": 1060, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.049590688198804855, \"iteration\": 1061, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.023352304473519325, \"iteration\": 1062, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.02057677134871483, \"iteration\": 1063, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.030285155400633812, \"iteration\": 1064, \"epoch\": 6}, {\"training_acc\": 0.984375, \"training_loss\": 0.07778440415859222, \"iteration\": 1065, \"epoch\": 6}, {\"training_acc\": 0.9921875, \"training_loss\": 0.0406833216547966, \"iteration\": 1066, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.020835958421230316, \"iteration\": 1067, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.03640914708375931, \"iteration\": 1068, \"epoch\": 6}, {\"training_acc\": 1.0, \"training_loss\": 0.011840072460472584, \"iteration\": 1069, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.017539996653795242, \"iteration\": 1070, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008348987437784672, \"iteration\": 1071, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012179458513855934, \"iteration\": 1072, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006479770410805941, \"iteration\": 1073, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010845713317394257, \"iteration\": 1074, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0162106491625309, \"iteration\": 1075, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03144102171063423, \"iteration\": 1076, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007742198184132576, \"iteration\": 1077, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013101087883114815, \"iteration\": 1078, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013162203133106232, \"iteration\": 1079, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0066752247512340546, \"iteration\": 1080, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.022564131766557693, \"iteration\": 1081, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.038757096976041794, \"iteration\": 1082, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012830968014895916, \"iteration\": 1083, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016735760495066643, \"iteration\": 1084, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009201625362038612, \"iteration\": 1085, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.017951762303709984, \"iteration\": 1086, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02747635915875435, \"iteration\": 1087, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.048689331859350204, \"iteration\": 1088, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 0.03235814720392227, \"iteration\": 1089, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01826927624642849, \"iteration\": 1090, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009209970943629742, \"iteration\": 1091, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008509326726198196, \"iteration\": 1092, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.035604506731033325, \"iteration\": 1093, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011786285787820816, \"iteration\": 1094, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00954982079565525, \"iteration\": 1095, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009196029976010323, \"iteration\": 1096, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.02166139893233776, \"iteration\": 1097, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00861374381929636, \"iteration\": 1098, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012905746698379517, \"iteration\": 1099, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01983673684298992, \"iteration\": 1100, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.026099417358636856, \"iteration\": 1101, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009031502529978752, \"iteration\": 1102, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010476518422365189, \"iteration\": 1103, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008006461896002293, \"iteration\": 1104, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010616783052682877, \"iteration\": 1105, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005574486684054136, \"iteration\": 1106, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013992608524858952, \"iteration\": 1107, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007630329579114914, \"iteration\": 1108, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0063072433695197105, \"iteration\": 1109, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016674339771270752, \"iteration\": 1110, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007280349265784025, \"iteration\": 1111, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01414220966398716, \"iteration\": 1112, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008424222469329834, \"iteration\": 1113, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011587894521653652, \"iteration\": 1114, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007950296625494957, \"iteration\": 1115, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008982818573713303, \"iteration\": 1116, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005631317850202322, \"iteration\": 1117, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008147803135216236, \"iteration\": 1118, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012975147925317287, \"iteration\": 1119, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006110057234764099, \"iteration\": 1120, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0089852474629879, \"iteration\": 1121, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007270097732543945, \"iteration\": 1122, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00810414832085371, \"iteration\": 1123, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0063555315136909485, \"iteration\": 1124, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008678779937326908, \"iteration\": 1125, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03325299918651581, \"iteration\": 1126, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005789534188807011, \"iteration\": 1127, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007607646752148867, \"iteration\": 1128, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037038528826087713, \"iteration\": 1129, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01055091992020607, \"iteration\": 1130, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008011977188289165, \"iteration\": 1131, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006314016878604889, \"iteration\": 1132, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01483162585645914, \"iteration\": 1133, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.016802018508315086, \"iteration\": 1134, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008867459371685982, \"iteration\": 1135, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007467735558748245, \"iteration\": 1136, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007975321263074875, \"iteration\": 1137, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008390233851969242, \"iteration\": 1138, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006182178854942322, \"iteration\": 1139, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008744508028030396, \"iteration\": 1140, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00569536816328764, \"iteration\": 1141, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006901392247527838, \"iteration\": 1142, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006613763980567455, \"iteration\": 1143, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005779671482741833, \"iteration\": 1144, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.014955515041947365, \"iteration\": 1145, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008699986152350903, \"iteration\": 1146, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007069452200084925, \"iteration\": 1147, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014778983779251575, \"iteration\": 1148, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011160830035805702, \"iteration\": 1149, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.053490642458200455, \"iteration\": 1150, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004487218800932169, \"iteration\": 1151, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00449590478092432, \"iteration\": 1152, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01284395344555378, \"iteration\": 1153, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004860682412981987, \"iteration\": 1154, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009577605873346329, \"iteration\": 1155, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005605906248092651, \"iteration\": 1156, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037363325245678425, \"iteration\": 1157, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007976225577294827, \"iteration\": 1158, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005574455950409174, \"iteration\": 1159, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0056409831158816814, \"iteration\": 1160, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010605426505208015, \"iteration\": 1161, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012843991629779339, \"iteration\": 1162, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008624741807579994, \"iteration\": 1163, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006665906868875027, \"iteration\": 1164, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005397938657552004, \"iteration\": 1165, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01001148670911789, \"iteration\": 1166, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006769483909010887, \"iteration\": 1167, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012707095593214035, \"iteration\": 1168, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008130516856908798, \"iteration\": 1169, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007233170326799154, \"iteration\": 1170, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01231205090880394, \"iteration\": 1171, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0042140851728618145, \"iteration\": 1172, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009168695658445358, \"iteration\": 1173, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008143885061144829, \"iteration\": 1174, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.024062298238277435, \"iteration\": 1175, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008430770598351955, \"iteration\": 1176, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.04196551442146301, \"iteration\": 1177, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.013824526220560074, \"iteration\": 1178, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004212389700114727, \"iteration\": 1179, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005450408905744553, \"iteration\": 1180, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0049232118763029575, \"iteration\": 1181, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007856865413486958, \"iteration\": 1182, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012608850374817848, \"iteration\": 1183, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009701510891318321, \"iteration\": 1184, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0025203549303114414, \"iteration\": 1185, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006623192690312862, \"iteration\": 1186, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.03776567429304123, \"iteration\": 1187, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.011107077822089195, \"iteration\": 1188, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00784648209810257, \"iteration\": 1189, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004874606616795063, \"iteration\": 1190, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005678876303136349, \"iteration\": 1191, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004361117258667946, \"iteration\": 1192, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004128740169107914, \"iteration\": 1193, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0074789333157241344, \"iteration\": 1194, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010083307512104511, \"iteration\": 1195, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006212050560861826, \"iteration\": 1196, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004282165318727493, \"iteration\": 1197, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003536239266395569, \"iteration\": 1198, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00350864976644516, \"iteration\": 1199, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006966431625187397, \"iteration\": 1200, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003644332755357027, \"iteration\": 1201, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012714001350104809, \"iteration\": 1202, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007977408356964588, \"iteration\": 1203, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00650327792391181, \"iteration\": 1204, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007427819073200226, \"iteration\": 1205, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004727523308247328, \"iteration\": 1206, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010173805989325047, \"iteration\": 1207, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0073911636136472225, \"iteration\": 1208, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007312054745852947, \"iteration\": 1209, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.007768054027110338, \"iteration\": 1210, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0037886276841163635, \"iteration\": 1211, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01997322589159012, \"iteration\": 1212, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003323611570522189, \"iteration\": 1213, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006167271174490452, \"iteration\": 1214, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.017612027004361153, \"iteration\": 1215, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008781813085079193, \"iteration\": 1216, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0076710134744644165, \"iteration\": 1217, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0061178915202617645, \"iteration\": 1218, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004342594183981419, \"iteration\": 1219, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0027882838621735573, \"iteration\": 1220, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004704863764345646, \"iteration\": 1221, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.009027991443872452, \"iteration\": 1222, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01462000422179699, \"iteration\": 1223, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0060049123130738735, \"iteration\": 1224, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.014708831906318665, \"iteration\": 1225, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.00545195396989584, \"iteration\": 1226, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005348728504031897, \"iteration\": 1227, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003913357388228178, \"iteration\": 1228, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0035306767094880342, \"iteration\": 1229, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004975664895027876, \"iteration\": 1230, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005638575181365013, \"iteration\": 1231, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.005128596443682909, \"iteration\": 1232, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.015019427984952927, \"iteration\": 1233, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.01898743212223053, \"iteration\": 1234, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004991199355572462, \"iteration\": 1235, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.027470111846923828, \"iteration\": 1236, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0051592448726296425, \"iteration\": 1237, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038547073490917683, \"iteration\": 1238, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.004707865417003632, \"iteration\": 1239, \"epoch\": 7}, {\"training_acc\": 0.9921875, \"training_loss\": 0.025511816143989563, \"iteration\": 1240, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.008484193123877048, \"iteration\": 1241, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.006428231485188007, \"iteration\": 1242, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.012583528645336628, \"iteration\": 1243, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0029842336662113667, \"iteration\": 1244, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.003952715080231428, \"iteration\": 1245, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.010217458009719849, \"iteration\": 1246, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 0.0038050173316150904, \"iteration\": 1247, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0034293129574507475, \"iteration\": 1248, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0031434602569788694, \"iteration\": 1249, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0035389482509344816, \"iteration\": 1250, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002114899456501007, \"iteration\": 1251, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002692039590328932, \"iteration\": 1252, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006256667897105217, \"iteration\": 1253, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001964177004992962, \"iteration\": 1254, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0025698537938296795, \"iteration\": 1255, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00302822794765234, \"iteration\": 1256, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0024216293822973967, \"iteration\": 1257, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0030338892247527838, \"iteration\": 1258, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0032842119690030813, \"iteration\": 1259, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005208478309214115, \"iteration\": 1260, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.006690305657684803, \"iteration\": 1261, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019862966146320105, \"iteration\": 1262, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00328323757275939, \"iteration\": 1263, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015637240139767528, \"iteration\": 1264, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015085641061887145, \"iteration\": 1265, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0028369324281811714, \"iteration\": 1266, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01001955196261406, \"iteration\": 1267, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007718056906014681, \"iteration\": 1268, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002771640894934535, \"iteration\": 1269, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002183143049478531, \"iteration\": 1270, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001728827366605401, \"iteration\": 1271, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002833177801221609, \"iteration\": 1272, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002839016495272517, \"iteration\": 1273, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.016852155327796936, \"iteration\": 1274, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002478630980476737, \"iteration\": 1275, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003973353188484907, \"iteration\": 1276, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014755409210920334, \"iteration\": 1277, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003653183812275529, \"iteration\": 1278, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0048665194772183895, \"iteration\": 1279, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0036292634904384613, \"iteration\": 1280, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004795169923454523, \"iteration\": 1281, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003489372320473194, \"iteration\": 1282, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023464078549295664, \"iteration\": 1283, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001822377904318273, \"iteration\": 1284, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015021112048998475, \"iteration\": 1285, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023018980864435434, \"iteration\": 1286, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018785680877044797, \"iteration\": 1287, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023228421341627836, \"iteration\": 1288, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002378832083195448, \"iteration\": 1289, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004491529893130064, \"iteration\": 1290, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0027048278134316206, \"iteration\": 1291, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003346033161506057, \"iteration\": 1292, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016785513143986464, \"iteration\": 1293, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0034196428023278713, \"iteration\": 1294, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022863999474793673, \"iteration\": 1295, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017153206281363964, \"iteration\": 1296, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018081110902130604, \"iteration\": 1297, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017781390342861414, \"iteration\": 1298, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002263540867716074, \"iteration\": 1299, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00261725508607924, \"iteration\": 1300, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022398533765226603, \"iteration\": 1301, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015314039774239063, \"iteration\": 1302, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013802717439830303, \"iteration\": 1303, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019858013838529587, \"iteration\": 1304, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0025062370114028454, \"iteration\": 1305, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023470153100788593, \"iteration\": 1306, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020305966027081013, \"iteration\": 1307, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0036567668430507183, \"iteration\": 1308, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010956787737086415, \"iteration\": 1309, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011764850933104753, \"iteration\": 1310, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016792089445516467, \"iteration\": 1311, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001608307589776814, \"iteration\": 1312, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019855445716530085, \"iteration\": 1313, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002457395428791642, \"iteration\": 1314, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015519801527261734, \"iteration\": 1315, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013796392595395446, \"iteration\": 1316, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0007938690250739455, \"iteration\": 1317, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001997089246287942, \"iteration\": 1318, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.008157696574926376, \"iteration\": 1319, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015394538640975952, \"iteration\": 1320, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018986407667398453, \"iteration\": 1321, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021194475702941418, \"iteration\": 1322, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019116776529699564, \"iteration\": 1323, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0028777054976671934, \"iteration\": 1324, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020656080450862646, \"iteration\": 1325, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001332537503913045, \"iteration\": 1326, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00098152004648, \"iteration\": 1327, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020494889467954636, \"iteration\": 1328, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019666925072669983, \"iteration\": 1329, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017645135521888733, \"iteration\": 1330, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023074420168995857, \"iteration\": 1331, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017245118506252766, \"iteration\": 1332, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.004132574424147606, \"iteration\": 1333, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016062059439718723, \"iteration\": 1334, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011332682333886623, \"iteration\": 1335, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0031492230482399464, \"iteration\": 1336, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005257284268736839, \"iteration\": 1337, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013981431256979704, \"iteration\": 1338, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001812687492929399, \"iteration\": 1339, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017141407588496804, \"iteration\": 1340, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003660502377897501, \"iteration\": 1341, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015759613597765565, \"iteration\": 1342, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013717875117436051, \"iteration\": 1343, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015538104344159365, \"iteration\": 1344, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016590525628998876, \"iteration\": 1345, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002306913724169135, \"iteration\": 1346, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0027299963403493166, \"iteration\": 1347, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01001232024282217, \"iteration\": 1348, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019789792131632566, \"iteration\": 1349, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002954592229798436, \"iteration\": 1350, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002962829079478979, \"iteration\": 1351, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013825362548232079, \"iteration\": 1352, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002009666757658124, \"iteration\": 1353, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019199601374566555, \"iteration\": 1354, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002945986809208989, \"iteration\": 1355, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023999190889298916, \"iteration\": 1356, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023048582952469587, \"iteration\": 1357, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011261433828622103, \"iteration\": 1358, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012723911786451936, \"iteration\": 1359, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018662743968889117, \"iteration\": 1360, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011302176862955093, \"iteration\": 1361, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001916619366966188, \"iteration\": 1362, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012705129338428378, \"iteration\": 1363, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013294239761307836, \"iteration\": 1364, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.003657640889286995, \"iteration\": 1365, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001305221812799573, \"iteration\": 1366, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016643402632325888, \"iteration\": 1367, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013387417420744896, \"iteration\": 1368, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002204712014645338, \"iteration\": 1369, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002339182188734412, \"iteration\": 1370, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009335632785223424, \"iteration\": 1371, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018076798878610134, \"iteration\": 1372, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.007257334887981415, \"iteration\": 1373, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009830977069213986, \"iteration\": 1374, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022538083139806986, \"iteration\": 1375, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0022918416652828455, \"iteration\": 1376, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002193417167291045, \"iteration\": 1377, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.01049906387925148, \"iteration\": 1378, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011927485466003418, \"iteration\": 1379, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0021466691978275776, \"iteration\": 1380, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002195048378780484, \"iteration\": 1381, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0023847692646086216, \"iteration\": 1382, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011272274423390627, \"iteration\": 1383, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001243487698957324, \"iteration\": 1384, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008493604836985469, \"iteration\": 1385, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017944487044587731, \"iteration\": 1386, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001043963711708784, \"iteration\": 1387, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015906303888186812, \"iteration\": 1388, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00147947296500206, \"iteration\": 1389, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008120685815811157, \"iteration\": 1390, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.005758581217378378, \"iteration\": 1391, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0020478414371609688, \"iteration\": 1392, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0015139463357627392, \"iteration\": 1393, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0010064048692584038, \"iteration\": 1394, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 0.01191050373017788, \"iteration\": 1395, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012217718176543713, \"iteration\": 1396, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016714532393962145, \"iteration\": 1397, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0019951441790908575, \"iteration\": 1398, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001271323300898075, \"iteration\": 1399, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011564503656700253, \"iteration\": 1400, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0018458202248439193, \"iteration\": 1401, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013637825613841414, \"iteration\": 1402, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0029134536162018776, \"iteration\": 1403, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011630652006715536, \"iteration\": 1404, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001392949721775949, \"iteration\": 1405, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0014274094719439745, \"iteration\": 1406, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012436277465894818, \"iteration\": 1407, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0016004699282348156, \"iteration\": 1408, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.00211406615562737, \"iteration\": 1409, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001026574638672173, \"iteration\": 1410, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011296247830614448, \"iteration\": 1411, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008755252929404378, \"iteration\": 1412, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013684576842933893, \"iteration\": 1413, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012133605778217316, \"iteration\": 1414, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.001998600084334612, \"iteration\": 1415, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0011797391343861818, \"iteration\": 1416, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0017544172005727887, \"iteration\": 1417, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0028439611196517944, \"iteration\": 1418, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0027940578293055296, \"iteration\": 1419, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0013208771124482155, \"iteration\": 1420, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009297660435549915, \"iteration\": 1421, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0009739205706864595, \"iteration\": 1422, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.002055976539850235, \"iteration\": 1423, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0012449329951778054, \"iteration\": 1424, \"epoch\": 8}, {\"training_acc\": 1.0, \"training_loss\": 0.0008354628225788474, \"iteration\": 1425, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009689124999567866, \"iteration\": 1426, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010066907852888107, \"iteration\": 1427, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009535035933367908, \"iteration\": 1428, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007791302632540464, \"iteration\": 1429, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009335016366094351, \"iteration\": 1430, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007324740872718394, \"iteration\": 1431, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005918925162404776, \"iteration\": 1432, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008753050351515412, \"iteration\": 1433, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013676055241376162, \"iteration\": 1434, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005890953470952809, \"iteration\": 1435, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006037399871274829, \"iteration\": 1436, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000928703520912677, \"iteration\": 1437, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007395098218694329, \"iteration\": 1438, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006657196790911257, \"iteration\": 1439, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009994987631216645, \"iteration\": 1440, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009754643542692065, \"iteration\": 1441, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008651547832414508, \"iteration\": 1442, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000659214798361063, \"iteration\": 1443, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0011726688826456666, \"iteration\": 1444, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007459819316864014, \"iteration\": 1445, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005702463677152991, \"iteration\": 1446, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001307420781813562, \"iteration\": 1447, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008676353609189391, \"iteration\": 1448, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006106136133894324, \"iteration\": 1449, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000643838313408196, \"iteration\": 1450, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008057039231061935, \"iteration\": 1451, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007232913048937917, \"iteration\": 1452, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005954946973361075, \"iteration\": 1453, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006200997158885002, \"iteration\": 1454, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006515359273180366, \"iteration\": 1455, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007596826180815697, \"iteration\": 1456, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006362166022881866, \"iteration\": 1457, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006008332711644471, \"iteration\": 1458, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006883482565172017, \"iteration\": 1459, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006214274908415973, \"iteration\": 1460, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005275470321066678, \"iteration\": 1461, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006599464686587453, \"iteration\": 1462, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005485662259161472, \"iteration\": 1463, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000504294119309634, \"iteration\": 1464, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006069064838811755, \"iteration\": 1465, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004612074699252844, \"iteration\": 1466, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004438800096977502, \"iteration\": 1467, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008979703998193145, \"iteration\": 1468, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00039926887257024646, \"iteration\": 1469, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007832968840375543, \"iteration\": 1470, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007770970114506781, \"iteration\": 1471, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006304981652647257, \"iteration\": 1472, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006679296493530273, \"iteration\": 1473, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004833207931369543, \"iteration\": 1474, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006632908480241895, \"iteration\": 1475, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005767761031165719, \"iteration\": 1476, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005450495518743992, \"iteration\": 1477, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000655433046631515, \"iteration\": 1478, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000411929126130417, \"iteration\": 1479, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004039099148940295, \"iteration\": 1480, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000651633192319423, \"iteration\": 1481, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004976840573363006, \"iteration\": 1482, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007371407700702548, \"iteration\": 1483, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006844489253126085, \"iteration\": 1484, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007105623953975737, \"iteration\": 1485, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006830036290921271, \"iteration\": 1486, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007866455125622451, \"iteration\": 1487, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006040947046130896, \"iteration\": 1488, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043163090595044196, \"iteration\": 1489, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006965314969420433, \"iteration\": 1490, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000737376045435667, \"iteration\": 1491, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007511808653362095, \"iteration\": 1492, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.001128014293499291, \"iteration\": 1493, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007649504113942385, \"iteration\": 1494, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005999996210448444, \"iteration\": 1495, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002977938565891236, \"iteration\": 1496, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006760420510545373, \"iteration\": 1497, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00044977280776947737, \"iteration\": 1498, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003898863506037742, \"iteration\": 1499, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007603033445775509, \"iteration\": 1500, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00035980690154246986, \"iteration\": 1501, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006842848379164934, \"iteration\": 1502, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005819997168146074, \"iteration\": 1503, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007196144433692098, \"iteration\": 1504, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005622880416922271, \"iteration\": 1505, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006802903953939676, \"iteration\": 1506, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005570692010223866, \"iteration\": 1507, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005336087197065353, \"iteration\": 1508, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006365595036186278, \"iteration\": 1509, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007072320440784097, \"iteration\": 1510, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005466969450935721, \"iteration\": 1511, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008043733541853726, \"iteration\": 1512, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005266075604595244, \"iteration\": 1513, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00048558140406385064, \"iteration\": 1514, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007581203244626522, \"iteration\": 1515, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00044960982631891966, \"iteration\": 1516, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005655977874994278, \"iteration\": 1517, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010423948988318443, \"iteration\": 1518, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006784888100810349, \"iteration\": 1519, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005706842639483511, \"iteration\": 1520, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005525195156224072, \"iteration\": 1521, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005551775102503598, \"iteration\": 1522, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000574461417272687, \"iteration\": 1523, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005809470894746482, \"iteration\": 1524, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005100040580146015, \"iteration\": 1525, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004918629419989884, \"iteration\": 1526, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0009002650622278452, \"iteration\": 1527, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005453187040984631, \"iteration\": 1528, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004913965822197497, \"iteration\": 1529, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0013736787950620055, \"iteration\": 1530, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004639366234187037, \"iteration\": 1531, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036202301271259785, \"iteration\": 1532, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005407768185250461, \"iteration\": 1533, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00047880367492325604, \"iteration\": 1534, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005686397780664265, \"iteration\": 1535, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00046434119576588273, \"iteration\": 1536, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003769657632801682, \"iteration\": 1537, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0010161139070987701, \"iteration\": 1538, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004389783716760576, \"iteration\": 1539, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005019080708734691, \"iteration\": 1540, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004543851828202605, \"iteration\": 1541, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008205578196793795, \"iteration\": 1542, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005182389286346734, \"iteration\": 1543, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005581547738984227, \"iteration\": 1544, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000634486845228821, \"iteration\": 1545, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008855696069076657, \"iteration\": 1546, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00038433659938164055, \"iteration\": 1547, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005539818666875362, \"iteration\": 1548, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000335682270815596, \"iteration\": 1549, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00045054848305881023, \"iteration\": 1550, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0008752261055633426, \"iteration\": 1551, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00040267984149977565, \"iteration\": 1552, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033350358717143536, \"iteration\": 1553, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005924190627411008, \"iteration\": 1554, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00033123756293207407, \"iteration\": 1555, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0002919186372309923, \"iteration\": 1556, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004252110084053129, \"iteration\": 1557, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003678514913190156, \"iteration\": 1558, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00046724954154342413, \"iteration\": 1559, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003820026176981628, \"iteration\": 1560, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004925751709379256, \"iteration\": 1561, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005159449647180736, \"iteration\": 1562, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005169840878807008, \"iteration\": 1563, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005035504000261426, \"iteration\": 1564, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005563640152104199, \"iteration\": 1565, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005581138539128006, \"iteration\": 1566, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006823285948485136, \"iteration\": 1567, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003807393950410187, \"iteration\": 1568, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006192071014083922, \"iteration\": 1569, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00028755608946084976, \"iteration\": 1570, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004270389617886394, \"iteration\": 1571, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005679717287421227, \"iteration\": 1572, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00038280454464256763, \"iteration\": 1573, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00037705994327552617, \"iteration\": 1574, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00040957413148134947, \"iteration\": 1575, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00043105141958221793, \"iteration\": 1576, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005442006513476372, \"iteration\": 1577, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003218741330783814, \"iteration\": 1578, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003319546231068671, \"iteration\": 1579, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000696642673574388, \"iteration\": 1580, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007070507854223251, \"iteration\": 1581, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003742957196664065, \"iteration\": 1582, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005976250977255404, \"iteration\": 1583, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007266944739967585, \"iteration\": 1584, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003780513070523739, \"iteration\": 1585, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004043866356369108, \"iteration\": 1586, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00036125758197158575, \"iteration\": 1587, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003289664746262133, \"iteration\": 1588, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003843927988782525, \"iteration\": 1589, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003933082625735551, \"iteration\": 1590, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006524139316752553, \"iteration\": 1591, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004401869955472648, \"iteration\": 1592, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004343489417806268, \"iteration\": 1593, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00031611579470336437, \"iteration\": 1594, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004427170497365296, \"iteration\": 1595, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005663821357302368, \"iteration\": 1596, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0007419923203997314, \"iteration\": 1597, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0004017885948996991, \"iteration\": 1598, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0005958151305094361, \"iteration\": 1599, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0003102608025074005, \"iteration\": 1600, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.0006229613209143281, \"iteration\": 1601, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.00047632469795644283, \"iteration\": 1602, \"epoch\": 9}, {\"training_acc\": 1.0, \"training_loss\": 0.000304292218061164, \"iteration\": 1603, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024214033328462392, \"iteration\": 1604, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003902588505297899, \"iteration\": 1605, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00033026403980329633, \"iteration\": 1606, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022667831217404455, \"iteration\": 1607, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00042036158265545964, \"iteration\": 1608, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028964129160158336, \"iteration\": 1609, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00041541861719451845, \"iteration\": 1610, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022586512204725295, \"iteration\": 1611, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027818052330985665, \"iteration\": 1612, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027351255994290113, \"iteration\": 1613, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002835342602338642, \"iteration\": 1614, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002004154521273449, \"iteration\": 1615, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023269676603376865, \"iteration\": 1616, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030065467581152916, \"iteration\": 1617, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00038647165638394654, \"iteration\": 1618, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021850157645531, \"iteration\": 1619, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030065991450101137, \"iteration\": 1620, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003718919469974935, \"iteration\": 1621, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028433569241315126, \"iteration\": 1622, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002773096493910998, \"iteration\": 1623, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028610037406906486, \"iteration\": 1624, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024421888520009816, \"iteration\": 1625, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00040873410762287676, \"iteration\": 1626, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00035165040753781796, \"iteration\": 1627, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00035555072827264667, \"iteration\": 1628, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002059624675894156, \"iteration\": 1629, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00042506400495767593, \"iteration\": 1630, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000290457159280777, \"iteration\": 1631, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022576667834073305, \"iteration\": 1632, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003796176169998944, \"iteration\": 1633, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00042302385554648936, \"iteration\": 1634, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030911783687770367, \"iteration\": 1635, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015578810416627675, \"iteration\": 1636, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030331267043948174, \"iteration\": 1637, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00034826749470084906, \"iteration\": 1638, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003047931531909853, \"iteration\": 1639, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002398294600425288, \"iteration\": 1640, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003423839807510376, \"iteration\": 1641, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00032210719655267894, \"iteration\": 1642, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023094004427548498, \"iteration\": 1643, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031204987317323685, \"iteration\": 1644, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002681127516552806, \"iteration\": 1645, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021188516984693706, \"iteration\": 1646, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020549555483739823, \"iteration\": 1647, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000208937082788907, \"iteration\": 1648, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00028990127611905336, \"iteration\": 1649, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002672359114512801, \"iteration\": 1650, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000255760969594121, \"iteration\": 1651, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030602229526266456, \"iteration\": 1652, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002705488004721701, \"iteration\": 1653, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002770226274151355, \"iteration\": 1654, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021622850908897817, \"iteration\": 1655, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020982879505027086, \"iteration\": 1656, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003344370343256742, \"iteration\": 1657, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00035605792072601616, \"iteration\": 1658, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001835553121054545, \"iteration\": 1659, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024634035071358085, \"iteration\": 1660, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002660795580595732, \"iteration\": 1661, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015487561176996678, \"iteration\": 1662, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002603334141895175, \"iteration\": 1663, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031933063291944563, \"iteration\": 1664, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020723446505144238, \"iteration\": 1665, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025531311985105276, \"iteration\": 1666, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018389020988252014, \"iteration\": 1667, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020292749104555696, \"iteration\": 1668, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024848172324709594, \"iteration\": 1669, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019160256488248706, \"iteration\": 1670, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002619700971990824, \"iteration\": 1671, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026322706253267825, \"iteration\": 1672, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026056106435135007, \"iteration\": 1673, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00030245521338656545, \"iteration\": 1674, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025553989689797163, \"iteration\": 1675, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002685898798517883, \"iteration\": 1676, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031355637474916875, \"iteration\": 1677, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0003368845209479332, \"iteration\": 1678, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013982399832457304, \"iteration\": 1679, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024598962045274675, \"iteration\": 1680, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026296888245269656, \"iteration\": 1681, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000184089076356031, \"iteration\": 1682, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00025923625798895955, \"iteration\": 1683, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011549456394277513, \"iteration\": 1684, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000247792195295915, \"iteration\": 1685, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001904078817460686, \"iteration\": 1686, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021977617871016264, \"iteration\": 1687, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002102622966049239, \"iteration\": 1688, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020713733101729304, \"iteration\": 1689, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002735822054091841, \"iteration\": 1690, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021774043852929026, \"iteration\": 1691, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019755841640289873, \"iteration\": 1692, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002107152104144916, \"iteration\": 1693, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002106982283294201, \"iteration\": 1694, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020109995966777205, \"iteration\": 1695, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023296121798921376, \"iteration\": 1696, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002796879562083632, \"iteration\": 1697, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020710434182547033, \"iteration\": 1698, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020585725724231452, \"iteration\": 1699, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002510985650587827, \"iteration\": 1700, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026030890876427293, \"iteration\": 1701, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001503023668192327, \"iteration\": 1702, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001510473812231794, \"iteration\": 1703, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001698510313872248, \"iteration\": 1704, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001571887987665832, \"iteration\": 1705, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00024564890190958977, \"iteration\": 1706, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020733739074785262, \"iteration\": 1707, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002560879220254719, \"iteration\": 1708, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019235737272538245, \"iteration\": 1709, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021140504395589232, \"iteration\": 1710, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023890502052381635, \"iteration\": 1711, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019821731257252395, \"iteration\": 1712, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002511603815946728, \"iteration\": 1713, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019542264635674655, \"iteration\": 1714, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013410260726232082, \"iteration\": 1715, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017929216846823692, \"iteration\": 1716, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00020464439876377583, \"iteration\": 1717, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011989438644377515, \"iteration\": 1718, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016512633010279387, \"iteration\": 1719, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001860462361946702, \"iteration\": 1720, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022354541579261422, \"iteration\": 1721, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000257402251008898, \"iteration\": 1722, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002213812986155972, \"iteration\": 1723, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019997618801426142, \"iteration\": 1724, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019402173347771168, \"iteration\": 1725, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00017097487580031157, \"iteration\": 1726, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002243039052700624, \"iteration\": 1727, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002256742591271177, \"iteration\": 1728, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023019220679998398, \"iteration\": 1729, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015761148824822158, \"iteration\": 1730, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013252564531285316, \"iteration\": 1731, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0006695418269373477, \"iteration\": 1732, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015496573178097606, \"iteration\": 1733, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015485772746615112, \"iteration\": 1734, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016027948004193604, \"iteration\": 1735, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00021369525347836316, \"iteration\": 1736, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013381084136199206, \"iteration\": 1737, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018098334840033203, \"iteration\": 1738, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013227711315266788, \"iteration\": 1739, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 9.581833000993356e-05, \"iteration\": 1740, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014042301336303353, \"iteration\": 1741, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019156266353093088, \"iteration\": 1742, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019748906197492033, \"iteration\": 1743, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011710998660419136, \"iteration\": 1744, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00022626113786827773, \"iteration\": 1745, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00019269147014711052, \"iteration\": 1746, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00013204979768488556, \"iteration\": 1747, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00031220150412991643, \"iteration\": 1748, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018829597684089094, \"iteration\": 1749, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001707903720671311, \"iteration\": 1750, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 8.874903141986579e-05, \"iteration\": 1751, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001663970178924501, \"iteration\": 1752, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001335185661446303, \"iteration\": 1753, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000230441422900185, \"iteration\": 1754, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001978072978090495, \"iteration\": 1755, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002124071615980938, \"iteration\": 1756, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0002023770211962983, \"iteration\": 1757, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00010683123400667682, \"iteration\": 1758, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001646509044803679, \"iteration\": 1759, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001871871209004894, \"iteration\": 1760, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018550398817751557, \"iteration\": 1761, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014689983800053596, \"iteration\": 1762, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.000261106964899227, \"iteration\": 1763, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 5.472246994031593e-05, \"iteration\": 1764, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014944630675017834, \"iteration\": 1765, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00018572075350675732, \"iteration\": 1766, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011780121712945402, \"iteration\": 1767, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00027198929456062615, \"iteration\": 1768, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014118614490143955, \"iteration\": 1769, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016164487169589847, \"iteration\": 1770, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00011375673057045788, \"iteration\": 1771, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001649566402193159, \"iteration\": 1772, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00026212300872430205, \"iteration\": 1773, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.0001865079830167815, \"iteration\": 1774, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016758445417508483, \"iteration\": 1775, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00014152425865177065, \"iteration\": 1776, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015938404249027371, \"iteration\": 1777, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00016904159565456212, \"iteration\": 1778, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00023261817113962024, \"iteration\": 1779, \"epoch\": 10}, {\"training_acc\": 1.0, \"training_loss\": 0.00015193081344477832, \"iteration\": 1780, \"epoch\": 10}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "USE_CACHE = False\n",
    "models_dir = Path(\"models\")\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(char_tfidf.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "if (models_dir / 'model_nn.pt').exists() and USE_CACHE:\n",
    "    model_nn = load_model(model_nn, models_dir, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(dataloader, train_config, disable_progress_bar=False)\n",
    "    save_model(model_nn, models_dir, \"model_nn\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # X_test = torch.stack([dta[0] for dta in test])\n",
    "    X_test = torch.stack([test[0] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_test = torch.stack([test[1] for test in test_data_nn]).to(model_nn.device)\n",
    "    y_pred = model_nn.predict(X_test)\n",
    "\n",
    "\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='binary'))\n",
    "print(\"AUC\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power-identification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
