{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from models import NeuralNetwork, TrainConfig, evaluate_nn_model, save_model, load_model, plot_results\n",
    "from utils import load_data, split_data, encode_data, mapping_dict\n",
    "from pathlib import Path\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"Device: cuda\")\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"Device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load power-gb-train.tsv...\n"
     ]
    }
   ],
   "source": [
    "# POC\n",
    "#%%\n",
    "file_list = [\n",
    "    'power-gb-train.tsv',\n",
    "    # 'power-ua-train.tsv',\n",
    "    # 'power-fr-train.tsv',\n",
    "    # 'power-nl-train.tsv',\n",
    "]\n",
    "\n",
    "full_data = load_data(folder_path=\"data/train/power/\", file_list=file_list,text_head='text_en')\n",
    "train_dev_raw, test_raw = split_data(full_data, test_size=0.2, random_state=0)\n",
    "train_raw, dev_raw = split_data(train_dev_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "file_list = [\n",
    "    'power-gb-test.tsv',\n",
    "    # 'power-ua-train.tsv',\n",
    "    # 'power-fr-train.tsv',\n",
    "    # 'power-nl-train.tsv',\n",
    "]\n",
    "\n",
    "test_data = load_data(folder_path=\"data/test/power/\", file_list=file_list,text_head='text_en')\n",
    "\n",
    "print(\"Prepare data encoder...\")\n",
    "# train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "train_encoder = TfidfVectorizer(max_features=10000)\n",
    "train_encoder.fit(train_raw.texts)\n",
    "\n",
    "print(\"Prepare data...\")\n",
    "train_dataset = encode_data(train_raw, train_encoder)\n",
    "dev_dataset = encode_data(dev_raw, train_encoder)\n",
    "test_dataset = encode_data(test_raw, train_encoder)\n",
    "\n",
    "print(\"Train model\")\n",
    "models_dir = Path('models')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(train_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "if Path('models/model_nn.pt').exists():\n",
    "    model_nn = load_model(model_nn, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(train_dataloader, train_config)\n",
    "    save_model(model_nn, \"model_nn\")\n",
    "\n",
    "model_nn_results = evaluate_nn_model(model_nn, test_dataset)\n",
    "np.save('models/model_nn_results.npy', model_nn_results)\n",
    "print(model_nn_results)\n",
    "\n",
    "\n",
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power-at-train (0.758832573890686, 0.5467289686203003, 0.5984655022621155)\n",
      "power-ba-train (0.8353909254074097, 0.9308755993843079, 0.9099099040031433)\n",
      "power-be-train (0.540569007396698, 0.39673912525177, 0.5011441707611084)\n",
      "power-bg-train (0.6343283653259277, 0.48170730471611023, 0.5632798671722412)\n",
      "power-cz-train (0.6032568216323853, 0.457337886095047, 0.5)\n",
      "power-dk-train (0.6287744045257568, 0.5846599340438843, 0.6590538620948792)\n",
      "power-es-ct-train (0.7605177760124207, 0.8916256427764893, 0.8302752375602722)\n",
      "power-es-ga-train (0.6823529601097107, 0.8928571343421936, 0.7352941036224365)\n",
      "power-es-pv-train (0.6978723406791687, 0.5773195624351501, 0.6120218634605408)\n",
      "power-es-train (0.7452702522277832, 0.7231897115707397, 0.8071611523628235)\n",
      "power-fi-train (0.5883293151855469, 0.5476190447807312, 0.537286639213562)\n",
      "power-fr-train (0.699592649936676, 0.35103243589401245, 0.4465290904045105)\n",
      "power-gb-train (0.7102324366569519, 0.7643880248069763, 0.7466350197792053)\n",
      "power-gr-train (0.8299845457077026, 0.8501326441764832, 0.853528618812561)\n",
      "power-hr-train (0.6590038537979126, 0.4323641061782837, 0.4899713397026062)\n",
      "power-hu-train (0.7833655476570129, 0.6521739363670349, 0.7466063499450684)\n",
      "power-it-train (0.734215259552002, 0.359375, 0.48364487290382385)\n",
      "power-lv-train (0.6348684430122375, 0.39316239953041077, 0.4532019793987274)\n",
      "power-nl-train (0.6361386179924011, 0.3384379744529724, 0.42912620306015015)\n",
      "power-pl-train (0.639352560043335, 0.5043706297874451, 0.6181039214134216)\n",
      "power-pt-train (0.7231980562210083, 0.4203389883041382, 0.5204616785049438)\n",
      "power-rs-train (0.781697154045105, 0.4863731563091278, 0.5858585834503174)\n",
      "power-si-train (0.7072637677192688, 0.2700348496437073, 0.36643025279045105)\n",
      "power-tr-train (0.835273027420044, 0.8069053888320923, 0.8205461502075195)\n",
      "power-ua-train (0.7176901698112488, 0.3505154550075531, 0.43589743971824646)\n",
      "power-at-train (0.7692780494689941, 0.37476634979248047, 0.5164198279380798)\n",
      "power-ba-train (0.751028835773468, 0.8018433451652527, 0.8518971800804138)\n",
      "power-be-train (0.5426765084266663, 0.3550724685192108, 0.47457626461982727)\n",
      "power-bg-train (0.579104483127594, 0.2301829308271408, 0.34872978925704956)\n",
      "power-cz-train (0.6313841342926025, 0.3464163839817047, 0.4491150379180908)\n",
      "power-dk-train (0.6083481311798096, 0.4862518012523651, 0.6037735939025879)\n",
      "power-es-ct-train (0.7896440029144287, 0.866995096206665, 0.8441246747970581)\n",
      "power-es-ga-train (0.6764705777168274, 0.9285714030265808, 0.7393364906311035)\n",
      "power-es-pv-train (0.7021276354789734, 0.876288652420044, 0.7083333134651184)\n",
      "power-es-train (0.7310810685157776, 0.684692919254303, 0.7896406054496765)\n",
      "power-fi-train (0.636290967464447, 0.24725274741649628, 0.3724137842655182)\n",
      "power-fr-train (0.7041751742362976, 0.29203540086746216, 0.405322402715683)\n",
      "power-gb-train (0.7174766063690186, 0.7887057662010193, 0.7571984529495239)\n",
      "power-gr-train (0.7581143975257874, 0.6140583753585815, 0.7473769187927246)\n",
      "power-hr-train (0.6762452125549316, 0.29962074756622314, 0.41217392683029175)\n",
      "power-hu-train (0.7485493421554565, 0.5415019989013672, 0.6782178282737732)\n",
      "power-it-train (0.7366205453872681, 0.3038194477558136, 0.44416242837905884)\n",
      "power-lv-train (0.6184210777282715, 0.18803419172763824, 0.2750000059604645)\n",
      "power-nl-train (0.6379950642585754, 0.2848392128944397, 0.3887147307395935)\n",
      "power-pl-train (0.6039453744888306, 0.3723776340484619, 0.5211009383201599)\n",
      "power-pt-train (0.7328891754150391, 0.4576271176338196, 0.5504587292671204)\n",
      "power-rs-train (0.7587354183197021, 0.28721174597740173, 0.43047916889190674)\n",
      "power-si-train (0.7187329530715942, 0.203832745552063, 0.31241655349731445)\n",
      "power-tr-train (0.8281109929084778, 0.6668797731399536, 0.7836213111877441)\n",
      "power-ua-train (0.7208982706069946, 0.17820324003696442, 0.2843713164329529)\n",
      "power-at-train.tsv: Positive 41.17%\n",
      "power-ba-train.tsv: Positive 83.17%\n",
      "power-be-train.tsv: Positive 52.57%\n",
      "power-bg-train.tsv: Positive 47.17%\n",
      "power-cz-train.tsv: Positive 52.25%\n",
      "power-dk-train.tsv: Positive 62.81%\n",
      "power-es-ct-train.tsv: Positive 65.18%\n",
      "power-es-ga-train.tsv: Positive 57.50%\n",
      "power-es-pv-train.tsv: Positive 56.35%\n",
      "power-es-train.tsv: Positive 70.73%\n",
      "power-fi-train.tsv: Positive 44.59%\n",
      "power-fr-train.tsv: Positive 37.04%\n",
      "power-gb-train.tsv: Positive 56.39%\n",
      "power-gr-train.tsv: Positive 62.70%\n",
      "power-hr-train.tsv: Positive 39.73%\n",
      "power-hu-train.tsv: Positive 40.89%\n",
      "power-it-train.tsv: Positive 37.49%\n",
      "power-lv-train.tsv: Positive 33.05%\n",
      "power-nl-train.tsv: Positive 41.50%\n",
      "power-pl-train.tsv: Positive 54.80%\n",
      "power-pt-train.tsv: Positive 41.32%\n",
      "power-rs-train.tsv: Positive 27.09%\n",
      "power-si-train.tsv: Positive 37.48%\n",
      "power-tr-train.tsv: Positive 51.38%\n",
      "power-ua-train.tsv: Positive 31.21%\n"
     ]
    }
   ],
   "source": [
    "# Mass testing all countries\"s English text\n",
    "\n",
    "parent_dir = Path(\"data/train/power\")\n",
    "\n",
    "file_list = sorted([file for file in parent_dir.glob(\"*.tsv\")])\n",
    "text_en_result_list = []\n",
    "\n",
    "for file in file_list:\n",
    "\n",
    "    full_data = load_data(folder_path=parent_dir, file_list=[file.name],text_head=\"text_en\")\n",
    "    train_dev_raw, test_raw = split_data(full_data, test_size=0.2, random_state=0)\n",
    "    train_raw, dev_raw = split_data(train_dev_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "    # train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "    train_encoder = TfidfVectorizer()\n",
    "    train_encoder.fit(train_raw.texts)\n",
    "\n",
    "    train_dataset = encode_data(train_raw, train_encoder)\n",
    "    dev_dataset = encode_data(dev_raw, train_encoder)\n",
    "    test_dataset = encode_data(test_raw, train_encoder)\n",
    "\n",
    "    train_config = TrainConfig(\n",
    "        num_epochs      = 10,\n",
    "        early_stop      = False,\n",
    "        violation_limit = 5,\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    dev_dataloader = DataLoader(dev_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "    model_nn = NeuralNetwork(\n",
    "        input_size=len(train_encoder.vocabulary_),\n",
    "        hidden_size=128,\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "    if Path(f\"models/model_nn_{file.stem}_en.pt\").exists():\n",
    "        model_nn = load_model(model_nn, f\"model_nn_{file.stem}_en\")\n",
    "    else:\n",
    "        model_nn.fit(train_dataloader, train_config)\n",
    "        save_model(model_nn, f\"model_nn_{file.stem}_en\")\n",
    "\n",
    "    model_nn_results = evaluate_nn_model(model_nn, test_dataset)\n",
    "    text_en_result_list.append(model_nn_results)\n",
    "    \n",
    "    np.save(f\"models/model_nn_{file.stem}_en_results.npy\", model_nn_results)\n",
    "    print(file.stem, model_nn_results)\n",
    "\n",
    "\n",
    "# Mass testing all countries's original text\n",
    "\n",
    "parent_dir = Path(\"data/train/power\")\n",
    "\n",
    "file_list = sorted([file for file in parent_dir.glob(\"*.tsv\")])\n",
    "text_ori_result_list = []\n",
    "\n",
    "for file in file_list:\n",
    "\n",
    "    full_data = load_data(folder_path=parent_dir, file_list=[file.name],text_head=\"text\")\n",
    "    train_dev_raw, test_raw = split_data(full_data, test_size=0.2, random_state=0)\n",
    "    train_raw, dev_raw = split_data(train_dev_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "    # train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "    train_encoder = TfidfVectorizer()\n",
    "    train_encoder.fit(train_raw.texts)\n",
    "\n",
    "    train_dataset = encode_data(train_raw, train_encoder)\n",
    "    dev_dataset = encode_data(dev_raw, train_encoder)\n",
    "    test_dataset = encode_data(test_raw, train_encoder)\n",
    "\n",
    "    train_config = TrainConfig(\n",
    "        num_epochs      = 10,\n",
    "        early_stop      = False,\n",
    "        violation_limit = 5,\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    dev_dataloader = DataLoader(dev_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "    model_nn = NeuralNetwork(\n",
    "        input_size=len(train_encoder.vocabulary_),\n",
    "        hidden_size=128,\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "    if Path(f\"models/model_nn_{file.stem}_ori.pt\").exists():\n",
    "        model_nn = load_model(model_nn, f\"model_nn_{file.stem}_ori\")\n",
    "    else:\n",
    "        model_nn.fit(train_dataloader, train_config)\n",
    "        save_model(model_nn, f\"model_nn_{file.stem}_ori\")\n",
    "\n",
    "    model_nn_results = evaluate_nn_model(model_nn, test_dataset)\n",
    "    text_ori_result_list.append(model_nn_results)\n",
    "    \n",
    "    np.save(f\"models/model_nn_{file.stem}_ori_results.npy\", model_nn_results)\n",
    "    print(file.stem, model_nn_results)\n",
    "\n",
    "\n",
    "# Detect class imbalance\n",
    "parent_dir = Path(\"data/train/power\")\n",
    "\n",
    "file_list = sorted([file for file in parent_dir.glob(\"*.tsv\")])\n",
    "stats = []\n",
    "\n",
    "for file in file_list:\n",
    "    full_data = load_data(folder_path=parent_dir, file_list=[file.name],text_head=\"text\")\n",
    "    positive = sum(full_data.labels)\n",
    "    stats.append((positive, len(full_data), positive / len(full_data)))\n",
    "    print(f\"{file.name}: Positive {positive / len(full_data) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance of the two languages\n",
    "\n",
    "def plot_countries(country_group):\n",
    "\n",
    "    for file, en ,ori, stat in zip(file_list, text_en_result_list, text_ori_result_list, stats):\n",
    "        data = [\n",
    "            ('en', stat[2], *en),\n",
    "            ('ori', stat[2], *ori)\n",
    "        ]\n",
    "\n",
    "        country_code = file.stem.replace('power-', '').replace('-train', '')\n",
    "        country_name = mapping_dict[country_code]\n",
    "\n",
    "        if country_code in country_group:\n",
    "\n",
    "            results_df = pd.DataFrame(data, columns=[\"language\", \"positive_pct\", \"precision\", \"recall\", 'f1']).melt(id_vars=\"language\")\n",
    "\n",
    "            result_chart = alt.Chart(results_df).mark_bar().encode(\n",
    "                x = alt.X('variable:N', axis = alt.Axis(title = '', labels = False, ticks = False), sort = None, ),\n",
    "                y = alt.Y('value:Q', axis = alt.Axis(title = 'Score'), scale=alt.Scale(domain=(0, 1))),\n",
    "                column=alt.Column('language:N', title='Language', sort = None),\n",
    "                color=alt.Color('variable:N', scale=alt.Scale(scheme='category20'), title='Evaluation Metric', sort = None)\n",
    "            ).properties(\n",
    "                width=200,\n",
    "                height=300,\n",
    "                title = f\"{country_code} - {country_name} - {stat[1]} datapoints\"\n",
    "            )\n",
    "\n",
    "            result_chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result summary\n",
    "- Austria: lots of data, good precision, low recall. Worse performance on original language\n",
    "- Bosnia: Not much data, good results overall\n",
    "- Belgium: medium data, bad result\n",
    "- Bulgaria: medium data, bad\n",
    "- Czechia: medium data, Bad results\n",
    "- Denmark: medium data, bad result\n",
    "- Catalonia: less data, result quite good, precision < recall. EN and ORI are comparable\n",
    "- Galacia: same with Catalonia\n",
    "- Basque: Same with others, but worse result using EN\n",
    "- Spain: Medium-large data, everything is balanced around 0.7 - 0.8, similar perofrmance in both lang. Lots of positive labels\n",
    "- Finland: medium data, overall bad performance, lower performance in ORI\n",
    "- France: medium-large data, very low recall -> cannot capture negative class. Similar performance in both lang\n",
    "- GB: large data, balance results\n",
    "- Greece: Medium data, good result on en text\n",
    "- Croatia: Large data, bad results on both. Slightly better in English\n",
    "- Hungary: less data, quite good results on EN\n",
    "- Italy: Medium data, good precision, bad recall, low positive percentage\n",
    "- Latvia: Not much data, bad result\n",
    "- Netherlands: medium data, slight class imbalance, overall bad result\n",
    "- Poland: class balance, result is bad / so-so\n",
    "- Portugal: medium data, Slight class imbalance, high precision but low recall\n",
    "- Serbia: large data, high class imbalance, high precision, low recall\n",
    "- Slovenia: Medium-large data ,high class imbalance, high precision, low recall\n",
    "- Turkey: Large data, balance class, good overall result on English\n",
    "- Ukraine: medium-large data, high class imbalance, high precision, low recall\n",
    "\n",
    "- Low positive score: good precision, bad recall (true positive / total positive) -> can easily capture true positive and negative by guessing all to be negative, so miss lots of true positive -> the effect of class imbalance\n",
    "\n",
    "- Less data = better result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Test by country groups\n",
    "\n",
    "- Balkan\n",
    "  - Bulgaria (bg)\n",
    "  - Bosnia and Herzegovina (ba)\n",
    "  - Greece (gr)\n",
    "  - Serbia (rs)\n",
    "  - Croatia (hr)\n",
    "\n",
    "- Spanish\n",
    "  - Spain (es)\n",
    "  - Catalonia (es-ct)\n",
    "  - Galicia (es-ga)\n",
    "  - Basque Country (es-pv) [only power]\n",
    "\n",
    "- Nordic\n",
    "  - Denmark (dk) \n",
    "  - Finland (fi)\n",
    "  - Iceland (is) [only political orientation] \n",
    "  - Norway (no) [only political orientation] \n",
    "  - Sweden (se) [only political orientation] \n",
    "\n",
    "- Slavic\n",
    "  - Poland (pl)\n",
    "  - Ukraine (ua)\n",
    "  - Czechia (cz)\n",
    "  - Serbia (rs)\n",
    "  - Slovenia (si)\n",
    "\n",
    "- West German\n",
    "  - Austria (at)\n",
    "  - Great Britain (gb)\n",
    "  - The Netherlands (nl)\n",
    "  - Norway (no) [only political orientation] \n",
    "  - Sweden (se) [only political orientation] \n",
    "  - Belgium (be)\n",
    "\n",
    "\n",
    "- Romance\n",
    "  - France (fr)\n",
    "  - Portugal (pt)\n",
    "  - Italy (it)\n",
    "\n",
    "- Uralic\n",
    "  - Estonia (ee) \n",
    "  - Hungary (hu)\n",
    "\n",
    "- Baltic\n",
    "  - Latvia (lv)\n",
    "  - Lithuanian\n",
    "\n",
    "\n",
    "- Turkic\n",
    "  - Turkey (tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ba \t Bosnia and Herzegovina \t 2531 \t Zahvaljujem gospodo predsjedavajući, dame i gospodo, Sa žaljenjem mogu konstatovati da na sjednici K\n",
      "hr \t Croatia \t 10741 \t Gospodine predsjedniče, uvaženi kolega zastupnik Leko i kolega zastupnik Arlović iznosili su neke ar\n",
      "rs \t Serbia \t 15114 \t Dame i gospodo, dozvolite da u ime našeg izbornog tela prenesem pozdrave i želju da ova skupština po\n"
     ]
    }
   ],
   "source": [
    "balkans = ['ba', 'hr', 'rs']\n",
    "parent_dir = Path(\"data/train/power\")\n",
    "\n",
    "for code in balkans:\n",
    "    full_data = load_data(folder_path=parent_dir, file_list=[f\"power-{code}-train.tsv\"],text_head=\"text\")\n",
    "    print(\n",
    "        code, \"\\t\", \n",
    "        mapping_dict[code], \"\\t\", \n",
    "        len(full_data), \"\\t\",\n",
    "        full_data.texts[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2c31ffc350554f9d831f0096bf9914de.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2c31ffc350554f9d831f0096bf9914de.vega-embed details,\n",
       "  #altair-viz-2c31ffc350554f9d831f0096bf9914de.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2c31ffc350554f9d831f0096bf9914de\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2c31ffc350554f9d831f0096bf9914de\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2c31ffc350554f9d831f0096bf9914de\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-68863f377eeaf60c46ba5db7d1f0d46f\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"variable\", \"scale\": {\"scheme\": \"category20\"}, \"sort\": null, \"title\": \"Evaluation Metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"language\", \"sort\": null, \"title\": \"Language\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"variable\", \"sort\": null, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Score\"}, \"field\": \"value\", \"scale\": {\"domain\": [0, 1]}, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"ba - Bosnia and Herzegovina - 2531 datapoints\", \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-68863f377eeaf60c46ba5db7d1f0d46f\": [{\"language\": \"en\", \"variable\": \"positive_pct\", \"value\": 0.8316870802054523}, {\"language\": \"ori\", \"variable\": \"positive_pct\", \"value\": 0.8316870802054523}, {\"language\": \"en\", \"variable\": \"precision\", \"value\": 0.8353909254074097}, {\"language\": \"ori\", \"variable\": \"precision\", \"value\": 0.751028835773468}, {\"language\": \"en\", \"variable\": \"recall\", \"value\": 0.9308755993843079}, {\"language\": \"ori\", \"variable\": \"recall\", \"value\": 0.8018433451652527}, {\"language\": \"en\", \"variable\": \"f1\", \"value\": 0.9099099040031433}, {\"language\": \"ori\", \"variable\": \"f1\", \"value\": 0.8518971800804138}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d78971936d43464797a10b586aadabb8.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d78971936d43464797a10b586aadabb8.vega-embed details,\n",
       "  #altair-viz-d78971936d43464797a10b586aadabb8.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d78971936d43464797a10b586aadabb8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d78971936d43464797a10b586aadabb8\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d78971936d43464797a10b586aadabb8\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-73f2c451278ff698a46d7d406845078c\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"variable\", \"scale\": {\"scheme\": \"category20\"}, \"sort\": null, \"title\": \"Evaluation Metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"language\", \"sort\": null, \"title\": \"Language\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"variable\", \"sort\": null, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Score\"}, \"field\": \"value\", \"scale\": {\"domain\": [0, 1]}, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"hr - Croatia - 10741 datapoints\", \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-73f2c451278ff698a46d7d406845078c\": [{\"language\": \"en\", \"variable\": \"positive_pct\", \"value\": 0.3972628246904385}, {\"language\": \"ori\", \"variable\": \"positive_pct\", \"value\": 0.3972628246904385}, {\"language\": \"en\", \"variable\": \"precision\", \"value\": 0.6590038537979126}, {\"language\": \"ori\", \"variable\": \"precision\", \"value\": 0.6762452125549316}, {\"language\": \"en\", \"variable\": \"recall\", \"value\": 0.4323641061782837}, {\"language\": \"ori\", \"variable\": \"recall\", \"value\": 0.29962074756622314}, {\"language\": \"en\", \"variable\": \"f1\", \"value\": 0.4899713397026062}, {\"language\": \"ori\", \"variable\": \"f1\", \"value\": 0.41217392683029175}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-75a02f5dd7ae4116bbf44e4603121dfb.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-75a02f5dd7ae4116bbf44e4603121dfb.vega-embed details,\n",
       "  #altair-viz-75a02f5dd7ae4116bbf44e4603121dfb.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-75a02f5dd7ae4116bbf44e4603121dfb\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-75a02f5dd7ae4116bbf44e4603121dfb\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-75a02f5dd7ae4116bbf44e4603121dfb\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-32a0df100d2301f1b294949a2a7d2dff\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"variable\", \"scale\": {\"scheme\": \"category20\"}, \"sort\": null, \"title\": \"Evaluation Metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"language\", \"sort\": null, \"title\": \"Language\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"variable\", \"sort\": null, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Score\"}, \"field\": \"value\", \"scale\": {\"domain\": [0, 1]}, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"rs - Serbia - 15114 datapoints\", \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-32a0df100d2301f1b294949a2a7d2dff\": [{\"language\": \"en\", \"variable\": \"positive_pct\", \"value\": 0.2708746857218473}, {\"language\": \"ori\", \"variable\": \"positive_pct\", \"value\": 0.2708746857218473}, {\"language\": \"en\", \"variable\": \"precision\", \"value\": 0.781697154045105}, {\"language\": \"ori\", \"variable\": \"precision\", \"value\": 0.7587354183197021}, {\"language\": \"en\", \"variable\": \"recall\", \"value\": 0.4863731563091278}, {\"language\": \"ori\", \"variable\": \"recall\", \"value\": 0.28721174597740173}, {\"language\": \"en\", \"variable\": \"f1\", \"value\": 0.5858585834503174}, {\"language\": \"ori\", \"variable\": \"f1\", \"value\": 0.43047916889190674}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_countries(balkans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to handle Croatia differently\n",
    "# How to deal with class imbalance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power-identification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
