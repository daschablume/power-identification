{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from models import NeuralNetwork, TrainConfig, evaluate_nn_model, save_model, load_model, plot_results\n",
    "from utils import load_data, split_data, encode_data\n",
    "from pathlib import Path\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"Device: cuda\")\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"Device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview of the flow:**\n",
    "1. Load the raw data in to a RawParliamentData object containing (text ID, speaker ID, text, label)\n",
    "2. Split the raw data into train, dev, test datasets. Data is split so that speakers in each set does not appear in another set.\n",
    "3. Prepare a TfidfVectorizer. Fit the vectorizer on the train set, and use it to transform all train, dev, test sets. Use the `create_dataset()` function on the RawParliamentData objects, and supply the fitted encoder so that the same trained encoder is used on all sets.\n",
    "4. Run the `train_neural_network()` function.\n",
    "\n",
    "**To test different types of train-dev-test sets:**\n",
    "If you want to use some countries as the **train set**, and some other countries as the **dev & test set**, you will need to load the train, dev, test countries separately. For example: \n",
    "\n",
    "```python\n",
    "train_raw = load_data(folder_path=\"data/power/\", file_list=['power-gb-train.tsv',],text_head='text_en')\n",
    "dev_raw = load_data(folder_path=\"data/power/\", file_list=['power-ua-train.tsv',],text_head='text_en')\n",
    "test_raw = load_data(folder_path=\"data/power/\", file_list=['power-cz-train.tsv',],text_head='text_en')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load power-gb-train.tsv...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%%\n",
    "file_list = [\n",
    "    'power-gb-train.tsv',\n",
    "    # 'power-ua-train.tsv',\n",
    "    # 'power-fr-train.tsv',\n",
    "    # 'power-nl-train.tsv',\n",
    "]\n",
    "\n",
    "full_data = load_data(folder_path=\"data/train/power/\", file_list=file_list,text_head='text_en')\n",
    "train_dev_raw, test_raw = split_data(full_data, test_size=0.2, random_state=0)\n",
    "train_raw, dev_raw = split_data(train_dev_raw, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\n",
    "    'power-gb-test.tsv',\n",
    "    # 'power-ua-train.tsv',\n",
    "    # 'power-fr-train.tsv',\n",
    "    # 'power-nl-train.tsv',\n",
    "]\n",
    "\n",
    "test_data = load_data(folder_path=\"data/test/power/\", file_list=file_list,text_head='text_en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data encoder...\n",
      "Prepare data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Prepare data encoder...\")\n",
    "# train_encoder = TfidfVectorizer(sublinear_tf=True, analyzer=\"char\", ngram_range=(1,3))\n",
    "train_encoder = TfidfVectorizer(max_features=10000)\n",
    "train_encoder.fit(train_raw.texts)\n",
    "\n",
    "print(\"Prepare data...\")\n",
    "train_dataset = encode_data(train_raw, train_encoder)\n",
    "dev_dataset = encode_data(dev_raw, train_encoder)\n",
    "test_dataset = encode_data(test_raw, train_encoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model.\n",
    "If you use Google Colab or your machine has a CUDA-supported graphic card, you can try setting `device='cuda'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 168/168 [00:01<00:00, 156.39batch/s, batch_accuracy=0.75, loss=68.4]\n",
      "Epoch 2: 100%|██████████| 168/168 [00:01<00:00, 162.30batch/s, batch_accuracy=0.875, loss=89.9]\n",
      "Epoch 3: 100%|██████████| 168/168 [00:01<00:00, 165.91batch/s, batch_accuracy=0.85, loss=81.5]\n",
      "Epoch 4: 100%|██████████| 168/168 [00:01<00:00, 159.18batch/s, batch_accuracy=0.95, loss=70.3]\n",
      "Epoch 5: 100%|██████████| 168/168 [00:01<00:00, 163.66batch/s, batch_accuracy=0.925, loss=62.3]\n",
      "Epoch 6: 100%|██████████| 168/168 [00:01<00:00, 159.80batch/s, batch_accuracy=0.975, loss=90.3]\n",
      "Epoch 7: 100%|██████████| 168/168 [00:01<00:00, 165.74batch/s, batch_accuracy=1, loss=68.2]   \n",
      "Epoch 8: 100%|██████████| 168/168 [00:01<00:00, 154.43batch/s, batch_accuracy=0.95, loss=64.5]\n",
      "Epoch 9: 100%|██████████| 168/168 [00:01<00:00, 151.17batch/s, batch_accuracy=1, loss=72.2]   \n",
      "Epoch 10: 100%|██████████| 168/168 [00:01<00:00, 148.66batch/s, batch_accuracy=1, loss=68.2]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7215514779090881, 0.8594974279403687, 0.7751919031143188)\n"
     ]
    }
   ],
   "source": [
    "models_dir = Path('models')\n",
    "\n",
    "if not models_dir.exists():\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    num_epochs      = 10,\n",
    "    early_stop      = False,\n",
    "    violation_limit = 5,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "model_nn = NeuralNetwork(\n",
    "    input_size=len(train_encoder.vocabulary_),\n",
    "    hidden_size=128,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "if Path('models/model_nn.pt').exists():\n",
    "    model_nn = load_model(model_nn, 'model_nn')\n",
    "else:\n",
    "    model_nn.fit(train_dataloader, train_config)\n",
    "    save_model(model_nn, \"model_nn\")\n",
    "\n",
    "model_nn_results = evaluate_nn_model(model_nn, test_dataset)\n",
    "np.save('models/model_nn_results.npy', model_nn_results)\n",
    "print(model_nn_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d27bd219496944839a8f05977fab80b7.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d27bd219496944839a8f05977fab80b7.vega-embed details,\n",
       "  #altair-viz-d27bd219496944839a8f05977fab80b7.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d27bd219496944839a8f05977fab80b7\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d27bd219496944839a8f05977fab80b7\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d27bd219496944839a8f05977fab80b7\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Accuracy\"}, \"field\": \"training_acc\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Accuracy\", \"width\": 600}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"epoch\", \"scale\": {\"scheme\": \"category20\"}, \"title\": \"Epoch\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -30, \"title\": \"Iteration\", \"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300]}, \"field\": \"iteration\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Loss\"}, \"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Loss\", \"width\": 600}], \"data\": {\"name\": \"data-747d18faa28aeb2c79f269bbc34c524f\"}, \"title\": \"Base Neural Network with Tf-Idf vectors\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-747d18faa28aeb2c79f269bbc34c524f\": [{\"training_acc\": 0.4375, \"training_loss\": 349.34979248046875, \"iteration\": 1, \"epoch\": 1}, {\"training_acc\": 0.421875, \"training_loss\": 359.0250549316406, \"iteration\": 2, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 310.4552001953125, \"iteration\": 3, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 363.79351806640625, \"iteration\": 4, \"epoch\": 1}, {\"training_acc\": 0.4765625, \"training_loss\": 324.77032470703125, \"iteration\": 5, \"epoch\": 1}, {\"training_acc\": 0.4140625, \"training_loss\": 363.4688720703125, \"iteration\": 6, \"epoch\": 1}, {\"training_acc\": 0.46875, \"training_loss\": 334.519287109375, \"iteration\": 7, \"epoch\": 1}, {\"training_acc\": 0.46875, \"training_loss\": 348.99310302734375, \"iteration\": 8, \"epoch\": 1}, {\"training_acc\": 0.40625, \"training_loss\": 411.9268798828125, \"iteration\": 9, \"epoch\": 1}, {\"training_acc\": 0.53125, \"training_loss\": 343.425537109375, \"iteration\": 10, \"epoch\": 1}, {\"training_acc\": 0.4609375, \"training_loss\": 383.04168701171875, \"iteration\": 11, \"epoch\": 1}, {\"training_acc\": 0.5, \"training_loss\": 357.77374267578125, \"iteration\": 12, \"epoch\": 1}, {\"training_acc\": 0.546875, \"training_loss\": 347.9529724121094, \"iteration\": 13, \"epoch\": 1}, {\"training_acc\": 0.4609375, \"training_loss\": 372.3583984375, \"iteration\": 14, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 333.50543212890625, \"iteration\": 15, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 352.341064453125, \"iteration\": 16, \"epoch\": 1}, {\"training_acc\": 0.6171875, \"training_loss\": 371.02508544921875, \"iteration\": 17, \"epoch\": 1}, {\"training_acc\": 0.5703125, \"training_loss\": 356.897705078125, \"iteration\": 18, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 327.41046142578125, \"iteration\": 19, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 321.8619689941406, \"iteration\": 20, \"epoch\": 1}, {\"training_acc\": 0.5859375, \"training_loss\": 380.127685546875, \"iteration\": 21, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 330.73455810546875, \"iteration\": 22, \"epoch\": 1}, {\"training_acc\": 0.6015625, \"training_loss\": 376.26361083984375, \"iteration\": 23, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 326.3365478515625, \"iteration\": 24, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 301.83148193359375, \"iteration\": 25, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 338.61724853515625, \"iteration\": 26, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 313.9000244140625, \"iteration\": 27, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 352.0885009765625, \"iteration\": 28, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 334.0635070800781, \"iteration\": 29, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 318.24725341796875, \"iteration\": 30, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 279.4871826171875, \"iteration\": 31, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 343.9727783203125, \"iteration\": 32, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 328.32147216796875, \"iteration\": 33, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 305.39031982421875, \"iteration\": 34, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 330.44482421875, \"iteration\": 35, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 345.73297119140625, \"iteration\": 36, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 321.04010009765625, \"iteration\": 37, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 303.15606689453125, \"iteration\": 38, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 320.82080078125, \"iteration\": 39, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 361.493408203125, \"iteration\": 40, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 350.285888671875, \"iteration\": 41, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 293.82012939453125, \"iteration\": 42, \"epoch\": 1}, {\"training_acc\": 0.796875, \"training_loss\": 341.7149658203125, \"iteration\": 43, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 331.91217041015625, \"iteration\": 44, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 378.773193359375, \"iteration\": 45, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 321.656982421875, \"iteration\": 46, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 306.4590148925781, \"iteration\": 47, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 280.5693359375, \"iteration\": 48, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 358.54931640625, \"iteration\": 49, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 357.6500244140625, \"iteration\": 50, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 325.749755859375, \"iteration\": 51, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 314.1101989746094, \"iteration\": 52, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 361.55816650390625, \"iteration\": 53, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 304.54193115234375, \"iteration\": 54, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 304.1250915527344, \"iteration\": 55, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 336.41278076171875, \"iteration\": 56, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 331.74853515625, \"iteration\": 57, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 345.5711975097656, \"iteration\": 58, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 358.0433349609375, \"iteration\": 59, \"epoch\": 1}, {\"training_acc\": 0.609375, \"training_loss\": 311.1392822265625, \"iteration\": 60, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 334.13458251953125, \"iteration\": 61, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 353.44561767578125, \"iteration\": 62, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 377.1097412109375, \"iteration\": 63, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 321.0025329589844, \"iteration\": 64, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 330.5653076171875, \"iteration\": 65, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 352.8302001953125, \"iteration\": 66, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 315.7213134765625, \"iteration\": 67, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 287.02960205078125, \"iteration\": 68, \"epoch\": 1}, {\"training_acc\": 0.6796875, \"training_loss\": 345.77490234375, \"iteration\": 69, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 381.3266906738281, \"iteration\": 70, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 387.7629089355469, \"iteration\": 71, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 384.2860107421875, \"iteration\": 72, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 329.00128173828125, \"iteration\": 73, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 322.14324951171875, \"iteration\": 74, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 307.9789123535156, \"iteration\": 75, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 327.28424072265625, \"iteration\": 76, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 329.82806396484375, \"iteration\": 77, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 317.9150695800781, \"iteration\": 78, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 326.7606506347656, \"iteration\": 79, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 318.8241271972656, \"iteration\": 80, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 329.71795654296875, \"iteration\": 81, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 360.22454833984375, \"iteration\": 82, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 288.37451171875, \"iteration\": 83, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 344.37060546875, \"iteration\": 84, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 350.2113037109375, \"iteration\": 85, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 358.68316650390625, \"iteration\": 86, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 359.6339416503906, \"iteration\": 87, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 357.319580078125, \"iteration\": 88, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 322.43731689453125, \"iteration\": 89, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 355.1538391113281, \"iteration\": 90, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 368.25177001953125, \"iteration\": 91, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 368.88751220703125, \"iteration\": 92, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 342.4228210449219, \"iteration\": 93, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 375.4251708984375, \"iteration\": 94, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 333.45257568359375, \"iteration\": 95, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 337.4407043457031, \"iteration\": 96, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 324.56488037109375, \"iteration\": 97, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 334.2557373046875, \"iteration\": 98, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 371.0163879394531, \"iteration\": 99, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 278.39154052734375, \"iteration\": 100, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 359.0823059082031, \"iteration\": 101, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 351.72137451171875, \"iteration\": 102, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 330.51806640625, \"iteration\": 103, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 301.9108581542969, \"iteration\": 104, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 334.79815673828125, \"iteration\": 105, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 308.6661682128906, \"iteration\": 106, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 354.8352966308594, \"iteration\": 107, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 309.88482666015625, \"iteration\": 108, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 329.5430908203125, \"iteration\": 109, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 362.2459411621094, \"iteration\": 110, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 307.6640319824219, \"iteration\": 111, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 334.2046813964844, \"iteration\": 112, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 347.1435241699219, \"iteration\": 113, \"epoch\": 1}, {\"training_acc\": 0.6875, \"training_loss\": 340.25146484375, \"iteration\": 114, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 315.447998046875, \"iteration\": 115, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 376.367431640625, \"iteration\": 116, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 340.47064208984375, \"iteration\": 117, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 326.7982177734375, \"iteration\": 118, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 348.0674743652344, \"iteration\": 119, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 361.9959716796875, \"iteration\": 120, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 367.1280517578125, \"iteration\": 121, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 343.30169677734375, \"iteration\": 122, \"epoch\": 1}, {\"training_acc\": 0.7890625, \"training_loss\": 385.6323547363281, \"iteration\": 123, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 350.74566650390625, \"iteration\": 124, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 325.66754150390625, \"iteration\": 125, \"epoch\": 1}, {\"training_acc\": 0.8359375, \"training_loss\": 313.99383544921875, \"iteration\": 126, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 338.1822204589844, \"iteration\": 127, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 351.091552734375, \"iteration\": 128, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 337.93548583984375, \"iteration\": 129, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 374.32012939453125, \"iteration\": 130, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 340.9294128417969, \"iteration\": 131, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 370.13446044921875, \"iteration\": 132, \"epoch\": 1}, {\"training_acc\": 0.625, \"training_loss\": 320.92822265625, \"iteration\": 133, \"epoch\": 1}, {\"training_acc\": 0.6640625, \"training_loss\": 367.6688537597656, \"iteration\": 134, \"epoch\": 1}, {\"training_acc\": 0.640625, \"training_loss\": 328.212158203125, \"iteration\": 135, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 357.7391357421875, \"iteration\": 136, \"epoch\": 1}, {\"training_acc\": 0.6484375, \"training_loss\": 337.86468505859375, \"iteration\": 137, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 332.6650085449219, \"iteration\": 138, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 377.566162109375, \"iteration\": 139, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 331.35821533203125, \"iteration\": 140, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 324.98504638671875, \"iteration\": 141, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 305.1375427246094, \"iteration\": 142, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 341.31005859375, \"iteration\": 143, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 348.9960632324219, \"iteration\": 144, \"epoch\": 1}, {\"training_acc\": 0.71875, \"training_loss\": 346.2018127441406, \"iteration\": 145, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 373.63177490234375, \"iteration\": 146, \"epoch\": 1}, {\"training_acc\": 0.765625, \"training_loss\": 353.9087829589844, \"iteration\": 147, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 386.10565185546875, \"iteration\": 148, \"epoch\": 1}, {\"training_acc\": 0.6953125, \"training_loss\": 332.7051086425781, \"iteration\": 149, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 377.86016845703125, \"iteration\": 150, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 327.64776611328125, \"iteration\": 151, \"epoch\": 1}, {\"training_acc\": 0.8203125, \"training_loss\": 331.33172607421875, \"iteration\": 152, \"epoch\": 1}, {\"training_acc\": 0.7734375, \"training_loss\": 335.1070251464844, \"iteration\": 153, \"epoch\": 1}, {\"training_acc\": 0.78125, \"training_loss\": 387.2056884765625, \"iteration\": 154, \"epoch\": 1}, {\"training_acc\": 0.7265625, \"training_loss\": 370.523681640625, \"iteration\": 155, \"epoch\": 1}, {\"training_acc\": 0.65625, \"training_loss\": 340.076416015625, \"iteration\": 156, \"epoch\": 1}, {\"training_acc\": 0.671875, \"training_loss\": 328.15118408203125, \"iteration\": 157, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 288.4769592285156, \"iteration\": 158, \"epoch\": 1}, {\"training_acc\": 0.7421875, \"training_loss\": 367.7241516113281, \"iteration\": 159, \"epoch\": 1}, {\"training_acc\": 0.703125, \"training_loss\": 336.84588623046875, \"iteration\": 160, \"epoch\": 1}, {\"training_acc\": 0.7109375, \"training_loss\": 322.05023193359375, \"iteration\": 161, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 375.9578857421875, \"iteration\": 162, \"epoch\": 1}, {\"training_acc\": 0.734375, \"training_loss\": 293.9514465332031, \"iteration\": 163, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 337.7886962890625, \"iteration\": 164, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 307.418701171875, \"iteration\": 165, \"epoch\": 1}, {\"training_acc\": 0.7578125, \"training_loss\": 327.056640625, \"iteration\": 166, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 364.11810302734375, \"iteration\": 167, \"epoch\": 1}, {\"training_acc\": 0.75, \"training_loss\": 83.66740417480469, \"iteration\": 168, \"epoch\": 1}, {\"training_acc\": 0.8046875, \"training_loss\": 331.50396728515625, \"iteration\": 169, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 301.57476806640625, \"iteration\": 170, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 337.68408203125, \"iteration\": 171, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 337.06439208984375, \"iteration\": 172, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 350.5102844238281, \"iteration\": 173, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 296.75933837890625, \"iteration\": 174, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 290.925537109375, \"iteration\": 175, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 320.49688720703125, \"iteration\": 176, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 298.1452331542969, \"iteration\": 177, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 325.335205078125, \"iteration\": 178, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 326.5059814453125, \"iteration\": 179, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 375.4155578613281, \"iteration\": 180, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 321.0876159667969, \"iteration\": 181, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 323.3330993652344, \"iteration\": 182, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 334.48724365234375, \"iteration\": 183, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 266.2494812011719, \"iteration\": 184, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 405.5067443847656, \"iteration\": 185, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 273.8031921386719, \"iteration\": 186, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 353.85760498046875, \"iteration\": 187, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 287.46160888671875, \"iteration\": 188, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 373.1198425292969, \"iteration\": 189, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 323.560791015625, \"iteration\": 190, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 296.5595397949219, \"iteration\": 191, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 319.57293701171875, \"iteration\": 192, \"epoch\": 2}, {\"training_acc\": 0.890625, \"training_loss\": 301.1336975097656, \"iteration\": 193, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 291.0291442871094, \"iteration\": 194, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 331.1133728027344, \"iteration\": 195, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 353.05316162109375, \"iteration\": 196, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 331.738525390625, \"iteration\": 197, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 348.5632019042969, \"iteration\": 198, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 332.1340637207031, \"iteration\": 199, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 321.2897033691406, \"iteration\": 200, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 392.6688537597656, \"iteration\": 201, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 346.445068359375, \"iteration\": 202, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 297.35546875, \"iteration\": 203, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 290.52301025390625, \"iteration\": 204, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 360.03289794921875, \"iteration\": 205, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 354.6078796386719, \"iteration\": 206, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 349.7177734375, \"iteration\": 207, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 299.2947998046875, \"iteration\": 208, \"epoch\": 2}, {\"training_acc\": 0.7109375, \"training_loss\": 325.8813781738281, \"iteration\": 209, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 367.1787414550781, \"iteration\": 210, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 334.4002685546875, \"iteration\": 211, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 362.5227966308594, \"iteration\": 212, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 357.674560546875, \"iteration\": 213, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 311.5696105957031, \"iteration\": 214, \"epoch\": 2}, {\"training_acc\": 0.90625, \"training_loss\": 330.8360595703125, \"iteration\": 215, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 308.7191467285156, \"iteration\": 216, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 325.9404296875, \"iteration\": 217, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 336.32867431640625, \"iteration\": 218, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 335.88751220703125, \"iteration\": 219, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 328.77655029296875, \"iteration\": 220, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 333.047607421875, \"iteration\": 221, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 358.0150451660156, \"iteration\": 222, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 320.43011474609375, \"iteration\": 223, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 351.1675109863281, \"iteration\": 224, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 277.37811279296875, \"iteration\": 225, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 352.5845947265625, \"iteration\": 226, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 339.0685119628906, \"iteration\": 227, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 291.8302001953125, \"iteration\": 228, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 384.05499267578125, \"iteration\": 229, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 303.0584411621094, \"iteration\": 230, \"epoch\": 2}, {\"training_acc\": 0.6796875, \"training_loss\": 336.5124816894531, \"iteration\": 231, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 315.44769287109375, \"iteration\": 232, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 340.4361877441406, \"iteration\": 233, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 327.8759765625, \"iteration\": 234, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 305.0829162597656, \"iteration\": 235, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 367.39178466796875, \"iteration\": 236, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 369.2916259765625, \"iteration\": 237, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 375.4581604003906, \"iteration\": 238, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 334.13751220703125, \"iteration\": 239, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 335.78936767578125, \"iteration\": 240, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 324.94342041015625, \"iteration\": 241, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 361.7722473144531, \"iteration\": 242, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 299.2437744140625, \"iteration\": 243, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 353.68475341796875, \"iteration\": 244, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 354.6404724121094, \"iteration\": 245, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 394.63201904296875, \"iteration\": 246, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 293.1490478515625, \"iteration\": 247, \"epoch\": 2}, {\"training_acc\": 0.703125, \"training_loss\": 319.7217102050781, \"iteration\": 248, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 350.06365966796875, \"iteration\": 249, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 308.13702392578125, \"iteration\": 250, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 316.72882080078125, \"iteration\": 251, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 329.2250061035156, \"iteration\": 252, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 318.8856506347656, \"iteration\": 253, \"epoch\": 2}, {\"training_acc\": 0.875, \"training_loss\": 348.567138671875, \"iteration\": 254, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 339.8229675292969, \"iteration\": 255, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 352.7605285644531, \"iteration\": 256, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 337.66192626953125, \"iteration\": 257, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 302.86712646484375, \"iteration\": 258, \"epoch\": 2}, {\"training_acc\": 0.7265625, \"training_loss\": 317.52056884765625, \"iteration\": 259, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 319.4643859863281, \"iteration\": 260, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 328.231689453125, \"iteration\": 261, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 361.7171630859375, \"iteration\": 262, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 365.2268981933594, \"iteration\": 263, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 288.08831787109375, \"iteration\": 264, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 357.0740661621094, \"iteration\": 265, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 290.3250732421875, \"iteration\": 266, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 324.64337158203125, \"iteration\": 267, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 375.60638427734375, \"iteration\": 268, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 359.8038330078125, \"iteration\": 269, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 266.77880859375, \"iteration\": 270, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 315.94384765625, \"iteration\": 271, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 296.950927734375, \"iteration\": 272, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 327.57049560546875, \"iteration\": 273, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 259.8493347167969, \"iteration\": 274, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 343.2702331542969, \"iteration\": 275, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 309.03466796875, \"iteration\": 276, \"epoch\": 2}, {\"training_acc\": 0.78125, \"training_loss\": 321.2630310058594, \"iteration\": 277, \"epoch\": 2}, {\"training_acc\": 0.8671875, \"training_loss\": 406.5440673828125, \"iteration\": 278, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 299.2872314453125, \"iteration\": 279, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 332.9407043457031, \"iteration\": 280, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 329.7560119628906, \"iteration\": 281, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 314.04998779296875, \"iteration\": 282, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 358.70501708984375, \"iteration\": 283, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 405.76336669921875, \"iteration\": 284, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 362.95880126953125, \"iteration\": 285, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 333.65911865234375, \"iteration\": 286, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 351.94195556640625, \"iteration\": 287, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 325.8157958984375, \"iteration\": 288, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 359.25775146484375, \"iteration\": 289, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 295.16314697265625, \"iteration\": 290, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 318.13751220703125, \"iteration\": 291, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 353.3878479003906, \"iteration\": 292, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 332.8551025390625, \"iteration\": 293, \"epoch\": 2}, {\"training_acc\": 0.7421875, \"training_loss\": 342.94403076171875, \"iteration\": 294, \"epoch\": 2}, {\"training_acc\": 0.7890625, \"training_loss\": 324.80438232421875, \"iteration\": 295, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 297.66815185546875, \"iteration\": 296, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 319.3415832519531, \"iteration\": 297, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 323.1549377441406, \"iteration\": 298, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 351.22247314453125, \"iteration\": 299, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 334.08624267578125, \"iteration\": 300, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 327.8471984863281, \"iteration\": 301, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 300.46356201171875, \"iteration\": 302, \"epoch\": 2}, {\"training_acc\": 0.8515625, \"training_loss\": 368.4456481933594, \"iteration\": 303, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 298.59954833984375, \"iteration\": 304, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 312.1972351074219, \"iteration\": 305, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 314.62127685546875, \"iteration\": 306, \"epoch\": 2}, {\"training_acc\": 0.7578125, \"training_loss\": 337.529052734375, \"iteration\": 307, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 375.86883544921875, \"iteration\": 308, \"epoch\": 2}, {\"training_acc\": 0.8046875, \"training_loss\": 329.0107421875, \"iteration\": 309, \"epoch\": 2}, {\"training_acc\": 0.75, \"training_loss\": 335.08941650390625, \"iteration\": 310, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 305.4657287597656, \"iteration\": 311, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 378.84002685546875, \"iteration\": 312, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 371.99908447265625, \"iteration\": 313, \"epoch\": 2}, {\"training_acc\": 0.734375, \"training_loss\": 322.011474609375, \"iteration\": 314, \"epoch\": 2}, {\"training_acc\": 0.8203125, \"training_loss\": 310.47705078125, \"iteration\": 315, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 312.2471008300781, \"iteration\": 316, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 334.92431640625, \"iteration\": 317, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 358.8055114746094, \"iteration\": 318, \"epoch\": 2}, {\"training_acc\": 0.859375, \"training_loss\": 318.4984436035156, \"iteration\": 319, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 327.2607421875, \"iteration\": 320, \"epoch\": 2}, {\"training_acc\": 0.828125, \"training_loss\": 358.217041015625, \"iteration\": 321, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 390.5896911621094, \"iteration\": 322, \"epoch\": 2}, {\"training_acc\": 0.71875, \"training_loss\": 337.76312255859375, \"iteration\": 323, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 355.2674560546875, \"iteration\": 324, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 337.2854919433594, \"iteration\": 325, \"epoch\": 2}, {\"training_acc\": 0.765625, \"training_loss\": 288.2408447265625, \"iteration\": 326, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 309.34326171875, \"iteration\": 327, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 342.2232360839844, \"iteration\": 328, \"epoch\": 2}, {\"training_acc\": 0.8125, \"training_loss\": 280.38458251953125, \"iteration\": 329, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 325.0717468261719, \"iteration\": 330, \"epoch\": 2}, {\"training_acc\": 0.84375, \"training_loss\": 350.3736572265625, \"iteration\": 331, \"epoch\": 2}, {\"training_acc\": 0.796875, \"training_loss\": 326.6767883300781, \"iteration\": 332, \"epoch\": 2}, {\"training_acc\": 0.8359375, \"training_loss\": 306.3699035644531, \"iteration\": 333, \"epoch\": 2}, {\"training_acc\": 0.703125, \"training_loss\": 304.1066589355469, \"iteration\": 334, \"epoch\": 2}, {\"training_acc\": 0.7734375, \"training_loss\": 341.02703857421875, \"iteration\": 335, \"epoch\": 2}, {\"training_acc\": 0.9, \"training_loss\": 101.79237365722656, \"iteration\": 336, \"epoch\": 2}, {\"training_acc\": 0.8828125, \"training_loss\": 333.98394775390625, \"iteration\": 337, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 355.8642272949219, \"iteration\": 338, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 292.259765625, \"iteration\": 339, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 341.3144226074219, \"iteration\": 340, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 308.980712890625, \"iteration\": 341, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 292.1417236328125, \"iteration\": 342, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 313.1579284667969, \"iteration\": 343, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 319.24957275390625, \"iteration\": 344, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 332.2239685058594, \"iteration\": 345, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 360.39154052734375, \"iteration\": 346, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 331.6086120605469, \"iteration\": 347, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 332.424072265625, \"iteration\": 348, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 308.0106506347656, \"iteration\": 349, \"epoch\": 3}, {\"training_acc\": 0.9453125, \"training_loss\": 363.49456787109375, \"iteration\": 350, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 332.93792724609375, \"iteration\": 351, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 359.4158935546875, \"iteration\": 352, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 348.6204833984375, \"iteration\": 353, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 296.7760925292969, \"iteration\": 354, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 368.1071472167969, \"iteration\": 355, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 307.0723571777344, \"iteration\": 356, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 320.64776611328125, \"iteration\": 357, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 334.34454345703125, \"iteration\": 358, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 268.5500183105469, \"iteration\": 359, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 319.01837158203125, \"iteration\": 360, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 329.0380859375, \"iteration\": 361, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 365.85693359375, \"iteration\": 362, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 303.11920166015625, \"iteration\": 363, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 313.16717529296875, \"iteration\": 364, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 322.2787170410156, \"iteration\": 365, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 355.503662109375, \"iteration\": 366, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 372.8734130859375, \"iteration\": 367, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 300.3609619140625, \"iteration\": 368, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 342.7068176269531, \"iteration\": 369, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 365.0714111328125, \"iteration\": 370, \"epoch\": 3}, {\"training_acc\": 0.921875, \"training_loss\": 363.75006103515625, \"iteration\": 371, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 286.4354248046875, \"iteration\": 372, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 349.37506103515625, \"iteration\": 373, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 313.2674560546875, \"iteration\": 374, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 322.3312683105469, \"iteration\": 375, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 401.4083251953125, \"iteration\": 376, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 322.5238037109375, \"iteration\": 377, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 293.4603271484375, \"iteration\": 378, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 327.7373046875, \"iteration\": 379, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 326.3713073730469, \"iteration\": 380, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 304.13336181640625, \"iteration\": 381, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 323.2576599121094, \"iteration\": 382, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 306.69232177734375, \"iteration\": 383, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 350.72137451171875, \"iteration\": 384, \"epoch\": 3}, {\"training_acc\": 0.9375, \"training_loss\": 352.4211730957031, \"iteration\": 385, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 341.4963684082031, \"iteration\": 386, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 337.46929931640625, \"iteration\": 387, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 323.55780029296875, \"iteration\": 388, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 303.7809753417969, \"iteration\": 389, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 282.845947265625, \"iteration\": 390, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 336.88299560546875, \"iteration\": 391, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 401.38897705078125, \"iteration\": 392, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 312.75286865234375, \"iteration\": 393, \"epoch\": 3}, {\"training_acc\": 0.7890625, \"training_loss\": 303.52484130859375, \"iteration\": 394, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 307.99664306640625, \"iteration\": 395, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 314.45941162109375, \"iteration\": 396, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 371.7823791503906, \"iteration\": 397, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 375.3572998046875, \"iteration\": 398, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 338.93780517578125, \"iteration\": 399, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 332.1895751953125, \"iteration\": 400, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 314.1145324707031, \"iteration\": 401, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 343.05523681640625, \"iteration\": 402, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 306.30548095703125, \"iteration\": 403, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 351.3030090332031, \"iteration\": 404, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 374.35888671875, \"iteration\": 405, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 342.9178466796875, \"iteration\": 406, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 303.26470947265625, \"iteration\": 407, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 296.2247619628906, \"iteration\": 408, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 333.7000427246094, \"iteration\": 409, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 315.2270812988281, \"iteration\": 410, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 360.0657043457031, \"iteration\": 411, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 293.0341796875, \"iteration\": 412, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 288.3551940917969, \"iteration\": 413, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 260.24615478515625, \"iteration\": 414, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 297.03448486328125, \"iteration\": 415, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 319.1941223144531, \"iteration\": 416, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 310.2453918457031, \"iteration\": 417, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 308.7322692871094, \"iteration\": 418, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 329.01568603515625, \"iteration\": 419, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 264.87921142578125, \"iteration\": 420, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 336.37744140625, \"iteration\": 421, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 304.70257568359375, \"iteration\": 422, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 304.063232421875, \"iteration\": 423, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 293.489501953125, \"iteration\": 424, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 317.96685791015625, \"iteration\": 425, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 342.287109375, \"iteration\": 426, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 371.4563903808594, \"iteration\": 427, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 289.40911865234375, \"iteration\": 428, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 316.3457336425781, \"iteration\": 429, \"epoch\": 3}, {\"training_acc\": 0.75, \"training_loss\": 305.90045166015625, \"iteration\": 430, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 341.55267333984375, \"iteration\": 431, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 365.18585205078125, \"iteration\": 432, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 275.22998046875, \"iteration\": 433, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 303.80413818359375, \"iteration\": 434, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 313.29400634765625, \"iteration\": 435, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 337.33026123046875, \"iteration\": 436, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 364.18475341796875, \"iteration\": 437, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 370.4229431152344, \"iteration\": 438, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 378.98046875, \"iteration\": 439, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 304.25970458984375, \"iteration\": 440, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 323.6872863769531, \"iteration\": 441, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 332.9306335449219, \"iteration\": 442, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 362.4325866699219, \"iteration\": 443, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 337.04022216796875, \"iteration\": 444, \"epoch\": 3}, {\"training_acc\": 0.7734375, \"training_loss\": 315.64117431640625, \"iteration\": 445, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 359.79925537109375, \"iteration\": 446, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 318.0448913574219, \"iteration\": 447, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 302.42755126953125, \"iteration\": 448, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 321.6588134765625, \"iteration\": 449, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 333.8143005371094, \"iteration\": 450, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 389.9965515136719, \"iteration\": 451, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 316.2232360839844, \"iteration\": 452, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 316.46441650390625, \"iteration\": 453, \"epoch\": 3}, {\"training_acc\": 0.7421875, \"training_loss\": 291.1321716308594, \"iteration\": 454, \"epoch\": 3}, {\"training_acc\": 0.875, \"training_loss\": 314.7499694824219, \"iteration\": 455, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 331.50860595703125, \"iteration\": 456, \"epoch\": 3}, {\"training_acc\": 0.78125, \"training_loss\": 321.20611572265625, \"iteration\": 457, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 286.66650390625, \"iteration\": 458, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 315.98779296875, \"iteration\": 459, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 326.47943115234375, \"iteration\": 460, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 324.4209289550781, \"iteration\": 461, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 364.9227600097656, \"iteration\": 462, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 339.82342529296875, \"iteration\": 463, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 266.8030700683594, \"iteration\": 464, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 331.460693359375, \"iteration\": 465, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 310.094970703125, \"iteration\": 466, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 296.5880432128906, \"iteration\": 467, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 320.23565673828125, \"iteration\": 468, \"epoch\": 3}, {\"training_acc\": 0.8046875, \"training_loss\": 339.39898681640625, \"iteration\": 469, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 303.4171447753906, \"iteration\": 470, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 342.19439697265625, \"iteration\": 471, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 309.3602294921875, \"iteration\": 472, \"epoch\": 3}, {\"training_acc\": 0.8671875, \"training_loss\": 325.23297119140625, \"iteration\": 473, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 347.00836181640625, \"iteration\": 474, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 341.7670593261719, \"iteration\": 475, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 307.9130859375, \"iteration\": 476, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 357.12127685546875, \"iteration\": 477, \"epoch\": 3}, {\"training_acc\": 0.9140625, \"training_loss\": 335.84735107421875, \"iteration\": 478, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 294.85626220703125, \"iteration\": 479, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 314.91192626953125, \"iteration\": 480, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 312.6380615234375, \"iteration\": 481, \"epoch\": 3}, {\"training_acc\": 0.84375, \"training_loss\": 335.0703125, \"iteration\": 482, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 289.3367919921875, \"iteration\": 483, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 333.16998291015625, \"iteration\": 484, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 348.70318603515625, \"iteration\": 485, \"epoch\": 3}, {\"training_acc\": 0.8203125, \"training_loss\": 313.2481689453125, \"iteration\": 486, \"epoch\": 3}, {\"training_acc\": 0.8984375, \"training_loss\": 351.89935302734375, \"iteration\": 487, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 304.56048583984375, \"iteration\": 488, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 359.8238830566406, \"iteration\": 489, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 268.73907470703125, \"iteration\": 490, \"epoch\": 3}, {\"training_acc\": 0.90625, \"training_loss\": 291.8302917480469, \"iteration\": 491, \"epoch\": 3}, {\"training_acc\": 0.8125, \"training_loss\": 330.4376220703125, \"iteration\": 492, \"epoch\": 3}, {\"training_acc\": 0.859375, \"training_loss\": 311.3444519042969, \"iteration\": 493, \"epoch\": 3}, {\"training_acc\": 0.796875, \"training_loss\": 374.3993225097656, \"iteration\": 494, \"epoch\": 3}, {\"training_acc\": 0.828125, \"training_loss\": 306.53533935546875, \"iteration\": 495, \"epoch\": 3}, {\"training_acc\": 0.8359375, \"training_loss\": 358.2095642089844, \"iteration\": 496, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 383.1484375, \"iteration\": 497, \"epoch\": 3}, {\"training_acc\": 0.890625, \"training_loss\": 336.535400390625, \"iteration\": 498, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 354.7398681640625, \"iteration\": 499, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 323.7448425292969, \"iteration\": 500, \"epoch\": 3}, {\"training_acc\": 0.9296875, \"training_loss\": 290.63726806640625, \"iteration\": 501, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 374.62127685546875, \"iteration\": 502, \"epoch\": 3}, {\"training_acc\": 0.8515625, \"training_loss\": 354.72674560546875, \"iteration\": 503, \"epoch\": 3}, {\"training_acc\": 0.8, \"training_loss\": 78.01535034179688, \"iteration\": 504, \"epoch\": 3}, {\"training_acc\": 0.8828125, \"training_loss\": 310.2340087890625, \"iteration\": 505, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 271.97210693359375, \"iteration\": 506, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 351.47265625, \"iteration\": 507, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 332.21331787109375, \"iteration\": 508, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 311.8026123046875, \"iteration\": 509, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 330.26312255859375, \"iteration\": 510, \"epoch\": 4}, {\"training_acc\": 0.9609375, \"training_loss\": 347.2408142089844, \"iteration\": 511, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 322.72918701171875, \"iteration\": 512, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 265.28118896484375, \"iteration\": 513, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 360.576904296875, \"iteration\": 514, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 294.437255859375, \"iteration\": 515, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 311.82977294921875, \"iteration\": 516, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 329.978515625, \"iteration\": 517, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 315.7630310058594, \"iteration\": 518, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 334.79742431640625, \"iteration\": 519, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 298.0050048828125, \"iteration\": 520, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 349.02392578125, \"iteration\": 521, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 354.4794006347656, \"iteration\": 522, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 280.62139892578125, \"iteration\": 523, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 321.7197570800781, \"iteration\": 524, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 311.08148193359375, \"iteration\": 525, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 327.0334167480469, \"iteration\": 526, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 308.8244323730469, \"iteration\": 527, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 290.04840087890625, \"iteration\": 528, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 304.41192626953125, \"iteration\": 529, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 327.72174072265625, \"iteration\": 530, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 326.1368408203125, \"iteration\": 531, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 339.2041015625, \"iteration\": 532, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 324.9697265625, \"iteration\": 533, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 257.1377258300781, \"iteration\": 534, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 368.5836181640625, \"iteration\": 535, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 368.5442810058594, \"iteration\": 536, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 312.94097900390625, \"iteration\": 537, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 297.09912109375, \"iteration\": 538, \"epoch\": 4}, {\"training_acc\": 0.9453125, \"training_loss\": 300.6391296386719, \"iteration\": 539, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 323.7474365234375, \"iteration\": 540, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 381.8917236328125, \"iteration\": 541, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 321.5152282714844, \"iteration\": 542, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 376.7525329589844, \"iteration\": 543, \"epoch\": 4}, {\"training_acc\": 0.8125, \"training_loss\": 299.93414306640625, \"iteration\": 544, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 318.38665771484375, \"iteration\": 545, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 336.220947265625, \"iteration\": 546, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 325.5189208984375, \"iteration\": 547, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 360.23126220703125, \"iteration\": 548, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 338.7393798828125, \"iteration\": 549, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 337.455810546875, \"iteration\": 550, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 263.43780517578125, \"iteration\": 551, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 319.838134765625, \"iteration\": 552, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 267.16485595703125, \"iteration\": 553, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 302.1243896484375, \"iteration\": 554, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 326.85992431640625, \"iteration\": 555, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 357.0806884765625, \"iteration\": 556, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 346.9075927734375, \"iteration\": 557, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 289.3809509277344, \"iteration\": 558, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 342.0761413574219, \"iteration\": 559, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 383.9347839355469, \"iteration\": 560, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 289.8353576660156, \"iteration\": 561, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 337.468017578125, \"iteration\": 562, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 311.13018798828125, \"iteration\": 563, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 292.5343322753906, \"iteration\": 564, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 343.58868408203125, \"iteration\": 565, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 345.5439758300781, \"iteration\": 566, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 285.547119140625, \"iteration\": 567, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 300.8211669921875, \"iteration\": 568, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 318.82373046875, \"iteration\": 569, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 288.32977294921875, \"iteration\": 570, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 313.01141357421875, \"iteration\": 571, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 304.1341552734375, \"iteration\": 572, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 293.7787170410156, \"iteration\": 573, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 383.07745361328125, \"iteration\": 574, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 288.2929382324219, \"iteration\": 575, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 321.58465576171875, \"iteration\": 576, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 309.49700927734375, \"iteration\": 577, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 338.8576354980469, \"iteration\": 578, \"epoch\": 4}, {\"training_acc\": 0.8125, \"training_loss\": 275.26025390625, \"iteration\": 579, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 319.75494384765625, \"iteration\": 580, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 324.2862243652344, \"iteration\": 581, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 312.3166198730469, \"iteration\": 582, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 339.80413818359375, \"iteration\": 583, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 317.9038391113281, \"iteration\": 584, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 319.27056884765625, \"iteration\": 585, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 374.8323974609375, \"iteration\": 586, \"epoch\": 4}, {\"training_acc\": 0.796875, \"training_loss\": 285.1249694824219, \"iteration\": 587, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 301.693115234375, \"iteration\": 588, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 325.187255859375, \"iteration\": 589, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 302.41546630859375, \"iteration\": 590, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 289.420654296875, \"iteration\": 591, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 312.9406433105469, \"iteration\": 592, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 330.0941162109375, \"iteration\": 593, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 359.1025390625, \"iteration\": 594, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 293.88299560546875, \"iteration\": 595, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 304.18597412109375, \"iteration\": 596, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 330.90728759765625, \"iteration\": 597, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 308.5041198730469, \"iteration\": 598, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 334.28680419921875, \"iteration\": 599, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 340.42864990234375, \"iteration\": 600, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 329.6746520996094, \"iteration\": 601, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 296.83184814453125, \"iteration\": 602, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 318.36798095703125, \"iteration\": 603, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 353.652587890625, \"iteration\": 604, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 272.3221130371094, \"iteration\": 605, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 367.7916259765625, \"iteration\": 606, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 341.1868591308594, \"iteration\": 607, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 305.55230712890625, \"iteration\": 608, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 359.2044677734375, \"iteration\": 609, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 354.7903137207031, \"iteration\": 610, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 334.34466552734375, \"iteration\": 611, \"epoch\": 4}, {\"training_acc\": 0.8046875, \"training_loss\": 337.11273193359375, \"iteration\": 612, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 305.29071044921875, \"iteration\": 613, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 298.0406188964844, \"iteration\": 614, \"epoch\": 4}, {\"training_acc\": 0.9296875, \"training_loss\": 342.1951599121094, \"iteration\": 615, \"epoch\": 4}, {\"training_acc\": 0.953125, \"training_loss\": 344.9494323730469, \"iteration\": 616, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 367.15087890625, \"iteration\": 617, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 281.01153564453125, \"iteration\": 618, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 357.7432861328125, \"iteration\": 619, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 334.6617431640625, \"iteration\": 620, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 328.7174072265625, \"iteration\": 621, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 304.575439453125, \"iteration\": 622, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 341.2791748046875, \"iteration\": 623, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 317.54461669921875, \"iteration\": 624, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 351.3123474121094, \"iteration\": 625, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 357.12646484375, \"iteration\": 626, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 319.41094970703125, \"iteration\": 627, \"epoch\": 4}, {\"training_acc\": 0.8359375, \"training_loss\": 339.11676025390625, \"iteration\": 628, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 311.7918701171875, \"iteration\": 629, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 355.2139587402344, \"iteration\": 630, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 305.74853515625, \"iteration\": 631, \"epoch\": 4}, {\"training_acc\": 0.9375, \"training_loss\": 316.26593017578125, \"iteration\": 632, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 323.21063232421875, \"iteration\": 633, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 275.63958740234375, \"iteration\": 634, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 271.708740234375, \"iteration\": 635, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 303.31146240234375, \"iteration\": 636, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 290.8298645019531, \"iteration\": 637, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 330.8424987792969, \"iteration\": 638, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 342.009033203125, \"iteration\": 639, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 336.1712646484375, \"iteration\": 640, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 344.96478271484375, \"iteration\": 641, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 353.5254211425781, \"iteration\": 642, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 324.47393798828125, \"iteration\": 643, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 327.7456359863281, \"iteration\": 644, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 335.97174072265625, \"iteration\": 645, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 300.65521240234375, \"iteration\": 646, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 264.97943115234375, \"iteration\": 647, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 349.5800476074219, \"iteration\": 648, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 323.28814697265625, \"iteration\": 649, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 354.93597412109375, \"iteration\": 650, \"epoch\": 4}, {\"training_acc\": 0.8515625, \"training_loss\": 344.741455078125, \"iteration\": 651, \"epoch\": 4}, {\"training_acc\": 0.828125, \"training_loss\": 331.87896728515625, \"iteration\": 652, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 320.48846435546875, \"iteration\": 653, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 317.55731201171875, \"iteration\": 654, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 348.7956237792969, \"iteration\": 655, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 339.02825927734375, \"iteration\": 656, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 323.542724609375, \"iteration\": 657, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 327.25958251953125, \"iteration\": 658, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 325.7334899902344, \"iteration\": 659, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 299.39691162109375, \"iteration\": 660, \"epoch\": 4}, {\"training_acc\": 0.8828125, \"training_loss\": 354.081787109375, \"iteration\": 661, \"epoch\": 4}, {\"training_acc\": 0.8671875, \"training_loss\": 299.0014343261719, \"iteration\": 662, \"epoch\": 4}, {\"training_acc\": 0.890625, \"training_loss\": 339.1826171875, \"iteration\": 663, \"epoch\": 4}, {\"training_acc\": 0.8984375, \"training_loss\": 338.56024169921875, \"iteration\": 664, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 316.77227783203125, \"iteration\": 665, \"epoch\": 4}, {\"training_acc\": 0.84375, \"training_loss\": 306.86212158203125, \"iteration\": 666, \"epoch\": 4}, {\"training_acc\": 0.859375, \"training_loss\": 302.6748962402344, \"iteration\": 667, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 356.9916076660156, \"iteration\": 668, \"epoch\": 4}, {\"training_acc\": 0.9140625, \"training_loss\": 305.53741455078125, \"iteration\": 669, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 341.9454345703125, \"iteration\": 670, \"epoch\": 4}, {\"training_acc\": 0.921875, \"training_loss\": 299.794921875, \"iteration\": 671, \"epoch\": 4}, {\"training_acc\": 0.875, \"training_loss\": 91.03910064697266, \"iteration\": 672, \"epoch\": 4}, {\"training_acc\": 0.90625, \"training_loss\": 372.84100341796875, \"iteration\": 673, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 359.76446533203125, \"iteration\": 674, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 293.8370056152344, \"iteration\": 675, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 289.07440185546875, \"iteration\": 676, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 373.5311279296875, \"iteration\": 677, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 357.81964111328125, \"iteration\": 678, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 267.4772033691406, \"iteration\": 679, \"epoch\": 5}, {\"training_acc\": 0.9765625, \"training_loss\": 273.9709167480469, \"iteration\": 680, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 303.6021728515625, \"iteration\": 681, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 340.7818603515625, \"iteration\": 682, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 401.59967041015625, \"iteration\": 683, \"epoch\": 5}, {\"training_acc\": 0.84375, \"training_loss\": 268.9378662109375, \"iteration\": 684, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 291.50836181640625, \"iteration\": 685, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 344.59112548828125, \"iteration\": 686, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 329.0838317871094, \"iteration\": 687, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 330.8602600097656, \"iteration\": 688, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 295.6455078125, \"iteration\": 689, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 299.818359375, \"iteration\": 690, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 304.2914123535156, \"iteration\": 691, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 334.3548583984375, \"iteration\": 692, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 291.54205322265625, \"iteration\": 693, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 251.70877075195312, \"iteration\": 694, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 324.1578063964844, \"iteration\": 695, \"epoch\": 5}, {\"training_acc\": 0.96875, \"training_loss\": 304.69757080078125, \"iteration\": 696, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 323.9930419921875, \"iteration\": 697, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 303.00048828125, \"iteration\": 698, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 349.3924255371094, \"iteration\": 699, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 323.7221984863281, \"iteration\": 700, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 290.7270812988281, \"iteration\": 701, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 300.3785095214844, \"iteration\": 702, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 322.05157470703125, \"iteration\": 703, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 342.3011474609375, \"iteration\": 704, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 269.0284423828125, \"iteration\": 705, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 316.5941162109375, \"iteration\": 706, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 339.62701416015625, \"iteration\": 707, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 305.9278259277344, \"iteration\": 708, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 316.9894714355469, \"iteration\": 709, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 325.3245849609375, \"iteration\": 710, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 307.94146728515625, \"iteration\": 711, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 255.78399658203125, \"iteration\": 712, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 312.44537353515625, \"iteration\": 713, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 344.182373046875, \"iteration\": 714, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 300.82733154296875, \"iteration\": 715, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 292.3772888183594, \"iteration\": 716, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 289.15478515625, \"iteration\": 717, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 311.7469787597656, \"iteration\": 718, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 298.19281005859375, \"iteration\": 719, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 279.06304931640625, \"iteration\": 720, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 270.846435546875, \"iteration\": 721, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 304.9707336425781, \"iteration\": 722, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 325.7425231933594, \"iteration\": 723, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 330.19049072265625, \"iteration\": 724, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 309.76678466796875, \"iteration\": 725, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 366.5315246582031, \"iteration\": 726, \"epoch\": 5}, {\"training_acc\": 0.84375, \"training_loss\": 290.00390625, \"iteration\": 727, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 330.522216796875, \"iteration\": 728, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 226.17962646484375, \"iteration\": 729, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 289.47821044921875, \"iteration\": 730, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 380.4459533691406, \"iteration\": 731, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 344.3586730957031, \"iteration\": 732, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 295.63018798828125, \"iteration\": 733, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 286.9425964355469, \"iteration\": 734, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 356.15155029296875, \"iteration\": 735, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 313.5491943359375, \"iteration\": 736, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 321.876953125, \"iteration\": 737, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 359.4095153808594, \"iteration\": 738, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 358.9393005371094, \"iteration\": 739, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 321.9830322265625, \"iteration\": 740, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 329.52996826171875, \"iteration\": 741, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 288.5879821777344, \"iteration\": 742, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 318.24530029296875, \"iteration\": 743, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 301.0177001953125, \"iteration\": 744, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 354.9178466796875, \"iteration\": 745, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 333.39361572265625, \"iteration\": 746, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 255.11282348632812, \"iteration\": 747, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 237.11668395996094, \"iteration\": 748, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 364.96826171875, \"iteration\": 749, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 324.3146057128906, \"iteration\": 750, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 374.02294921875, \"iteration\": 751, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 345.5545349121094, \"iteration\": 752, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 344.31573486328125, \"iteration\": 753, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 326.3801574707031, \"iteration\": 754, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 333.28289794921875, \"iteration\": 755, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 327.8092041015625, \"iteration\": 756, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 316.2485656738281, \"iteration\": 757, \"epoch\": 5}, {\"training_acc\": 0.859375, \"training_loss\": 249.59280395507812, \"iteration\": 758, \"epoch\": 5}, {\"training_acc\": 0.859375, \"training_loss\": 270.6259765625, \"iteration\": 759, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 303.6092529296875, \"iteration\": 760, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 300.3114013671875, \"iteration\": 761, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 380.81427001953125, \"iteration\": 762, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 318.0155334472656, \"iteration\": 763, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 354.9037170410156, \"iteration\": 764, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 307.134521484375, \"iteration\": 765, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 369.7710266113281, \"iteration\": 766, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 350.3110046386719, \"iteration\": 767, \"epoch\": 5}, {\"training_acc\": 0.8515625, \"training_loss\": 295.2578125, \"iteration\": 768, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 325.21527099609375, \"iteration\": 769, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 297.9049987792969, \"iteration\": 770, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 311.60552978515625, \"iteration\": 771, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 306.62158203125, \"iteration\": 772, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 334.03216552734375, \"iteration\": 773, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 317.719482421875, \"iteration\": 774, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 321.43353271484375, \"iteration\": 775, \"epoch\": 5}, {\"training_acc\": 0.84375, \"training_loss\": 302.619140625, \"iteration\": 776, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 334.0836181640625, \"iteration\": 777, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 367.3835144042969, \"iteration\": 778, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 367.75286865234375, \"iteration\": 779, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 348.0662841796875, \"iteration\": 780, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 264.95684814453125, \"iteration\": 781, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 310.4597473144531, \"iteration\": 782, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 303.059814453125, \"iteration\": 783, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 338.0355529785156, \"iteration\": 784, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 317.74658203125, \"iteration\": 785, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 326.60308837890625, \"iteration\": 786, \"epoch\": 5}, {\"training_acc\": 0.8515625, \"training_loss\": 300.9161376953125, \"iteration\": 787, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 353.3920593261719, \"iteration\": 788, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 324.87664794921875, \"iteration\": 789, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 302.67266845703125, \"iteration\": 790, \"epoch\": 5}, {\"training_acc\": 0.8515625, \"training_loss\": 306.08642578125, \"iteration\": 791, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 366.85858154296875, \"iteration\": 792, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 324.41497802734375, \"iteration\": 793, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 326.8471374511719, \"iteration\": 794, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 291.1186218261719, \"iteration\": 795, \"epoch\": 5}, {\"training_acc\": 0.859375, \"training_loss\": 279.7138977050781, \"iteration\": 796, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 349.1105041503906, \"iteration\": 797, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 307.97198486328125, \"iteration\": 798, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 329.2984313964844, \"iteration\": 799, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 326.5692138671875, \"iteration\": 800, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 287.61041259765625, \"iteration\": 801, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 348.4556884765625, \"iteration\": 802, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 266.3066101074219, \"iteration\": 803, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 328.380615234375, \"iteration\": 804, \"epoch\": 5}, {\"training_acc\": 0.8515625, \"training_loss\": 328.547607421875, \"iteration\": 805, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 326.860595703125, \"iteration\": 806, \"epoch\": 5}, {\"training_acc\": 0.8359375, \"training_loss\": 299.2953796386719, \"iteration\": 807, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 324.0011291503906, \"iteration\": 808, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 315.1274719238281, \"iteration\": 809, \"epoch\": 5}, {\"training_acc\": 0.953125, \"training_loss\": 340.0652160644531, \"iteration\": 810, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 328.1036376953125, \"iteration\": 811, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 283.91998291015625, \"iteration\": 812, \"epoch\": 5}, {\"training_acc\": 0.875, \"training_loss\": 325.7642822265625, \"iteration\": 813, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 292.59906005859375, \"iteration\": 814, \"epoch\": 5}, {\"training_acc\": 0.9609375, \"training_loss\": 330.42120361328125, \"iteration\": 815, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 332.2405700683594, \"iteration\": 816, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 319.0318908691406, \"iteration\": 817, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 398.3081359863281, \"iteration\": 818, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 317.7361145019531, \"iteration\": 819, \"epoch\": 5}, {\"training_acc\": 0.8359375, \"training_loss\": 280.72772216796875, \"iteration\": 820, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 302.5621337890625, \"iteration\": 821, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 344.5412292480469, \"iteration\": 822, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 289.50927734375, \"iteration\": 823, \"epoch\": 5}, {\"training_acc\": 0.9375, \"training_loss\": 317.647216796875, \"iteration\": 824, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 315.7999267578125, \"iteration\": 825, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 358.0528869628906, \"iteration\": 826, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 373.69500732421875, \"iteration\": 827, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 360.3499755859375, \"iteration\": 828, \"epoch\": 5}, {\"training_acc\": 0.890625, \"training_loss\": 379.490234375, \"iteration\": 829, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 385.39208984375, \"iteration\": 830, \"epoch\": 5}, {\"training_acc\": 0.9140625, \"training_loss\": 343.1168212890625, \"iteration\": 831, \"epoch\": 5}, {\"training_acc\": 0.8984375, \"training_loss\": 305.63812255859375, \"iteration\": 832, \"epoch\": 5}, {\"training_acc\": 0.9296875, \"training_loss\": 313.3313903808594, \"iteration\": 833, \"epoch\": 5}, {\"training_acc\": 0.90625, \"training_loss\": 349.0544128417969, \"iteration\": 834, \"epoch\": 5}, {\"training_acc\": 0.828125, \"training_loss\": 276.3013916015625, \"iteration\": 835, \"epoch\": 5}, {\"training_acc\": 0.8828125, \"training_loss\": 351.9706115722656, \"iteration\": 836, \"epoch\": 5}, {\"training_acc\": 0.828125, \"training_loss\": 293.58209228515625, \"iteration\": 837, \"epoch\": 5}, {\"training_acc\": 0.8671875, \"training_loss\": 307.6482238769531, \"iteration\": 838, \"epoch\": 5}, {\"training_acc\": 0.921875, \"training_loss\": 373.55706787109375, \"iteration\": 839, \"epoch\": 5}, {\"training_acc\": 0.95, \"training_loss\": 79.84449768066406, \"iteration\": 840, \"epoch\": 5}, {\"training_acc\": 0.9453125, \"training_loss\": 350.0428466796875, \"iteration\": 841, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 320.475341796875, \"iteration\": 842, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 341.72064208984375, \"iteration\": 843, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 391.2561950683594, \"iteration\": 844, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 280.9349365234375, \"iteration\": 845, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 355.58935546875, \"iteration\": 846, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 327.90216064453125, \"iteration\": 847, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 321.37054443359375, \"iteration\": 848, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 280.4013671875, \"iteration\": 849, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 361.6698303222656, \"iteration\": 850, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 335.02838134765625, \"iteration\": 851, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 310.4402160644531, \"iteration\": 852, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 263.0141906738281, \"iteration\": 853, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 331.27374267578125, \"iteration\": 854, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 350.0501708984375, \"iteration\": 855, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 287.8457946777344, \"iteration\": 856, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 309.7628173828125, \"iteration\": 857, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 291.5369873046875, \"iteration\": 858, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 348.9139404296875, \"iteration\": 859, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 303.8896789550781, \"iteration\": 860, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 346.52716064453125, \"iteration\": 861, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 274.43768310546875, \"iteration\": 862, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 311.8296813964844, \"iteration\": 863, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 321.30859375, \"iteration\": 864, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 275.2085876464844, \"iteration\": 865, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 331.69500732421875, \"iteration\": 866, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 295.52838134765625, \"iteration\": 867, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 346.16741943359375, \"iteration\": 868, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 326.171142578125, \"iteration\": 869, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 302.0816650390625, \"iteration\": 870, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 282.5036926269531, \"iteration\": 871, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 335.66766357421875, \"iteration\": 872, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 319.4166259765625, \"iteration\": 873, \"epoch\": 6}, {\"training_acc\": 0.8828125, \"training_loss\": 261.24896240234375, \"iteration\": 874, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 335.04449462890625, \"iteration\": 875, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 303.5822448730469, \"iteration\": 876, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 292.95928955078125, \"iteration\": 877, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 368.58941650390625, \"iteration\": 878, \"epoch\": 6}, {\"training_acc\": 0.890625, \"training_loss\": 326.85723876953125, \"iteration\": 879, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 327.286865234375, \"iteration\": 880, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 265.01824951171875, \"iteration\": 881, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 317.00384521484375, \"iteration\": 882, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 351.3749694824219, \"iteration\": 883, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 282.70501708984375, \"iteration\": 884, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 326.13922119140625, \"iteration\": 885, \"epoch\": 6}, {\"training_acc\": 0.875, \"training_loss\": 303.56231689453125, \"iteration\": 886, \"epoch\": 6}, {\"training_acc\": 0.890625, \"training_loss\": 313.13800048828125, \"iteration\": 887, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 379.22283935546875, \"iteration\": 888, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 343.15753173828125, \"iteration\": 889, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 301.8765869140625, \"iteration\": 890, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 394.5166931152344, \"iteration\": 891, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 334.49090576171875, \"iteration\": 892, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 279.2886962890625, \"iteration\": 893, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 310.7037658691406, \"iteration\": 894, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 273.502685546875, \"iteration\": 895, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 326.5888977050781, \"iteration\": 896, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 310.48785400390625, \"iteration\": 897, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 342.3189392089844, \"iteration\": 898, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 295.7137451171875, \"iteration\": 899, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 337.9753112792969, \"iteration\": 900, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 312.6075439453125, \"iteration\": 901, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 330.9603576660156, \"iteration\": 902, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 278.82037353515625, \"iteration\": 903, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 295.88494873046875, \"iteration\": 904, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 307.5458068847656, \"iteration\": 905, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 289.2506408691406, \"iteration\": 906, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 342.18267822265625, \"iteration\": 907, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 340.5081787109375, \"iteration\": 908, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 305.6448974609375, \"iteration\": 909, \"epoch\": 6}, {\"training_acc\": 0.890625, \"training_loss\": 281.4529724121094, \"iteration\": 910, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 330.5395202636719, \"iteration\": 911, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 351.8576965332031, \"iteration\": 912, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 309.71258544921875, \"iteration\": 913, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 310.24298095703125, \"iteration\": 914, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 340.3238525390625, \"iteration\": 915, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 232.99835205078125, \"iteration\": 916, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 290.8379211425781, \"iteration\": 917, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 359.6759338378906, \"iteration\": 918, \"epoch\": 6}, {\"training_acc\": 0.890625, \"training_loss\": 235.01409912109375, \"iteration\": 919, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 322.41546630859375, \"iteration\": 920, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 316.77520751953125, \"iteration\": 921, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 329.7530212402344, \"iteration\": 922, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 327.0233154296875, \"iteration\": 923, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 344.9576721191406, \"iteration\": 924, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 324.02099609375, \"iteration\": 925, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 335.1839294433594, \"iteration\": 926, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 325.4540710449219, \"iteration\": 927, \"epoch\": 6}, {\"training_acc\": 0.8671875, \"training_loss\": 250.73983764648438, \"iteration\": 928, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 354.1000061035156, \"iteration\": 929, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 328.7234191894531, \"iteration\": 930, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 331.79058837890625, \"iteration\": 931, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 300.6944580078125, \"iteration\": 932, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 318.727294921875, \"iteration\": 933, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 337.393798828125, \"iteration\": 934, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 313.4356994628906, \"iteration\": 935, \"epoch\": 6}, {\"training_acc\": 0.890625, \"training_loss\": 329.51531982421875, \"iteration\": 936, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 307.396728515625, \"iteration\": 937, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 300.55413818359375, \"iteration\": 938, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 286.4007568359375, \"iteration\": 939, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 378.271484375, \"iteration\": 940, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 328.4600524902344, \"iteration\": 941, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 326.3565673828125, \"iteration\": 942, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 333.33221435546875, \"iteration\": 943, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 349.3589172363281, \"iteration\": 944, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 310.43817138671875, \"iteration\": 945, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 301.5797119140625, \"iteration\": 946, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 356.2063903808594, \"iteration\": 947, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 323.171875, \"iteration\": 948, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 285.70489501953125, \"iteration\": 949, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 317.8306884765625, \"iteration\": 950, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 362.67822265625, \"iteration\": 951, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 260.89337158203125, \"iteration\": 952, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 307.22564697265625, \"iteration\": 953, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 343.1694641113281, \"iteration\": 954, \"epoch\": 6}, {\"training_acc\": 0.875, \"training_loss\": 341.1607666015625, \"iteration\": 955, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 323.7706604003906, \"iteration\": 956, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 320.83111572265625, \"iteration\": 957, \"epoch\": 6}, {\"training_acc\": 0.8828125, \"training_loss\": 329.64581298828125, \"iteration\": 958, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 328.58465576171875, \"iteration\": 959, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 306.12677001953125, \"iteration\": 960, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 299.78521728515625, \"iteration\": 961, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 344.17315673828125, \"iteration\": 962, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 286.6419677734375, \"iteration\": 963, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 327.469970703125, \"iteration\": 964, \"epoch\": 6}, {\"training_acc\": 0.8828125, \"training_loss\": 318.8884582519531, \"iteration\": 965, \"epoch\": 6}, {\"training_acc\": 0.859375, \"training_loss\": 290.76873779296875, \"iteration\": 966, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 348.768798828125, \"iteration\": 967, \"epoch\": 6}, {\"training_acc\": 0.8828125, \"training_loss\": 375.2723693847656, \"iteration\": 968, \"epoch\": 6}, {\"training_acc\": 0.8828125, \"training_loss\": 334.88134765625, \"iteration\": 969, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 286.8330078125, \"iteration\": 970, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 320.97454833984375, \"iteration\": 971, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 349.73516845703125, \"iteration\": 972, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 340.9063720703125, \"iteration\": 973, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 351.19091796875, \"iteration\": 974, \"epoch\": 6}, {\"training_acc\": 0.8671875, \"training_loss\": 304.18157958984375, \"iteration\": 975, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 390.74273681640625, \"iteration\": 976, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 355.7708740234375, \"iteration\": 977, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 307.65362548828125, \"iteration\": 978, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 244.4379425048828, \"iteration\": 979, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 262.06817626953125, \"iteration\": 980, \"epoch\": 6}, {\"training_acc\": 0.9765625, \"training_loss\": 335.2342529296875, \"iteration\": 981, \"epoch\": 6}, {\"training_acc\": 0.8828125, \"training_loss\": 315.3299560546875, \"iteration\": 982, \"epoch\": 6}, {\"training_acc\": 0.8515625, \"training_loss\": 270.409912109375, \"iteration\": 983, \"epoch\": 6}, {\"training_acc\": 0.875, \"training_loss\": 286.68084716796875, \"iteration\": 984, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 322.4653625488281, \"iteration\": 985, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 361.43896484375, \"iteration\": 986, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 322.9744873046875, \"iteration\": 987, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 315.47784423828125, \"iteration\": 988, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 352.4002380371094, \"iteration\": 989, \"epoch\": 6}, {\"training_acc\": 0.9140625, \"training_loss\": 276.490478515625, \"iteration\": 990, \"epoch\": 6}, {\"training_acc\": 0.953125, \"training_loss\": 293.2635192871094, \"iteration\": 991, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 321.7813720703125, \"iteration\": 992, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 311.26043701171875, \"iteration\": 993, \"epoch\": 6}, {\"training_acc\": 0.96875, \"training_loss\": 371.62664794921875, \"iteration\": 994, \"epoch\": 6}, {\"training_acc\": 0.9375, \"training_loss\": 305.4678955078125, \"iteration\": 995, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 318.6315002441406, \"iteration\": 996, \"epoch\": 6}, {\"training_acc\": 0.9609375, \"training_loss\": 275.9346923828125, \"iteration\": 997, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 318.41778564453125, \"iteration\": 998, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 274.3221740722656, \"iteration\": 999, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 323.11688232421875, \"iteration\": 1000, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 307.38861083984375, \"iteration\": 1001, \"epoch\": 6}, {\"training_acc\": 0.90625, \"training_loss\": 288.2665710449219, \"iteration\": 1002, \"epoch\": 6}, {\"training_acc\": 0.9296875, \"training_loss\": 281.9842529296875, \"iteration\": 1003, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 338.2260437011719, \"iteration\": 1004, \"epoch\": 6}, {\"training_acc\": 0.8984375, \"training_loss\": 282.0330810546875, \"iteration\": 1005, \"epoch\": 6}, {\"training_acc\": 0.921875, \"training_loss\": 322.69586181640625, \"iteration\": 1006, \"epoch\": 6}, {\"training_acc\": 0.875, \"training_loss\": 256.2362060546875, \"iteration\": 1007, \"epoch\": 6}, {\"training_acc\": 0.925, \"training_loss\": 63.178802490234375, \"iteration\": 1008, \"epoch\": 6}, {\"training_acc\": 0.9453125, \"training_loss\": 313.315673828125, \"iteration\": 1009, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 288.3133850097656, \"iteration\": 1010, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 287.9862060546875, \"iteration\": 1011, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 302.51409912109375, \"iteration\": 1012, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 310.1551818847656, \"iteration\": 1013, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 302.78265380859375, \"iteration\": 1014, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 309.73150634765625, \"iteration\": 1015, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 318.38916015625, \"iteration\": 1016, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 314.85888671875, \"iteration\": 1017, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 285.0972900390625, \"iteration\": 1018, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 298.002685546875, \"iteration\": 1019, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 304.2791442871094, \"iteration\": 1020, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 313.0164794921875, \"iteration\": 1021, \"epoch\": 7}, {\"training_acc\": 0.890625, \"training_loss\": 348.8837890625, \"iteration\": 1022, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 294.7655944824219, \"iteration\": 1023, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 265.1175537109375, \"iteration\": 1024, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 357.32818603515625, \"iteration\": 1025, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 336.9998779296875, \"iteration\": 1026, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 303.5718994140625, \"iteration\": 1027, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 307.3666076660156, \"iteration\": 1028, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 262.5064697265625, \"iteration\": 1029, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 300.2270202636719, \"iteration\": 1030, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 317.9095458984375, \"iteration\": 1031, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 323.3043518066406, \"iteration\": 1032, \"epoch\": 7}, {\"training_acc\": 0.90625, \"training_loss\": 396.3013000488281, \"iteration\": 1033, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 283.9175720214844, \"iteration\": 1034, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 276.18353271484375, \"iteration\": 1035, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 293.51751708984375, \"iteration\": 1036, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 319.4495849609375, \"iteration\": 1037, \"epoch\": 7}, {\"training_acc\": 0.875, \"training_loss\": 307.86932373046875, \"iteration\": 1038, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 312.97113037109375, \"iteration\": 1039, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 339.20233154296875, \"iteration\": 1040, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 276.32666015625, \"iteration\": 1041, \"epoch\": 7}, {\"training_acc\": 0.890625, \"training_loss\": 294.9900817871094, \"iteration\": 1042, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 351.09307861328125, \"iteration\": 1043, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 335.5374450683594, \"iteration\": 1044, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 334.00445556640625, \"iteration\": 1045, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 297.72265625, \"iteration\": 1046, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 298.0072021484375, \"iteration\": 1047, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 345.2484436035156, \"iteration\": 1048, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 286.07965087890625, \"iteration\": 1049, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 294.8292541503906, \"iteration\": 1050, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 288.4322204589844, \"iteration\": 1051, \"epoch\": 7}, {\"training_acc\": 0.890625, \"training_loss\": 294.96868896484375, \"iteration\": 1052, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 313.6624755859375, \"iteration\": 1053, \"epoch\": 7}, {\"training_acc\": 0.8984375, \"training_loss\": 269.7814025878906, \"iteration\": 1054, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 350.1722412109375, \"iteration\": 1055, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 315.5295104980469, \"iteration\": 1056, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 308.7772216796875, \"iteration\": 1057, \"epoch\": 7}, {\"training_acc\": 0.90625, \"training_loss\": 325.9468688964844, \"iteration\": 1058, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 355.29681396484375, \"iteration\": 1059, \"epoch\": 7}, {\"training_acc\": 0.90625, \"training_loss\": 294.4884033203125, \"iteration\": 1060, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 325.98089599609375, \"iteration\": 1061, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 353.0234375, \"iteration\": 1062, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 324.8658447265625, \"iteration\": 1063, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 325.7923889160156, \"iteration\": 1064, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 300.2304992675781, \"iteration\": 1065, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 340.6685791015625, \"iteration\": 1066, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 304.00714111328125, \"iteration\": 1067, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 361.2521667480469, \"iteration\": 1068, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 298.7919006347656, \"iteration\": 1069, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 335.3191833496094, \"iteration\": 1070, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 268.94415283203125, \"iteration\": 1071, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 302.974853515625, \"iteration\": 1072, \"epoch\": 7}, {\"training_acc\": 0.90625, \"training_loss\": 291.17205810546875, \"iteration\": 1073, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 257.90545654296875, \"iteration\": 1074, \"epoch\": 7}, {\"training_acc\": 0.90625, \"training_loss\": 379.6549987792969, \"iteration\": 1075, \"epoch\": 7}, {\"training_acc\": 0.90625, \"training_loss\": 342.21759033203125, \"iteration\": 1076, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 322.47039794921875, \"iteration\": 1077, \"epoch\": 7}, {\"training_acc\": 0.90625, \"training_loss\": 295.58795166015625, \"iteration\": 1078, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 281.3438415527344, \"iteration\": 1079, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 275.67291259765625, \"iteration\": 1080, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 312.3755798339844, \"iteration\": 1081, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 287.3378601074219, \"iteration\": 1082, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 271.5166015625, \"iteration\": 1083, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 295.9103088378906, \"iteration\": 1084, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 303.4659729003906, \"iteration\": 1085, \"epoch\": 7}, {\"training_acc\": 0.890625, \"training_loss\": 328.4794921875, \"iteration\": 1086, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 294.4490966796875, \"iteration\": 1087, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 302.80029296875, \"iteration\": 1088, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 262.552490234375, \"iteration\": 1089, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 329.87591552734375, \"iteration\": 1090, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 313.26043701171875, \"iteration\": 1091, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 304.3011779785156, \"iteration\": 1092, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 333.9835510253906, \"iteration\": 1093, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 355.677734375, \"iteration\": 1094, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 326.32061767578125, \"iteration\": 1095, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 295.45648193359375, \"iteration\": 1096, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 291.69012451171875, \"iteration\": 1097, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 338.42926025390625, \"iteration\": 1098, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 381.21624755859375, \"iteration\": 1099, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 307.2313232421875, \"iteration\": 1100, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 350.41204833984375, \"iteration\": 1101, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 283.30413818359375, \"iteration\": 1102, \"epoch\": 7}, {\"training_acc\": 0.8984375, \"training_loss\": 306.97430419921875, \"iteration\": 1103, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 319.73602294921875, \"iteration\": 1104, \"epoch\": 7}, {\"training_acc\": 0.9765625, \"training_loss\": 366.18011474609375, \"iteration\": 1105, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 288.95391845703125, \"iteration\": 1106, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 363.6847839355469, \"iteration\": 1107, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 345.7657165527344, \"iteration\": 1108, \"epoch\": 7}, {\"training_acc\": 0.859375, \"training_loss\": 366.1640319824219, \"iteration\": 1109, \"epoch\": 7}, {\"training_acc\": 0.90625, \"training_loss\": 347.3033142089844, \"iteration\": 1110, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 288.49859619140625, \"iteration\": 1111, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 367.28326416015625, \"iteration\": 1112, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 263.840576171875, \"iteration\": 1113, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 308.6614685058594, \"iteration\": 1114, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 319.1866455078125, \"iteration\": 1115, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 359.8297119140625, \"iteration\": 1116, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 328.83074951171875, \"iteration\": 1117, \"epoch\": 7}, {\"training_acc\": 0.890625, \"training_loss\": 324.56866455078125, \"iteration\": 1118, \"epoch\": 7}, {\"training_acc\": 0.875, \"training_loss\": 342.67181396484375, \"iteration\": 1119, \"epoch\": 7}, {\"training_acc\": 0.875, \"training_loss\": 275.41046142578125, \"iteration\": 1120, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 346.23504638671875, \"iteration\": 1121, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 263.0938720703125, \"iteration\": 1122, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 297.5953369140625, \"iteration\": 1123, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 352.504150390625, \"iteration\": 1124, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 314.7823486328125, \"iteration\": 1125, \"epoch\": 7}, {\"training_acc\": 0.875, \"training_loss\": 353.87384033203125, \"iteration\": 1126, \"epoch\": 7}, {\"training_acc\": 0.8515625, \"training_loss\": 291.5505676269531, \"iteration\": 1127, \"epoch\": 7}, {\"training_acc\": 0.890625, \"training_loss\": 334.37396240234375, \"iteration\": 1128, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 312.478515625, \"iteration\": 1129, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 304.1175537109375, \"iteration\": 1130, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 259.68310546875, \"iteration\": 1131, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 324.6065979003906, \"iteration\": 1132, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 315.99176025390625, \"iteration\": 1133, \"epoch\": 7}, {\"training_acc\": 0.8984375, \"training_loss\": 351.76922607421875, \"iteration\": 1134, \"epoch\": 7}, {\"training_acc\": 0.90625, \"training_loss\": 303.5760498046875, \"iteration\": 1135, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 389.1020202636719, \"iteration\": 1136, \"epoch\": 7}, {\"training_acc\": 0.8984375, \"training_loss\": 327.64337158203125, \"iteration\": 1137, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 336.5926513671875, \"iteration\": 1138, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 280.3629150390625, \"iteration\": 1139, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 337.9220886230469, \"iteration\": 1140, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 299.53814697265625, \"iteration\": 1141, \"epoch\": 7}, {\"training_acc\": 0.890625, \"training_loss\": 291.91754150390625, \"iteration\": 1142, \"epoch\": 7}, {\"training_acc\": 0.9140625, \"training_loss\": 345.297119140625, \"iteration\": 1143, \"epoch\": 7}, {\"training_acc\": 0.8828125, \"training_loss\": 282.2098388671875, \"iteration\": 1144, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 321.8868103027344, \"iteration\": 1145, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 316.0420227050781, \"iteration\": 1146, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 327.92962646484375, \"iteration\": 1147, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 319.24658203125, \"iteration\": 1148, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 313.48291015625, \"iteration\": 1149, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 328.4173278808594, \"iteration\": 1150, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 345.7298583984375, \"iteration\": 1151, \"epoch\": 7}, {\"training_acc\": 0.890625, \"training_loss\": 327.3573913574219, \"iteration\": 1152, \"epoch\": 7}, {\"training_acc\": 0.859375, \"training_loss\": 394.7784423828125, \"iteration\": 1153, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 322.04815673828125, \"iteration\": 1154, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 320.1229553222656, \"iteration\": 1155, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 407.4827880859375, \"iteration\": 1156, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 321.91845703125, \"iteration\": 1157, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 328.7745666503906, \"iteration\": 1158, \"epoch\": 7}, {\"training_acc\": 0.8984375, \"training_loss\": 247.654052734375, \"iteration\": 1159, \"epoch\": 7}, {\"training_acc\": 0.8828125, \"training_loss\": 295.89642333984375, \"iteration\": 1160, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 301.1177673339844, \"iteration\": 1161, \"epoch\": 7}, {\"training_acc\": 0.953125, \"training_loss\": 314.2103271484375, \"iteration\": 1162, \"epoch\": 7}, {\"training_acc\": 0.984375, \"training_loss\": 307.2416076660156, \"iteration\": 1163, \"epoch\": 7}, {\"training_acc\": 0.8828125, \"training_loss\": 315.4634704589844, \"iteration\": 1164, \"epoch\": 7}, {\"training_acc\": 0.90625, \"training_loss\": 342.8711242675781, \"iteration\": 1165, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 327.3275146484375, \"iteration\": 1166, \"epoch\": 7}, {\"training_acc\": 0.8984375, \"training_loss\": 305.35955810546875, \"iteration\": 1167, \"epoch\": 7}, {\"training_acc\": 0.9609375, \"training_loss\": 313.775146484375, \"iteration\": 1168, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 299.8576965332031, \"iteration\": 1169, \"epoch\": 7}, {\"training_acc\": 0.9375, \"training_loss\": 315.3355407714844, \"iteration\": 1170, \"epoch\": 7}, {\"training_acc\": 0.96875, \"training_loss\": 324.4222106933594, \"iteration\": 1171, \"epoch\": 7}, {\"training_acc\": 0.921875, \"training_loss\": 284.77423095703125, \"iteration\": 1172, \"epoch\": 7}, {\"training_acc\": 0.8828125, \"training_loss\": 297.88055419921875, \"iteration\": 1173, \"epoch\": 7}, {\"training_acc\": 0.8828125, \"training_loss\": 297.02655029296875, \"iteration\": 1174, \"epoch\": 7}, {\"training_acc\": 0.9453125, \"training_loss\": 328.78753662109375, \"iteration\": 1175, \"epoch\": 7}, {\"training_acc\": 1.0, \"training_loss\": 95.36510467529297, \"iteration\": 1176, \"epoch\": 7}, {\"training_acc\": 0.9296875, \"training_loss\": 294.46063232421875, \"iteration\": 1177, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 282.21160888671875, \"iteration\": 1178, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 288.0484619140625, \"iteration\": 1179, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 308.9246826171875, \"iteration\": 1180, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 291.26898193359375, \"iteration\": 1181, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 293.27618408203125, \"iteration\": 1182, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 328.5210266113281, \"iteration\": 1183, \"epoch\": 8}, {\"training_acc\": 0.8984375, \"training_loss\": 283.9029235839844, \"iteration\": 1184, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 344.9256591796875, \"iteration\": 1185, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 317.31439208984375, \"iteration\": 1186, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 275.4864501953125, \"iteration\": 1187, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 292.5257568359375, \"iteration\": 1188, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 334.2651062011719, \"iteration\": 1189, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 334.2799377441406, \"iteration\": 1190, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 356.494140625, \"iteration\": 1191, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 338.69586181640625, \"iteration\": 1192, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 313.76739501953125, \"iteration\": 1193, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 290.32122802734375, \"iteration\": 1194, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 338.2042541503906, \"iteration\": 1195, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 285.4180908203125, \"iteration\": 1196, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 308.960205078125, \"iteration\": 1197, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 335.09576416015625, \"iteration\": 1198, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 308.7488708496094, \"iteration\": 1199, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 340.7810363769531, \"iteration\": 1200, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 313.076904296875, \"iteration\": 1201, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 288.46063232421875, \"iteration\": 1202, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 319.4554443359375, \"iteration\": 1203, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 343.23284912109375, \"iteration\": 1204, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 354.7767028808594, \"iteration\": 1205, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 346.591796875, \"iteration\": 1206, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 300.050537109375, \"iteration\": 1207, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 319.9345397949219, \"iteration\": 1208, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 302.41192626953125, \"iteration\": 1209, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 315.4996337890625, \"iteration\": 1210, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 258.6049499511719, \"iteration\": 1211, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 314.2094421386719, \"iteration\": 1212, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 359.8727111816406, \"iteration\": 1213, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 341.65374755859375, \"iteration\": 1214, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 357.3271484375, \"iteration\": 1215, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 318.8153381347656, \"iteration\": 1216, \"epoch\": 8}, {\"training_acc\": 0.90625, \"training_loss\": 347.11810302734375, \"iteration\": 1217, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 320.1561279296875, \"iteration\": 1218, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 324.6829833984375, \"iteration\": 1219, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 308.5032958984375, \"iteration\": 1220, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 275.83502197265625, \"iteration\": 1221, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 299.4617919921875, \"iteration\": 1222, \"epoch\": 8}, {\"training_acc\": 0.890625, \"training_loss\": 320.9456787109375, \"iteration\": 1223, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 324.09417724609375, \"iteration\": 1224, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 348.8676452636719, \"iteration\": 1225, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 343.82281494140625, \"iteration\": 1226, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 305.1186218261719, \"iteration\": 1227, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 334.65496826171875, \"iteration\": 1228, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 317.6027526855469, \"iteration\": 1229, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 277.0982971191406, \"iteration\": 1230, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 284.20770263671875, \"iteration\": 1231, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 261.1170654296875, \"iteration\": 1232, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 265.15374755859375, \"iteration\": 1233, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 301.78741455078125, \"iteration\": 1234, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 317.27838134765625, \"iteration\": 1235, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 309.80364990234375, \"iteration\": 1236, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 319.8837585449219, \"iteration\": 1237, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 328.44415283203125, \"iteration\": 1238, \"epoch\": 8}, {\"training_acc\": 0.890625, \"training_loss\": 265.80548095703125, \"iteration\": 1239, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 297.726806640625, \"iteration\": 1240, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 287.55267333984375, \"iteration\": 1241, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 298.27911376953125, \"iteration\": 1242, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 275.5980529785156, \"iteration\": 1243, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 318.0361328125, \"iteration\": 1244, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 278.7500915527344, \"iteration\": 1245, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 346.1056823730469, \"iteration\": 1246, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 302.78350830078125, \"iteration\": 1247, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 302.4441223144531, \"iteration\": 1248, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 292.03656005859375, \"iteration\": 1249, \"epoch\": 8}, {\"training_acc\": 0.984375, \"training_loss\": 275.563232421875, \"iteration\": 1250, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 303.72430419921875, \"iteration\": 1251, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 307.81036376953125, \"iteration\": 1252, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 278.6714172363281, \"iteration\": 1253, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 347.34307861328125, \"iteration\": 1254, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 308.8102722167969, \"iteration\": 1255, \"epoch\": 8}, {\"training_acc\": 0.9765625, \"training_loss\": 374.90423583984375, \"iteration\": 1256, \"epoch\": 8}, {\"training_acc\": 0.890625, \"training_loss\": 300.3271789550781, \"iteration\": 1257, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 272.9700927734375, \"iteration\": 1258, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 319.3245849609375, \"iteration\": 1259, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 371.47509765625, \"iteration\": 1260, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 265.090576171875, \"iteration\": 1261, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 366.71185302734375, \"iteration\": 1262, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 334.9706115722656, \"iteration\": 1263, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 301.92694091796875, \"iteration\": 1264, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 340.6348571777344, \"iteration\": 1265, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 298.05706787109375, \"iteration\": 1266, \"epoch\": 8}, {\"training_acc\": 0.90625, \"training_loss\": 273.10943603515625, \"iteration\": 1267, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 314.1883239746094, \"iteration\": 1268, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 304.72064208984375, \"iteration\": 1269, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 346.62066650390625, \"iteration\": 1270, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 242.76043701171875, \"iteration\": 1271, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 340.34564208984375, \"iteration\": 1272, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 288.01678466796875, \"iteration\": 1273, \"epoch\": 8}, {\"training_acc\": 0.890625, \"training_loss\": 305.9620361328125, \"iteration\": 1274, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 329.9814453125, \"iteration\": 1275, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 335.1912841796875, \"iteration\": 1276, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 333.1445007324219, \"iteration\": 1277, \"epoch\": 8}, {\"training_acc\": 0.8671875, \"training_loss\": 276.0360107421875, \"iteration\": 1278, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 313.0015869140625, \"iteration\": 1279, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 298.7996826171875, \"iteration\": 1280, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 272.4449157714844, \"iteration\": 1281, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 329.7376403808594, \"iteration\": 1282, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 319.09783935546875, \"iteration\": 1283, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 306.8919982910156, \"iteration\": 1284, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 331.2596130371094, \"iteration\": 1285, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 287.08551025390625, \"iteration\": 1286, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 319.3253479003906, \"iteration\": 1287, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 329.83148193359375, \"iteration\": 1288, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 301.7418212890625, \"iteration\": 1289, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 292.183349609375, \"iteration\": 1290, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 288.9190673828125, \"iteration\": 1291, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 250.3536834716797, \"iteration\": 1292, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 329.04046630859375, \"iteration\": 1293, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 345.384033203125, \"iteration\": 1294, \"epoch\": 8}, {\"training_acc\": 0.90625, \"training_loss\": 331.18292236328125, \"iteration\": 1295, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 313.8831481933594, \"iteration\": 1296, \"epoch\": 8}, {\"training_acc\": 0.90625, \"training_loss\": 348.520751953125, \"iteration\": 1297, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 333.7821350097656, \"iteration\": 1298, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 345.9306640625, \"iteration\": 1299, \"epoch\": 8}, {\"training_acc\": 0.890625, \"training_loss\": 294.31072998046875, \"iteration\": 1300, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 335.15380859375, \"iteration\": 1301, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 389.11700439453125, \"iteration\": 1302, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 333.4358825683594, \"iteration\": 1303, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 378.72357177734375, \"iteration\": 1304, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 297.03936767578125, \"iteration\": 1305, \"epoch\": 8}, {\"training_acc\": 0.9921875, \"training_loss\": 359.24786376953125, \"iteration\": 1306, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 292.8854064941406, \"iteration\": 1307, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 331.70648193359375, \"iteration\": 1308, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 365.98370361328125, \"iteration\": 1309, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 329.4376220703125, \"iteration\": 1310, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 360.74871826171875, \"iteration\": 1311, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 341.23663330078125, \"iteration\": 1312, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 331.72174072265625, \"iteration\": 1313, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 344.647216796875, \"iteration\": 1314, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 334.31219482421875, \"iteration\": 1315, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 309.9605407714844, \"iteration\": 1316, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 329.7873229980469, \"iteration\": 1317, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 320.301513671875, \"iteration\": 1318, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 273.1118469238281, \"iteration\": 1319, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 340.19854736328125, \"iteration\": 1320, \"epoch\": 8}, {\"training_acc\": 0.9609375, \"training_loss\": 339.207763671875, \"iteration\": 1321, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 273.588623046875, \"iteration\": 1322, \"epoch\": 8}, {\"training_acc\": 0.96875, \"training_loss\": 344.18670654296875, \"iteration\": 1323, \"epoch\": 8}, {\"training_acc\": 0.8828125, \"training_loss\": 328.9719543457031, \"iteration\": 1324, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 277.4266052246094, \"iteration\": 1325, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 281.8463439941406, \"iteration\": 1326, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 353.7369384765625, \"iteration\": 1327, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 329.78118896484375, \"iteration\": 1328, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 315.6048278808594, \"iteration\": 1329, \"epoch\": 8}, {\"training_acc\": 0.890625, \"training_loss\": 285.65386962890625, \"iteration\": 1330, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 282.1962890625, \"iteration\": 1331, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 303.23919677734375, \"iteration\": 1332, \"epoch\": 8}, {\"training_acc\": 0.953125, \"training_loss\": 306.9673156738281, \"iteration\": 1333, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 348.42413330078125, \"iteration\": 1334, \"epoch\": 8}, {\"training_acc\": 0.9140625, \"training_loss\": 313.7601318359375, \"iteration\": 1335, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 340.5810241699219, \"iteration\": 1336, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 326.5399169921875, \"iteration\": 1337, \"epoch\": 8}, {\"training_acc\": 0.9296875, \"training_loss\": 282.751953125, \"iteration\": 1338, \"epoch\": 8}, {\"training_acc\": 0.8984375, \"training_loss\": 305.12420654296875, \"iteration\": 1339, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 303.99853515625, \"iteration\": 1340, \"epoch\": 8}, {\"training_acc\": 0.921875, \"training_loss\": 290.3461608886719, \"iteration\": 1341, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 276.428955078125, \"iteration\": 1342, \"epoch\": 8}, {\"training_acc\": 0.9453125, \"training_loss\": 351.80621337890625, \"iteration\": 1343, \"epoch\": 8}, {\"training_acc\": 0.95, \"training_loss\": 46.125370025634766, \"iteration\": 1344, \"epoch\": 8}, {\"training_acc\": 0.9375, \"training_loss\": 312.4088134765625, \"iteration\": 1345, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 329.1018981933594, \"iteration\": 1346, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 318.29656982421875, \"iteration\": 1347, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 354.95361328125, \"iteration\": 1348, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 301.63165283203125, \"iteration\": 1349, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 329.10546875, \"iteration\": 1350, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 300.6646728515625, \"iteration\": 1351, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 284.637451171875, \"iteration\": 1352, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 376.7432556152344, \"iteration\": 1353, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 354.130126953125, \"iteration\": 1354, \"epoch\": 9}, {\"training_acc\": 0.90625, \"training_loss\": 312.4078674316406, \"iteration\": 1355, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 285.20562744140625, \"iteration\": 1356, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 338.5677185058594, \"iteration\": 1357, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 367.1937561035156, \"iteration\": 1358, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 259.89349365234375, \"iteration\": 1359, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 301.5456848144531, \"iteration\": 1360, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 343.7102966308594, \"iteration\": 1361, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 249.97825622558594, \"iteration\": 1362, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 264.9247741699219, \"iteration\": 1363, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 343.49859619140625, \"iteration\": 1364, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 312.45806884765625, \"iteration\": 1365, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 345.90069580078125, \"iteration\": 1366, \"epoch\": 9}, {\"training_acc\": 0.8984375, \"training_loss\": 272.793701171875, \"iteration\": 1367, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 295.3182067871094, \"iteration\": 1368, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 311.8782653808594, \"iteration\": 1369, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 277.0668640136719, \"iteration\": 1370, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 307.4633483886719, \"iteration\": 1371, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 308.01776123046875, \"iteration\": 1372, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 284.5899353027344, \"iteration\": 1373, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 295.85418701171875, \"iteration\": 1374, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 349.66717529296875, \"iteration\": 1375, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 322.41131591796875, \"iteration\": 1376, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 343.66827392578125, \"iteration\": 1377, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 288.504150390625, \"iteration\": 1378, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 316.80181884765625, \"iteration\": 1379, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 360.61407470703125, \"iteration\": 1380, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 317.06866455078125, \"iteration\": 1381, \"epoch\": 9}, {\"training_acc\": 0.8828125, \"training_loss\": 282.575439453125, \"iteration\": 1382, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 292.48663330078125, \"iteration\": 1383, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 297.39166259765625, \"iteration\": 1384, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 251.73001098632812, \"iteration\": 1385, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 305.7767639160156, \"iteration\": 1386, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 318.8713684082031, \"iteration\": 1387, \"epoch\": 9}, {\"training_acc\": 0.8984375, \"training_loss\": 299.8199462890625, \"iteration\": 1388, \"epoch\": 9}, {\"training_acc\": 0.9140625, \"training_loss\": 293.5376892089844, \"iteration\": 1389, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 301.6787109375, \"iteration\": 1390, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 306.7115478515625, \"iteration\": 1391, \"epoch\": 9}, {\"training_acc\": 0.90625, \"training_loss\": 325.04986572265625, \"iteration\": 1392, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 365.55572509765625, \"iteration\": 1393, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 339.01800537109375, \"iteration\": 1394, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 328.0592041015625, \"iteration\": 1395, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 292.29730224609375, \"iteration\": 1396, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 291.2640380859375, \"iteration\": 1397, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 366.2553405761719, \"iteration\": 1398, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 348.7249450683594, \"iteration\": 1399, \"epoch\": 9}, {\"training_acc\": 0.984375, \"training_loss\": 358.1907653808594, \"iteration\": 1400, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 264.77105712890625, \"iteration\": 1401, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 327.6558837890625, \"iteration\": 1402, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 293.88409423828125, \"iteration\": 1403, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 349.40155029296875, \"iteration\": 1404, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 316.7127685546875, \"iteration\": 1405, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 328.8659973144531, \"iteration\": 1406, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 312.0645751953125, \"iteration\": 1407, \"epoch\": 9}, {\"training_acc\": 0.9765625, \"training_loss\": 380.9542541503906, \"iteration\": 1408, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 286.0135803222656, \"iteration\": 1409, \"epoch\": 9}, {\"training_acc\": 0.984375, \"training_loss\": 358.55694580078125, \"iteration\": 1410, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 300.6805725097656, \"iteration\": 1411, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 345.5158996582031, \"iteration\": 1412, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 322.40924072265625, \"iteration\": 1413, \"epoch\": 9}, {\"training_acc\": 0.9921875, \"training_loss\": 325.795166015625, \"iteration\": 1414, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 338.658447265625, \"iteration\": 1415, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 314.0780029296875, \"iteration\": 1416, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 276.7470703125, \"iteration\": 1417, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 317.2330322265625, \"iteration\": 1418, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 318.0123291015625, \"iteration\": 1419, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 287.7186279296875, \"iteration\": 1420, \"epoch\": 9}, {\"training_acc\": 0.9140625, \"training_loss\": 324.29107666015625, \"iteration\": 1421, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 318.06610107421875, \"iteration\": 1422, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 313.7578125, \"iteration\": 1423, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 343.2403869628906, \"iteration\": 1424, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 339.4693603515625, \"iteration\": 1425, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 355.47601318359375, \"iteration\": 1426, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 345.0093688964844, \"iteration\": 1427, \"epoch\": 9}, {\"training_acc\": 0.890625, \"training_loss\": 319.8951721191406, \"iteration\": 1428, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 313.2257080078125, \"iteration\": 1429, \"epoch\": 9}, {\"training_acc\": 0.9140625, \"training_loss\": 307.36138916015625, \"iteration\": 1430, \"epoch\": 9}, {\"training_acc\": 0.9765625, \"training_loss\": 294.8424377441406, \"iteration\": 1431, \"epoch\": 9}, {\"training_acc\": 0.9140625, \"training_loss\": 324.9735107421875, \"iteration\": 1432, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 303.08648681640625, \"iteration\": 1433, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 324.32806396484375, \"iteration\": 1434, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 275.8721618652344, \"iteration\": 1435, \"epoch\": 9}, {\"training_acc\": 0.875, \"training_loss\": 288.95263671875, \"iteration\": 1436, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 349.50689697265625, \"iteration\": 1437, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 334.58935546875, \"iteration\": 1438, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 311.8951416015625, \"iteration\": 1439, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 292.4493408203125, \"iteration\": 1440, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 296.12451171875, \"iteration\": 1441, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 322.40380859375, \"iteration\": 1442, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 296.62359619140625, \"iteration\": 1443, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 311.5947265625, \"iteration\": 1444, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 292.6653747558594, \"iteration\": 1445, \"epoch\": 9}, {\"training_acc\": 0.984375, \"training_loss\": 288.90130615234375, \"iteration\": 1446, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 284.820068359375, \"iteration\": 1447, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 301.0610656738281, \"iteration\": 1448, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 282.27032470703125, \"iteration\": 1449, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 261.193115234375, \"iteration\": 1450, \"epoch\": 9}, {\"training_acc\": 0.90625, \"training_loss\": 314.2127380371094, \"iteration\": 1451, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 302.4691162109375, \"iteration\": 1452, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 317.866455078125, \"iteration\": 1453, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 291.3518981933594, \"iteration\": 1454, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 291.38262939453125, \"iteration\": 1455, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 318.95892333984375, \"iteration\": 1456, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 361.46142578125, \"iteration\": 1457, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 317.74383544921875, \"iteration\": 1458, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 307.8211669921875, \"iteration\": 1459, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 308.07891845703125, \"iteration\": 1460, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 302.92584228515625, \"iteration\": 1461, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 271.12408447265625, \"iteration\": 1462, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 286.11444091796875, \"iteration\": 1463, \"epoch\": 9}, {\"training_acc\": 0.9765625, \"training_loss\": 321.50836181640625, \"iteration\": 1464, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 312.66754150390625, \"iteration\": 1465, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 325.25262451171875, \"iteration\": 1466, \"epoch\": 9}, {\"training_acc\": 0.9140625, \"training_loss\": 364.71258544921875, \"iteration\": 1467, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 290.14404296875, \"iteration\": 1468, \"epoch\": 9}, {\"training_acc\": 0.8984375, \"training_loss\": 346.60748291015625, \"iteration\": 1469, \"epoch\": 9}, {\"training_acc\": 0.9140625, \"training_loss\": 319.48980712890625, \"iteration\": 1470, \"epoch\": 9}, {\"training_acc\": 0.890625, \"training_loss\": 309.62530517578125, \"iteration\": 1471, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 294.0874328613281, \"iteration\": 1472, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 287.05877685546875, \"iteration\": 1473, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 333.69927978515625, \"iteration\": 1474, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 309.3647766113281, \"iteration\": 1475, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 266.6578674316406, \"iteration\": 1476, \"epoch\": 9}, {\"training_acc\": 0.84375, \"training_loss\": 244.28492736816406, \"iteration\": 1477, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 328.9571533203125, \"iteration\": 1478, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 339.76348876953125, \"iteration\": 1479, \"epoch\": 9}, {\"training_acc\": 0.8984375, \"training_loss\": 331.4134216308594, \"iteration\": 1480, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 323.0458679199219, \"iteration\": 1481, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 318.8624267578125, \"iteration\": 1482, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 280.3541259765625, \"iteration\": 1483, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 308.81402587890625, \"iteration\": 1484, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 311.6170959472656, \"iteration\": 1485, \"epoch\": 9}, {\"training_acc\": 0.9140625, \"training_loss\": 310.4112548828125, \"iteration\": 1486, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 276.1119689941406, \"iteration\": 1487, \"epoch\": 9}, {\"training_acc\": 0.9140625, \"training_loss\": 277.7122497558594, \"iteration\": 1488, \"epoch\": 9}, {\"training_acc\": 0.890625, \"training_loss\": 331.6884460449219, \"iteration\": 1489, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 318.53851318359375, \"iteration\": 1490, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 281.49920654296875, \"iteration\": 1491, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 361.4442443847656, \"iteration\": 1492, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 318.0025634765625, \"iteration\": 1493, \"epoch\": 9}, {\"training_acc\": 0.9765625, \"training_loss\": 359.5181884765625, \"iteration\": 1494, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 319.0638732910156, \"iteration\": 1495, \"epoch\": 9}, {\"training_acc\": 0.984375, \"training_loss\": 322.4936828613281, \"iteration\": 1496, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 322.3814697265625, \"iteration\": 1497, \"epoch\": 9}, {\"training_acc\": 0.90625, \"training_loss\": 362.9861145019531, \"iteration\": 1498, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 301.8935546875, \"iteration\": 1499, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 331.0067138671875, \"iteration\": 1500, \"epoch\": 9}, {\"training_acc\": 0.9296875, \"training_loss\": 336.75311279296875, \"iteration\": 1501, \"epoch\": 9}, {\"training_acc\": 0.921875, \"training_loss\": 288.66278076171875, \"iteration\": 1502, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 307.8638916015625, \"iteration\": 1503, \"epoch\": 9}, {\"training_acc\": 0.9375, \"training_loss\": 303.8883056640625, \"iteration\": 1504, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 281.511962890625, \"iteration\": 1505, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 309.82379150390625, \"iteration\": 1506, \"epoch\": 9}, {\"training_acc\": 0.9453125, \"training_loss\": 302.56402587890625, \"iteration\": 1507, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 343.5474853515625, \"iteration\": 1508, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 360.22412109375, \"iteration\": 1509, \"epoch\": 9}, {\"training_acc\": 0.953125, \"training_loss\": 301.287109375, \"iteration\": 1510, \"epoch\": 9}, {\"training_acc\": 0.96875, \"training_loss\": 284.9973449707031, \"iteration\": 1511, \"epoch\": 9}, {\"training_acc\": 0.925, \"training_loss\": 57.61466598510742, \"iteration\": 1512, \"epoch\": 9}, {\"training_acc\": 0.9609375, \"training_loss\": 300.31256103515625, \"iteration\": 1513, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 250.32937622070312, \"iteration\": 1514, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 375.85760498046875, \"iteration\": 1515, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 315.7679138183594, \"iteration\": 1516, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 370.004150390625, \"iteration\": 1517, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 364.5953674316406, \"iteration\": 1518, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 328.9002990722656, \"iteration\": 1519, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 290.97406005859375, \"iteration\": 1520, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 332.9758605957031, \"iteration\": 1521, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 315.74993896484375, \"iteration\": 1522, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 344.02392578125, \"iteration\": 1523, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 317.7155456542969, \"iteration\": 1524, \"epoch\": 10}, {\"training_acc\": 0.9921875, \"training_loss\": 336.28704833984375, \"iteration\": 1525, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 318.1661682128906, \"iteration\": 1526, \"epoch\": 10}, {\"training_acc\": 0.9765625, \"training_loss\": 258.3335876464844, \"iteration\": 1527, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 323.3229675292969, \"iteration\": 1528, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 290.6502685546875, \"iteration\": 1529, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 305.2521057128906, \"iteration\": 1530, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 300.7119445800781, \"iteration\": 1531, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 333.7259826660156, \"iteration\": 1532, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 344.01519775390625, \"iteration\": 1533, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 338.2084655761719, \"iteration\": 1534, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 359.7528076171875, \"iteration\": 1535, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 322.3961486816406, \"iteration\": 1536, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 344.3493957519531, \"iteration\": 1537, \"epoch\": 10}, {\"training_acc\": 0.8828125, \"training_loss\": 288.23016357421875, \"iteration\": 1538, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 301.0663757324219, \"iteration\": 1539, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 320.40496826171875, \"iteration\": 1540, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 292.5408935546875, \"iteration\": 1541, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 355.08148193359375, \"iteration\": 1542, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 300.9934997558594, \"iteration\": 1543, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 315.8074951171875, \"iteration\": 1544, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 301.0133056640625, \"iteration\": 1545, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 270.3901062011719, \"iteration\": 1546, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 296.5650329589844, \"iteration\": 1547, \"epoch\": 10}, {\"training_acc\": 0.9140625, \"training_loss\": 319.2210693359375, \"iteration\": 1548, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 322.0685729980469, \"iteration\": 1549, \"epoch\": 10}, {\"training_acc\": 0.8984375, \"training_loss\": 282.38427734375, \"iteration\": 1550, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 290.4129638671875, \"iteration\": 1551, \"epoch\": 10}, {\"training_acc\": 0.9765625, \"training_loss\": 353.365234375, \"iteration\": 1552, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 295.69549560546875, \"iteration\": 1553, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 355.39215087890625, \"iteration\": 1554, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 306.578369140625, \"iteration\": 1555, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 316.5954284667969, \"iteration\": 1556, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 264.021484375, \"iteration\": 1557, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 322.7109680175781, \"iteration\": 1558, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 306.6900634765625, \"iteration\": 1559, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 321.21905517578125, \"iteration\": 1560, \"epoch\": 10}, {\"training_acc\": 0.8984375, \"training_loss\": 320.6424560546875, \"iteration\": 1561, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 318.15576171875, \"iteration\": 1562, \"epoch\": 10}, {\"training_acc\": 0.921875, \"training_loss\": 286.76605224609375, \"iteration\": 1563, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 311.9427185058594, \"iteration\": 1564, \"epoch\": 10}, {\"training_acc\": 0.90625, \"training_loss\": 266.90826416015625, \"iteration\": 1565, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 292.8023376464844, \"iteration\": 1566, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 279.8390197753906, \"iteration\": 1567, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 270.3758544921875, \"iteration\": 1568, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 311.6600646972656, \"iteration\": 1569, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 353.98065185546875, \"iteration\": 1570, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 371.534423828125, \"iteration\": 1571, \"epoch\": 10}, {\"training_acc\": 0.921875, \"training_loss\": 352.44171142578125, \"iteration\": 1572, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 286.118408203125, \"iteration\": 1573, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 291.50750732421875, \"iteration\": 1574, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 305.7113342285156, \"iteration\": 1575, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 370.31805419921875, \"iteration\": 1576, \"epoch\": 10}, {\"training_acc\": 0.8984375, \"training_loss\": 346.54248046875, \"iteration\": 1577, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 266.1661682128906, \"iteration\": 1578, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 330.6832580566406, \"iteration\": 1579, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 313.13702392578125, \"iteration\": 1580, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 328.03338623046875, \"iteration\": 1581, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 261.67803955078125, \"iteration\": 1582, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 306.4828186035156, \"iteration\": 1583, \"epoch\": 10}, {\"training_acc\": 0.9140625, \"training_loss\": 256.11669921875, \"iteration\": 1584, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 364.97564697265625, \"iteration\": 1585, \"epoch\": 10}, {\"training_acc\": 0.9140625, \"training_loss\": 276.382568359375, \"iteration\": 1586, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 312.55169677734375, \"iteration\": 1587, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 343.8758544921875, \"iteration\": 1588, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 323.9833068847656, \"iteration\": 1589, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 349.89312744140625, \"iteration\": 1590, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 311.6966857910156, \"iteration\": 1591, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 312.707275390625, \"iteration\": 1592, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 339.0418395996094, \"iteration\": 1593, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 323.2742919921875, \"iteration\": 1594, \"epoch\": 10}, {\"training_acc\": 0.8984375, \"training_loss\": 226.5029754638672, \"iteration\": 1595, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 342.5255126953125, \"iteration\": 1596, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 281.0315246582031, \"iteration\": 1597, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 307.2229919433594, \"iteration\": 1598, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 271.8131103515625, \"iteration\": 1599, \"epoch\": 10}, {\"training_acc\": 0.9765625, \"training_loss\": 369.03546142578125, \"iteration\": 1600, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 269.480224609375, \"iteration\": 1601, \"epoch\": 10}, {\"training_acc\": 0.9765625, \"training_loss\": 343.30352783203125, \"iteration\": 1602, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 255.4776611328125, \"iteration\": 1603, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 286.9108581542969, \"iteration\": 1604, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 317.0372314453125, \"iteration\": 1605, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 307.52301025390625, \"iteration\": 1606, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 295.7652587890625, \"iteration\": 1607, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 311.45880126953125, \"iteration\": 1608, \"epoch\": 10}, {\"training_acc\": 0.8984375, \"training_loss\": 313.4417419433594, \"iteration\": 1609, \"epoch\": 10}, {\"training_acc\": 0.90625, \"training_loss\": 257.27239990234375, \"iteration\": 1610, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 281.7566223144531, \"iteration\": 1611, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 325.97979736328125, \"iteration\": 1612, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 305.1922912597656, \"iteration\": 1613, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 370.647216796875, \"iteration\": 1614, \"epoch\": 10}, {\"training_acc\": 0.9140625, \"training_loss\": 272.1468200683594, \"iteration\": 1615, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 297.94244384765625, \"iteration\": 1616, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 328.81427001953125, \"iteration\": 1617, \"epoch\": 10}, {\"training_acc\": 0.921875, \"training_loss\": 326.94580078125, \"iteration\": 1618, \"epoch\": 10}, {\"training_acc\": 0.9140625, \"training_loss\": 312.391845703125, \"iteration\": 1619, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 334.7448425292969, \"iteration\": 1620, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 318.5419006347656, \"iteration\": 1621, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 327.9629211425781, \"iteration\": 1622, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 323.52557373046875, \"iteration\": 1623, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 301.00897216796875, \"iteration\": 1624, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 307.2080993652344, \"iteration\": 1625, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 322.295654296875, \"iteration\": 1626, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 327.2349853515625, \"iteration\": 1627, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 280.4701843261719, \"iteration\": 1628, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 328.0859680175781, \"iteration\": 1629, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 301.9974365234375, \"iteration\": 1630, \"epoch\": 10}, {\"training_acc\": 0.8984375, \"training_loss\": 362.55645751953125, \"iteration\": 1631, \"epoch\": 10}, {\"training_acc\": 0.9765625, \"training_loss\": 326.70806884765625, \"iteration\": 1632, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 305.384521484375, \"iteration\": 1633, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 308.2415771484375, \"iteration\": 1634, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 308.0155334472656, \"iteration\": 1635, \"epoch\": 10}, {\"training_acc\": 0.9765625, \"training_loss\": 322.0645446777344, \"iteration\": 1636, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 304.88720703125, \"iteration\": 1637, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 280.318603515625, \"iteration\": 1638, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 290.8531494140625, \"iteration\": 1639, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 306.361572265625, \"iteration\": 1640, \"epoch\": 10}, {\"training_acc\": 0.9140625, \"training_loss\": 351.5430603027344, \"iteration\": 1641, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 305.73150634765625, \"iteration\": 1642, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 285.22698974609375, \"iteration\": 1643, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 334.2079162597656, \"iteration\": 1644, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 302.5499572753906, \"iteration\": 1645, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 332.71380615234375, \"iteration\": 1646, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 306.12615966796875, \"iteration\": 1647, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 295.9501037597656, \"iteration\": 1648, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 288.4161682128906, \"iteration\": 1649, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 300.749755859375, \"iteration\": 1650, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 286.64617919921875, \"iteration\": 1651, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 290.97186279296875, \"iteration\": 1652, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 322.29852294921875, \"iteration\": 1653, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 327.6289978027344, \"iteration\": 1654, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 344.1741943359375, \"iteration\": 1655, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 313.4632568359375, \"iteration\": 1656, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 330.74725341796875, \"iteration\": 1657, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 313.9557800292969, \"iteration\": 1658, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 305.114990234375, \"iteration\": 1659, \"epoch\": 10}, {\"training_acc\": 0.8671875, \"training_loss\": 267.96466064453125, \"iteration\": 1660, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 251.49949645996094, \"iteration\": 1661, \"epoch\": 10}, {\"training_acc\": 0.921875, \"training_loss\": 287.76104736328125, \"iteration\": 1662, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 277.5332946777344, \"iteration\": 1663, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 375.1012268066406, \"iteration\": 1664, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 323.08538818359375, \"iteration\": 1665, \"epoch\": 10}, {\"training_acc\": 0.984375, \"training_loss\": 358.9044189453125, \"iteration\": 1666, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 287.88299560546875, \"iteration\": 1667, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 316.8836975097656, \"iteration\": 1668, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 359.73876953125, \"iteration\": 1669, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 365.9345703125, \"iteration\": 1670, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 338.5163269042969, \"iteration\": 1671, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 339.658447265625, \"iteration\": 1672, \"epoch\": 10}, {\"training_acc\": 0.953125, \"training_loss\": 316.8719787597656, \"iteration\": 1673, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 350.59881591796875, \"iteration\": 1674, \"epoch\": 10}, {\"training_acc\": 0.96875, \"training_loss\": 279.57275390625, \"iteration\": 1675, \"epoch\": 10}, {\"training_acc\": 0.9296875, \"training_loss\": 282.06805419921875, \"iteration\": 1676, \"epoch\": 10}, {\"training_acc\": 0.9453125, \"training_loss\": 349.4903564453125, \"iteration\": 1677, \"epoch\": 10}, {\"training_acc\": 0.921875, \"training_loss\": 277.0634460449219, \"iteration\": 1678, \"epoch\": 10}, {\"training_acc\": 0.9375, \"training_loss\": 286.795654296875, \"iteration\": 1679, \"epoch\": 10}, {\"training_acc\": 0.975, \"training_loss\": 81.56416320800781, \"iteration\": 1680, \"epoch\": 10}, {\"training_acc\": 0.9609375, \"training_loss\": 289.4216613769531, \"iteration\": 1681, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 264.842041015625, \"iteration\": 1682, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 321.2002868652344, \"iteration\": 1683, \"epoch\": 11}, {\"training_acc\": 0.984375, \"training_loss\": 278.33905029296875, \"iteration\": 1684, \"epoch\": 11}, {\"training_acc\": 0.984375, \"training_loss\": 278.00982666015625, \"iteration\": 1685, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 364.9600830078125, \"iteration\": 1686, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 311.8409118652344, \"iteration\": 1687, \"epoch\": 11}, {\"training_acc\": 0.921875, \"training_loss\": 301.5483093261719, \"iteration\": 1688, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 274.267578125, \"iteration\": 1689, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 323.5128173828125, \"iteration\": 1690, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 342.8586120605469, \"iteration\": 1691, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 311.0442810058594, \"iteration\": 1692, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 279.437255859375, \"iteration\": 1693, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 266.5201416015625, \"iteration\": 1694, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 391.2496337890625, \"iteration\": 1695, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 296.49481201171875, \"iteration\": 1696, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 311.07562255859375, \"iteration\": 1697, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 300.52545166015625, \"iteration\": 1698, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 289.8251037597656, \"iteration\": 1699, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 342.7305908203125, \"iteration\": 1700, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 317.37579345703125, \"iteration\": 1701, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 321.64678955078125, \"iteration\": 1702, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 353.62139892578125, \"iteration\": 1703, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 369.388427734375, \"iteration\": 1704, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 290.9382629394531, \"iteration\": 1705, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 289.993408203125, \"iteration\": 1706, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 296.4945373535156, \"iteration\": 1707, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 316.1268310546875, \"iteration\": 1708, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 333.2712707519531, \"iteration\": 1709, \"epoch\": 11}, {\"training_acc\": 0.921875, \"training_loss\": 282.1046142578125, \"iteration\": 1710, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 300.03887939453125, \"iteration\": 1711, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 386.90423583984375, \"iteration\": 1712, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 316.03192138671875, \"iteration\": 1713, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 318.7668151855469, \"iteration\": 1714, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 317.72784423828125, \"iteration\": 1715, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 326.9280090332031, \"iteration\": 1716, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 269.20220947265625, \"iteration\": 1717, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 311.555419921875, \"iteration\": 1718, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 321.6219787597656, \"iteration\": 1719, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 366.01580810546875, \"iteration\": 1720, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 315.51129150390625, \"iteration\": 1721, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 295.6156005859375, \"iteration\": 1722, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 349.4423522949219, \"iteration\": 1723, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 332.232177734375, \"iteration\": 1724, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 274.316650390625, \"iteration\": 1725, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 290.7725830078125, \"iteration\": 1726, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 354.007568359375, \"iteration\": 1727, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 321.3310852050781, \"iteration\": 1728, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 244.22169494628906, \"iteration\": 1729, \"epoch\": 11}, {\"training_acc\": 0.9765625, \"training_loss\": 315.395263671875, \"iteration\": 1730, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 289.5601806640625, \"iteration\": 1731, \"epoch\": 11}, {\"training_acc\": 0.9765625, \"training_loss\": 305.4197998046875, \"iteration\": 1732, \"epoch\": 11}, {\"training_acc\": 0.984375, \"training_loss\": 304.289306640625, \"iteration\": 1733, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 289.38751220703125, \"iteration\": 1734, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 275.744140625, \"iteration\": 1735, \"epoch\": 11}, {\"training_acc\": 0.984375, \"training_loss\": 295.012451171875, \"iteration\": 1736, \"epoch\": 11}, {\"training_acc\": 0.9765625, \"training_loss\": 353.0526428222656, \"iteration\": 1737, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 342.5657958984375, \"iteration\": 1738, \"epoch\": 11}, {\"training_acc\": 0.9140625, \"training_loss\": 339.01654052734375, \"iteration\": 1739, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 250.29000854492188, \"iteration\": 1740, \"epoch\": 11}, {\"training_acc\": 0.9140625, \"training_loss\": 271.5030212402344, \"iteration\": 1741, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 295.9298095703125, \"iteration\": 1742, \"epoch\": 11}, {\"training_acc\": 0.9765625, \"training_loss\": 353.5799560546875, \"iteration\": 1743, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 321.3074951171875, \"iteration\": 1744, \"epoch\": 11}, {\"training_acc\": 0.921875, \"training_loss\": 286.168212890625, \"iteration\": 1745, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 393.75518798828125, \"iteration\": 1746, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 290.44317626953125, \"iteration\": 1747, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 344.29541015625, \"iteration\": 1748, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 264.6575927734375, \"iteration\": 1749, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 322.534423828125, \"iteration\": 1750, \"epoch\": 11}, {\"training_acc\": 0.90625, \"training_loss\": 339.3495178222656, \"iteration\": 1751, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 249.22264099121094, \"iteration\": 1752, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 260.3518371582031, \"iteration\": 1753, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 353.83172607421875, \"iteration\": 1754, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 321.67388916015625, \"iteration\": 1755, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 306.92840576171875, \"iteration\": 1756, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 397.1492004394531, \"iteration\": 1757, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 327.0878601074219, \"iteration\": 1758, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 327.30316162109375, \"iteration\": 1759, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 327.095703125, \"iteration\": 1760, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 269.0564880371094, \"iteration\": 1761, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 332.3431396484375, \"iteration\": 1762, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 333.00091552734375, \"iteration\": 1763, \"epoch\": 11}, {\"training_acc\": 0.921875, \"training_loss\": 344.543212890625, \"iteration\": 1764, \"epoch\": 11}, {\"training_acc\": 0.890625, \"training_loss\": 271.9232177734375, \"iteration\": 1765, \"epoch\": 11}, {\"training_acc\": 0.9140625, \"training_loss\": 302.1398620605469, \"iteration\": 1766, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 343.38372802734375, \"iteration\": 1767, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 375.766357421875, \"iteration\": 1768, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 316.7840576171875, \"iteration\": 1769, \"epoch\": 11}, {\"training_acc\": 0.9765625, \"training_loss\": 315.4256286621094, \"iteration\": 1770, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 278.9712219238281, \"iteration\": 1771, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 285.44915771484375, \"iteration\": 1772, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 291.3499450683594, \"iteration\": 1773, \"epoch\": 11}, {\"training_acc\": 0.984375, \"training_loss\": 326.88787841796875, \"iteration\": 1774, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 305.55731201171875, \"iteration\": 1775, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 294.8031921386719, \"iteration\": 1776, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 269.27996826171875, \"iteration\": 1777, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 332.6883544921875, \"iteration\": 1778, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 348.8366394042969, \"iteration\": 1779, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 312.11383056640625, \"iteration\": 1780, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 328.39990234375, \"iteration\": 1781, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 316.6672668457031, \"iteration\": 1782, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 255.18795776367188, \"iteration\": 1783, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 316.49761962890625, \"iteration\": 1784, \"epoch\": 11}, {\"training_acc\": 0.984375, \"training_loss\": 396.44012451171875, \"iteration\": 1785, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 327.9679870605469, \"iteration\": 1786, \"epoch\": 11}, {\"training_acc\": 0.90625, \"training_loss\": 307.5221862792969, \"iteration\": 1787, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 311.27752685546875, \"iteration\": 1788, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 364.7618103027344, \"iteration\": 1789, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 327.8777160644531, \"iteration\": 1790, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 273.4685974121094, \"iteration\": 1791, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 306.5213623046875, \"iteration\": 1792, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 243.2082977294922, \"iteration\": 1793, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 318.15496826171875, \"iteration\": 1794, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 316.8578186035156, \"iteration\": 1795, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 301.29510498046875, \"iteration\": 1796, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 300.6695251464844, \"iteration\": 1797, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 285.04443359375, \"iteration\": 1798, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 369.5089111328125, \"iteration\": 1799, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 323.76007080078125, \"iteration\": 1800, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 306.06866455078125, \"iteration\": 1801, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 328.34716796875, \"iteration\": 1802, \"epoch\": 11}, {\"training_acc\": 0.984375, \"training_loss\": 310.279541015625, \"iteration\": 1803, \"epoch\": 11}, {\"training_acc\": 0.9765625, \"training_loss\": 371.1466979980469, \"iteration\": 1804, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 323.54449462890625, \"iteration\": 1805, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 295.3516845703125, \"iteration\": 1806, \"epoch\": 11}, {\"training_acc\": 0.921875, \"training_loss\": 313.2335510253906, \"iteration\": 1807, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 312.5797119140625, \"iteration\": 1808, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 360.385009765625, \"iteration\": 1809, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 327.12738037109375, \"iteration\": 1810, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 340.0238037109375, \"iteration\": 1811, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 318.46844482421875, \"iteration\": 1812, \"epoch\": 11}, {\"training_acc\": 0.9375, \"training_loss\": 302.0455322265625, \"iteration\": 1813, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 255.6522216796875, \"iteration\": 1814, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 290.2156677246094, \"iteration\": 1815, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 305.90655517578125, \"iteration\": 1816, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 287.1528625488281, \"iteration\": 1817, \"epoch\": 11}, {\"training_acc\": 0.9140625, \"training_loss\": 291.3501892089844, \"iteration\": 1818, \"epoch\": 11}, {\"training_acc\": 0.9140625, \"training_loss\": 296.757568359375, \"iteration\": 1819, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 302.5055847167969, \"iteration\": 1820, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 350.0744323730469, \"iteration\": 1821, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 356.1329345703125, \"iteration\": 1822, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 322.2216796875, \"iteration\": 1823, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 344.64068603515625, \"iteration\": 1824, \"epoch\": 11}, {\"training_acc\": 0.9921875, \"training_loss\": 258.861328125, \"iteration\": 1825, \"epoch\": 11}, {\"training_acc\": 0.9765625, \"training_loss\": 294.84771728515625, \"iteration\": 1826, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 338.75408935546875, \"iteration\": 1827, \"epoch\": 11}, {\"training_acc\": 0.9765625, \"training_loss\": 294.578857421875, \"iteration\": 1828, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 311.8262634277344, \"iteration\": 1829, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 284.84588623046875, \"iteration\": 1830, \"epoch\": 11}, {\"training_acc\": 0.90625, \"training_loss\": 334.1995849609375, \"iteration\": 1831, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 340.4707946777344, \"iteration\": 1832, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 305.86077880859375, \"iteration\": 1833, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 299.7587890625, \"iteration\": 1834, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 295.87457275390625, \"iteration\": 1835, \"epoch\": 11}, {\"training_acc\": 0.96875, \"training_loss\": 326.6393127441406, \"iteration\": 1836, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 306.20758056640625, \"iteration\": 1837, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 264.6688232421875, \"iteration\": 1838, \"epoch\": 11}, {\"training_acc\": 0.9140625, \"training_loss\": 260.81829833984375, \"iteration\": 1839, \"epoch\": 11}, {\"training_acc\": 0.9296875, \"training_loss\": 290.99664306640625, \"iteration\": 1840, \"epoch\": 11}, {\"training_acc\": 0.921875, \"training_loss\": 312.5225524902344, \"iteration\": 1841, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 274.4031677246094, \"iteration\": 1842, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 279.7848815917969, \"iteration\": 1843, \"epoch\": 11}, {\"training_acc\": 0.9453125, \"training_loss\": 322.678955078125, \"iteration\": 1844, \"epoch\": 11}, {\"training_acc\": 0.984375, \"training_loss\": 305.13250732421875, \"iteration\": 1845, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 301.3495178222656, \"iteration\": 1846, \"epoch\": 11}, {\"training_acc\": 0.9609375, \"training_loss\": 366.53521728515625, \"iteration\": 1847, \"epoch\": 11}, {\"training_acc\": 0.925, \"training_loss\": 53.40937042236328, \"iteration\": 1848, \"epoch\": 11}, {\"training_acc\": 0.953125, \"training_loss\": 248.40750122070312, \"iteration\": 1849, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 290.52325439453125, \"iteration\": 1850, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 254.33380126953125, \"iteration\": 1851, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 258.45159912109375, \"iteration\": 1852, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 327.4039306640625, \"iteration\": 1853, \"epoch\": 12}, {\"training_acc\": 0.9921875, \"training_loss\": 314.7322998046875, \"iteration\": 1854, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 234.30487060546875, \"iteration\": 1855, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 342.4136962890625, \"iteration\": 1856, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 359.39813232421875, \"iteration\": 1857, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 252.61912536621094, \"iteration\": 1858, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 289.59869384765625, \"iteration\": 1859, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 300.88653564453125, \"iteration\": 1860, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 365.060791015625, \"iteration\": 1861, \"epoch\": 12}, {\"training_acc\": 0.984375, \"training_loss\": 368.46551513671875, \"iteration\": 1862, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 315.3737487792969, \"iteration\": 1863, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 321.355712890625, \"iteration\": 1864, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 327.2728271484375, \"iteration\": 1865, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 289.50115966796875, \"iteration\": 1866, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 385.41595458984375, \"iteration\": 1867, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 295.28924560546875, \"iteration\": 1868, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 311.918212890625, \"iteration\": 1869, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 311.0715026855469, \"iteration\": 1870, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 289.70880126953125, \"iteration\": 1871, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 311.1571350097656, \"iteration\": 1872, \"epoch\": 12}, {\"training_acc\": 0.984375, \"training_loss\": 380.01409912109375, \"iteration\": 1873, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 320.5209655761719, \"iteration\": 1874, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 320.62445068359375, \"iteration\": 1875, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 302.1950988769531, \"iteration\": 1876, \"epoch\": 12}, {\"training_acc\": 0.984375, \"training_loss\": 314.7333984375, \"iteration\": 1877, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 264.8145751953125, \"iteration\": 1878, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 289.50830078125, \"iteration\": 1879, \"epoch\": 12}, {\"training_acc\": 0.9140625, \"training_loss\": 323.37091064453125, \"iteration\": 1880, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 284.2823486328125, \"iteration\": 1881, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 320.9890441894531, \"iteration\": 1882, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 299.4793395996094, \"iteration\": 1883, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 331.30419921875, \"iteration\": 1884, \"epoch\": 12}, {\"training_acc\": 0.9140625, \"training_loss\": 327.1715087890625, \"iteration\": 1885, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 274.571044921875, \"iteration\": 1886, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 291.602294921875, \"iteration\": 1887, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 290.62811279296875, \"iteration\": 1888, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 380.021240234375, \"iteration\": 1889, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 311.58245849609375, \"iteration\": 1890, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 306.50738525390625, \"iteration\": 1891, \"epoch\": 12}, {\"training_acc\": 0.984375, \"training_loss\": 357.7530517578125, \"iteration\": 1892, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 295.6335144042969, \"iteration\": 1893, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 310.7078552246094, \"iteration\": 1894, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 332.0349426269531, \"iteration\": 1895, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 315.15997314453125, \"iteration\": 1896, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 360.3138732910156, \"iteration\": 1897, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 305.83587646484375, \"iteration\": 1898, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 321.6596984863281, \"iteration\": 1899, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 305.5333251953125, \"iteration\": 1900, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 279.51409912109375, \"iteration\": 1901, \"epoch\": 12}, {\"training_acc\": 0.984375, \"training_loss\": 293.83251953125, \"iteration\": 1902, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 259.33837890625, \"iteration\": 1903, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 253.12484741210938, \"iteration\": 1904, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 376.4704895019531, \"iteration\": 1905, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 310.7108154296875, \"iteration\": 1906, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 289.4862976074219, \"iteration\": 1907, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 315.0037841796875, \"iteration\": 1908, \"epoch\": 12}, {\"training_acc\": 0.984375, \"training_loss\": 262.6431884765625, \"iteration\": 1909, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 321.84857177734375, \"iteration\": 1910, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 342.24560546875, \"iteration\": 1911, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 326.33624267578125, \"iteration\": 1912, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 314.98486328125, \"iteration\": 1913, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 315.63739013671875, \"iteration\": 1914, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 331.91705322265625, \"iteration\": 1915, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 363.2589416503906, \"iteration\": 1916, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 336.32659912109375, \"iteration\": 1917, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 300.95849609375, \"iteration\": 1918, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 375.62164306640625, \"iteration\": 1919, \"epoch\": 12}, {\"training_acc\": 0.921875, \"training_loss\": 322.39984130859375, \"iteration\": 1920, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 315.54534912109375, \"iteration\": 1921, \"epoch\": 12}, {\"training_acc\": 0.9140625, \"training_loss\": 276.1289978027344, \"iteration\": 1922, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 300.12445068359375, \"iteration\": 1923, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 326.0948181152344, \"iteration\": 1924, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 310.95550537109375, \"iteration\": 1925, \"epoch\": 12}, {\"training_acc\": 0.921875, \"training_loss\": 294.05718994140625, \"iteration\": 1926, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 325.8418884277344, \"iteration\": 1927, \"epoch\": 12}, {\"training_acc\": 0.9921875, \"training_loss\": 335.78875732421875, \"iteration\": 1928, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 326.6993408203125, \"iteration\": 1929, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 301.0970764160156, \"iteration\": 1930, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 299.85467529296875, \"iteration\": 1931, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 316.431884765625, \"iteration\": 1932, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 342.17742919921875, \"iteration\": 1933, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 316.2303466796875, \"iteration\": 1934, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 322.0733642578125, \"iteration\": 1935, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 294.87451171875, \"iteration\": 1936, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 300.80291748046875, \"iteration\": 1937, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 243.02978515625, \"iteration\": 1938, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 322.85595703125, \"iteration\": 1939, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 342.9136962890625, \"iteration\": 1940, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 347.743408203125, \"iteration\": 1941, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 304.6617431640625, \"iteration\": 1942, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 278.786376953125, \"iteration\": 1943, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 301.3228759765625, \"iteration\": 1944, \"epoch\": 12}, {\"training_acc\": 0.921875, \"training_loss\": 291.0823974609375, \"iteration\": 1945, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 342.8666687011719, \"iteration\": 1946, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 327.853759765625, \"iteration\": 1947, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 312.200927734375, \"iteration\": 1948, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 279.3587646484375, \"iteration\": 1949, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 310.898681640625, \"iteration\": 1950, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 270.58880615234375, \"iteration\": 1951, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 321.3082580566406, \"iteration\": 1952, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 294.9158935546875, \"iteration\": 1953, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 268.7955322265625, \"iteration\": 1954, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 321.50042724609375, \"iteration\": 1955, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 331.228271484375, \"iteration\": 1956, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 341.9666748046875, \"iteration\": 1957, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 301.1509704589844, \"iteration\": 1958, \"epoch\": 12}, {\"training_acc\": 0.984375, \"training_loss\": 267.8522033691406, \"iteration\": 1959, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 331.6348571777344, \"iteration\": 1960, \"epoch\": 12}, {\"training_acc\": 0.921875, \"training_loss\": 332.87921142578125, \"iteration\": 1961, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 368.92620849609375, \"iteration\": 1962, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 278.45068359375, \"iteration\": 1963, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 347.5237121582031, \"iteration\": 1964, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 321.67620849609375, \"iteration\": 1965, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 321.5350646972656, \"iteration\": 1966, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 306.57159423828125, \"iteration\": 1967, \"epoch\": 12}, {\"training_acc\": 0.9921875, \"training_loss\": 299.08660888671875, \"iteration\": 1968, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 315.60675048828125, \"iteration\": 1969, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 311.4314270019531, \"iteration\": 1970, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 359.0299987792969, \"iteration\": 1971, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 304.7737121582031, \"iteration\": 1972, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 305.15228271484375, \"iteration\": 1973, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 242.7284393310547, \"iteration\": 1974, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 315.552734375, \"iteration\": 1975, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 331.6461181640625, \"iteration\": 1976, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 315.9898376464844, \"iteration\": 1977, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 315.4943542480469, \"iteration\": 1978, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 343.12200927734375, \"iteration\": 1979, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 322.18341064453125, \"iteration\": 1980, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 305.7482604980469, \"iteration\": 1981, \"epoch\": 12}, {\"training_acc\": 0.9140625, \"training_loss\": 316.2671203613281, \"iteration\": 1982, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 296.86566162109375, \"iteration\": 1983, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 327.7315368652344, \"iteration\": 1984, \"epoch\": 12}, {\"training_acc\": 0.96875, \"training_loss\": 354.0066833496094, \"iteration\": 1985, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 290.86083984375, \"iteration\": 1986, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 300.27154541015625, \"iteration\": 1987, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 368.0722351074219, \"iteration\": 1988, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 322.3105163574219, \"iteration\": 1989, \"epoch\": 12}, {\"training_acc\": 0.875, \"training_loss\": 318.4051513671875, \"iteration\": 1990, \"epoch\": 12}, {\"training_acc\": 0.875, \"training_loss\": 291.9724426269531, \"iteration\": 1991, \"epoch\": 12}, {\"training_acc\": 0.8984375, \"training_loss\": 319.4028625488281, \"iteration\": 1992, \"epoch\": 12}, {\"training_acc\": 0.9296875, \"training_loss\": 346.09625244140625, \"iteration\": 1993, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 307.22900390625, \"iteration\": 1994, \"epoch\": 12}, {\"training_acc\": 0.9609375, \"training_loss\": 300.9159240722656, \"iteration\": 1995, \"epoch\": 12}, {\"training_acc\": 1.0, \"training_loss\": 315.9503173828125, \"iteration\": 1996, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 330.69720458984375, \"iteration\": 1997, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 290.351318359375, \"iteration\": 1998, \"epoch\": 12}, {\"training_acc\": 0.90625, \"training_loss\": 239.2206573486328, \"iteration\": 1999, \"epoch\": 12}, {\"training_acc\": 0.9140625, \"training_loss\": 338.6556701660156, \"iteration\": 2000, \"epoch\": 12}, {\"training_acc\": 0.90625, \"training_loss\": 318.1669921875, \"iteration\": 2001, \"epoch\": 12}, {\"training_acc\": 0.9375, \"training_loss\": 241.45790100097656, \"iteration\": 2002, \"epoch\": 12}, {\"training_acc\": 0.921875, \"training_loss\": 266.707763671875, \"iteration\": 2003, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 277.4599304199219, \"iteration\": 2004, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 300.73193359375, \"iteration\": 2005, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 265.9584045410156, \"iteration\": 2006, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 364.93621826171875, \"iteration\": 2007, \"epoch\": 12}, {\"training_acc\": 0.921875, \"training_loss\": 339.43646240234375, \"iteration\": 2008, \"epoch\": 12}, {\"training_acc\": 0.90625, \"training_loss\": 327.46942138671875, \"iteration\": 2009, \"epoch\": 12}, {\"training_acc\": 0.8984375, \"training_loss\": 323.90325927734375, \"iteration\": 2010, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 360.8235778808594, \"iteration\": 2011, \"epoch\": 12}, {\"training_acc\": 0.953125, \"training_loss\": 328.38787841796875, \"iteration\": 2012, \"epoch\": 12}, {\"training_acc\": 0.9765625, \"training_loss\": 291.2697448730469, \"iteration\": 2013, \"epoch\": 12}, {\"training_acc\": 0.9453125, \"training_loss\": 298.08563232421875, \"iteration\": 2014, \"epoch\": 12}, {\"training_acc\": 0.921875, \"training_loss\": 293.7144775390625, \"iteration\": 2015, \"epoch\": 12}, {\"training_acc\": 0.95, \"training_loss\": 57.15910720825195, \"iteration\": 2016, \"epoch\": 12}, {\"training_acc\": 0.9140625, \"training_loss\": 272.70526123046875, \"iteration\": 2017, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 331.5776062011719, \"iteration\": 2018, \"epoch\": 13}, {\"training_acc\": 0.921875, \"training_loss\": 284.54071044921875, \"iteration\": 2019, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 296.4033508300781, \"iteration\": 2020, \"epoch\": 13}, {\"training_acc\": 0.9140625, \"training_loss\": 286.59246826171875, \"iteration\": 2021, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 294.4278564453125, \"iteration\": 2022, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 342.009521484375, \"iteration\": 2023, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 294.612060546875, \"iteration\": 2024, \"epoch\": 13}, {\"training_acc\": 0.9921875, \"training_loss\": 325.49224853515625, \"iteration\": 2025, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 326.8729248046875, \"iteration\": 2026, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 300.15118408203125, \"iteration\": 2027, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 285.1264343261719, \"iteration\": 2028, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 300.063232421875, \"iteration\": 2029, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 305.47882080078125, \"iteration\": 2030, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 358.16802978515625, \"iteration\": 2031, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 331.71380615234375, \"iteration\": 2032, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 337.21514892578125, \"iteration\": 2033, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 305.4765625, \"iteration\": 2034, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 326.7032775878906, \"iteration\": 2035, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 290.39935302734375, \"iteration\": 2036, \"epoch\": 13}, {\"training_acc\": 0.9921875, \"training_loss\": 304.14202880859375, \"iteration\": 2037, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 347.9788818359375, \"iteration\": 2038, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 320.7920227050781, \"iteration\": 2039, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 331.41973876953125, \"iteration\": 2040, \"epoch\": 13}, {\"training_acc\": 0.9296875, \"training_loss\": 290.17242431640625, \"iteration\": 2041, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 353.19659423828125, \"iteration\": 2042, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 279.33135986328125, \"iteration\": 2043, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 284.33489990234375, \"iteration\": 2044, \"epoch\": 13}, {\"training_acc\": 0.9296875, \"training_loss\": 295.28155517578125, \"iteration\": 2045, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 310.3351745605469, \"iteration\": 2046, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 315.288330078125, \"iteration\": 2047, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 317.0433349609375, \"iteration\": 2048, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 336.580322265625, \"iteration\": 2049, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 304.8957214355469, \"iteration\": 2050, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 290.052978515625, \"iteration\": 2051, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 316.009765625, \"iteration\": 2052, \"epoch\": 13}, {\"training_acc\": 0.9140625, \"training_loss\": 210.27804565429688, \"iteration\": 2053, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 310.00946044921875, \"iteration\": 2054, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 316.23895263671875, \"iteration\": 2055, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 305.6524658203125, \"iteration\": 2056, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 374.00927734375, \"iteration\": 2057, \"epoch\": 13}, {\"training_acc\": 0.9921875, \"training_loss\": 341.80615234375, \"iteration\": 2058, \"epoch\": 13}, {\"training_acc\": 0.9296875, \"training_loss\": 316.4797668457031, \"iteration\": 2059, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 322.7220153808594, \"iteration\": 2060, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 369.4664611816406, \"iteration\": 2061, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 299.7406921386719, \"iteration\": 2062, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 299.83575439453125, \"iteration\": 2063, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 337.060546875, \"iteration\": 2064, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 338.2857666015625, \"iteration\": 2065, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 330.7098693847656, \"iteration\": 2066, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 348.46307373046875, \"iteration\": 2067, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 273.98590087890625, \"iteration\": 2068, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 332.05377197265625, \"iteration\": 2069, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 285.646484375, \"iteration\": 2070, \"epoch\": 13}, {\"training_acc\": 0.9921875, \"training_loss\": 324.9397277832031, \"iteration\": 2071, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 321.7181701660156, \"iteration\": 2072, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 331.32073974609375, \"iteration\": 2073, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 332.2684326171875, \"iteration\": 2074, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 304.9417724609375, \"iteration\": 2075, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 315.1033935546875, \"iteration\": 2076, \"epoch\": 13}, {\"training_acc\": 0.921875, \"training_loss\": 295.8520202636719, \"iteration\": 2077, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 331.4300537109375, \"iteration\": 2078, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 295.2863464355469, \"iteration\": 2079, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 294.1726379394531, \"iteration\": 2080, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 284.58154296875, \"iteration\": 2081, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 322.45928955078125, \"iteration\": 2082, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 294.79217529296875, \"iteration\": 2083, \"epoch\": 13}, {\"training_acc\": 0.921875, \"training_loss\": 348.75750732421875, \"iteration\": 2084, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 325.8383483886719, \"iteration\": 2085, \"epoch\": 13}, {\"training_acc\": 0.9296875, \"training_loss\": 290.08837890625, \"iteration\": 2086, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 336.89825439453125, \"iteration\": 2087, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 341.84765625, \"iteration\": 2088, \"epoch\": 13}, {\"training_acc\": 0.9296875, \"training_loss\": 311.59716796875, \"iteration\": 2089, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 283.57257080078125, \"iteration\": 2090, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 279.9276123046875, \"iteration\": 2091, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 351.92730712890625, \"iteration\": 2092, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 268.03741455078125, \"iteration\": 2093, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 336.48773193359375, \"iteration\": 2094, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 336.02923583984375, \"iteration\": 2095, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 331.94305419921875, \"iteration\": 2096, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 315.53497314453125, \"iteration\": 2097, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 364.34429931640625, \"iteration\": 2098, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 253.19100952148438, \"iteration\": 2099, \"epoch\": 13}, {\"training_acc\": 0.9296875, \"training_loss\": 268.9499206542969, \"iteration\": 2100, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 310.29547119140625, \"iteration\": 2101, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 299.524658203125, \"iteration\": 2102, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 310.26055908203125, \"iteration\": 2103, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 337.0917053222656, \"iteration\": 2104, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 331.7637939453125, \"iteration\": 2105, \"epoch\": 13}, {\"training_acc\": 1.0, \"training_loss\": 325.08740234375, \"iteration\": 2106, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 304.25262451171875, \"iteration\": 2107, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 321.67462158203125, \"iteration\": 2108, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 269.287109375, \"iteration\": 2109, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 295.8598937988281, \"iteration\": 2110, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 331.51092529296875, \"iteration\": 2111, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 337.0572509765625, \"iteration\": 2112, \"epoch\": 13}, {\"training_acc\": 0.9921875, \"training_loss\": 352.0728759765625, \"iteration\": 2113, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 294.54058837890625, \"iteration\": 2114, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 310.9438171386719, \"iteration\": 2115, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 336.8360595703125, \"iteration\": 2116, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 295.6783447265625, \"iteration\": 2117, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 380.89434814453125, \"iteration\": 2118, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 315.1152648925781, \"iteration\": 2119, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 289.6165466308594, \"iteration\": 2120, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 300.266357421875, \"iteration\": 2121, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 325.779052734375, \"iteration\": 2122, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 316.7497253417969, \"iteration\": 2123, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 315.20159912109375, \"iteration\": 2124, \"epoch\": 13}, {\"training_acc\": 0.9296875, \"training_loss\": 264.3949279785156, \"iteration\": 2125, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 315.4886474609375, \"iteration\": 2126, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 343.24285888671875, \"iteration\": 2127, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 320.92132568359375, \"iteration\": 2128, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 309.86248779296875, \"iteration\": 2129, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 274.4060363769531, \"iteration\": 2130, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 331.7248840332031, \"iteration\": 2131, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 336.44659423828125, \"iteration\": 2132, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 258.31829833984375, \"iteration\": 2133, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 325.7947082519531, \"iteration\": 2134, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 412.70367431640625, \"iteration\": 2135, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 289.66748046875, \"iteration\": 2136, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 364.1781921386719, \"iteration\": 2137, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 263.5639953613281, \"iteration\": 2138, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 337.1696472167969, \"iteration\": 2139, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 332.1502380371094, \"iteration\": 2140, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 314.82958984375, \"iteration\": 2141, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 314.59088134765625, \"iteration\": 2142, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 268.548095703125, \"iteration\": 2143, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 283.3052978515625, \"iteration\": 2144, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 331.39447021484375, \"iteration\": 2145, \"epoch\": 13}, {\"training_acc\": 0.9921875, \"training_loss\": 341.2995300292969, \"iteration\": 2146, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 289.5008544921875, \"iteration\": 2147, \"epoch\": 13}, {\"training_acc\": 0.9921875, \"training_loss\": 325.0511474609375, \"iteration\": 2148, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 289.3409729003906, \"iteration\": 2149, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 343.54541015625, \"iteration\": 2150, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 284.25115966796875, \"iteration\": 2151, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 279.7834167480469, \"iteration\": 2152, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 325.23114013671875, \"iteration\": 2153, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 233.0745849609375, \"iteration\": 2154, \"epoch\": 13}, {\"training_acc\": 0.984375, \"training_loss\": 320.68572998046875, \"iteration\": 2155, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 299.284423828125, \"iteration\": 2156, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 316.29217529296875, \"iteration\": 2157, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 279.312255859375, \"iteration\": 2158, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 352.6099853515625, \"iteration\": 2159, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 254.24786376953125, \"iteration\": 2160, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 263.7563781738281, \"iteration\": 2161, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 290.92919921875, \"iteration\": 2162, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 325.70416259765625, \"iteration\": 2163, \"epoch\": 13}, {\"training_acc\": 0.9140625, \"training_loss\": 245.00372314453125, \"iteration\": 2164, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 332.8349609375, \"iteration\": 2165, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 285.08502197265625, \"iteration\": 2166, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 259.76068115234375, \"iteration\": 2167, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 386.2457580566406, \"iteration\": 2168, \"epoch\": 13}, {\"training_acc\": 0.96875, \"training_loss\": 316.08404541015625, \"iteration\": 2169, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 280.30572509765625, \"iteration\": 2170, \"epoch\": 13}, {\"training_acc\": 0.9453125, \"training_loss\": 311.7813720703125, \"iteration\": 2171, \"epoch\": 13}, {\"training_acc\": 0.90625, \"training_loss\": 320.8631591796875, \"iteration\": 2172, \"epoch\": 13}, {\"training_acc\": 0.890625, \"training_loss\": 311.1531677246094, \"iteration\": 2173, \"epoch\": 13}, {\"training_acc\": 0.875, \"training_loss\": 295.61322021484375, \"iteration\": 2174, \"epoch\": 13}, {\"training_acc\": 0.9296875, \"training_loss\": 311.7908935546875, \"iteration\": 2175, \"epoch\": 13}, {\"training_acc\": 0.9140625, \"training_loss\": 309.785400390625, \"iteration\": 2176, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 375.986572265625, \"iteration\": 2177, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 285.9884033203125, \"iteration\": 2178, \"epoch\": 13}, {\"training_acc\": 0.9375, \"training_loss\": 285.0771179199219, \"iteration\": 2179, \"epoch\": 13}, {\"training_acc\": 0.9609375, \"training_loss\": 311.42840576171875, \"iteration\": 2180, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 271.0828552246094, \"iteration\": 2181, \"epoch\": 13}, {\"training_acc\": 0.953125, \"training_loss\": 300.4337158203125, \"iteration\": 2182, \"epoch\": 13}, {\"training_acc\": 0.9765625, \"training_loss\": 283.45001220703125, \"iteration\": 2183, \"epoch\": 13}, {\"training_acc\": 0.95, \"training_loss\": 68.89570617675781, \"iteration\": 2184, \"epoch\": 13}, {\"training_acc\": 0.9296875, \"training_loss\": 289.724853515625, \"iteration\": 2185, \"epoch\": 14}, {\"training_acc\": 0.9375, \"training_loss\": 338.13238525390625, \"iteration\": 2186, \"epoch\": 14}, {\"training_acc\": 0.8828125, \"training_loss\": 318.7237854003906, \"iteration\": 2187, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 374.16070556640625, \"iteration\": 2188, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 325.9703674316406, \"iteration\": 2189, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 315.6415710449219, \"iteration\": 2190, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 304.788818359375, \"iteration\": 2191, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 300.5954284667969, \"iteration\": 2192, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 358.5967102050781, \"iteration\": 2193, \"epoch\": 14}, {\"training_acc\": 0.90625, \"training_loss\": 302.0235595703125, \"iteration\": 2194, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 320.3976135253906, \"iteration\": 2195, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 352.24786376953125, \"iteration\": 2196, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 346.3722839355469, \"iteration\": 2197, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 390.724365234375, \"iteration\": 2198, \"epoch\": 14}, {\"training_acc\": 0.9375, \"training_loss\": 274.6390380859375, \"iteration\": 2199, \"epoch\": 14}, {\"training_acc\": 0.9921875, \"training_loss\": 288.5648498535156, \"iteration\": 2200, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 299.1248474121094, \"iteration\": 2201, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 299.4849853515625, \"iteration\": 2202, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 310.25567626953125, \"iteration\": 2203, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 379.08001708984375, \"iteration\": 2204, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 283.9681701660156, \"iteration\": 2205, \"epoch\": 14}, {\"training_acc\": 0.9375, \"training_loss\": 300.1001281738281, \"iteration\": 2206, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 288.82373046875, \"iteration\": 2207, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 303.8311767578125, \"iteration\": 2208, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 336.11029052734375, \"iteration\": 2209, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 262.9765625, \"iteration\": 2210, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 347.7521667480469, \"iteration\": 2211, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 304.81268310546875, \"iteration\": 2212, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 362.8122863769531, \"iteration\": 2213, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 320.63995361328125, \"iteration\": 2214, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 315.6925354003906, \"iteration\": 2215, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 305.253173828125, \"iteration\": 2216, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 304.16632080078125, \"iteration\": 2217, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 299.5882568359375, \"iteration\": 2218, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 335.86785888671875, \"iteration\": 2219, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 358.811767578125, \"iteration\": 2220, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 299.1530456542969, \"iteration\": 2221, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 310.1976318359375, \"iteration\": 2222, \"epoch\": 14}, {\"training_acc\": 0.9921875, \"training_loss\": 314.51092529296875, \"iteration\": 2223, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 304.70086669921875, \"iteration\": 2224, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 278.78521728515625, \"iteration\": 2225, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 336.09161376953125, \"iteration\": 2226, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 315.0590515136719, \"iteration\": 2227, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 314.90771484375, \"iteration\": 2228, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 320.1692810058594, \"iteration\": 2229, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 283.5938720703125, \"iteration\": 2230, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 336.511962890625, \"iteration\": 2231, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 359.143798828125, \"iteration\": 2232, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 310.0355529785156, \"iteration\": 2233, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 294.7450866699219, \"iteration\": 2234, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 325.6041259765625, \"iteration\": 2235, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 325.1061096191406, \"iteration\": 2236, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 299.35931396484375, \"iteration\": 2237, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 304.38885498046875, \"iteration\": 2238, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 284.0516662597656, \"iteration\": 2239, \"epoch\": 14}, {\"training_acc\": 0.9296875, \"training_loss\": 285.0535888671875, \"iteration\": 2240, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 353.21331787109375, \"iteration\": 2241, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 294.5128173828125, \"iteration\": 2242, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 341.6724853515625, \"iteration\": 2243, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 309.8041076660156, \"iteration\": 2244, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 289.44873046875, \"iteration\": 2245, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 293.60516357421875, \"iteration\": 2246, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 347.03277587890625, \"iteration\": 2247, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 305.41961669921875, \"iteration\": 2248, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 336.0870361328125, \"iteration\": 2249, \"epoch\": 14}, {\"training_acc\": 1.0, \"training_loss\": 325.59063720703125, \"iteration\": 2250, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 341.55340576171875, \"iteration\": 2251, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 263.6490783691406, \"iteration\": 2252, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 253.84963989257812, \"iteration\": 2253, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 353.010498046875, \"iteration\": 2254, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 294.3277587890625, \"iteration\": 2255, \"epoch\": 14}, {\"training_acc\": 0.9375, \"training_loss\": 299.7156677246094, \"iteration\": 2256, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 316.2958984375, \"iteration\": 2257, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 305.8840026855469, \"iteration\": 2258, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 327.40179443359375, \"iteration\": 2259, \"epoch\": 14}, {\"training_acc\": 0.9296875, \"training_loss\": 255.67002868652344, \"iteration\": 2260, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 363.5980224609375, \"iteration\": 2261, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 310.7275085449219, \"iteration\": 2262, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 330.85467529296875, \"iteration\": 2263, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 300.252685546875, \"iteration\": 2264, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 290.990478515625, \"iteration\": 2265, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 314.6725769042969, \"iteration\": 2266, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 294.3700866699219, \"iteration\": 2267, \"epoch\": 14}, {\"training_acc\": 0.9375, \"training_loss\": 290.1724853515625, \"iteration\": 2268, \"epoch\": 14}, {\"training_acc\": 0.9375, \"training_loss\": 358.4884948730469, \"iteration\": 2269, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 252.1739501953125, \"iteration\": 2270, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 348.39202880859375, \"iteration\": 2271, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 257.728759765625, \"iteration\": 2272, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 352.34515380859375, \"iteration\": 2273, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 241.9993438720703, \"iteration\": 2274, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 288.1241455078125, \"iteration\": 2275, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 317.40045166015625, \"iteration\": 2276, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 290.1064147949219, \"iteration\": 2277, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 283.7132568359375, \"iteration\": 2278, \"epoch\": 14}, {\"training_acc\": 0.9140625, \"training_loss\": 295.1238098144531, \"iteration\": 2279, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 311.0218505859375, \"iteration\": 2280, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 332.80657958984375, \"iteration\": 2281, \"epoch\": 14}, {\"training_acc\": 0.9921875, \"training_loss\": 312.221923828125, \"iteration\": 2282, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 288.80487060546875, \"iteration\": 2283, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 283.31536865234375, \"iteration\": 2284, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 270.06103515625, \"iteration\": 2285, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 320.7223815917969, \"iteration\": 2286, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 329.2144775390625, \"iteration\": 2287, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 331.5603942871094, \"iteration\": 2288, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 310.16400146484375, \"iteration\": 2289, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 363.19818115234375, \"iteration\": 2290, \"epoch\": 14}, {\"training_acc\": 0.9140625, \"training_loss\": 300.6689758300781, \"iteration\": 2291, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 326.23779296875, \"iteration\": 2292, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 320.55902099609375, \"iteration\": 2293, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 284.2756652832031, \"iteration\": 2294, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 336.5745849609375, \"iteration\": 2295, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 300.05194091796875, \"iteration\": 2296, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 272.85284423828125, \"iteration\": 2297, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 289.1209716796875, \"iteration\": 2298, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 284.1416015625, \"iteration\": 2299, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 283.39849853515625, \"iteration\": 2300, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 320.19610595703125, \"iteration\": 2301, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 283.9395446777344, \"iteration\": 2302, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 299.7765808105469, \"iteration\": 2303, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 283.7864990234375, \"iteration\": 2304, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 325.3761901855469, \"iteration\": 2305, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 293.70513916015625, \"iteration\": 2306, \"epoch\": 14}, {\"training_acc\": 0.9375, \"training_loss\": 322.94525146484375, \"iteration\": 2307, \"epoch\": 14}, {\"training_acc\": 0.9921875, \"training_loss\": 340.689208984375, \"iteration\": 2308, \"epoch\": 14}, {\"training_acc\": 0.9921875, \"training_loss\": 373.8190612792969, \"iteration\": 2309, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 293.8544921875, \"iteration\": 2310, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 236.74725341796875, \"iteration\": 2311, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 283.26824951171875, \"iteration\": 2312, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 279.4394226074219, \"iteration\": 2313, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 330.38372802734375, \"iteration\": 2314, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 331.35491943359375, \"iteration\": 2315, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 267.8365173339844, \"iteration\": 2316, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 288.87152099609375, \"iteration\": 2317, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 352.15313720703125, \"iteration\": 2318, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 325.60528564453125, \"iteration\": 2319, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 325.19378662109375, \"iteration\": 2320, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 315.02972412109375, \"iteration\": 2321, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 288.7445373535156, \"iteration\": 2322, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 320.1727294921875, \"iteration\": 2323, \"epoch\": 14}, {\"training_acc\": 0.9296875, \"training_loss\": 305.740478515625, \"iteration\": 2324, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 347.06695556640625, \"iteration\": 2325, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 257.97772216796875, \"iteration\": 2326, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 288.38592529296875, \"iteration\": 2327, \"epoch\": 14}, {\"training_acc\": 0.9921875, \"training_loss\": 283.01495361328125, \"iteration\": 2328, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 325.63653564453125, \"iteration\": 2329, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 326.3384704589844, \"iteration\": 2330, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 283.2425537109375, \"iteration\": 2331, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 347.0914611816406, \"iteration\": 2332, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 352.487548828125, \"iteration\": 2333, \"epoch\": 14}, {\"training_acc\": 0.9375, \"training_loss\": 348.26544189453125, \"iteration\": 2334, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 369.68218994140625, \"iteration\": 2335, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 287.99932861328125, \"iteration\": 2336, \"epoch\": 14}, {\"training_acc\": 0.9921875, \"training_loss\": 298.7981872558594, \"iteration\": 2337, \"epoch\": 14}, {\"training_acc\": 0.9921875, \"training_loss\": 325.6606750488281, \"iteration\": 2338, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 300.08758544921875, \"iteration\": 2339, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 320.7618103027344, \"iteration\": 2340, \"epoch\": 14}, {\"training_acc\": 0.984375, \"training_loss\": 304.11138916015625, \"iteration\": 2341, \"epoch\": 14}, {\"training_acc\": 0.9609375, \"training_loss\": 311.90802001953125, \"iteration\": 2342, \"epoch\": 14}, {\"training_acc\": 0.953125, \"training_loss\": 258.37646484375, \"iteration\": 2343, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 272.57940673828125, \"iteration\": 2344, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 257.36029052734375, \"iteration\": 2345, \"epoch\": 14}, {\"training_acc\": 0.96875, \"training_loss\": 320.75250244140625, \"iteration\": 2346, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 253.49075317382812, \"iteration\": 2347, \"epoch\": 14}, {\"training_acc\": 0.9296875, \"training_loss\": 327.62078857421875, \"iteration\": 2348, \"epoch\": 14}, {\"training_acc\": 0.9375, \"training_loss\": 342.1708679199219, \"iteration\": 2349, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 290.7805480957031, \"iteration\": 2350, \"epoch\": 14}, {\"training_acc\": 0.9453125, \"training_loss\": 327.58819580078125, \"iteration\": 2351, \"epoch\": 14}, {\"training_acc\": 0.9, \"training_loss\": 86.49934387207031, \"iteration\": 2352, \"epoch\": 14}, {\"training_acc\": 0.9765625, \"training_loss\": 315.87884521484375, \"iteration\": 2353, \"epoch\": 15}, {\"training_acc\": 0.9453125, \"training_loss\": 294.8529968261719, \"iteration\": 2354, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 319.51727294921875, \"iteration\": 2355, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 330.22479248046875, \"iteration\": 2356, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 309.07940673828125, \"iteration\": 2357, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 278.1534423828125, \"iteration\": 2358, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 282.4499816894531, \"iteration\": 2359, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 315.07421875, \"iteration\": 2360, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 352.0726318359375, \"iteration\": 2361, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 288.3804626464844, \"iteration\": 2362, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 309.59698486328125, \"iteration\": 2363, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 320.5248107910156, \"iteration\": 2364, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 293.6691589355469, \"iteration\": 2365, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 319.90777587890625, \"iteration\": 2366, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 352.28302001953125, \"iteration\": 2367, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 336.4497375488281, \"iteration\": 2368, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 273.06121826171875, \"iteration\": 2369, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 362.3743896484375, \"iteration\": 2370, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 304.1239929199219, \"iteration\": 2371, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 319.68603515625, \"iteration\": 2372, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 330.3143310546875, \"iteration\": 2373, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 252.4995574951172, \"iteration\": 2374, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 357.7127380371094, \"iteration\": 2375, \"epoch\": 15}, {\"training_acc\": 0.953125, \"training_loss\": 310.17919921875, \"iteration\": 2376, \"epoch\": 15}, {\"training_acc\": 0.9375, \"training_loss\": 284.3114929199219, \"iteration\": 2377, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 277.8363037109375, \"iteration\": 2378, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 293.57904052734375, \"iteration\": 2379, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 362.16839599609375, \"iteration\": 2380, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 330.359375, \"iteration\": 2381, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 283.01409912109375, \"iteration\": 2382, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 303.56512451171875, \"iteration\": 2383, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 277.48687744140625, \"iteration\": 2384, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 303.64825439453125, \"iteration\": 2385, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 293.82861328125, \"iteration\": 2386, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 287.5185546875, \"iteration\": 2387, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 314.4974060058594, \"iteration\": 2388, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 293.392578125, \"iteration\": 2389, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 309.2847900390625, \"iteration\": 2390, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 335.4793395996094, \"iteration\": 2391, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 309.1685791015625, \"iteration\": 2392, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 308.9424743652344, \"iteration\": 2393, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 262.856689453125, \"iteration\": 2394, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 277.7444152832031, \"iteration\": 2395, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 362.7812805175781, \"iteration\": 2396, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 336.0196228027344, \"iteration\": 2397, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 293.0856018066406, \"iteration\": 2398, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 262.75201416015625, \"iteration\": 2399, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 340.7734375, \"iteration\": 2400, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 314.81597900390625, \"iteration\": 2401, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 314.5391540527344, \"iteration\": 2402, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 309.18145751953125, \"iteration\": 2403, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 325.8951416015625, \"iteration\": 2404, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 346.5730895996094, \"iteration\": 2405, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 262.3179931640625, \"iteration\": 2406, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 277.4749755859375, \"iteration\": 2407, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 308.85205078125, \"iteration\": 2408, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 341.0667724609375, \"iteration\": 2409, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 319.1080627441406, \"iteration\": 2410, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 315.3688049316406, \"iteration\": 2411, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 334.98529052734375, \"iteration\": 2412, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 335.55682373046875, \"iteration\": 2413, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 262.64495849609375, \"iteration\": 2414, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 330.9606018066406, \"iteration\": 2415, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 336.581298828125, \"iteration\": 2416, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 293.31573486328125, \"iteration\": 2417, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 324.7037658691406, \"iteration\": 2418, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 299.2955322265625, \"iteration\": 2419, \"epoch\": 15}, {\"training_acc\": 0.953125, \"training_loss\": 294.86602783203125, \"iteration\": 2420, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 303.388916015625, \"iteration\": 2421, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 357.4278869628906, \"iteration\": 2422, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 319.7917175292969, \"iteration\": 2423, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 309.20465087890625, \"iteration\": 2424, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 324.83770751953125, \"iteration\": 2425, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 279.7989501953125, \"iteration\": 2426, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 335.41192626953125, \"iteration\": 2427, \"epoch\": 15}, {\"training_acc\": 0.953125, \"training_loss\": 304.1796569824219, \"iteration\": 2428, \"epoch\": 15}, {\"training_acc\": 0.953125, \"training_loss\": 336.4048767089844, \"iteration\": 2429, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 320.07275390625, \"iteration\": 2430, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 374.320556640625, \"iteration\": 2431, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 294.25140380859375, \"iteration\": 2432, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 330.4989013671875, \"iteration\": 2433, \"epoch\": 15}, {\"training_acc\": 0.953125, \"training_loss\": 325.26190185546875, \"iteration\": 2434, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 309.81707763671875, \"iteration\": 2435, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 283.2217712402344, \"iteration\": 2436, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 346.1991882324219, \"iteration\": 2437, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 308.8876953125, \"iteration\": 2438, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 304.08001708984375, \"iteration\": 2439, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 336.4981384277344, \"iteration\": 2440, \"epoch\": 15}, {\"training_acc\": 0.953125, \"training_loss\": 288.38702392578125, \"iteration\": 2441, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 324.85418701171875, \"iteration\": 2442, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 282.9517822265625, \"iteration\": 2443, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 325.100341796875, \"iteration\": 2444, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 335.78216552734375, \"iteration\": 2445, \"epoch\": 15}, {\"training_acc\": 0.9453125, \"training_loss\": 295.3175964355469, \"iteration\": 2446, \"epoch\": 15}, {\"training_acc\": 0.9375, \"training_loss\": 273.53521728515625, \"iteration\": 2447, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 293.6536560058594, \"iteration\": 2448, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 340.93426513671875, \"iteration\": 2449, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 340.564697265625, \"iteration\": 2450, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 221.6407470703125, \"iteration\": 2451, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 267.7907409667969, \"iteration\": 2452, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 308.98065185546875, \"iteration\": 2453, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 330.6248779296875, \"iteration\": 2454, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 309.2016906738281, \"iteration\": 2455, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 320.312255859375, \"iteration\": 2456, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 257.4415588378906, \"iteration\": 2457, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 330.349609375, \"iteration\": 2458, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 351.9923400878906, \"iteration\": 2459, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 346.3312072753906, \"iteration\": 2460, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 289.4002380371094, \"iteration\": 2461, \"epoch\": 15}, {\"training_acc\": 0.953125, \"training_loss\": 352.301025390625, \"iteration\": 2462, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 341.42462158203125, \"iteration\": 2463, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 314.653564453125, \"iteration\": 2464, \"epoch\": 15}, {\"training_acc\": 0.953125, \"training_loss\": 304.3231201171875, \"iteration\": 2465, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 362.43011474609375, \"iteration\": 2466, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 330.0897521972656, \"iteration\": 2467, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 247.28878784179688, \"iteration\": 2468, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 330.0311279296875, \"iteration\": 2469, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 262.589599609375, \"iteration\": 2470, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 236.61846923828125, \"iteration\": 2471, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 272.37384033203125, \"iteration\": 2472, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 314.02545166015625, \"iteration\": 2473, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 309.686767578125, \"iteration\": 2474, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 277.83306884765625, \"iteration\": 2475, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 325.31439208984375, \"iteration\": 2476, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 351.6111755371094, \"iteration\": 2477, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 293.5792236328125, \"iteration\": 2478, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 288.3812255859375, \"iteration\": 2479, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 293.06903076171875, \"iteration\": 2480, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 309.61187744140625, \"iteration\": 2481, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 325.14752197265625, \"iteration\": 2482, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 309.759033203125, \"iteration\": 2483, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 303.98504638671875, \"iteration\": 2484, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 303.32818603515625, \"iteration\": 2485, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 341.3687744140625, \"iteration\": 2486, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 298.9025573730469, \"iteration\": 2487, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 304.44287109375, \"iteration\": 2488, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 336.00323486328125, \"iteration\": 2489, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 288.94000244140625, \"iteration\": 2490, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 272.479248046875, \"iteration\": 2491, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 304.2921142578125, \"iteration\": 2492, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 304.2312927246094, \"iteration\": 2493, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 278.132568359375, \"iteration\": 2494, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 346.39007568359375, \"iteration\": 2495, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 345.86138916015625, \"iteration\": 2496, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 277.3548889160156, \"iteration\": 2497, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 335.6692199707031, \"iteration\": 2498, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 309.0799865722656, \"iteration\": 2499, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 319.8854064941406, \"iteration\": 2500, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 277.9797058105469, \"iteration\": 2501, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 336.0074157714844, \"iteration\": 2502, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 298.46209716796875, \"iteration\": 2503, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 226.72921752929688, \"iteration\": 2504, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 308.90472412109375, \"iteration\": 2505, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 309.32501220703125, \"iteration\": 2506, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 351.13275146484375, \"iteration\": 2507, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 288.0839538574219, \"iteration\": 2508, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 351.8037414550781, \"iteration\": 2509, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 319.52490234375, \"iteration\": 2510, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 368.5022277832031, \"iteration\": 2511, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 274.41876220703125, \"iteration\": 2512, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 282.9241638183594, \"iteration\": 2513, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 325.7720031738281, \"iteration\": 2514, \"epoch\": 15}, {\"training_acc\": 0.9765625, \"training_loss\": 283.3763427734375, \"iteration\": 2515, \"epoch\": 15}, {\"training_acc\": 0.96875, \"training_loss\": 336.37017822265625, \"iteration\": 2516, \"epoch\": 15}, {\"training_acc\": 0.9609375, \"training_loss\": 315.37042236328125, \"iteration\": 2517, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 272.10748291015625, \"iteration\": 2518, \"epoch\": 15}, {\"training_acc\": 0.984375, \"training_loss\": 309.4708251953125, \"iteration\": 2519, \"epoch\": 15}, {\"training_acc\": 1.0, \"training_loss\": 52.20492172241211, \"iteration\": 2520, \"epoch\": 15}, {\"training_acc\": 0.9921875, \"training_loss\": 357.4658203125, \"iteration\": 2521, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 257.001953125, \"iteration\": 2522, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 324.7964172363281, \"iteration\": 2523, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 319.2860412597656, \"iteration\": 2524, \"epoch\": 16}, {\"training_acc\": 0.96875, \"training_loss\": 293.100830078125, \"iteration\": 2525, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 298.18707275390625, \"iteration\": 2526, \"epoch\": 16}, {\"training_acc\": 0.96875, \"training_loss\": 330.50323486328125, \"iteration\": 2527, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 329.8212890625, \"iteration\": 2528, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 367.982421875, \"iteration\": 2529, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 282.5291748046875, \"iteration\": 2530, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 335.14154052734375, \"iteration\": 2531, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 345.9698486328125, \"iteration\": 2532, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 298.2343444824219, \"iteration\": 2533, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 324.395751953125, \"iteration\": 2534, \"epoch\": 16}, {\"training_acc\": 0.96875, \"training_loss\": 331.73931884765625, \"iteration\": 2535, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 313.904052734375, \"iteration\": 2536, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 319.47930908203125, \"iteration\": 2537, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 367.8243103027344, \"iteration\": 2538, \"epoch\": 16}, {\"training_acc\": 0.9609375, \"training_loss\": 324.7337951660156, \"iteration\": 2539, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 267.17547607421875, \"iteration\": 2540, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 303.6152648925781, \"iteration\": 2541, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 226.78575134277344, \"iteration\": 2542, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 362.0981140136719, \"iteration\": 2543, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 340.8244323730469, \"iteration\": 2544, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 324.52734375, \"iteration\": 2545, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 378.7023010253906, \"iteration\": 2546, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 314.5014343261719, \"iteration\": 2547, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 262.18328857421875, \"iteration\": 2548, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 319.34283447265625, \"iteration\": 2549, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 329.67315673828125, \"iteration\": 2550, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 346.8712463378906, \"iteration\": 2551, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 329.7342834472656, \"iteration\": 2552, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 378.6206359863281, \"iteration\": 2553, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 303.6739501953125, \"iteration\": 2554, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 314.335693359375, \"iteration\": 2555, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 287.6104736328125, \"iteration\": 2556, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 346.38104248046875, \"iteration\": 2557, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 324.64544677734375, \"iteration\": 2558, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 298.47491455078125, \"iteration\": 2559, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 324.5864562988281, \"iteration\": 2560, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 272.5342102050781, \"iteration\": 2561, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 319.3954772949219, \"iteration\": 2562, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 313.9862060546875, \"iteration\": 2563, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 299.5188903808594, \"iteration\": 2564, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 319.14410400390625, \"iteration\": 2565, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 309.22900390625, \"iteration\": 2566, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 298.3503112792969, \"iteration\": 2567, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 309.040771484375, \"iteration\": 2568, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 272.29827880859375, \"iteration\": 2569, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 303.5074462890625, \"iteration\": 2570, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 282.6453857421875, \"iteration\": 2571, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 236.76620483398438, \"iteration\": 2572, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 345.8878479003906, \"iteration\": 2573, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 272.3603210449219, \"iteration\": 2574, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 261.7626953125, \"iteration\": 2575, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 292.7246398925781, \"iteration\": 2576, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 303.87152099609375, \"iteration\": 2577, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 298.06549072265625, \"iteration\": 2578, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 330.0132141113281, \"iteration\": 2579, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 319.21649169921875, \"iteration\": 2580, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 324.87939453125, \"iteration\": 2581, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 308.75714111328125, \"iteration\": 2582, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 282.1431884765625, \"iteration\": 2583, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 303.57598876953125, \"iteration\": 2584, \"epoch\": 16}, {\"training_acc\": 0.96875, \"training_loss\": 288.0422058105469, \"iteration\": 2585, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 256.8409423828125, \"iteration\": 2586, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 341.251953125, \"iteration\": 2587, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 308.5167541503906, \"iteration\": 2588, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 303.55780029296875, \"iteration\": 2589, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 292.72369384765625, \"iteration\": 2590, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 303.22735595703125, \"iteration\": 2591, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 335.3819274902344, \"iteration\": 2592, \"epoch\": 16}, {\"training_acc\": 0.953125, \"training_loss\": 289.215576171875, \"iteration\": 2593, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 288.02264404296875, \"iteration\": 2594, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 313.944091796875, \"iteration\": 2595, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 314.057861328125, \"iteration\": 2596, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 303.379638671875, \"iteration\": 2597, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 271.86700439453125, \"iteration\": 2598, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 308.4481201171875, \"iteration\": 2599, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 287.67523193359375, \"iteration\": 2600, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 330.1158447265625, \"iteration\": 2601, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 319.02880859375, \"iteration\": 2602, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 324.8232421875, \"iteration\": 2603, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 261.86346435546875, \"iteration\": 2604, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 308.95904541015625, \"iteration\": 2605, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 277.58477783203125, \"iteration\": 2606, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 314.088134765625, \"iteration\": 2607, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 308.653076171875, \"iteration\": 2608, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 330.57574462890625, \"iteration\": 2609, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 319.0448913574219, \"iteration\": 2610, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 261.7193603515625, \"iteration\": 2611, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 362.3466491699219, \"iteration\": 2612, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 287.424072265625, \"iteration\": 2613, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 303.75970458984375, \"iteration\": 2614, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 298.4906005859375, \"iteration\": 2615, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 308.77685546875, \"iteration\": 2616, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 308.6600341796875, \"iteration\": 2617, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 329.9580993652344, \"iteration\": 2618, \"epoch\": 16}, {\"training_acc\": 0.96875, \"training_loss\": 319.9252014160156, \"iteration\": 2619, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 330.4759216308594, \"iteration\": 2620, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 308.4454345703125, \"iteration\": 2621, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 308.8866882324219, \"iteration\": 2622, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 324.6480712890625, \"iteration\": 2623, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 287.92718505859375, \"iteration\": 2624, \"epoch\": 16}, {\"training_acc\": 0.9609375, \"training_loss\": 226.5162353515625, \"iteration\": 2625, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 340.54241943359375, \"iteration\": 2626, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 303.7117919921875, \"iteration\": 2627, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 324.69134521484375, \"iteration\": 2628, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 298.26910400390625, \"iteration\": 2629, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 298.14459228515625, \"iteration\": 2630, \"epoch\": 16}, {\"training_acc\": 0.96875, \"training_loss\": 314.77484130859375, \"iteration\": 2631, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 324.8353576660156, \"iteration\": 2632, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 324.384521484375, \"iteration\": 2633, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 309.6881103515625, \"iteration\": 2634, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 356.8114929199219, \"iteration\": 2635, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 293.353271484375, \"iteration\": 2636, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 251.86184692382812, \"iteration\": 2637, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 335.299560546875, \"iteration\": 2638, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 309.00048828125, \"iteration\": 2639, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 324.840087890625, \"iteration\": 2640, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 335.549072265625, \"iteration\": 2641, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 351.1769104003906, \"iteration\": 2642, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 293.103515625, \"iteration\": 2643, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 351.272216796875, \"iteration\": 2644, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 330.2816162109375, \"iteration\": 2645, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 282.29327392578125, \"iteration\": 2646, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 314.12701416015625, \"iteration\": 2647, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 303.54937744140625, \"iteration\": 2648, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 251.55453491210938, \"iteration\": 2649, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 277.64398193359375, \"iteration\": 2650, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 293.78997802734375, \"iteration\": 2651, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 246.82821655273438, \"iteration\": 2652, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 292.78857421875, \"iteration\": 2653, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 324.36419677734375, \"iteration\": 2654, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 313.9955139160156, \"iteration\": 2655, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 335.71795654296875, \"iteration\": 2656, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 356.6331481933594, \"iteration\": 2657, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 330.2499084472656, \"iteration\": 2658, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 373.1730651855469, \"iteration\": 2659, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 303.35577392578125, \"iteration\": 2660, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 329.5313720703125, \"iteration\": 2661, \"epoch\": 16}, {\"training_acc\": 0.96875, \"training_loss\": 251.74806213378906, \"iteration\": 2662, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 346.18902587890625, \"iteration\": 2663, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 282.56878662109375, \"iteration\": 2664, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 293.0285339355469, \"iteration\": 2665, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 325.9173889160156, \"iteration\": 2666, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 314.05560302734375, \"iteration\": 2667, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 251.54415893554688, \"iteration\": 2668, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 315.009521484375, \"iteration\": 2669, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 314.03973388671875, \"iteration\": 2670, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 267.15264892578125, \"iteration\": 2671, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 335.89215087890625, \"iteration\": 2672, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 330.2486572265625, \"iteration\": 2673, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 335.62872314453125, \"iteration\": 2674, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 340.8170471191406, \"iteration\": 2675, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 320.2831726074219, \"iteration\": 2676, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 356.61309814453125, \"iteration\": 2677, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 335.0942077636719, \"iteration\": 2678, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 272.1304931640625, \"iteration\": 2679, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 330.99273681640625, \"iteration\": 2680, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 303.5904541015625, \"iteration\": 2681, \"epoch\": 16}, {\"training_acc\": 0.9921875, \"training_loss\": 303.3010559082031, \"iteration\": 2682, \"epoch\": 16}, {\"training_acc\": 0.96875, \"training_loss\": 293.3521423339844, \"iteration\": 2683, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 330.292236328125, \"iteration\": 2684, \"epoch\": 16}, {\"training_acc\": 0.96875, \"training_loss\": 267.9193420410156, \"iteration\": 2685, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 277.2304992675781, \"iteration\": 2686, \"epoch\": 16}, {\"training_acc\": 0.9765625, \"training_loss\": 246.9925537109375, \"iteration\": 2687, \"epoch\": 16}, {\"training_acc\": 1.0, \"training_loss\": 56.19527053833008, \"iteration\": 2688, \"epoch\": 16}, {\"training_acc\": 0.984375, \"training_loss\": 251.6201171875, \"iteration\": 2689, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 292.75274658203125, \"iteration\": 2690, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 324.55987548828125, \"iteration\": 2691, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 282.72259521484375, \"iteration\": 2692, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 283.0100402832031, \"iteration\": 2693, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 292.8682861328125, \"iteration\": 2694, \"epoch\": 17}, {\"training_acc\": 0.9765625, \"training_loss\": 303.6951599121094, \"iteration\": 2695, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 324.08551025390625, \"iteration\": 2696, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 287.4405517578125, \"iteration\": 2697, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 335.2054138183594, \"iteration\": 2698, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 201.22305297851562, \"iteration\": 2699, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 345.5544738769531, \"iteration\": 2700, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 345.84979248046875, \"iteration\": 2701, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 361.7110595703125, \"iteration\": 2702, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 251.217041015625, \"iteration\": 2703, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 350.914794921875, \"iteration\": 2704, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 303.416748046875, \"iteration\": 2705, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 303.223388671875, \"iteration\": 2706, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 282.1298828125, \"iteration\": 2707, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 282.3775634765625, \"iteration\": 2708, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 372.8050537109375, \"iteration\": 2709, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 303.2249755859375, \"iteration\": 2710, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 308.296875, \"iteration\": 2711, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 251.67730712890625, \"iteration\": 2712, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 287.4505310058594, \"iteration\": 2713, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 308.7620849609375, \"iteration\": 2714, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 287.7701416015625, \"iteration\": 2715, \"epoch\": 17}, {\"training_acc\": 0.9765625, \"training_loss\": 287.8248291015625, \"iteration\": 2716, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 340.49224853515625, \"iteration\": 2717, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 350.82904052734375, \"iteration\": 2718, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 287.6665954589844, \"iteration\": 2719, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 308.45263671875, \"iteration\": 2720, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 276.98529052734375, \"iteration\": 2721, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 318.895263671875, \"iteration\": 2722, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 319.223876953125, \"iteration\": 2723, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 334.8251647949219, \"iteration\": 2724, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 361.8595275878906, \"iteration\": 2725, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 292.9449462890625, \"iteration\": 2726, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 313.80670166015625, \"iteration\": 2727, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 267.04437255859375, \"iteration\": 2728, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 292.74603271484375, \"iteration\": 2729, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 346.2791442871094, \"iteration\": 2730, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 287.47320556640625, \"iteration\": 2731, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 292.5396728515625, \"iteration\": 2732, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 272.0122375488281, \"iteration\": 2733, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 340.5846252441406, \"iteration\": 2734, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 277.21258544921875, \"iteration\": 2735, \"epoch\": 17}, {\"training_acc\": 0.9765625, \"training_loss\": 319.4695739746094, \"iteration\": 2736, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 314.0931701660156, \"iteration\": 2737, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 319.24761962890625, \"iteration\": 2738, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 345.8958740234375, \"iteration\": 2739, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 303.3096008300781, \"iteration\": 2740, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 324.28070068359375, \"iteration\": 2741, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 309.04656982421875, \"iteration\": 2742, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 361.96246337890625, \"iteration\": 2743, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 277.4693908691406, \"iteration\": 2744, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 319.64276123046875, \"iteration\": 2745, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 334.81744384765625, \"iteration\": 2746, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 236.2703094482422, \"iteration\": 2747, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 241.78448486328125, \"iteration\": 2748, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 324.5831298828125, \"iteration\": 2749, \"epoch\": 17}, {\"training_acc\": 0.9765625, \"training_loss\": 287.8839111328125, \"iteration\": 2750, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 266.9765625, \"iteration\": 2751, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 319.3624267578125, \"iteration\": 2752, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 335.42974853515625, \"iteration\": 2753, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 246.8428955078125, \"iteration\": 2754, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 330.0041198730469, \"iteration\": 2755, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 330.2730712890625, \"iteration\": 2756, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 356.5819396972656, \"iteration\": 2757, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 298.29266357421875, \"iteration\": 2758, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 266.8763732910156, \"iteration\": 2759, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 330.063232421875, \"iteration\": 2760, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 292.7335510253906, \"iteration\": 2761, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 356.6082763671875, \"iteration\": 2762, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 351.5704345703125, \"iteration\": 2763, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 298.524169921875, \"iteration\": 2764, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 288.1243896484375, \"iteration\": 2765, \"epoch\": 17}, {\"training_acc\": 0.96875, \"training_loss\": 303.9990234375, \"iteration\": 2766, \"epoch\": 17}, {\"training_acc\": 0.9765625, \"training_loss\": 319.3269348144531, \"iteration\": 2767, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 298.2245178222656, \"iteration\": 2768, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 340.58880615234375, \"iteration\": 2769, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 319.3353271484375, \"iteration\": 2770, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 330.3799743652344, \"iteration\": 2771, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 308.89727783203125, \"iteration\": 2772, \"epoch\": 17}, {\"training_acc\": 0.96875, \"training_loss\": 298.54400634765625, \"iteration\": 2773, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 277.36065673828125, \"iteration\": 2774, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 287.6805114746094, \"iteration\": 2775, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 334.83599853515625, \"iteration\": 2776, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 319.05609130859375, \"iteration\": 2777, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 292.72332763671875, \"iteration\": 2778, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 378.3290710449219, \"iteration\": 2779, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 362.26165771484375, \"iteration\": 2780, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 340.36480712890625, \"iteration\": 2781, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 329.87115478515625, \"iteration\": 2782, \"epoch\": 17}, {\"training_acc\": 0.9765625, \"training_loss\": 251.84539794921875, \"iteration\": 2783, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 282.08111572265625, \"iteration\": 2784, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 241.14512634277344, \"iteration\": 2785, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 329.45343017578125, \"iteration\": 2786, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 309.0126953125, \"iteration\": 2787, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 345.7696533203125, \"iteration\": 2788, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 340.3273010253906, \"iteration\": 2789, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 324.2792663574219, \"iteration\": 2790, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 319.5283508300781, \"iteration\": 2791, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 292.7939453125, \"iteration\": 2792, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 266.7120056152344, \"iteration\": 2793, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 303.49749755859375, \"iteration\": 2794, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 324.44873046875, \"iteration\": 2795, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 352.498291015625, \"iteration\": 2796, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 389.2303466796875, \"iteration\": 2797, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 329.6011962890625, \"iteration\": 2798, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 313.9269714355469, \"iteration\": 2799, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 324.68798828125, \"iteration\": 2800, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 324.6027526855469, \"iteration\": 2801, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 282.56341552734375, \"iteration\": 2802, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 293.18939208984375, \"iteration\": 2803, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 277.1935729980469, \"iteration\": 2804, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 314.2247314453125, \"iteration\": 2805, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 330.14288330078125, \"iteration\": 2806, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 319.1798095703125, \"iteration\": 2807, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 335.15142822265625, \"iteration\": 2808, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 335.24700927734375, \"iteration\": 2809, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 313.92254638671875, \"iteration\": 2810, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 251.42733764648438, \"iteration\": 2811, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 298.0689697265625, \"iteration\": 2812, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 329.7602844238281, \"iteration\": 2813, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 282.2458801269531, \"iteration\": 2814, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 335.4231872558594, \"iteration\": 2815, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 288.2865905761719, \"iteration\": 2816, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 324.4437255859375, \"iteration\": 2817, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 297.93463134765625, \"iteration\": 2818, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 319.4204406738281, \"iteration\": 2819, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 262.0481872558594, \"iteration\": 2820, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 272.6094970703125, \"iteration\": 2821, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 345.73895263671875, \"iteration\": 2822, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 303.89703369140625, \"iteration\": 2823, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 361.67828369140625, \"iteration\": 2824, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 329.9394226074219, \"iteration\": 2825, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 282.55889892578125, \"iteration\": 2826, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 308.812744140625, \"iteration\": 2827, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 261.4613037109375, \"iteration\": 2828, \"epoch\": 17}, {\"training_acc\": 0.96875, \"training_loss\": 303.8702392578125, \"iteration\": 2829, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 292.8227233886719, \"iteration\": 2830, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 303.63153076171875, \"iteration\": 2831, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 303.13848876953125, \"iteration\": 2832, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 308.50506591796875, \"iteration\": 2833, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 303.3688659667969, \"iteration\": 2834, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 282.21728515625, \"iteration\": 2835, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 324.1043395996094, \"iteration\": 2836, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 298.1217956542969, \"iteration\": 2837, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 329.9323425292969, \"iteration\": 2838, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 351.26837158203125, \"iteration\": 2839, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 277.19305419921875, \"iteration\": 2840, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 297.8529968261719, \"iteration\": 2841, \"epoch\": 17}, {\"training_acc\": 0.9765625, \"training_loss\": 282.55413818359375, \"iteration\": 2842, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 313.7899169921875, \"iteration\": 2843, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 308.65997314453125, \"iteration\": 2844, \"epoch\": 17}, {\"training_acc\": 0.9765625, \"training_loss\": 267.38739013671875, \"iteration\": 2845, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 378.1954650878906, \"iteration\": 2846, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 282.629150390625, \"iteration\": 2847, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 329.65264892578125, \"iteration\": 2848, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 308.55487060546875, \"iteration\": 2849, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 271.962890625, \"iteration\": 2850, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 329.59808349609375, \"iteration\": 2851, \"epoch\": 17}, {\"training_acc\": 0.984375, \"training_loss\": 303.5687561035156, \"iteration\": 2852, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 368.0255432128906, \"iteration\": 2853, \"epoch\": 17}, {\"training_acc\": 0.9921875, \"training_loss\": 313.8294677734375, \"iteration\": 2854, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 351.023193359375, \"iteration\": 2855, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 80.80683898925781, \"iteration\": 2856, \"epoch\": 17}, {\"training_acc\": 1.0, \"training_loss\": 282.1286926269531, \"iteration\": 2857, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 330.0481872558594, \"iteration\": 2858, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 297.7400207519531, \"iteration\": 2859, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 356.3938293457031, \"iteration\": 2860, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 350.94403076171875, \"iteration\": 2861, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 282.28680419921875, \"iteration\": 2862, \"epoch\": 18}, {\"training_acc\": 0.9765625, \"training_loss\": 329.9150695800781, \"iteration\": 2863, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 324.2428283691406, \"iteration\": 2864, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 272.43756103515625, \"iteration\": 2865, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 256.1173095703125, \"iteration\": 2866, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 266.7061767578125, \"iteration\": 2867, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 334.7973327636719, \"iteration\": 2868, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 292.6578369140625, \"iteration\": 2869, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 297.8070068359375, \"iteration\": 2870, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 334.983642578125, \"iteration\": 2871, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 340.58538818359375, \"iteration\": 2872, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 340.306396484375, \"iteration\": 2873, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 303.1732482910156, \"iteration\": 2874, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 308.5760498046875, \"iteration\": 2875, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 345.57373046875, \"iteration\": 2876, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 319.152099609375, \"iteration\": 2877, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 324.47265625, \"iteration\": 2878, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 287.3390808105469, \"iteration\": 2879, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 324.5718078613281, \"iteration\": 2880, \"epoch\": 18}, {\"training_acc\": 0.9765625, \"training_loss\": 351.5700988769531, \"iteration\": 2881, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 282.215576171875, \"iteration\": 2882, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 241.71913146972656, \"iteration\": 2883, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 335.11175537109375, \"iteration\": 2884, \"epoch\": 18}, {\"training_acc\": 0.984375, \"training_loss\": 277.3995361328125, \"iteration\": 2885, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 329.57281494140625, \"iteration\": 2886, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 345.82080078125, \"iteration\": 2887, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 329.7480163574219, \"iteration\": 2888, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 334.998046875, \"iteration\": 2889, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 277.2588806152344, \"iteration\": 2890, \"epoch\": 18}, {\"training_acc\": 0.984375, \"training_loss\": 319.50164794921875, \"iteration\": 2891, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 271.693359375, \"iteration\": 2892, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 335.0227966308594, \"iteration\": 2893, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 351.1158752441406, \"iteration\": 2894, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 361.7604675292969, \"iteration\": 2895, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 287.3058776855469, \"iteration\": 2896, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 313.462158203125, \"iteration\": 2897, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 324.3597412109375, \"iteration\": 2898, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 277.0941162109375, \"iteration\": 2899, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 319.39837646484375, \"iteration\": 2900, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 308.41619873046875, \"iteration\": 2901, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 303.29248046875, \"iteration\": 2902, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 297.97747802734375, \"iteration\": 2903, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 324.6916198730469, \"iteration\": 2904, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 261.65740966796875, \"iteration\": 2905, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 361.85235595703125, \"iteration\": 2906, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 361.70062255859375, \"iteration\": 2907, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 308.5009765625, \"iteration\": 2908, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 329.7108154296875, \"iteration\": 2909, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 303.1752014160156, \"iteration\": 2910, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 303.13812255859375, \"iteration\": 2911, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 308.5860595703125, \"iteration\": 2912, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 261.4652099609375, \"iteration\": 2913, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 287.52984619140625, \"iteration\": 2914, \"epoch\": 18}, {\"training_acc\": 0.984375, \"training_loss\": 277.25830078125, \"iteration\": 2915, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 277.14959716796875, \"iteration\": 2916, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 340.44805908203125, \"iteration\": 2917, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 303.88983154296875, \"iteration\": 2918, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 297.779541015625, \"iteration\": 2919, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 313.492919921875, \"iteration\": 2920, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 350.798095703125, \"iteration\": 2921, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 334.904052734375, \"iteration\": 2922, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 272.115478515625, \"iteration\": 2923, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 335.373291015625, \"iteration\": 2924, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 303.2329406738281, \"iteration\": 2925, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 282.16119384765625, \"iteration\": 2926, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 297.9853210449219, \"iteration\": 2927, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 298.1131591796875, \"iteration\": 2928, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 292.64862060546875, \"iteration\": 2929, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 351.05560302734375, \"iteration\": 2930, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 287.4384765625, \"iteration\": 2931, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 345.62762451171875, \"iteration\": 2932, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 256.501953125, \"iteration\": 2933, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 235.7145233154297, \"iteration\": 2934, \"epoch\": 18}, {\"training_acc\": 0.984375, \"training_loss\": 282.370849609375, \"iteration\": 2935, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 329.59783935546875, \"iteration\": 2936, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 324.3815612792969, \"iteration\": 2937, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 282.481689453125, \"iteration\": 2938, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 251.20736694335938, \"iteration\": 2939, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 324.1875, \"iteration\": 2940, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 303.1279296875, \"iteration\": 2941, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 346.10211181640625, \"iteration\": 2942, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 256.294921875, \"iteration\": 2943, \"epoch\": 18}, {\"training_acc\": 0.984375, \"training_loss\": 308.8138427734375, \"iteration\": 2944, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 324.41436767578125, \"iteration\": 2945, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 330.1526794433594, \"iteration\": 2946, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 335.3038330078125, \"iteration\": 2947, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 308.76995849609375, \"iteration\": 2948, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 329.95947265625, \"iteration\": 2949, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 293.63458251953125, \"iteration\": 2950, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 261.4479675292969, \"iteration\": 2951, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 319.06744384765625, \"iteration\": 2952, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 324.4659729003906, \"iteration\": 2953, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 276.87969970703125, \"iteration\": 2954, \"epoch\": 18}, {\"training_acc\": 0.984375, \"training_loss\": 258.02581787109375, \"iteration\": 2955, \"epoch\": 18}, {\"training_acc\": 0.984375, \"training_loss\": 246.53289794921875, \"iteration\": 2956, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 351.2039794921875, \"iteration\": 2957, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 256.34661865234375, \"iteration\": 2958, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 271.8963623046875, \"iteration\": 2959, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 303.2704162597656, \"iteration\": 2960, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 356.47613525390625, \"iteration\": 2961, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 329.78057861328125, \"iteration\": 2962, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 319.1503601074219, \"iteration\": 2963, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 319.35345458984375, \"iteration\": 2964, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 329.6288757324219, \"iteration\": 2965, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 308.5970458984375, \"iteration\": 2966, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 298.0523986816406, \"iteration\": 2967, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 313.79510498046875, \"iteration\": 2968, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 266.61346435546875, \"iteration\": 2969, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 361.8331298828125, \"iteration\": 2970, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 313.7296142578125, \"iteration\": 2971, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 320.54296875, \"iteration\": 2972, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 319.261474609375, \"iteration\": 2973, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 335.15020751953125, \"iteration\": 2974, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 335.1981201171875, \"iteration\": 2975, \"epoch\": 18}, {\"training_acc\": 0.984375, \"training_loss\": 303.82421875, \"iteration\": 2976, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 236.35043334960938, \"iteration\": 2977, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 367.43536376953125, \"iteration\": 2978, \"epoch\": 18}, {\"training_acc\": 0.9765625, \"training_loss\": 341.2794189453125, \"iteration\": 2979, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 351.2999267578125, \"iteration\": 2980, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 303.3160095214844, \"iteration\": 2981, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 345.5535888671875, \"iteration\": 2982, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 350.86968994140625, \"iteration\": 2983, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 303.30029296875, \"iteration\": 2984, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 251.52880859375, \"iteration\": 2985, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 276.88311767578125, \"iteration\": 2986, \"epoch\": 18}, {\"training_acc\": 0.984375, \"training_loss\": 345.9129943847656, \"iteration\": 2987, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 297.7034912109375, \"iteration\": 2988, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 383.4721374511719, \"iteration\": 2989, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 308.1849060058594, \"iteration\": 2990, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 324.09295654296875, \"iteration\": 2991, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 292.4561767578125, \"iteration\": 2992, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 329.6999206542969, \"iteration\": 2993, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 378.0981140136719, \"iteration\": 2994, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 324.7451171875, \"iteration\": 2995, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 318.8277893066406, \"iteration\": 2996, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 266.44091796875, \"iteration\": 2997, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 303.0632629394531, \"iteration\": 2998, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 314.0546875, \"iteration\": 2999, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 324.6105041503906, \"iteration\": 3000, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 298.2076416015625, \"iteration\": 3001, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 303.24365234375, \"iteration\": 3002, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 303.3135986328125, \"iteration\": 3003, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 277.4721374511719, \"iteration\": 3004, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 256.4344482421875, \"iteration\": 3005, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 378.64215087890625, \"iteration\": 3006, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 292.8617248535156, \"iteration\": 3007, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 329.55157470703125, \"iteration\": 3008, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 256.2827453613281, \"iteration\": 3009, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 313.7294006347656, \"iteration\": 3010, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 292.9970703125, \"iteration\": 3011, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 292.81195068359375, \"iteration\": 3012, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 266.791748046875, \"iteration\": 3013, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 308.7290344238281, \"iteration\": 3014, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 282.57342529296875, \"iteration\": 3015, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 330.0993347167969, \"iteration\": 3016, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 266.7947998046875, \"iteration\": 3017, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 329.6947021484375, \"iteration\": 3018, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 356.5419921875, \"iteration\": 3019, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 318.871826171875, \"iteration\": 3020, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 282.48089599609375, \"iteration\": 3021, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 324.201416015625, \"iteration\": 3022, \"epoch\": 18}, {\"training_acc\": 0.9921875, \"training_loss\": 216.23057556152344, \"iteration\": 3023, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 97.744873046875, \"iteration\": 3024, \"epoch\": 18}, {\"training_acc\": 1.0, \"training_loss\": 340.41070556640625, \"iteration\": 3025, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 356.3121643066406, \"iteration\": 3026, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 313.58544921875, \"iteration\": 3027, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 271.77203369140625, \"iteration\": 3028, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 340.18939208984375, \"iteration\": 3029, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 308.97100830078125, \"iteration\": 3030, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 271.835205078125, \"iteration\": 3031, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 318.7708435058594, \"iteration\": 3032, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 266.46014404296875, \"iteration\": 3033, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 372.64776611328125, \"iteration\": 3034, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 319.0838928222656, \"iteration\": 3035, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 340.24505615234375, \"iteration\": 3036, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 313.6953125, \"iteration\": 3037, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 308.4240417480469, \"iteration\": 3038, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 282.1145324707031, \"iteration\": 3039, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 329.644287109375, \"iteration\": 3040, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 340.26080322265625, \"iteration\": 3041, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 266.52252197265625, \"iteration\": 3042, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 256.40679931640625, \"iteration\": 3043, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 287.28472900390625, \"iteration\": 3044, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 324.0343017578125, \"iteration\": 3045, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 261.36090087890625, \"iteration\": 3046, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 308.57037353515625, \"iteration\": 3047, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 334.9620361328125, \"iteration\": 3048, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 277.07525634765625, \"iteration\": 3049, \"epoch\": 19}, {\"training_acc\": 0.984375, \"training_loss\": 313.7751770019531, \"iteration\": 3050, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 266.50213623046875, \"iteration\": 3051, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 282.02001953125, \"iteration\": 3052, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 282.1225280761719, \"iteration\": 3053, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 334.752197265625, \"iteration\": 3054, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.44384765625, \"iteration\": 3055, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 361.80499267578125, \"iteration\": 3056, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 324.4932861328125, \"iteration\": 3057, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 361.717529296875, \"iteration\": 3058, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 266.52691650390625, \"iteration\": 3059, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 313.618408203125, \"iteration\": 3060, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 240.98251342773438, \"iteration\": 3061, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 329.42901611328125, \"iteration\": 3062, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 308.47491455078125, \"iteration\": 3063, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 287.61328125, \"iteration\": 3064, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 298.05767822265625, \"iteration\": 3065, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 324.18096923828125, \"iteration\": 3066, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 308.3302001953125, \"iteration\": 3067, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 329.5533752441406, \"iteration\": 3068, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 304.1665954589844, \"iteration\": 3069, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 350.75927734375, \"iteration\": 3070, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 297.9441223144531, \"iteration\": 3071, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 308.27166748046875, \"iteration\": 3072, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 271.64410400390625, \"iteration\": 3073, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 345.54278564453125, \"iteration\": 3074, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 324.25872802734375, \"iteration\": 3075, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 282.171142578125, \"iteration\": 3076, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 319.14959716796875, \"iteration\": 3077, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 308.35638427734375, \"iteration\": 3078, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 319.1275329589844, \"iteration\": 3079, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 313.5412292480469, \"iteration\": 3080, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 356.314697265625, \"iteration\": 3081, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 308.6057434082031, \"iteration\": 3082, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 356.4177551269531, \"iteration\": 3083, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 313.88531494140625, \"iteration\": 3084, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 271.7306823730469, \"iteration\": 3085, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 340.5855407714844, \"iteration\": 3086, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 313.8914794921875, \"iteration\": 3087, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 256.31048583984375, \"iteration\": 3088, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.7078857421875, \"iteration\": 3089, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 261.43426513671875, \"iteration\": 3090, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 318.66094970703125, \"iteration\": 3091, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 340.2187805175781, \"iteration\": 3092, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 282.1609802246094, \"iteration\": 3093, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 256.205810546875, \"iteration\": 3094, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 340.11029052734375, \"iteration\": 3095, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 324.2425537109375, \"iteration\": 3096, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 345.67083740234375, \"iteration\": 3097, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 251.14793395996094, \"iteration\": 3098, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 329.4754333496094, \"iteration\": 3099, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 282.12127685546875, \"iteration\": 3100, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 313.5791015625, \"iteration\": 3101, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 351.0191955566406, \"iteration\": 3102, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 271.6422119140625, \"iteration\": 3103, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.6375732421875, \"iteration\": 3104, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 308.49237060546875, \"iteration\": 3105, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 350.9605712890625, \"iteration\": 3106, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 304.12188720703125, \"iteration\": 3107, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 297.6966552734375, \"iteration\": 3108, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 319.1139221191406, \"iteration\": 3109, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 303.0855712890625, \"iteration\": 3110, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 251.27005004882812, \"iteration\": 3111, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.60247802734375, \"iteration\": 3112, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 313.55706787109375, \"iteration\": 3113, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 329.42767333984375, \"iteration\": 3114, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 329.4831237792969, \"iteration\": 3115, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 266.43426513671875, \"iteration\": 3116, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 302.8443603515625, \"iteration\": 3117, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 297.86370849609375, \"iteration\": 3118, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 287.36767578125, \"iteration\": 3119, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.475830078125, \"iteration\": 3120, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 297.6595153808594, \"iteration\": 3121, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 282.1654357910156, \"iteration\": 3122, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 309.00872802734375, \"iteration\": 3123, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 318.9385986328125, \"iteration\": 3124, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 350.805419921875, \"iteration\": 3125, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 281.90179443359375, \"iteration\": 3126, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.5613098144531, \"iteration\": 3127, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 251.25885009765625, \"iteration\": 3128, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.6797180175781, \"iteration\": 3129, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 324.0138244628906, \"iteration\": 3130, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 329.4365234375, \"iteration\": 3131, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 277.1431884765625, \"iteration\": 3132, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 308.17388916015625, \"iteration\": 3133, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 303.0218811035156, \"iteration\": 3134, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 313.6434326171875, \"iteration\": 3135, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 303.02191162109375, \"iteration\": 3136, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 356.35247802734375, \"iteration\": 3137, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 361.7403259277344, \"iteration\": 3138, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 356.2572021484375, \"iteration\": 3139, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 277.49676513671875, \"iteration\": 3140, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 324.09881591796875, \"iteration\": 3141, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 282.0863037109375, \"iteration\": 3142, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 282.14007568359375, \"iteration\": 3143, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 314.62506103515625, \"iteration\": 3144, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 367.14154052734375, \"iteration\": 3145, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 324.1839599609375, \"iteration\": 3146, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 256.4667053222656, \"iteration\": 3147, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 351.54180908203125, \"iteration\": 3148, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 335.11517333984375, \"iteration\": 3149, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 277.3330078125, \"iteration\": 3150, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 313.9534606933594, \"iteration\": 3151, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 282.87432861328125, \"iteration\": 3152, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 297.90142822265625, \"iteration\": 3153, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 329.74652099609375, \"iteration\": 3154, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 287.59112548828125, \"iteration\": 3155, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 335.2440185546875, \"iteration\": 3156, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 319.04864501953125, \"iteration\": 3157, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 357.04522705078125, \"iteration\": 3158, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 303.155029296875, \"iteration\": 3159, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 292.7118835449219, \"iteration\": 3160, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 318.8663330078125, \"iteration\": 3161, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 345.47613525390625, \"iteration\": 3162, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 318.9012756347656, \"iteration\": 3163, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 334.83648681640625, \"iteration\": 3164, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 356.3573913574219, \"iteration\": 3165, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.7960205078125, \"iteration\": 3166, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 287.46026611328125, \"iteration\": 3167, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 318.98175048828125, \"iteration\": 3168, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 313.77313232421875, \"iteration\": 3169, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 330.1363525390625, \"iteration\": 3170, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 335.269775390625, \"iteration\": 3171, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 261.51629638671875, \"iteration\": 3172, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 297.846923828125, \"iteration\": 3173, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 287.92584228515625, \"iteration\": 3174, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.70306396484375, \"iteration\": 3175, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 308.4103698730469, \"iteration\": 3176, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 303.2212829589844, \"iteration\": 3177, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.5311584472656, \"iteration\": 3178, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 356.4304504394531, \"iteration\": 3179, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 282.222900390625, \"iteration\": 3180, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 329.630126953125, \"iteration\": 3181, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 292.66168212890625, \"iteration\": 3182, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 345.7806396484375, \"iteration\": 3183, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 256.0526123046875, \"iteration\": 3184, \"epoch\": 19}, {\"training_acc\": 0.9921875, \"training_loss\": 351.09442138671875, \"iteration\": 3185, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 350.9010009765625, \"iteration\": 3186, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 297.970458984375, \"iteration\": 3187, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 282.0546875, \"iteration\": 3188, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 266.5382080078125, \"iteration\": 3189, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 383.3309631347656, \"iteration\": 3190, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 287.20880126953125, \"iteration\": 3191, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 68.06219482421875, \"iteration\": 3192, \"epoch\": 19}, {\"training_acc\": 1.0, \"training_loss\": 318.8521728515625, \"iteration\": 3193, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.6148376464844, \"iteration\": 3194, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.389404296875, \"iteration\": 3195, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 302.94903564453125, \"iteration\": 3196, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 308.28460693359375, \"iteration\": 3197, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 281.90362548828125, \"iteration\": 3198, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 330.00665283203125, \"iteration\": 3199, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.6427917480469, \"iteration\": 3200, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 308.2161560058594, \"iteration\": 3201, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.3399963378906, \"iteration\": 3202, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.3999328613281, \"iteration\": 3203, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 351.55108642578125, \"iteration\": 3204, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 266.47393798828125, \"iteration\": 3205, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.46588134765625, \"iteration\": 3206, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 324.2514343261719, \"iteration\": 3207, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 287.1935729980469, \"iteration\": 3208, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 350.82421875, \"iteration\": 3209, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 308.23095703125, \"iteration\": 3210, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 340.03179931640625, \"iteration\": 3211, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 340.22332763671875, \"iteration\": 3212, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 266.460205078125, \"iteration\": 3213, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.613525390625, \"iteration\": 3214, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 303.0359191894531, \"iteration\": 3215, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.13671875, \"iteration\": 3216, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 356.2261657714844, \"iteration\": 3217, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 277.008056640625, \"iteration\": 3218, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 361.59478759765625, \"iteration\": 3219, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.7611999511719, \"iteration\": 3220, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.5981750488281, \"iteration\": 3221, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.50921630859375, \"iteration\": 3222, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.5267333984375, \"iteration\": 3223, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.33660888671875, \"iteration\": 3224, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 276.75323486328125, \"iteration\": 3225, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.0430603027344, \"iteration\": 3226, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.4920349121094, \"iteration\": 3227, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 399.8132019042969, \"iteration\": 3228, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.30377197265625, \"iteration\": 3229, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 345.58953857421875, \"iteration\": 3230, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.32568359375, \"iteration\": 3231, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 266.6057434082031, \"iteration\": 3232, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 267.1140441894531, \"iteration\": 3233, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.17803955078125, \"iteration\": 3234, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.27911376953125, \"iteration\": 3235, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.2843017578125, \"iteration\": 3236, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 277.05657958984375, \"iteration\": 3237, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.73272705078125, \"iteration\": 3238, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.70074462890625, \"iteration\": 3239, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.5336608886719, \"iteration\": 3240, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 276.78125, \"iteration\": 3241, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 287.59197998046875, \"iteration\": 3242, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 287.201416015625, \"iteration\": 3243, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 256.189453125, \"iteration\": 3244, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.4759521484375, \"iteration\": 3245, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 302.99298095703125, \"iteration\": 3246, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 308.2797546386719, \"iteration\": 3247, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 345.5205383300781, \"iteration\": 3248, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.5099182128906, \"iteration\": 3249, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 340.10089111328125, \"iteration\": 3250, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 308.0986328125, \"iteration\": 3251, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 276.8999938964844, \"iteration\": 3252, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 329.5376281738281, \"iteration\": 3253, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 235.9095458984375, \"iteration\": 3254, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 308.206298828125, \"iteration\": 3255, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 366.9820556640625, \"iteration\": 3256, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 271.65985107421875, \"iteration\": 3257, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.54241943359375, \"iteration\": 3258, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.519287109375, \"iteration\": 3259, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 319.1468811035156, \"iteration\": 3260, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.9154052734375, \"iteration\": 3261, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 345.463623046875, \"iteration\": 3262, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.327880859375, \"iteration\": 3263, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 256.13079833984375, \"iteration\": 3264, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.481201171875, \"iteration\": 3265, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.49200439453125, \"iteration\": 3266, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.22918701171875, \"iteration\": 3267, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 266.4547119140625, \"iteration\": 3268, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 313.822998046875, \"iteration\": 3269, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 350.8441162109375, \"iteration\": 3270, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.0397033691406, \"iteration\": 3271, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.5498046875, \"iteration\": 3272, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 303.6642150878906, \"iteration\": 3273, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 261.228271484375, \"iteration\": 3274, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.51239013671875, \"iteration\": 3275, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 318.7729187011719, \"iteration\": 3276, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 361.53350830078125, \"iteration\": 3277, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 303.145263671875, \"iteration\": 3278, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.78924560546875, \"iteration\": 3279, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.7617492675781, \"iteration\": 3280, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 276.9541931152344, \"iteration\": 3281, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 281.91790771484375, \"iteration\": 3282, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.1301574707031, \"iteration\": 3283, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.7099609375, \"iteration\": 3284, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.15185546875, \"iteration\": 3285, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 356.2109375, \"iteration\": 3286, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 318.7153015136719, \"iteration\": 3287, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.2082214355469, \"iteration\": 3288, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 356.1629333496094, \"iteration\": 3289, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.10003662109375, \"iteration\": 3290, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 276.859130859375, \"iteration\": 3291, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 271.68377685546875, \"iteration\": 3292, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 399.70660400390625, \"iteration\": 3293, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.2887268066406, \"iteration\": 3294, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 282.00946044921875, \"iteration\": 3295, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 281.9287414550781, \"iteration\": 3296, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.6292724609375, \"iteration\": 3297, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.4664611816406, \"iteration\": 3298, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 261.3638916015625, \"iteration\": 3299, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 340.0079650878906, \"iteration\": 3300, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 247.18734741210938, \"iteration\": 3301, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.3460693359375, \"iteration\": 3302, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 308.155029296875, \"iteration\": 3303, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 276.8663330078125, \"iteration\": 3304, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 345.4725036621094, \"iteration\": 3305, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 340.10205078125, \"iteration\": 3306, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 287.37774658203125, \"iteration\": 3307, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 256.23468017578125, \"iteration\": 3308, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 334.8163757324219, \"iteration\": 3309, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.61737060546875, \"iteration\": 3310, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 313.6121826171875, \"iteration\": 3311, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 271.95330810546875, \"iteration\": 3312, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 318.896484375, \"iteration\": 3313, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 335.0559387207031, \"iteration\": 3314, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 303.0155029296875, \"iteration\": 3315, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.63995361328125, \"iteration\": 3316, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.63983154296875, \"iteration\": 3317, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.65972900390625, \"iteration\": 3318, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 345.50341796875, \"iteration\": 3319, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 345.4903564453125, \"iteration\": 3320, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.4897155761719, \"iteration\": 3321, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 318.99212646484375, \"iteration\": 3322, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 303.033447265625, \"iteration\": 3323, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.5792236328125, \"iteration\": 3324, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 308.3944091796875, \"iteration\": 3325, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 340.0715026855469, \"iteration\": 3326, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 324.3121643066406, \"iteration\": 3327, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.60528564453125, \"iteration\": 3328, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 334.8419189453125, \"iteration\": 3329, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 271.56396484375, \"iteration\": 3330, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 303.0386962890625, \"iteration\": 3331, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.403564453125, \"iteration\": 3332, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 251.21112060546875, \"iteration\": 3333, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 308.2269287109375, \"iteration\": 3334, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.47613525390625, \"iteration\": 3335, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 261.2998046875, \"iteration\": 3336, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.625732421875, \"iteration\": 3337, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 251.0867919921875, \"iteration\": 3338, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 319.02423095703125, \"iteration\": 3339, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 308.1334228515625, \"iteration\": 3340, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 351.0407409667969, \"iteration\": 3341, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 267.008056640625, \"iteration\": 3342, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 302.99041748046875, \"iteration\": 3343, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.4897766113281, \"iteration\": 3344, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 351.02886962890625, \"iteration\": 3345, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 319.02923583984375, \"iteration\": 3346, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 318.8937683105469, \"iteration\": 3347, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 287.2767333984375, \"iteration\": 3348, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 282.12603759765625, \"iteration\": 3349, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 372.6417236328125, \"iteration\": 3350, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 313.4122009277344, \"iteration\": 3351, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 329.4227294921875, \"iteration\": 3352, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 261.35540771484375, \"iteration\": 3353, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 287.0571594238281, \"iteration\": 3354, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 297.70489501953125, \"iteration\": 3355, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 256.25469970703125, \"iteration\": 3356, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 276.84686279296875, \"iteration\": 3357, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 292.41668701171875, \"iteration\": 3358, \"epoch\": 20}, {\"training_acc\": 0.9921875, \"training_loss\": 335.20745849609375, \"iteration\": 3359, \"epoch\": 20}, {\"training_acc\": 1.0, \"training_loss\": 80.52240753173828, \"iteration\": 3360, \"epoch\": 20}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training accuracy and loss side-by-side\n",
    "plot_results(model_nn, train_config, train_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power-identification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
